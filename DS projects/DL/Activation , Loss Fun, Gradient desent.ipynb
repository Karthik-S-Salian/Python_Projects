{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74f39a8",
   "metadata": {},
   "source": [
    "# ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51f1d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as  plt\n",
    "import numpy as np\n",
    "from math import exp\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a486e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testlist=np.arange(-10,10,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e31484",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=len(testlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ed1beb",
   "metadata": {},
   "source": [
    "### Step Function\n",
    "\n",
    "Function based on condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53dfe31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    if x<0:\n",
    "        return  -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f769ceac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testlist,[0]*l,linestyle='dashed')\n",
    "plt.plot([0]*l,[step(x) for x in testlist],linestyle='dashed')\n",
    "plt.plot(testlist,[step(x) for x in testlist],linewidth=5)\n",
    "plt.title('Step Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11250375",
   "metadata": {},
   "source": [
    "### Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbfec3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 +  exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1611d463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testlist,[0]*l,linestyle='dashed')\n",
    "plt.plot([0]*l,[sigmoid(x) for x in testlist],linestyle='dashed')\n",
    "plt.plot(testlist,[sigmoid(x) for x in testlist],linewidth=5)\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0212d2ee",
   "metadata": {},
   "source": [
    "## tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d66a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (exp(x)-exp(-x))/(exp(x)+exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "920245bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAn+klEQVR4nO3deZwcdZ3/8ddnLnLfk2SSEHIQIkkkAcYElEVYgoQsGEREUBFxNboPcVdXf4qLi+iyiqy7KCuCwWXBi0tAAwYQsiAoAplAgBzkTsgwk2RynySZmc/vj65gT1fNTE+6+kq/n1CP7v58v1X16ZpJf+ZbVV1l7o6IiJSusnwnICIi+aVCICJS4lQIRERKnAqBiEiJUyEQESlxKgQiIiVOhUBKmpm5mR2f7zzSZWZLzOysfOchRxcVAikqZrbOzKbnad3Xm9khM9uTNH0ti+u7y8xuSI65+0R3fyZb65TSVJHvBESKzH3u/ol8JyESJ40IpGiY2S+AkcAjyX+Nm9kDZrbRzHaa2bNmNjFpnrvM7FYz+72Z7TazF81sbMqip5vZSjPbHvS1LuZ1vZn9Mun1qGCXU0Xw+hkz+zcz+3OQwx/MbFBS/zPM7Hkz22FmG8zsU2Y2G/g48LXgvT4S9H1nRGRmx5jZD82sIZh+aGbHBG1nmVm9mX3FzDabWaOZXdWV9yWlQ4VAioa7XwG8CVzo7r3c/aag6TFgHDAYeBn4VcqslwPfBvoDq4B/T2m/AHgPMBm4FDgvC+l/DLgqyLEK+CqAmY0M8v9voBqYAixy9znB+7gpeK8XRizzWuC0YJ7JwFTgm0ntQ4G+wHDg74Fbzax/3G9Mip8KgRQ9d7/T3Xe7+wHgemCymfVN6vKQu7/k7s0kPlynpCziRnff4e5vAk9HtCe7NPjL/fA0LM00/9fdV7j7fuD+pHV8HHjK3e9x90PuvtXdF6W5zI8D33H3ze7eRKLYXZHUfihoP+Tu84A9wPg0ly0lRIVAipqZlZvZjWa22sx2AeuCpkFJ3TYmPd8H9EpZTGftye53935JU0Oaqba3jmOB1WkuI9UwYH3S6/VB7LCtQfGLWq/IO1QIpNikXi73Y8AsYDqJ3SCjgniX9vNnaC/QI+n10C7MuwFIPWZxWGeXBm4Ajkt6PTKIiXSJCoEUm03AmKTXvYEDwFYSH8bfzUNOi4AzzWxksEvqG12Y91ckDlZfamYVZjbQzKYEbanvNdU9wDfNrDo4+Hwd8MsO+otEUiGQYvM9Eh9+O8zsq8DPSewSeQtYCryQ64Tc/UngPuA1YCHwaBfmfROYCXwF2EaiqEwOmv8HmBC8199GzH4DUBes93USB8pviOgn0iHTjWlEREqbRgQiIiVOhUBEpMSpEIiIlDgVAhGREleUF50bNGiQjxo1Kt9piIgUlYULF25x9+rUeFEWglGjRlFXV5fvNEREioqZrY+Ka9eQiEiJUyEQESlxKgQiIiVOhUBEpMSpEIiIlLhYzhoysztJ3OVps7tPimg34EckLq61D/iUu78ctM0I2sqBn7n7jXHkJCKZa2ltodmbOdRyiObWZpq9mebWZg61Hnrn0d1x/K+POIn/28YOX9esTTx4BCjU6555p1cDz4/aIbWUl5XHsqy4Th+9C/gxiStBRjmfxK0ExwHTgNuAaWZWDtwKnAvUAwvMbK67L40pLxEJtLS20LCngca9jWzat4lN+zaxed9mtuzfwt5De9+Z9hzaw96De9nbvJdWb8132tKOuk/UUU4BFQJ3f9bMRnXQZRbwc0+U/BfMrJ+Z1ZC4icgqd18DYGb3Bn1VCEQy4O7U76nnpcaXeHnzy6zcvpI1O9dwoOVAvlOTApSrL5QNJ3EnpsPqg1hUfFrUAsxsNjAbYOTIkdnJUqTIrdi+gt+u+i3z18+nYa9uVibpyVUhiLptoHcQDwfd5wBzAGprawtzp53I6qcTj2PPztkqD7UcYu7qudy3/D6WbVuWs/XK0SNXhaCexE26DxtB4t6qVe3ERYrTsz9IPOagELg7j697nB+9/CPe2vNW1tZTWVZJRVkFFWUV7zx/J2YVlJWVYYf/s8Qj8M7zNnGj476Wy1tNp89yegvs9JTFeNJnrgrBXODq4BjANGCnuzeaWRMwzsxGk7jV4GUkbkYuIh3YuHcj1/35Ov7S+Jcuzde7qjej+45mSI8hDOkxhME9BlPdo5q+VX3pWdmTnpU96VXVi54ViecVZRUF++Es8Ynr9NF7gLOAQWZWD3wLqARw99uBeSROHV1F4vTRq4K2ZjO7GniCxOmjd7r7kjhyEjla/emtP/GN577BjgM7OuxXbuVMHDSRaUOncfLgkxk/YDzV3av1wS4hcZ01dHkn7Q58oZ22eSQKhYh04oEVD3DDCzd0eFrnpIGTuOj4i5gxegZ9j+mbw+ykWBXlZahFStHdS+7mB3U/aLf9jOFncPWUq5k4aGIOs5KjgQqBSJwu/GFWFvvgigfbLQKDuw/mX0//V8469qysrFuOfioEInEaNC72Rb7Q+ALfeeE7kW2n1ZzG98/8PgO6DYh9vVI6dNE5kTgtfywxxWTj3o187Y9fizwmcOGYC/nJ9J+oCEjGNCIQidPzP048jj8/40W1eivXPHcN2w9sD7XNHD2TG864gTLT33KSOf0WiRSo+5ffz8JNC0Px9wx9j4qAxEq/SSIFaOPejdy88OZQfHCPwdx05k1UllXmISs5WqkQiBSgW16+hX3N+0Lxfz/j3xnUfVAeMpKjmQqBSIFZunUpj655NBS/5IRLOK3mtDxkJEc7HSwWidPFP814ET9c+MPQXbH6H9OfL5/65YyXLRJFhUAkTn1HZDT74i2LIy8k97nJn6NPVZ+Mli3SHu0aEonT4gcT0xG6c/GdodjI3iO59IRLM8lKpEMaEYjEaUHwQT7pw12edd3OdTy1/qlQ/DPv/gyV5TpLSLJHIwKRAnHPG/eEjg0M7jGYC8ZckKeMpFSoEIgUgP3N+3lkzSOh+CcnfFKjAck6FQKRAvDk+ifZfXB3m1i38m5cPO7iPGUkpSSWQmBmM8xsuZmtMrNrItr/n5ktCqbFZtZiZgOCtnVm9nrQVhdHPiLF5jcrfhOKzRg9g95VvfOQjZSajA8Wm1k5cCtwLomb1C8ws7nuvvRwH3f/D+A/gv4XAl92921Jiznb3bdkmotI3l368y7PsmHXBl7Z/EoofskJl8SRkUin4hgRTAVWufsadz8I3AvM6qD/5cA9MaxXpPD0HJiYuuCJ9U+EYsf3O56TBp0UV1YiHYqjEAwHNiS9rg9iIWbWA5gBJJ9o7cAfzGyhmc1ubyVmNtvM6sysrqmpKYa0RbLglV8lpi54bG34/gV/N+bvdJN5yZk4CkHUb6tHxAAuBP6cslvofe5+CnA+8AUzOzNqRnef4+617l5bXV2dWcYi2bLo14kpTWt2rGHF9hWh+HmjzoszK5EOxVEI6oFjk16PABra6XsZKbuF3L0heNwMPExiV5NISXhiXXi30KSBkzi297ERvUWyI45CsAAYZ2ajzayKxIf93NROZtYXeD/wu6RYTzPrffg58AFgcQw5iRSFZ+qfCcVmjJ6R+0SkpGV81pC7N5vZ1cATQDlwp7svMbPPB+23B10/BPzB3fcmzT4EeDjYF1oB/NrdH880J5Fi0LSviaVbl4bi54w8Jw/ZSCmL5VpD7j4PmJcSuz3l9V3AXSmxNcDkOHIQKTbPvfVcKHZ8v+MZ0TuzK5iKdJUuOicSp48/kHbXP274Yyh25ojIcyVEskqFQCROVT3S6naw5WDkfQfeP+L9cWck0ilda0gkTi/dkZg68WrTq+xv3t8m1veYvpxUrS+RSe6pEIjEaclvE1MnXmx8MRQ7reY0Kso0SJfcUyEQyYOXNr4Uik2rmZaHTERUCERybt+hfbze9HooPm2oCoHkhwqBSI4t3LSQZm9uE6vpWaNvE0veqBCI5FjUbqGpQ6fqInOSNzoyJRKnq37faZeFmxaGYlNrdIktyR+NCERyaH/zfpZtXRaK1w6pzUM2IgkqBCJx+vMtiakdS7YsCR0fGNxjMDU9a7KdmUi7VAhE4rTiicTUjkVNi0KxkwefrOMDklcqBCI5FHVv4pMHn5yHTET+SoVAJEdavZVFmxeF4lOqp+Q8F5FkKgQiObJu5zp2HdzVJta9ojsnDDghTxmJJOj0UZE4VXZrt2nx1vDN9yYNmkRlWWU2MxLpVCwjAjObYWbLzWyVmV0T0X6Wme00s0XBdF2684oUlU88mJgiLN4SXQhE8i3jEYGZlQO3AueSuJH9AjOb6+6p9+B7zt0vOMJ5RYreki1LQrFJA1UIJP/iGBFMBVa5+xp3PwjcC8zKwbwiheePNyWmFIdaDvHGtjdCcY0IpBDEUQiGAxuSXtcHsVSnm9mrZvaYmU3s4ryY2WwzqzOzuqamphjSFsmCNX9MTClW7ljJwdaDbWIDug3QF8mkIMRRCKK+CeMpr18GjnP3ycB/A7/twryJoPscd69199rq6uojzVUkL5ZsDe8Wmjhwor5IJgUhjkJQDyRfP3cE0JDcwd13ufue4Pk8oNLMBqUzr8jRIPL4gHYLSYGIoxAsAMaZ2WgzqwIuA+YmdzCzoRb86WNmU4P1bk1nXpGjwbJt4QvNqRBIocj4rCF3bzazq4EngHLgTndfYmafD9pvBy4B/sHMmoH9wGXu7kDkvJnmJJI3PfqHQs2tzazavioUf9eAd+UiI5FOxfKFsmB3z7yU2O1Jz38M/DjdeUWK1kd/GQq9uevN0IHifsf0o7q7jnVJYdAlJkSybMX2FaHY+P7jdaBYCoYKgUicnro+MSVZvn15qNu4/uNyk49IGnStIZE4bVgQCkWNCE7orwvNSeHQiEAky5ZvC48Ixg8Yn4dMRKKpEIhk0c4DO9m0b1ObWJmVMbbf2DxlJBKmQiCSRVG7hUb1GcUx5cfkIRuRaDpGIBKnPsPavGzvjCGRQqJCIBKnD9/R5mXkgWLdkUwKjHYNiWRR1IFinTEkhUaFQCROj12TmICW1hZW7QhfWkKFQAqNdg2JxGnj6+88fXP3mxxoOdCmuU9VH4b0GJLrrEQ6pBGBSJZEfaN4/ABdWkIKjwqBSJas2KZvFEtxUCEQyZKV21eGYioEUoh0jEAkTgP/+o1hHSiWYhFLITCzGcCPSNxc5mfufmNK+8eBrwcv9wD/4O6vBm3rgN1AC9Ds7rVx5CSSFx+8BYC3m9/mrT1vhZrH9B2T64xEOpVxITCzcuBW4FwS9yBeYGZz3X1pUre1wPvdfbuZnQ/MAaYltZ/t7lsyzUWkUKzftR7H28SG9hxKj8oeecpIpH1xjAimAqvcfQ2Amd0LzALeKQTu/nxS/xdI3KRe5Ogz9x8BWPvumaGm0X1G5zobkbTEcbB4OLAh6XV9EGvP3wOPJb124A9mttDMZrc3k5nNNrM6M6tramrKKGGRrNm6GrauZu3OtaGmMf20W0gKUxwjgqiToj0ihpmdTaIQnJEUfp+7N5jZYOBJM3vD3Z8NLdB9DoldStTW1kYuX6RQrNm5JhTTiEAKVRwjgnrg2KTXI4CG1E5mdhLwM2CWu289HHf3huBxM/AwiV1NIkVNIwIpJnEUggXAODMbbWZVwGXA3OQOZjYSeAi4wt1XJMV7mlnvw8+BDwCLY8hJJG9acNbtWheKj+6rEYEUpox3Dbl7s5ldDTxB4vTRO919iZl9Pmi/HbgOGAj8JPh6/eHTRIcADwexCuDX7v54pjmJ5M3Qd9PYso8DWze0Cfeu6s3AbgPzlJRIx2L5HoG7zwPmpcRuT3r+GeAzEfOtASbHkYNIQTj/RtbUPwvzn24THtN3jK4xJAVLl5gQiVnU8QHtFpJCpktMiMTpwc+y9u3wGUP6RrEUMhUCkTjtamCN7QydVK0RgRQy7RoSidlaDoViGhFIIVMhEInRNlrYYa1tYpVllQzrNSxPGYl0ToVAJEZRo4Hj+hxHRZn2wkrhUiEQidGaAeHLbOn4gBQ6FQKRGK0dNikU0/EBKXQqBCIxirzYnEYEUuBUCERitK5hQSimEYEUOhUCkZjsb95PQ+vBUPy4PsflIRuR9KkQiMRk/a71eMoXyYb1HKbbU0rBUyEQicmaHRHHB/rp+IAUPhUCkZis3RVxsTndlUyKgAqBSEyiRgS6K5kUAxUCkZhoRCDFKpZCYGYzzGy5ma0ys2si2s3MbgnaXzOzU9KdV6QYtLS2sH7n+lBcIwIpBhkXAjMrB24FzgcmAJeb2YSUbucD44JpNnBbF+YVKXhv7XmLgymnjvY9pi/9j+mfp4xE0hfHlbCmAquC205iZvcCs4ClSX1mAT93dwdeMLN+ZlYDjEpj3lh99Kd/CcUuOKmGK04fxf6DLXzqf18KtV9y6gg+Unss2/Ye5B9+uTDU/onTjuPCycNo2LGfL9+3KNT+2b8Zw/QJQ1jdtId/eej1UPsX/3YcZ4wbxJKGnXznkfBb/9qM8Zx63AAWrt/GTY8vD7Vfd+EEJg7ry59WbuG//29lqP27F7+bsdW9eGrpJu54Lrwf++aPTmFYv+488moDv3wh/FftbZ84lQE9q3igbgO/WVgfar/rqql0ryrnF39Zx6OvNYba7/vc6QDMeXY185dtbtPWrbKcuz89FYBb5q/kz6u2tGnv36OK2684FYDvP/4GL6/f3qa9pm83fnjZyQB8+5ElLG3Y1aZ9THVPvnfxSQB846HXWNO0t037hGF9+NaFEwH40r2v0Ljz7TbtpxzXn6/PeBcAn//FQrbva/th/77jB/GP54yLvCvZwf2DuOO5Ncw+cyyg3z397sXzu3f4PcUpjl1Dw4HkO3XXB7F0+qQzLwBmNtvM6sysrqmpKeOkReIUdWmJY1pr8pCJSNdZ4o/0DBZg9hHgvOAG9ZjZFcBUd/9iUp/fA99z9z8Fr+cDXwPGdDZvlNraWq+rq8sob5E4Xffn63h41cNtYl+t/SpXTrwyTxmJhJnZQnevTY3HsWuoHjg26fUIoCHNPlVpzCtS8HSxOSlmcewaWgCMM7PRZlYFXAbMTekzF/hkcPbQacBOd29Mc16RgubukccIVAikWGQ8InD3ZjO7GngCKAfudPclZvb5oP12YB4wE1gF7AOu6mjeTHMSyaWtb29l18G2BwqryqoY1lO3p5TiEMv989x9HokP++TY7UnPHfhCuvOKFJOo0cCovqMoLyvPQzYiXadvFotkSLuFpNipEIhkKKoQ6GY0UkxUCEQypDOGpNipEIhkSCMCKXYqBCIZ2HdoH417217awFy3p5TiokIgkoF1u9aFYsOq+tCtolvukxE5QioEIhmIOj4wZvDkPGQicuRUCEQyEHnqaK9jI3qKFC4VApEMRB4oXvZ4HjIROXIqBCIZiBwRxPOFfZGcUSEQOULNrc2RB4vHUJn7ZEQyoEIgcoTqd9fT3NrcJtbfy+iHrjEkxUWFQOQIRe8W0mhAio92ZoocodU7V4diowe+C0acn4dsRI6cCoHIEVq9I1wIxo49DyZ8PA/ZiBw57RoSOUJRheD4boNh79Y8ZCNy5DIqBGY2wMyeNLOVwWP/iD7HmtnTZrbMzJaY2T8ltV1vZm+Z2aJgmplJPiK50tLaEvmt4uP/eDPc/8k8ZCRy5DIdEVwDzHf3ccD84HWqZuAr7n4icBrwBTObkNR+s7tPCSbdqUyKQv2eeg60HGgT61PVh0EaZEsRyvS3dhZwd/D8buCi1A7u3ujuLwfPdwPLgOEZrlckr1ZtXxWKHd/veAzLQzYimcm0EAxx90ZIfOADgzvqbGajgJOBF5PCV5vZa2Z2Z9SupaR5Z5tZnZnVNTU1ZZi2SGZW7YguBCLFqNNCYGZPmdniiGlWV1ZkZr2AB4EvufuuIHwbMBaYAjQC/9ne/O4+x91r3b22urq6K6sWiV1kIeivQiDFqdPTR919enttZrbJzGrcvdHMaoDN7fSrJFEEfuXuDyUte1NSnzuAR7uSvEi+tDsieM+n85CNSGYy/R7BXOBK4Mbg8XepHczMgP8Blrn7f6W01RzetQR8CFicYT4iWXeo9VDkNYbG9hsLQ9+T+4REMpTpMYIbgXPNbCVwbvAaMxtmZofPAHofcAXwtxGnid5kZq+b2WvA2cCXM8xHJOve3PVm6BpDA7oNYEC3AbCzPjGJFJGMRgTuvhU4JyLeAMwMnv8Jok+lcPcrMlm/SD50eKD4oc8lHq/6fQ4zEsmMTnoW6SKdMSRHGxUCkS6KvMZQv7F5yEQkHioEIl0UNSIY139cHjIRiYcKgUgXHGw5yJu73gzFNSKQYqbLUIt0wdqda2nxljaxwd0H06eqT+LFe6/OQ1YimVEhEOmCTr9RPF43pZHio11DIl2wcvvKUKzNbqEtKxOTSBHRiECkC97Y/kYoNq5f0oHiR76UeNT3CKSIaEQg0gXLty0PxU4ceGIeMhGJjwqBSJq27N/Clv1b2sQqyioY21dnDElxUyEQSVPUaGBs37FUllfmIRuR+KgQiKTpjW3h4wPjB4zPQyYi8dLBYpE0RR4fGJByfODMr+YoG5H4qBCIpGnZtmWhWGhEMPbsHGUjEh/tGhJJw75D+1i/a30oHioEja8lJpEiklEhMLMBZvakma0MHiNvPm9m64Ib0Cwys7quzi+Sb0u3LsXxNrHhvYb/9dIShz3+jcQkUkQyHRFcA8x393HA/OB1e8529ynuXnuE84vkzZKtS0KxSYMm5SETkfhlWghmAXcHz+8GLsrx/CI5sXhL+HbakwaqEMjRIdNCMOTwzeeDx8Ht9HPgD2a20MxmH8H8mNlsM6szs7qmpqYM0xbpmqhCMHHQxDxkIhK/Ts8aMrOngKERTdd2YT3vc/cGMxsMPGlmb7j7s12YH3efA8wBqK2t9U66i8Rm54Gd1O9pe0N6w5gwcEKeMhKJV6eFwN2nt9dmZpvMrMbdG82sBtjczjIagsfNZvYwMBV4FkhrfpF8WrIlfHxgTN8x9KzsGe58znU5yEgkXpnuGpoLXBk8vxL4XWoHM+tpZr0PPwc+ACxOd36RfFu8tQu7hUZOS0wiRSTTQnAjcK6ZrQTODV5jZsPMbF7QZwjwJzN7FXgJ+L27P97R/CKFZNHmRaFYu2cMvfliYhIpIhl9s9jdtwLnRMQbgJnB8zXA5K7ML1IoWr2VRU2LQvEp1VOiZ5j/ncSj7kcgRUTfLBbpwJoda9h9cHebWPeK7ozrP66dOUSKjwqBSAdeaXolFDup+iQqynSZLjl6qBCIdCDq+MDJg0/OfSIiWaRCINKBVzaHRwQnV6sQyNFF41uRdjTta2LD7g1tYmVWxknVJ7U/04zvZTkrkfipEIi048WN4dNAT+h/Ar2qerU/U00HRUKkQGnXkEg7Xmp8KRSbOnRqxzOtfjoxiRQRjQhEIrg7LzaGRwTTajr51vCzP0g86k5lUkQ0IhCJUL+nnoa9DW1i5VbOKYNPyVNGItmjQiASIWo0MGnQpI6PD4gUKRUCkQjPNzwfinV6fECkSKkQiKQ41HIoshCcPuz0PGQjkn06WCySYuHmhew9tLdNrHdlb6YMntL5zBf+MCs5iWSTCoFIimfrwzfPe+/w91JZVtn5zIN0MTopPto1JJIiqhC8f8T705t5+WOJSaSIaEQgkmT1jtWs37W+Tcwwzhh+RnoLeP7Hicfx58ecmUj2ZDQiMLMBZvakma0MHvtH9BlvZouSpl1m9qWg7XozeyupbWYm+Yhk6rG14b/mJ1dPpn+30K+2yFEj011D1wDz3X0cMD943Ya7L3f3Ke4+BTgV2Ac8nNTl5sPt7j4vdX6RXHF3nlj3RCh+3qjz8pCNSO5kWghmAXcHz+8GLuqk/znAandf30k/kZx7Y9sbrNu1rk3MMD4w6gP5SUgkRzItBEPcvREgeBzcSf/LgHtSYleb2WtmdmfUrqXDzGy2mdWZWV1TU1NmWYtEmLc2PCA9dcipDO7R2a+1SHHrtBCY2VNmtjhimtWVFZlZFfBB4IGk8G3AWGAK0Aj8Z3vzu/scd69199rq6uqurFqkU4daDjF39dxQfMaoGV1b0MU/TUwiRaTTs4bcfXp7bWa2ycxq3L3RzGqAzR0s6nzgZXfflLTsd56b2R3Ao+mlLRKvpzc8zba3t7WJVZZVdn23UN8RMWYlkhuZ7hqaC1wZPL8S+F0HfS8nZbdQUDwO+xCwOMN8RI7Ib1b8JhSbPnJ6188WWvxgYhIpIpkWghuBc81sJXBu8BozG2Zm7+xwNbMeQftDKfPfZGavm9lrwNnAlzPMR6TL1u5cy18a/xKKf/iED3d9YQvuTEwiRSSjL5S5+1YSZwKlxhuAmUmv9wEDI/pdkcn6ReJw15K7QrGRvUfynqHvyX0yInmgS0xISdu0d1PkQeKPjv8oZaZ/HlIa9JsuJe2uJXfR3NrcJtanqg+XnHBJnjISyT0VAilZG3Zt4N7l94bil7/rcnpU9shDRiL5oYvOScn60Ss/Co0Guld052MnfuzIF3rpzzPMSiT3VAikJD3f8HzkdYU+NfFTDOg24MgX3DN0ToRIwdOuISk5ew/t5dvPfzsUH9R9EJ+a+KnMFv7KrxKTSBFRIZCS4u5898Xv0rC3IdT2xZO/mPmxgUW/TkwiRUSFQErKAyseiDxddNrQaXzo+A/lISOR/FMhkJLxzIZn+O6L3w3Fu1d051vv/RZmlvukRAqACoGUhOfqn+Mrz3yFFm8Jtf3LtH/h2N7H5iErkcKgQiBHNXfn/uX388X/+yIHWw+G2j9ywke46PiLcp+YSAHR6aNy1Nr+9na+9+L3eGxd+D7EANNqpnHN1NDdVTPz8Qc67yNSYFQI5KhzoOUAv1nxG2579TZ2HtgZ2eekQSdxy9m3UFVeFe/Kq/SNZCk+KgRy1Fi5fSW/W/U7HlnzSOgmM8mm1Uzj5rNuzs5lJF66I/E49bPxL1skS1QIpGhte3sbr25+lZc2vsSLG19k5faVnc5z8biL+ea0b1JZXpmdpJb8NvGoQiBFRIVACk5Lawu7D+5m98Hd7Dq4i10Hd7H17a1s3LuRxj2NrN+9nlXbV7H17a1pL7NXZS+uPe1aLhhzQRYzFylOGRUCM/sIcD1wIjDV3eva6TcD+BFQDvzM3Q/fyWwAcB8wClgHXOru2zPJKcqSrUt4eOXD77x29zbtjkc+j+qbqs28HSw3nfau9O3KesMv03+/GeXobdfT6q0caj3EwZaDbR6bW5vfeb6/eT97Du1pd51dZRgXjLmAf679ZwZ1HxTbckWOJpmOCBYDFwM/ba+DmZUDt5K4VWU9sMDM5rr7UuAaYL6732hm1wSvv55hTiEbdm/gvuX3xb1YKWCVZZVMHzmdz570Wcb1H5fvdEQKWqa3qlwGdPaNzKnAKndfE/S9F5gFLA0ezwr63Q08QxYKgZSOCQMnMGvsLGaOnkm/bv3ynY5IUcjFMYLhwIak1/XAtOD5EHdvBHD3RjMb3N5CzGw2MBtg5MiRXUrA0KUDjkYVVsGovqOYXD2ZqUOnMrVmav53/1z1+/yuX+QIdFoIzOwpYGhE07Xu/rs01hH1KdzxjveoGdznAHMAamtruzy/FJdelb3oU9WHPsf0oXdVb/pW9WVoz6HvTGP6jmFUn1HZO/tHpIR0WgjcfXqG66gHki/kMgI4fA3gTWZWE4wGaoDNGa4r0okDTuTaade2iaWOEjravZXaFpo36XVnfTtadmc5dbSsruTY2XrDL4/8/Sa/LrMyqsqrqCyrpLK8kqqyKirKKv4aK6ukW0U3elb2pKJMJ7SJ5Eou/rUtAMaZ2WjgLeAy4PC9AOcCVwI3Bo/pjDC6bGSfkYzs07XdSSIipSKji86Z2YfMrB44Hfi9mT0RxIeZ2TwAd28GrgaeAJYB97v7kmARNwLnmtlKEmcV3ZhJPiIi0nXW2Xnyhai2ttbr6iK/siAiIu0ws4XuXpsa12WoRURKnAqBiEiJUyEQESlxKgQiIiWuKA8Wm1kTsP4IZx8EbIkxnbgUal5QuLkpr64p1LygcHM72vI6zt2rU4NFWQgyYWZ1UUfN861Q84LCzU15dU2h5gWFm1up5KVdQyIiJU6FQESkxJViIZiT7wTaUah5QeHmpry6plDzgsLNrSTyKrljBCIi0lYpjghERCSJCoGISIk7KguBmX3EzJaYWauZ1aa0fcPMVpnZcjM7r535B5jZk2a2Mnjsn4Uc7zOzRcG0zswWtdNvnZm9HvTLyZX2zOx6M3srKb+Z7fSbEWzHVcE9p7Od13+Y2Rtm9pqZPWxm/drpl5Nt1tn7t4RbgvbXzOyUbOWStM5jzexpM1sW/Bv4p4g+Z5nZzqSf73XZzitYb4c/l3xsr2C945O2xSIz22VmX0rpk5NtZmZ3mtlmM1ucFEvr8yijf4/uftRNwInAeBL3QK5Nik8AXgWOAUYDq4HyiPlvAq4Jnl8DfD/L+f4ncF07beuAQTneftcDX+2kT3mw/cYAVcF2nZDlvD4AVATPv9/ezyUX2yyd9w/MBB4jcauf04AXc/CzqwFOCZ73BlZE5HUW8Gguf6fS+bnkY3u183PdSOKLVznfZsCZwCnA4qRYp59Hmf57PCpHBO6+zN2XRzTNAu519wPuvhZYBUxtp9/dwfO7gYuykiiJv4KAS4F7srWOLJkKrHL3Ne5+ELiXxHbLGnf/gyfubwHwAom73eVLOu9/FvBzT3gB6GeJO/Fljbs3uvvLwfPdJO4BMjyb64xRzrdXhHOA1e5+pFcuyIi7PwtsSwmn83mU0b/Ho7IQdGA4sCHpdT3R/0iGuHsjJP5hAYOzmNPfAJvcfWU77Q78wcwWmtnsLOaR6upgeH5nO0PRdLdltnyaxF+PUXKxzdJ5/3ndRmY2CjgZeDGi+XQze9XMHjOziTlKqbOfS75/pyBxB8X2/ijLxzaD9D6PMtp2RXtjWDN7Chga0XStu7d3y8uom/5m7fzZNHO8nI5HA+9z9wYzGww8aWZvBH81ZC034Dbg30hsm38jsevq06mLiJg3422ZzjYzs2uBZuBX7SwmK9ssNdWIWOr7z+nvW5sVm/UCHgS+5O67UppfJrHrY09w/Oe3wLgcpNXZzyVv2wvAzKqADwLfiGjO1zZLV0bbrmgLgbtPP4LZ6oFjk16PABoi+m0ysxp3bwyGppuzkaOZVQAXA6d2sIyG4HGzmT1MYgiY8YdautvPzO4AHo1oSndbxpqXmV0JXACc48HO0YhlZGWbpUjn/WdlG3XGzCpJFIFfuftDqe3JhcHd55nZT8xskLtn9eJqafxc8rK9kpwPvOzum1Ib8rXNAul8HmW07Upt19Bc4DIzO8bMRpOo6C+10+/K4PmVQHsjjExNB95w9/qoRjPraWa9Dz8ncbB0cVTfOKXsl/1QO+tcAIwzs9HBX1KXkdhu2cxrBvB14IPuvq+dPrnaZum8/7nAJ4OzYU4Ddh4e4mdLcMzpf4Bl7v5f7fQZGvTDzKaS+BzYmuW80vm55Hx7pWh3dJ6PbZYknc+jzP49ZvsoeD4mEh9e9cABYBPwRFLbtSSOri8Hzk+K/4zgDCNgIDAfWBk8DshSnncBn0+JDQPmBc/HkDj6/yqwhMTukVxsv18ArwOvBb9MNam5Ba9nkjgrZXUuciNxcH8DsCiYbs/nNot6/8DnD/9MSQzXbw3aXyfpDLYs5nQGiV0CryVtp5kpeV0dbJtXSRx0f28O8or8ueR7eyXl14PEB3vfpFjOtxmJQtQIHAo+w/6+vc+jOP896hITIiIlrtR2DYmISAoVAhGREqdCICJS4lQIRERKnAqBiEiJUyEQESlxKgQiIiXu/wM8eLuC47OPYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testlist,[0]*l,linestyle='dashed')\n",
    "plt.plot([0]*l,[tanh(x) for x in testlist],linestyle='dashed')\n",
    "plt.plot(testlist,[tanh(x) for x in testlist],linewidth=5)\n",
    "plt.title('tanh Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b5464",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e90999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167918ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(testlist,[0]*l,linestyle='dashed')\n",
    "plt.plot([0]*l,[relu(x) for x in testlist],linestyle='dashed')\n",
    "plt.plot(testlist,[relu(x) for x in testlist],linewidth=5)\n",
    "plt.title('relu Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df2197",
   "metadata": {},
   "source": [
    "## Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f20706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return max(0.1*x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726da802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqC0lEQVR4nO3deXxU5dn/8c+VDZKwQyDsKCIobgguCCIQ26p9UGtt1T5af1prF8KiIqJYwQVFxAISbOvW2qpVq9a6P1oWQVRWAUFAhIIsAcIWIGHJcv/+mMGGnAkkmcmcmeT7fr3Oayb3NTPnOyfJlZN7zpwx5xwiIhJ/EvwOICIi1aMGLiISp9TARUTilBq4iEicUgMXEYlTauAiInFKDVyOy8zWm9nFEXicv5jZQ5HIVM31zzKzW/xafzjM7EIzW+13DoktauAilRD8I3bAzPaXWdrU4PqcmZ105Gvn3BznXNeaWp/EJzVwqRXMLCkKqxnknGtQZtkShXWKVEgNXKrEzBLMbJSZrTWznWb2qpk1K1P/h5ltNbN8M5ttZt0reJyGZjbTzJ4ws2lm9ni5+ttmNvw4Wdab2V1mtgwoMLMkMzvfzD41sz1mttTM+ldw37Fm9kKZrzsF93qr9Ieg/PRS2cct85g3mtm3ZrbDzEaXuW2imd0T3Jb7zGyRmbU3s9nBmywN7ulfY2b9zWxTmfueEpwS2mNmK8zs8jK1vwS36bvBx51nZp2r8rwkPqiBS1UNBa4ELgLaALuBaWXq7wNdgJbAYuDF8g9gZs2B6cBc59xQ4HngOjNLCNZbAFnA3yuR5zrgh0AToBXwLvAQ0AwYAbxuZhlVfI6R1hfoSuA53WdmpwTHbyeQ/zKgEXAzUOic6xesnxnc03+l7IOZWTLwNvAhge08BHjRzMpOsVwH3A80Bb4BxtXEExN/qYFLVf0KGO2c2+ScOwSMBa4+sufqnHvOObevTO1MM2tc5v5tgI+Bfzjn7g3eZz6QT6DBAVwLzHLObatEnieccxudcweA64H3nHPvOedKnXMfAQsJNMhIeDO4x7vHzN6swv3ud84dcM4tBZYCZwbHbwHudc6tdgFLnXM7K/F45wMNgPHOucPOuRnAOwSa9hFvOOfmO+eKCfwRPasKeSVOqIFLVXUE/nmkkQErgRKgVXBKYHxwSmAvsD54nxZl7v9DIBX4Y7nHfZ5AAyZ4+bdK5tlYLttPyjTZPQT2fltX8rGO50rnXJPgcmUV7re1zPVCAs0XoD2wtho52gAbnXOlZcY2AG0rsU6pRaLxwo/ULhuBm51zc8sXzOwG4ArgYgLNuzGBKRYrc7OnCfxb/56ZXeKcKwiOvwAsN7MzgVOANyuZp+zpNDcCf3PO/bIS9ysA0sp8nVnJ9UXycTYCnYHlVVznFqC9mSWUaeIdgK+r+DgS57QHLlX1R2CcmXUEMLMMM7siWGsIHAJ2EmhqD1fwGNnAauAdM0sFcM5tAhYQ2PN+PTglUlUvAIPM7AfB/wbqB1/8axfitkuAfmbWITjFc3c11nfkca41s2Qz6wVcXYX7PgM8aGZdLOCM4OsDANuAEyu43zwCfzhGBtfbHxgEvFydJyDxSw1cqmoK8BbwoZntAz4HzgvW/krgX/nNwFfBmocLnIT+VgJ7oP8ys/rB0vPA6VR++qT8424k8B/APUBe8PHvJMTPeXB+/BVgGbCIwBxydfyOwF70bgIvGr5Uhfv+HniVwIuRe4FnCUwvQeD1g+eDU0E/LZf9MHA5cCmwA3gS+LlzblU1n4PEKdMHOkisMLN+BPaiO5Wb3xWRELQHLjEheGjcMOAZNW+RylEDF98Fj4veQ+BokcllxjvY0W9dL7t08CmuSMzQFIqISJzSHriISJyK6nHgLVq0cJ06dYrmKkVE4t6iRYt2OOc8p4SIagPv1KkTCxcujOYqRUTinpltCDWuKRQRkTilBi4iEqfUwEVE4tRxG7iZPWdm281seZmxZmb2kZmtCV42rdmYIiJSXmX2wP8CXFJubBQw3TnXhcCJ+UdFOJeISK2x++DuGnnc4zZw59xsYFe54SsInHiI4OWVkY0lIlI7vLTyJS5/83IWbVsU8ceu7hx4K+dcLkDwsmVFNzSzW81soZktzMvLq+bqRETizyebP+HRBY+y59AebvnwFv71zb8i+vg1/iKmc+4p51wv51yvjAy/P5pQRCQ61uxew4iPR1AaPDdbcWkx9869lymLpxCpU5hUt4FvM7PWAMHL7RFJIyJSC+w8sJMhM4ZQUFTgqe07vC9i66luA38LuDF4/UYgsv8XiETb2pmBRSRMh0oOMXzmcDbv3+yp9W7dm7vOvQszC3HPqjvuW+nN7O9Af6CFmW0CxgDjgVfN7BfAt8BPIpJGxC+zJwYuOw/wN4fENeccYz4dw5K8JZ7aCY1PYGL/iSQnJEdsfcdt4M656yooZUUshYhILfDUsqd4d927nvEm9ZowbeA0GqU0iuj69E5MEZEI+GD9B+QsyfGMJyUkMXnAZNo3ah/xdaqBi4iE6cu8L7n3k3tD1sb2HkvPVj1rZL1q4CIiYdhasJUhM4ZwqOSQp3bL6bdwxUlX1Ni6o3o+cJGYNWiy3wkkDhUWFZI9PZudB3d6ahd3uJghPYbU6PrVwEUAWnTxO4HEmZLSEu6acxerd6/21E5pdgrj+o4jwWp2kkNTKCIAq98PLCKVNHnxZGZtnOUZb5nakqkDp5KWnFbjGbQHLgLwafDoga6X+ptD4sLrX7/OX1b8xTOempTK1KyptEpvFZUc2gMXEamC+bnzeejzh0LWHun7CKc2PzVqWdTARUQqaX3+em6bdRvFrthTG372cLI6Rvf9jWrgIiKVkH8on+wZ2ew9vNdTu6LzFdx82s1Rz6QGLiJyHEUlRdw+63Y27N3gqfVs1ZMxvcdE7ARVVaEXMUUArvqT3wkkRjnneGjeQ8zfOt9Ta9+wPZP6TyI5MXInqKoKNXARgMbt/E4gMeqvX/2VN9a84RlvmNyQnKwcmtb37zPdNYUiArD89cAiUsbMb2fy+MLHPeOJlsjj/R/nxMYn+pDqv7QHLgKw4LnA5Wk/9jeHxIzVu1Zz15y7cHg//uye8+6hd5vePqQ6mvbARUTKySvMI3tGNgeKD3hq159yPT/t+lMfUnmpgYuIlHGw+CBDZwxla8FWT+3CthcyotcIH1KFpgYuIhJU6koZ/clolu9c7qmd1OQkJvSbQGJCog/JQlMDFxEJenLJk3y44UPPeLP6zcjJyqFBSgMfUlVML2KKAPz0r34nEJ+9s+4d/rTM+36AlIQUpgyYQtsGbX1IdWxq4CIA6c39TiA++mL7F9w3976QtQf7PMhZLc+KbqBK0hSKCMAXLwYWqXM27dvE8JnDKSot8tR+c+ZvuOzEy3xIVTlq4CIAS14KLFKn7Du8j+zp2ew6uMtTu7TTpfzmzN/4kKry1MBFpE4qLi3mztl3sjZ/rad2RoszeKDPA76coKoq1MBFpE56bMFjzN081zOemZ7JlIFTqJ9U34dUVaMGLiJ1zsurXualVd4ps7SkNHIG5tAitYUPqapODVxE6pRPN3/K+PnjPeOGMaHfBLo26+pDqurRYYQiAP/7D78TSBSs3bOWOz6+gxJX4qmN6DWCi9pf5EOq6gtrD9zMbjOzFWa23Mz+bmaxP2kkEkpKWmCRWmvXwV0Mnj6Y/UX7PbWrT76aG069wYdU4al2AzeztsBQoJdz7jQgEbg2UsFEomr+04FFaqXDJYe5beZtbN6/2VM7L/M87jnvnpg/4iSUcOfAk4BUM0sC0oAt4UcS8cGKNwOL1DrOOe7/7H4Wb1/sqXVq1InH+z9OcoI/H4kWrmo3cOfcZmAi8C2QC+Q75zxngTGzW81soZktzMvLq35SEZFqeHb5s7y19i3PeON6jcnJyqFxvcY+pIqMcKZQmgJXACcAbYB0M7u+/O2cc08553o553plZGRUP6mISBV9tOEjpiye4hlPSkhiUv9JdGzU0YdUkRPOFMrFwH+cc3nOuSLgDeCCyMQSEQnPih0ruGfOPSFr951/H+dknhPlRJEXTgP/FjjfzNIsMPufBayMTCwRkerbWrCVITOGcLDkoKd2U/eb+FGXH/mQKvKqfRy4c26emb0GLAaKgS+ApyIVTCSqbnrX7wQSIYVFhQydMZS8A97X3Aa0H8Cws4f5kKpmhPVGHufcGGBMhLKIiISl1JVy95y7WbnLOxnQrVk3xl84PqY+Ei1ceiu9CMDcJwKLxLUpi6cwY+MMz3hGagZTB04lLbl2vVlLDVwE4Ov/CywSt/655p88t/w5z3j9xPpMHTiVzPRMH1LVLDVwEYl7C7Yu4IHPHwhZG9d3HN1bdI9youhQAxeRuPbt3m+5bdZtFJcWe2pDewzl+52+70Oq6FADF5G4lX8on8HTB5N/KN9TG3TiIG45/RYfUkWPTicrApCsE2nGm6LSIu74+A7W713vqfVo2YOxF4yNyxNUVYUauAjA9a/7nUCqwDnHw/MeZl7uPE+tbYO2TB4wmZTEFB+SRZemUEQk7ryw8gVe+/o1z3iD5AZMy5pGs/rNfEgVfWrgIgAfTwgsEvM+3vgxjy14zDOeYAlMvGginZt09iGVP9TARQDWfRxYJKat3rWakbNH4nCe2qhzR9GnbR8fUvlHDVxE4sKOAzsYMmMIhcWFntp13a7jum7X+ZDKX2rgIhLzDhYfZNjMYeQW5Hpqfdr0YeQ5I31I5T81cBGJac457pt7H8vylnlqnRt35rGLHiMpoW4eUFc3n7VIeWlN/U4gFfjj0j/y/vr3PeNN6zUlJyuHhikNfUgVG9TARQCuecHvBBLCe+ve48mlT3rGkxOSmTJwCu0atvMhVezQFIqIxKSleUv53dzfhazdf8H99GjZI8qJYo8auAjAv8cGFokJW/ZvYeiMoRwuPeyp3XrGrQzqPMiHVLFHUygiABsX+J1AgvYf3s/g6YPZdXCXp/a9jt9j8FmDfUgVm7QHLiIxo6S0hJGzR/LNnm88te7NuzOu7zgSTG3rCG0JEYkZExdOZM7mOZ7xVmmtmDpwKqlJqT6kil1q4CISE15d/SovrPQeDZSalEpOVg4ZaRk+pIptmgMXAWjUxu8EddpnWz7j4XkPe8YNY/yF4+nWrJsPqWKfGrgIwI+f9jtBnbUufx13zLqDElfiqd3e83YGdhjoQ6r4oCkUEfHNnoN7yJ6ezb6ifZ7aVV2u4sbuN/qQKn6ogYsAvD8qsEjUFJUUMXzWcDbu2+ipnZN5Dveed2+t/0i0cGkKRQRg65d+J6hTnHM88PkDLNq2yFPr2Kgjk/pPIjkx2Ydk8UV74CISdX9e8Wfe/OZNz3ijlEbkDMyhcb3G0Q8Vh8Jq4GbWxMxeM7NVZrbSzHpHKpiI1E7TN0xn8qLJnvEkS+L3/X9Pp8adop4pXoU7hTIF+MA5d7WZpQBpEcgkIrXUVzu/4u5P7g75kWijzx/Nea3P8yFV/Kp2AzezRkA/4P8BOOcOA94zz4jEg+Z154Nw/bKtYBtDpg/hQPEBT+3np/6cq0++2odU8S2cPfATgTzgz2Z2JrAIGOacKyh7IzO7FbgVoEOHDmGsTqQGXf6E3wlqtcKiQobMGML2A9s9tYvaXcTtPW/3IVX8C2cOPAk4G/iDc64HUAB4jsNyzj3lnOvlnOuVkaG3worUNaWulNGfjGblrpWe2slNT+bRfo+SmJDoQ7L4F04D3wRscs7NC379GoGGLhJ/3hoaWCTipn4xlX9/+2/PePP6zckZmEN6croPqWqHak+hOOe2mtlGM+vqnFsNZAFfRS6aSBTtXOt3glrprbVv8cyXz3jG6yXW44mBT9C6QWsfUtUe4R6FMgR4MXgEyjrgpvAjiUhtsGjbIsZ8OiZk7aG+D3FGxhlRTlT7hNXAnXNLgF6RiSIitcXGvRsZPnM4xaXFntrgswZzSadLfEhV++idmCISUXsP7yV7RjZ7Du3x1C474TJ+dcavoh+qltK5UEQAMk/3O0GtUFxazIhZI1iXv85TOzPjTB7o84BOUBVBauAiAJeO9ztB3HPOMX7+eD7L/cxTa5PehskDJlMvsZ4PyWovTaGISES8tOolXln9imc8PTmdnKwcWqS28CFV7aYGLgLw+i8Di1TLnE1zmLBggmc8wRKY0G8CXZp28SFV7acpFBGAvVv8ThC31uxew52z76TUlXpqI88ZSb92/XxIVTdoD1xEqm3ngZ1kT8+moKjAU7um6zX8rNvPfEhVd6iBi0i1HCo5xLCZw9hS4P3vpXfr3tx17l064qSGqYGLSJU55xjz6RiW5i311E5ofAIT+08kOUEfiVbTNAcuAtD+HL8TxJWnlj3Fu+ve9Yw3qdeEaQOn0SilkQ+p6h41cBGAi8f6nSBufLD+A3KW5HjGkxKSmDxgMu0btfchVd2kKRQRqbQv877k3k/uDVkb23ssPVv1jHKiuk0NXATglesDi1Qod38uQ2YM4VDJIU/tF6f9gitOusKHVHWbplBEAAp3+50gphUUFZA9I5udB3d6alkdshh6tj4Mww/aAxeRYyopLWHU7FF8vftrT+2UZqfwcN+HSTC1Ej9oq4vIMU1aNIlZm2Z5xlumtmTqwKmkJadFP5QAauAicgyvff0az3/1vGc8NSmVqVlTaZXeyodUcoTmwEUATrzI7wQxZ17uPMZ9Pi5k7ZG+j3Bq81OjnEjKUwMXAbhopN8JYsr6/PXcNus2ip33I9GGnz2crI5ZPqSS8jSFIiJHyT+UT/aMbPYd3uepXdH5Cm4+7WYfUkkoauAiAC/8OLDUcUUlRdw+63Y27N3gqfVs1ZMxvcfoBFUxRFMoIgBFB/1O4DvnHA/Ne4j5W+d7au0atGNS/0kkJ+oEVbFEe+AiAsBfv/orb6x5wzPeMLkh07Km0bR+Ux9SybGogYsIM7+dyeMLH/eMJ1oiE/tP5MQmJ/qQSo5HDVykjlu1axV3zbkLh/PU7jnvHi5oc4EPqaQyNAcuAnDyD/xO4Iu8wjyyp2dzoPiAp3b9Kdfz064/9SGVVJYauAhAn7p3MqYDxQcYOmMo2wq3eWoXtr2QEb1G+JBKqiLsKRQzSzSzL8zsnUgEEpGaV+pKGf3JaJbvXO6pndTkJCb0m0BiQqIPyaQqIjEHPgxYGYHHEfHPn38YWOqIaUum8dGGjzzjzeo3IycrhwYpDXxIJVUVVgM3s3bAD4FnIhNHRGra22vf5qllT3nGUxJSmDJgCm0btPUhlVRHuHvgk4GRQGlFNzCzW81soZktzMvLC3N1IhKOL7Z/wZhPx4SsPdjnQc5qeVZ0A0lYqt3Azex/gO3OuUXHup1z7innXC/nXK+MjIzqrk5EwrRp3yaGzxxOUWmRp/brM3/NZSde5kMqCUc4e+B9gMvNbD3wMjDQzF6ISCoRiah9h/eRPT2bXQd3eWqXdLqE3575Wx9SSbiqfRihc+5u4G4AM+sPjHDO6VNhJT51v9LvBDWmuLSYO2ffydr8tZ7a6S1O58E+D+oEVXFKx4GLAJz7S78T1JjHFjzG3M1zPeOZ6Zk8MfAJ6ifV9yGVREJEGrhzbhYwKxKPJeKLw4WBy5Ta9fmOf1/1d15a9ZJnPC0pjZyBObRIbeFDKokU7YGLALz4k8DlTe/6myOC5m6ey6PzH/WMG8aEfhPo2qyrD6kkknQyK5FaaO2etYz4eAQlrsRTG9FrBBe112eA1gZq4CK1zK6Duxg8fTD7i/Z7aleffDU3nHqDD6mkJqiBi9Qih0sOM3zmcDbv3+ypnZd5Hvecd4+OOKlF1MBFagnnHGM/HcsX27/w1Do16sTj/R8nOUEfiVab6EVMEYCzfuZ3grA9u/xZ3l73tme8UUojcrJyaFyvsQ+ppCapgYsA9PhfvxOE5aMNHzFl8RTPeJIlMXnAZDo26uhDKqlpmkIRASjYGVji0IodK7hnzj0ha7/r/TvOyTwnyokkWrQHLgLw6s8Dl3F2HPjWgq0MmTGEgyUHPbWbut/EVV2u8iGVRIv2wEXiVGFRIUNmDCHvgPc0zQPaD2DY2cN8SCXRpAYuEodKXSmj5oxi1a5Vnlq3Zt0Yf+F4fSRaHaAGLhKHJi+ezMyNMz3jGakZTB04lbTk2nVOFwlNDVwkzvxzzT/58/I/e8brJ9Zn6sCpZKZn+pBK/KAXMUUAzrnZ7wSVsmDrAh747IGQtXF9x9G9RfcoJxI/qYGLAJz2Y78THNeGvRu4bdZtFLtiT21oj6F8v9P3fUglftIUighA/qbAEqPyD+WTPT2b/EP5ntqgEwdxy+m3+JBK/KY9cBGAN34VuIzB48CLSou44+M7WL93vafWo2UPxl4wVieoqqO0By4Sw5xzPDzvYeblzvPU2jZoy+QBk0lJTPEhmcQCNXCRGPbCyhd47evXPOMNkhuQMzCHZvWb+ZBKYoUauEiM+njjxzy24DHPeIIlMPGiiZzU9CQfUkksUQMXiUGrd61m5OyROJynNurcUfRp28eHVBJr9CKmCMAF2X4n+M6OAzsYMmMIhcWFntp13a7jum7X+ZBKYpEauAhA10v9TgDAweKDDJsxjNyCXE+tT5s+jDxnpA+pJFZpCkUEYMeawOIj5xy/m/s7lu1Y5ql1btyZxy56jKQE7XPJf+mnQQTg7eGBSx+PA//D0j/wwfoPPONN6zUlJyuHhikNfUglsUx74CIx4N117/KHpX/wjCcnJDNl4BTaNWznQyqJdWrgIj5bsn0J9829L2Tt/gvup0fLHlFOJPGi2g3czNqb2UwzW2lmK8xMH/8hUkVb9m9h2MxhHC497Kn98vRfMqjzIB9SSbwIZw68GLjDObfYzBoCi8zsI+fcVxHKJlKr7T+8n8HTB7Pr4C5P7Xsdv0d2j9g5tFFiU7UbuHMuF8gNXt9nZiuBtoAauMSffiOiurqS0hJGzh7JN3u+8dS6N+/OuL7jSDDNcMqxReQoFDPrBPQAvGfcEYkHnQdEdXUTF05kzuY5nvFWaa2YOnAqqUmpUc0j8SnsP/Fm1gB4HRjunNsbon6rmS00s4V5ed5PzxaJCbnLAksUvLr6VV5Y+YJnPDUplZysHDLSMqKSQ+JfWA3czJIJNO8XnXNvhLqNc+4p51wv51yvjAz9YEqM+uDuwFLDPtvyGQ/Pe9gzbhjjLxxPt2bdajyD1B7hHIViwLPASufc7yMXSaR2Wpe/jjtm3UGJK/HUbu95OwM7DPQhlcSzcPbA+wA3AAPNbElwuSxCuURqld0Hd5M9PZt9Rfs8tau6XMWN3W/0IZXEu3COQvkE0Oc4iRzH4ZLDDJ85nI37Nnpq52Sew73n3auPRJNq0XFKIjXIOcf9n93P4u2LPbUODTswqf8kkhOTfUgmtYFOZiUCkBX6rezhem75c7y19i3PeMOUhuRk5dC4XuMaWa/UDWrgIgAdzov4Q07fMJ0pi6d4xpMsid/3/z0nND4h4uuUukVTKCIA384LLBHy1c6vuPuTu0N+JNro80dzfuvzI7Yuqbu0By4CMP2BwGUEzge+rWAbQ6YP4UDxAU/t56f+nKtPvjrsdYiA9sBFIqqwqJAhM4aw/cB2T+2idhdxe8/bfUgltZUauEiElLpSRn8ympW7VnpqJzc9mUf7PUpiQqIPyaS2UgMXiZCpX0zl39/+2zPevH5zcgbmkJ6c7kMqqc3UwEUi4F/f/ItnvnzGM14vsR5PDHyC1g1a+5BKaju9iCkCcMkj1b7rom2LGPvZ2JC1h/o+xBkZZ1T7sUWORQ1cBKB19Zrsxr0bGT5zOMWlxZ7ab8/6LZd0uiTcZCIV0hSKCMDamYGlCvYe3svgGYPZc2iPp3bpCZfy6zN+HaFwIqFpD1wEYPbEwGUlP5mnuLSYEbNG8J/8/3hqZ2acyYN9HtQJqqTGaQ9cpIqcc4yfP57Pcj/z1Nqkt2HygMnUS6znQzKpa9TARaropVUv8crqVzzj6cnp5GTl0CK1hQ+ppC5SAxepgjmb5jBhwQTPeIIlMKHfBLo07eJDKqmr1MBFKmnN7jXcOftOSl2ppzbynJH0a9fPh1RSl+lFTBGAQZOPWd55YCfZ07MpKCrw1K7peg0/6/azGgomUjE1cBGAFhVPfRwqOcSwmcPYUrDFU+vdujd3nXuXjjgRX2gKRQRg9fuBpRznHPfNvY+leUs9tRMan8DE/hNJTtBHook/tAcuAvBpTuCy66VHDf9p2Z947z/veW7epF4Tpg2cRqOURtFIJxKS9sBFKvDBfz5g2pJpnvGkhCQm9Z9E+0btfUgl8l9q4CIhLMtbxr1z7w1ZG9N7DL0ye0U5kYiXGrhIObn7cxk6YyiHSg55ar847RdcedKV0Q8lEoIauEgZBUUFZM/IZufBnZ5aVocshp491IdUIqHpRUwRgKv+RIkrYdTsUXy9+2tP+ZRmp/Bw34dJMO3zSOzQT6MIQON2TFrzD2ZtmuUptUxtydSBU0lLTot+LpFj0B64CPDazHt4/tu3PeOpSalMzZpKq/RWPqQSObawGriZXQJMARKBZ5xz4yOSSqSGOOfIP5RPbkEuWwq2sLVgK5v2beLlDW9DiDdTPtL3EU5tfmr0g4pUQrUbuJklAtOA7wGbgAVm9pZz7qtIhROpqqLSIrYXbmfL/kBzzi3IPep6bkEuB4oPeO8YonkPP3s4WR2zaj60SDWFswd+LvCNc24dgJm9DFwB1EgDv+ZP3pPn/88ZrbmhdycOHC7h//15vqd+dc92/KRXe3YVHOY3Lyzy1K8/vyODzmzDlj0HuO2VJZ76Ly88kYtPbcXavP3c88aXnvqQgV3o26UFK7bk88Db3qc98pKu9OzYjEUbdjHhg9We+n2DTqV7m8Z8smYHU2es8dQfvup0Omc04N9fbePpOes89UnXnEWbJqm8vXQLL3y+wVP/w/U9aZaewj8WbuS1RZs89b/cdC6pKYn87bP1vLMs11N/5Ve9AXhq9lqmr9x+VK1+ciLP33wuAE9MX8Pcb3YcVW+alsIfb+gJwKMfrGLxht1H1Vs3rs/ka3sAcP/bK/hqy96j6idmpPPIVYHPqbz7jWWsywucRKqEQopsF5nNDzCgewq5Bbm8+9VX7C3Oo8h2Ukw+mPM8l6rq1mAAN592M6CfPf3sHX0Cs1PbNGLMoO4ADH/5C3LzDx5VP7tjU+66pBsAv/7bInYXHj7qOUVSOA28LbCxzNebgPPK38jMbgVuBejQoUMYq5PazlFKMfkU2U42FxXw7JcLyC3IZX7havJTAg261AK/LOv2w6fzytw5gi/Hp5V2YWCL3+oEVRLzzLnq7a2Y2U+AHzjnbgl+fQNwrnNuSEX36dWrl1u4cGG11ifxr7CokK0FW9lSsCUwnbE/97tpja0FW9lWsI1i5/1092g6rflpPHnxkzSt39TXHCJlmdki55zn7b/h7IFvAsqeDKId4D3fptQJpa6UXQd3sWX/lu8a8lHXC7aQfyjf75gA1EusR+v01oGlQWsy0zNpk9SIjg3bc3q7PiQmJPodUaRSwmngC4AuZnYCsBm4FtBZ7WupQyWHvmvKFb04WFRa5HdMAJrVb/Zdg85Mz6RNgzZHNeym9ZpqekRqhWo3cOdcsZllA/9H4DDC55xzKyKWTKLGOceeQ3uOmtY4cohd7v7A9V0Hd/kdEwicCTAzLdCUM9MzaZ3e+rvrbdIDl/WT6lf9gb94MXDZ438jG1ikBoV1HLhz7j3Ae7JkiSlFJUVsK9z23Z5y2bnnI1McIQ+t80GjlEZHN+f0NmQ2+O/15qnNa+bt7EteClyqgUsc0Tsx45xzjn1F+45uyuWu5x3IwxH+oXXhSrREWqW1CjTnBq2/22Muuxednpzud0yRuKEGHuOKS4vZcWDHdy8IhtqDDvVBu35IT07/71xzcL75yPU2DdrQIrUFSQn6kROJFP02+aywqPDo5lyuSW8v3E6JK/E7JoaRkZYRsjkf+bphckO9OCgSRWrgNajUlbLzwM7vjnveuv+/x0AfOaJj7+G9x3+gKKifWD9kUz5yvVVaK5IT9eG9IrFEDTwMB4sPHvVCYPljoLcWbqW41N83phzRvH7zCvecW6e3pkm9JnV77/l//+F3ApEqUwOvgHOO3Yd2HzXfXP6451g5tC45ITn01EaD/+49V+vQurokRef6lvhTZxt4UUnRUc247HHPR8ZCfSaiH5rUaxL6TSnBJt2sfjN9Uky45j8duDz3l/7mEKmCWtnAnXPsPbw35BEbR77ecWBHTBxal2RJtEpvddQbUY4cYnekaeuTYKJgxZuBSzVwiSNx2cCLS4vZXri9wuOecwtyKSwu9DsmAA2TG5LZINNzzPOR5pyRmqFzb4hItcR0A1+1axXL8pZ5Toq0vXA7pa7U73gkWAIZqRkhj3k+0qwbpjT0O6aI1FIx3cA/XP8hT3/5tG/rT01KDX3kRnCsZVpLkhN0aJ2I+COmG3hmemaNPn6L1BbHfOdgo5RGdfvQOhGJaTHdwNs0aFPt+6YkpBzzjSmZ6ZmkJKZEMK3EtZve9TuBSJXFdANvnd66wlrTek2P2aCb1W+mvWcRqdVivoFf3vny7w6xa53e+rtTi6YmpfodT0TEVzHdwNOS0xjXd5zfMUREYpLeviciEqfUwEVE4pQauIhInFIDFxGJU2rgIiJxSg1cRCROmXPRO6WqmeUBG6p59xbAjgjGiZRYzQWxm025qiZWc0HsZqttuTo65zLKD0a1gYfDzBY653r5naO8WM0FsZtNuaomVnNB7GarK7k0hSIiEqfUwEVE4lQ8NfCn/A5QgVjNBbGbTbmqJlZzQexmqxO54mYOXEREjhZPe+AiIlKGGriISJyKqQZuZj8xsxVmVmpmvcrV7jazb8xstZn9oIL7NzOzj8xsTfCyaQ1kfMXMlgSX9Wa2pILbrTezL4O3WxjpHBWsc6yZbS6T77IKbndJcDt+Y2ajopDrMTNbZWbLzOyfZtakgttFZZsd7/lbwBPB+jIzO7umspRZZ3szm2lmK4O/A8NC3Ka/meWX+f7eV9O5gus95vfFj+0VXG/XMttiiZntNbPh5W4TlW1mZs+Z2XYzW15mrFL9KKzfR+dczCzAKUBXYBbQq8z4qcBSoB5wArAWSAxx/wnAqOD1UcCjNZz3ceC+CmrrgRZR3n5jgRHHuU1icPudCKQEt+upNZzr+0BS8PqjFX1forHNKvP8gcuA9wEDzgfmReF71xo4O3i9IfB1iFz9gXei+TNVme+LH9urgu/rVgJveIn6NgP6AWcDy8uMHbcfhfv7GFN74M65lc651SFKVwAvO+cOOef+A3wDnFvB7Z4PXn8euLJGghLY6wB+Cvy9ptZRQ84FvnHOrXPOHQZeJrDdaoxz7kPnXHHwy8+BdjW5vuOozPO/AvirC/gcaGJmFX++XwQ453Kdc4uD1/cBK4G2NbnOCIr69gohC1jrnKvuO73D4pybDewqN1yZfhTW72NMNfBjaAtsLPP1JkL/cLdyzuVC4BcCaFmDmS4Etjnn1lRQd8CHZrbIzG6twRzlZQf/jX2ugn/ZKrsta8rNBPbWQonGNqvM8/d1G5lZJ6AHMC9EubeZLTWz982se5QiHe/74vfPFMC1VLwz5cc2g8r1o7C2XdQ/Us3M/g1khiiNds79q6K7hRirseMfK5nxOo69993HObfFzFoCH5nZquBf6RrLBvwBeJDAtnmQwBTPzeUfIsR9w96WldlmZjYaKAZerOBhamSblY8aYqz884/qz9tRKzZrALwODHfO7S1XXkxgimB/8PWNN4EuUYh1vO+Lb9sLwMxSgMuBu0OU/dpmlRXWtot6A3fOXVyNu20C2pf5uh2wJcTttplZa+dcbvBfuO01kdHMkoCrgJ7HeIwtwcvtZvZPAv8qhd2MKrv9zOxp4J0Qpcpuy4jmMrMbgf8Bslxw8i/EY9TINiunMs+/RrbR8ZhZMoHm/aJz7o3y9bIN3Tn3npk9aWYtnHM1etKmSnxffNleZVwKLHbObStf8GubBVWmH4W17eJlCuUt4Fozq2dmJxD4Czq/gtvdGLx+I1DRHn24LgZWOec2hSqaWbqZNTxyncCLeMtD3TaSys07/qiCdS4AupjZCcE9l2sJbLeazHUJcBdwuXOusILbRGubVeb5vwX8PHh0xflA/pF/hWtK8DWVZ4GVzrnfV3CbzODtMLNzCfz+7qzhXJX5vkR9e5VT4X/DfmyzMirTj8L7fazpV2er+Erujwj8RToEbAP+r0xtNIFXa1cDl5YZf4bgEStAc2A6sCZ42ayGcv4F+HW5sTbAe8HrJxJ4NXkpsILANEI0tt/fgC+BZcEfgtblswW/vozAUQ5ro5GNwIvOG4ElweWPfm6zUM8f+PWR7ymBf2unBetfUuaIqBrM1JfAv87Lymyny8rlyg5um6UEXgy+IAq5Qn5f/N5eZfKlEWjIjcuMRX2bEfgDkgsUBXvYLyrqR5H8fdRb6UVE4lS8TKGIiEg5auAiInFKDVxEJE6pgYuIxCk1cBGROKUGLiISp9TARUTi1P8HSq2rCru5F7cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(testlist,[0]*l,linestyle='dashed')\n",
    "plt.plot([0]*l,[leaky_relu(x) for x in testlist],linestyle='dashed')\n",
    "plt.plot(testlist,[leaky_relu(x) for x in testlist],linewidth=5)\n",
    "plt.title('leaky_relu Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1167c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb9e41",
   "metadata": {},
   "source": [
    "sigmoid is used mostly in output layer when output is binary\n",
    "\n",
    "tanh is used in hidden layer\n",
    "\n",
    "Relu is used in Hidden layers if not sure about which function to choose\n",
    "\n",
    "sigmoid ,tanh ,relu has vanishing gradient problem (learning rate becoming slower when derivative approaches to zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665085de",
   "metadata": {},
   "source": [
    " \n",
    " # LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1ca9c",
   "metadata": {},
   "source": [
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26e45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=np.array([2,5,7,9,10,11,15])\n",
    "y_predicted=np.array([15,26,37,43,56,68,74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c33cfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.142857142857146"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_abs_error(true,predicted):\n",
    "    return np.mean(np.abs(true-predicted))\n",
    "\n",
    "mean_abs_error(y_true,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ffe8d",
   "metadata": {},
   "source": [
    "## Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa8aead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644.5714285714287"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_sqr_error(true,predicted):\n",
    "    return np.mean((true-predicted)**2)\n",
    "\n",
    "mean_sqr_error(y_true,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c73b7",
   "metadata": {},
   "source": [
    "## Log Loss OR Binary Crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2409e45",
   "metadata": {},
   "source": [
    "Used as loss function for logistic regression (binary target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d21a3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true2=np.array([1,0,0,1,1,0,1])\n",
    "y_predicted2=np.array([1,1,0,1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d851425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.86833605532165"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_loss(true,predicted):\n",
    "    true=true.astype(np.float64,copy=False)\n",
    "    predicted=predicted.astype(np.float64,copy=False)\n",
    "    epsilon=1e-15\n",
    "    predicted[predicted==0]=epsilon\n",
    "    predicted[predicted==1]=1-epsilon\n",
    "    return -np.mean(true*np.log(predicted)+(1-true)*np.log(1-predicted))\n",
    "    \n",
    "    \n",
    "log_loss(y_true2,y_predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc0c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3296b88",
   "metadata": {},
   "source": [
    "## GREDIENT DESENT for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcbd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7886bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('../resources/Excel_sheets/insurance_data.csv')\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f4a0ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  affordibility  bought_insurance\n",
       "0  0.22              1                 0\n",
       "1  0.25              0                 0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df1.copy()\n",
    "\n",
    "df['age']=df['age']/100\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6670291",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df[['age','affordibility']],df.bought_insurance,\n",
    "                                              test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57455f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7311 - accuracy: 0.5000\n",
      "Epoch 2/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7306 - accuracy: 0.5000\n",
      "Epoch 3/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7302 - accuracy: 0.5000\n",
      "Epoch 4/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.5000\n",
      "Epoch 5/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7293 - accuracy: 0.5000\n",
      "Epoch 6/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7289 - accuracy: 0.5000\n",
      "Epoch 7/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7285 - accuracy: 0.5000\n",
      "Epoch 8/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7281 - accuracy: 0.5000\n",
      "Epoch 9/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7276 - accuracy: 0.5000\n",
      "Epoch 10/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7272 - accuracy: 0.5000\n",
      "Epoch 11/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7268 - accuracy: 0.5000\n",
      "Epoch 12/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7264 - accuracy: 0.5000\n",
      "Epoch 13/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7259 - accuracy: 0.5000\n",
      "Epoch 14/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7255 - accuracy: 0.5000\n",
      "Epoch 15/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7251 - accuracy: 0.5000\n",
      "Epoch 16/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7247 - accuracy: 0.5000\n",
      "Epoch 17/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7242 - accuracy: 0.5000\n",
      "Epoch 18/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7238 - accuracy: 0.5000\n",
      "Epoch 19/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7234 - accuracy: 0.5000\n",
      "Epoch 20/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7230 - accuracy: 0.5000\n",
      "Epoch 21/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7226 - accuracy: 0.5000\n",
      "Epoch 22/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7222 - accuracy: 0.5000\n",
      "Epoch 23/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7217 - accuracy: 0.5000\n",
      "Epoch 24/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7213 - accuracy: 0.5000\n",
      "Epoch 25/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7209 - accuracy: 0.5000\n",
      "Epoch 26/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7205 - accuracy: 0.5000\n",
      "Epoch 27/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7201 - accuracy: 0.5000\n",
      "Epoch 28/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7197 - accuracy: 0.5000\n",
      "Epoch 29/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7193 - accuracy: 0.5000\n",
      "Epoch 30/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7189 - accuracy: 0.5000\n",
      "Epoch 31/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7185 - accuracy: 0.5000\n",
      "Epoch 32/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7181 - accuracy: 0.5000\n",
      "Epoch 33/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7177 - accuracy: 0.5000\n",
      "Epoch 34/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7173 - accuracy: 0.5000\n",
      "Epoch 35/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7169 - accuracy: 0.5000\n",
      "Epoch 36/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7165 - accuracy: 0.5000\n",
      "Epoch 37/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7161 - accuracy: 0.5000\n",
      "Epoch 38/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7157 - accuracy: 0.5000\n",
      "Epoch 39/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7153 - accuracy: 0.5000\n",
      "Epoch 40/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7149 - accuracy: 0.5000\n",
      "Epoch 41/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7145 - accuracy: 0.5000\n",
      "Epoch 42/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7141 - accuracy: 0.5000\n",
      "Epoch 43/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7137 - accuracy: 0.5000\n",
      "Epoch 44/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7133 - accuracy: 0.5000\n",
      "Epoch 45/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7129 - accuracy: 0.5000\n",
      "Epoch 46/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7125 - accuracy: 0.5000\n",
      "Epoch 47/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7122 - accuracy: 0.5000\n",
      "Epoch 48/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "Epoch 49/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7114 - accuracy: 0.5000\n",
      "Epoch 50/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7110 - accuracy: 0.5000\n",
      "Epoch 51/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7106 - accuracy: 0.5000\n",
      "Epoch 52/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7102 - accuracy: 0.5000\n",
      "Epoch 53/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7099 - accuracy: 0.5000\n",
      "Epoch 54/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7095 - accuracy: 0.5000\n",
      "Epoch 55/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7091 - accuracy: 0.5000\n",
      "Epoch 56/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7087 - accuracy: 0.5000\n",
      "Epoch 57/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7084 - accuracy: 0.5000\n",
      "Epoch 58/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7080 - accuracy: 0.5000\n",
      "Epoch 59/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7076 - accuracy: 0.5000\n",
      "Epoch 60/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7072 - accuracy: 0.5000\n",
      "Epoch 61/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7069 - accuracy: 0.5000\n",
      "Epoch 62/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.5000\n",
      "Epoch 63/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7061 - accuracy: 0.5000\n",
      "Epoch 64/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7058 - accuracy: 0.5000\n",
      "Epoch 65/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7054 - accuracy: 0.5000\n",
      "Epoch 66/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7050 - accuracy: 0.5000\n",
      "Epoch 67/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7047 - accuracy: 0.5000\n",
      "Epoch 68/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "Epoch 69/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7040 - accuracy: 0.5000\n",
      "Epoch 70/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7036 - accuracy: 0.5000\n",
      "Epoch 71/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7032 - accuracy: 0.5000\n",
      "Epoch 72/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7029 - accuracy: 0.5000\n",
      "Epoch 73/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 74/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7022 - accuracy: 0.5000\n",
      "Epoch 75/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7018 - accuracy: 0.5000\n",
      "Epoch 76/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7015 - accuracy: 0.5000\n",
      "Epoch 77/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7011 - accuracy: 0.5000\n",
      "Epoch 78/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7008 - accuracy: 0.5000\n",
      "Epoch 79/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7004 - accuracy: 0.5000\n",
      "Epoch 80/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7001 - accuracy: 0.5000\n",
      "Epoch 81/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6997 - accuracy: 0.5000\n",
      "Epoch 82/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6994 - accuracy: 0.5000\n",
      "Epoch 83/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.5000\n",
      "Epoch 84/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6987 - accuracy: 0.5000\n",
      "Epoch 85/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6983 - accuracy: 0.5000\n",
      "Epoch 86/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6980 - accuracy: 0.5000\n",
      "Epoch 87/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6977 - accuracy: 0.5000\n",
      "Epoch 88/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6973 - accuracy: 0.5000\n",
      "Epoch 89/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6970 - accuracy: 0.5000\n",
      "Epoch 90/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6966 - accuracy: 0.5000\n",
      "Epoch 91/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6963 - accuracy: 0.5000\n",
      "Epoch 92/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6960 - accuracy: 0.5000\n",
      "Epoch 93/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6956 - accuracy: 0.5000\n",
      "Epoch 94/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6953 - accuracy: 0.5000\n",
      "Epoch 95/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6950 - accuracy: 0.5000\n",
      "Epoch 96/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6946 - accuracy: 0.5000\n",
      "Epoch 97/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6943 - accuracy: 0.5000\n",
      "Epoch 98/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6940 - accuracy: 0.5000\n",
      "Epoch 99/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6937 - accuracy: 0.5000\n",
      "Epoch 100/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 101/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6930 - accuracy: 0.5000\n",
      "Epoch 102/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.5000\n",
      "Epoch 103/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5000\n",
      "Epoch 104/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6920 - accuracy: 0.5000\n",
      "Epoch 105/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5000\n",
      "Epoch 106/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6914 - accuracy: 0.5000\n",
      "Epoch 107/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.5000\n",
      "Epoch 108/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6908 - accuracy: 0.5000\n",
      "Epoch 109/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.5000\n",
      "Epoch 110/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6901 - accuracy: 0.5000\n",
      "Epoch 111/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5000\n",
      "Epoch 112/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5000\n",
      "Epoch 113/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5000\n",
      "Epoch 114/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 0.5000\n",
      "Epoch 115/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6886 - accuracy: 0.5000\n",
      "Epoch 116/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6883 - accuracy: 0.5000\n",
      "Epoch 117/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6880 - accuracy: 0.5000\n",
      "Epoch 118/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6877 - accuracy: 0.5000\n",
      "Epoch 119/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6874 - accuracy: 0.5000\n",
      "Epoch 120/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6871 - accuracy: 0.5000\n",
      "Epoch 121/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6868 - accuracy: 0.5000\n",
      "Epoch 122/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6865 - accuracy: 0.5000\n",
      "Epoch 123/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6862 - accuracy: 0.5000\n",
      "Epoch 124/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6859 - accuracy: 0.5000\n",
      "Epoch 125/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6856 - accuracy: 0.5000\n",
      "Epoch 126/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6853 - accuracy: 0.5000\n",
      "Epoch 127/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6850 - accuracy: 0.5000\n",
      "Epoch 128/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6847 - accuracy: 0.5000\n",
      "Epoch 129/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6844 - accuracy: 0.5000\n",
      "Epoch 130/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6841 - accuracy: 0.5000\n",
      "Epoch 131/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.5000\n",
      "Epoch 132/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6835 - accuracy: 0.5000\n",
      "Epoch 133/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6832 - accuracy: 0.5000\n",
      "Epoch 134/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6829 - accuracy: 0.5000\n",
      "Epoch 135/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6826 - accuracy: 0.5000\n",
      "Epoch 136/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6824 - accuracy: 0.5000\n",
      "Epoch 137/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6821 - accuracy: 0.5000\n",
      "Epoch 138/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6818 - accuracy: 0.5000\n",
      "Epoch 139/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6815 - accuracy: 0.5000\n",
      "Epoch 140/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6812 - accuracy: 0.5000\n",
      "Epoch 141/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6809 - accuracy: 0.5000\n",
      "Epoch 142/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6807 - accuracy: 0.5000\n",
      "Epoch 143/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6804 - accuracy: 0.5000\n",
      "Epoch 144/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6801 - accuracy: 0.5000\n",
      "Epoch 145/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6798 - accuracy: 0.5000\n",
      "Epoch 146/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.5000\n",
      "Epoch 147/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6793 - accuracy: 0.5000\n",
      "Epoch 148/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6790 - accuracy: 0.5000\n",
      "Epoch 149/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6787 - accuracy: 0.5000\n",
      "Epoch 150/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6785 - accuracy: 0.5000\n",
      "Epoch 151/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6782 - accuracy: 0.5000\n",
      "Epoch 152/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6779 - accuracy: 0.5000\n",
      "Epoch 153/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.5000\n",
      "Epoch 154/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6774 - accuracy: 0.5000\n",
      "Epoch 155/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6771 - accuracy: 0.5000\n",
      "Epoch 156/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.5000\n",
      "Epoch 157/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6766 - accuracy: 0.5000\n",
      "Epoch 158/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6763 - accuracy: 0.5000\n",
      "Epoch 159/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6761 - accuracy: 0.5000\n",
      "Epoch 160/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6758 - accuracy: 0.5000\n",
      "Epoch 161/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6755 - accuracy: 0.5000\n",
      "Epoch 162/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6753 - accuracy: 0.5000\n",
      "Epoch 163/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6750 - accuracy: 0.5000\n",
      "Epoch 164/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6748 - accuracy: 0.5000\n",
      "Epoch 165/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6745 - accuracy: 0.5000\n",
      "Epoch 166/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6743 - accuracy: 0.5000\n",
      "Epoch 167/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6740 - accuracy: 0.5000\n",
      "Epoch 168/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6738 - accuracy: 0.5000\n",
      "Epoch 169/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6735 - accuracy: 0.5000\n",
      "Epoch 170/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6733 - accuracy: 0.5000\n",
      "Epoch 171/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6730 - accuracy: 0.5000\n",
      "Epoch 172/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.5455\n",
      "Epoch 173/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6725 - accuracy: 0.5455\n",
      "Epoch 174/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6723 - accuracy: 0.5455\n",
      "Epoch 175/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6720 - accuracy: 0.5455\n",
      "Epoch 176/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6718 - accuracy: 0.5455\n",
      "Epoch 177/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6715 - accuracy: 0.5455\n",
      "Epoch 178/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6713 - accuracy: 0.5455\n",
      "Epoch 179/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6710 - accuracy: 0.5455\n",
      "Epoch 180/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6708 - accuracy: 0.5455\n",
      "Epoch 181/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6706 - accuracy: 0.5455\n",
      "Epoch 182/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6703 - accuracy: 0.5455\n",
      "Epoch 183/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6701 - accuracy: 0.5455\n",
      "Epoch 184/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6698 - accuracy: 0.5455\n",
      "Epoch 185/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6696 - accuracy: 0.5455\n",
      "Epoch 186/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6694 - accuracy: 0.5455\n",
      "Epoch 187/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6691 - accuracy: 0.5455\n",
      "Epoch 188/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6689 - accuracy: 0.5455\n",
      "Epoch 189/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.5455\n",
      "Epoch 190/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6684 - accuracy: 0.5455\n",
      "Epoch 191/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6682 - accuracy: 0.5455\n",
      "Epoch 192/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6680 - accuracy: 0.5455\n",
      "Epoch 193/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6678 - accuracy: 0.5455\n",
      "Epoch 194/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6675 - accuracy: 0.5455\n",
      "Epoch 195/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6673 - accuracy: 0.5455\n",
      "Epoch 196/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6671 - accuracy: 0.5455\n",
      "Epoch 197/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6669 - accuracy: 0.5455\n",
      "Epoch 198/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6666 - accuracy: 0.5455\n",
      "Epoch 199/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6664 - accuracy: 0.5455\n",
      "Epoch 200/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6662 - accuracy: 0.5455\n",
      "Epoch 201/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6660 - accuracy: 0.5455\n",
      "Epoch 202/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6657 - accuracy: 0.5455\n",
      "Epoch 203/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6655 - accuracy: 0.5455\n",
      "Epoch 204/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6653 - accuracy: 0.5455\n",
      "Epoch 205/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6651 - accuracy: 0.5455\n",
      "Epoch 206/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6649 - accuracy: 0.5455\n",
      "Epoch 207/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6647 - accuracy: 0.5455\n",
      "Epoch 208/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6645 - accuracy: 0.5455\n",
      "Epoch 209/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6642 - accuracy: 0.5455\n",
      "Epoch 210/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6640 - accuracy: 0.5455\n",
      "Epoch 211/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6638 - accuracy: 0.5455\n",
      "Epoch 212/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6636 - accuracy: 0.5455\n",
      "Epoch 213/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6634 - accuracy: 0.5455\n",
      "Epoch 214/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6632 - accuracy: 0.5455\n",
      "Epoch 215/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6630 - accuracy: 0.5455\n",
      "Epoch 216/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6628 - accuracy: 0.5455\n",
      "Epoch 217/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6626 - accuracy: 0.5455\n",
      "Epoch 218/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6624 - accuracy: 0.5455\n",
      "Epoch 219/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6622 - accuracy: 0.5455\n",
      "Epoch 220/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6620 - accuracy: 0.5455\n",
      "Epoch 221/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6617 - accuracy: 0.5455\n",
      "Epoch 222/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6615 - accuracy: 0.5455\n",
      "Epoch 223/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6613 - accuracy: 0.5455\n",
      "Epoch 224/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6611 - accuracy: 0.5455\n",
      "Epoch 225/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6609 - accuracy: 0.5455\n",
      "Epoch 226/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6608 - accuracy: 0.5455\n",
      "Epoch 227/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6606 - accuracy: 0.5455\n",
      "Epoch 228/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6604 - accuracy: 0.5455\n",
      "Epoch 229/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6602 - accuracy: 0.5455\n",
      "Epoch 230/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6600 - accuracy: 0.5455\n",
      "Epoch 231/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6598 - accuracy: 0.5455\n",
      "Epoch 232/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6596 - accuracy: 0.5455\n",
      "Epoch 233/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6594 - accuracy: 0.5455\n",
      "Epoch 234/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.5455\n",
      "Epoch 235/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6590 - accuracy: 0.5455\n",
      "Epoch 236/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6588 - accuracy: 0.5455\n",
      "Epoch 237/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6586 - accuracy: 0.5455\n",
      "Epoch 238/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6584 - accuracy: 0.5909\n",
      "Epoch 239/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6583 - accuracy: 0.5909\n",
      "Epoch 240/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6581 - accuracy: 0.5909\n",
      "Epoch 241/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6579 - accuracy: 0.5909\n",
      "Epoch 242/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6577 - accuracy: 0.5909\n",
      "Epoch 243/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6575 - accuracy: 0.5909\n",
      "Epoch 244/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6573 - accuracy: 0.5909\n",
      "Epoch 245/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6571 - accuracy: 0.5909\n",
      "Epoch 246/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6570 - accuracy: 0.5909\n",
      "Epoch 247/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6568 - accuracy: 0.5909\n",
      "Epoch 248/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6566 - accuracy: 0.5909\n",
      "Epoch 249/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6564 - accuracy: 0.5909\n",
      "Epoch 250/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6563 - accuracy: 0.5909\n",
      "Epoch 251/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6561 - accuracy: 0.5909\n",
      "Epoch 252/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6559 - accuracy: 0.5909\n",
      "Epoch 253/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6557 - accuracy: 0.5909\n",
      "Epoch 254/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6555 - accuracy: 0.5909\n",
      "Epoch 255/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6554 - accuracy: 0.5909\n",
      "Epoch 256/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6552 - accuracy: 0.5909\n",
      "Epoch 257/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6550 - accuracy: 0.5909\n",
      "Epoch 258/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6549 - accuracy: 0.5909\n",
      "Epoch 259/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6547 - accuracy: 0.5909\n",
      "Epoch 260/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6545 - accuracy: 0.5909\n",
      "Epoch 261/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6543 - accuracy: 0.5909\n",
      "Epoch 262/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6542 - accuracy: 0.5909\n",
      "Epoch 263/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6540 - accuracy: 0.5909\n",
      "Epoch 264/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6538 - accuracy: 0.5909\n",
      "Epoch 265/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6537 - accuracy: 0.5909\n",
      "Epoch 266/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6535 - accuracy: 0.5909\n",
      "Epoch 267/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6533 - accuracy: 0.5909\n",
      "Epoch 268/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6532 - accuracy: 0.5909\n",
      "Epoch 269/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6530 - accuracy: 0.5909\n",
      "Epoch 270/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6529 - accuracy: 0.5909\n",
      "Epoch 271/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6527 - accuracy: 0.5909\n",
      "Epoch 272/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6525 - accuracy: 0.5909\n",
      "Epoch 273/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6524 - accuracy: 0.5909\n",
      "Epoch 274/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6522 - accuracy: 0.5909\n",
      "Epoch 275/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6521 - accuracy: 0.5909\n",
      "Epoch 276/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6519 - accuracy: 0.5909\n",
      "Epoch 277/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6517 - accuracy: 0.5909\n",
      "Epoch 278/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.5909\n",
      "Epoch 279/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6514 - accuracy: 0.5909\n",
      "Epoch 280/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6513 - accuracy: 0.5909\n",
      "Epoch 281/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6511 - accuracy: 0.5909\n",
      "Epoch 282/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6510 - accuracy: 0.5909\n",
      "Epoch 283/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6508 - accuracy: 0.5909\n",
      "Epoch 284/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6507 - accuracy: 0.5909\n",
      "Epoch 285/5000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6505 - accuracy: 0.5909\n",
      "Epoch 286/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6504 - accuracy: 0.5909\n",
      "Epoch 287/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6502 - accuracy: 0.5909\n",
      "Epoch 288/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6501 - accuracy: 0.5909\n",
      "Epoch 289/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6499 - accuracy: 0.5909\n",
      "Epoch 290/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6498 - accuracy: 0.5909\n",
      "Epoch 291/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6496 - accuracy: 0.5909\n",
      "Epoch 292/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6495 - accuracy: 0.5909\n",
      "Epoch 293/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6493 - accuracy: 0.5909\n",
      "Epoch 294/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6492 - accuracy: 0.5909\n",
      "Epoch 295/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 0.5909\n",
      "Epoch 296/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6489 - accuracy: 0.5909\n",
      "Epoch 297/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6488 - accuracy: 0.5909\n",
      "Epoch 298/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6486 - accuracy: 0.5909\n",
      "Epoch 299/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6485 - accuracy: 0.5909\n",
      "Epoch 300/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6483 - accuracy: 0.5909\n",
      "Epoch 301/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6482 - accuracy: 0.5909\n",
      "Epoch 302/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6481 - accuracy: 0.5909\n",
      "Epoch 303/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6479 - accuracy: 0.5909\n",
      "Epoch 304/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6478 - accuracy: 0.5909\n",
      "Epoch 305/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6476 - accuracy: 0.5909\n",
      "Epoch 306/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6475 - accuracy: 0.5909\n",
      "Epoch 307/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6474 - accuracy: 0.5909\n",
      "Epoch 308/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6472 - accuracy: 0.5909\n",
      "Epoch 309/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6471 - accuracy: 0.5909\n",
      "Epoch 310/5000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6470 - accuracy: 0.5909\n",
      "Epoch 311/5000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6468 - accuracy: 0.5909\n",
      "Epoch 312/5000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6467 - accuracy: 0.5909\n",
      "Epoch 313/5000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6466 - accuracy: 0.5909\n",
      "Epoch 314/5000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6464 - accuracy: 0.5909\n",
      "Epoch 315/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6463 - accuracy: 0.5909\n",
      "Epoch 316/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6462 - accuracy: 0.5909\n",
      "Epoch 317/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6460 - accuracy: 0.5909\n",
      "Epoch 318/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.5909\n",
      "Epoch 319/5000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6458 - accuracy: 0.5909\n",
      "Epoch 320/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.5909\n",
      "Epoch 321/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6455 - accuracy: 0.5909\n",
      "Epoch 322/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.5909\n",
      "Epoch 323/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.5909\n",
      "Epoch 324/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6451 - accuracy: 0.5909\n",
      "Epoch 325/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6450 - accuracy: 0.5909\n",
      "Epoch 326/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6449 - accuracy: 0.5909\n",
      "Epoch 327/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6448 - accuracy: 0.5909\n",
      "Epoch 328/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6446 - accuracy: 0.5909\n",
      "Epoch 329/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.6445 - accuracy: 0.5909\n",
      "Epoch 330/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6444 - accuracy: 0.5909\n",
      "Epoch 331/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6443 - accuracy: 0.5909\n",
      "Epoch 332/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6442 - accuracy: 0.5909\n",
      "Epoch 333/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6440 - accuracy: 0.5909\n",
      "Epoch 334/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6439 - accuracy: 0.5909\n",
      "Epoch 335/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6438 - accuracy: 0.5909\n",
      "Epoch 336/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6437 - accuracy: 0.5909\n",
      "Epoch 337/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.5909\n",
      "Epoch 338/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6434 - accuracy: 0.5909\n",
      "Epoch 339/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6433 - accuracy: 0.5909\n",
      "Epoch 340/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6432 - accuracy: 0.5909\n",
      "Epoch 341/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6431 - accuracy: 0.5909\n",
      "Epoch 342/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6430 - accuracy: 0.5909\n",
      "Epoch 343/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6429 - accuracy: 0.5909\n",
      "Epoch 344/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6428 - accuracy: 0.5909\n",
      "Epoch 345/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6426 - accuracy: 0.5909\n",
      "Epoch 346/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6425 - accuracy: 0.5909\n",
      "Epoch 347/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6424 - accuracy: 0.5909\n",
      "Epoch 348/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6423 - accuracy: 0.5909\n",
      "Epoch 349/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6422 - accuracy: 0.5909\n",
      "Epoch 350/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6421 - accuracy: 0.5909\n",
      "Epoch 351/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6420 - accuracy: 0.5909\n",
      "Epoch 352/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6419 - accuracy: 0.5909\n",
      "Epoch 353/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6417 - accuracy: 0.5909\n",
      "Epoch 354/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6416 - accuracy: 0.5909\n",
      "Epoch 355/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6415 - accuracy: 0.5909\n",
      "Epoch 356/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6414 - accuracy: 0.5909\n",
      "Epoch 357/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6413 - accuracy: 0.5909\n",
      "Epoch 358/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6412 - accuracy: 0.5909\n",
      "Epoch 359/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6411 - accuracy: 0.5909\n",
      "Epoch 360/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.5909\n",
      "Epoch 361/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6409 - accuracy: 0.5909\n",
      "Epoch 362/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6408 - accuracy: 0.5909\n",
      "Epoch 363/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6407 - accuracy: 0.5909\n",
      "Epoch 364/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6406 - accuracy: 0.5909\n",
      "Epoch 365/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.5909\n",
      "Epoch 366/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6404 - accuracy: 0.5909\n",
      "Epoch 367/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6403 - accuracy: 0.5909\n",
      "Epoch 368/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6402 - accuracy: 0.5909\n",
      "Epoch 369/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.5909\n",
      "Epoch 370/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6400 - accuracy: 0.5909\n",
      "Epoch 371/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6399 - accuracy: 0.5909\n",
      "Epoch 372/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6398 - accuracy: 0.5909\n",
      "Epoch 373/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6397 - accuracy: 0.5909\n",
      "Epoch 374/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6396 - accuracy: 0.5909\n",
      "Epoch 375/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6395 - accuracy: 0.5909\n",
      "Epoch 376/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6394 - accuracy: 0.5909\n",
      "Epoch 377/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6393 - accuracy: 0.5909\n",
      "Epoch 378/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6392 - accuracy: 0.5909\n",
      "Epoch 379/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6391 - accuracy: 0.5909\n",
      "Epoch 380/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6390 - accuracy: 0.5909\n",
      "Epoch 381/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6389 - accuracy: 0.5909\n",
      "Epoch 382/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6388 - accuracy: 0.5909\n",
      "Epoch 383/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6387 - accuracy: 0.5909\n",
      "Epoch 384/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6386 - accuracy: 0.5909\n",
      "Epoch 385/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6385 - accuracy: 0.5909\n",
      "Epoch 386/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6384 - accuracy: 0.5909\n",
      "Epoch 387/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6383 - accuracy: 0.5909\n",
      "Epoch 388/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6382 - accuracy: 0.5909\n",
      "Epoch 389/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6381 - accuracy: 0.5909\n",
      "Epoch 390/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6380 - accuracy: 0.5909\n",
      "Epoch 391/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6380 - accuracy: 0.5909\n",
      "Epoch 392/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.5909\n",
      "Epoch 393/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6378 - accuracy: 0.5909\n",
      "Epoch 394/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6377 - accuracy: 0.5909\n",
      "Epoch 395/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6376 - accuracy: 0.5909\n",
      "Epoch 396/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6375 - accuracy: 0.5909\n",
      "Epoch 397/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.5909\n",
      "Epoch 398/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6373 - accuracy: 0.5909\n",
      "Epoch 399/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6372 - accuracy: 0.5909\n",
      "Epoch 400/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6372 - accuracy: 0.5909\n",
      "Epoch 401/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6371 - accuracy: 0.5909\n",
      "Epoch 402/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6370 - accuracy: 0.5909\n",
      "Epoch 403/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6369 - accuracy: 0.5909\n",
      "Epoch 404/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6368 - accuracy: 0.5909\n",
      "Epoch 405/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6367 - accuracy: 0.5909\n",
      "Epoch 406/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6366 - accuracy: 0.5909\n",
      "Epoch 407/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6365 - accuracy: 0.5909\n",
      "Epoch 408/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6365 - accuracy: 0.5909\n",
      "Epoch 409/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6364 - accuracy: 0.5909\n",
      "Epoch 410/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6363 - accuracy: 0.5909\n",
      "Epoch 411/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6362 - accuracy: 0.5909\n",
      "Epoch 412/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6361 - accuracy: 0.5909\n",
      "Epoch 413/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6360 - accuracy: 0.5909\n",
      "Epoch 414/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6360 - accuracy: 0.5909\n",
      "Epoch 415/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6359 - accuracy: 0.5909\n",
      "Epoch 416/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6358 - accuracy: 0.5909\n",
      "Epoch 417/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6357 - accuracy: 0.5909\n",
      "Epoch 418/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6356 - accuracy: 0.5909\n",
      "Epoch 419/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6356 - accuracy: 0.5909\n",
      "Epoch 420/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6355 - accuracy: 0.5909\n",
      "Epoch 421/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6354 - accuracy: 0.5909\n",
      "Epoch 422/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6353 - accuracy: 0.5909\n",
      "Epoch 423/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.5909\n",
      "Epoch 424/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6352 - accuracy: 0.5909\n",
      "Epoch 425/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6351 - accuracy: 0.5909\n",
      "Epoch 426/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6350 - accuracy: 0.5909\n",
      "Epoch 427/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6349 - accuracy: 0.5909\n",
      "Epoch 428/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6348 - accuracy: 0.5909\n",
      "Epoch 429/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6348 - accuracy: 0.5909\n",
      "Epoch 430/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6347 - accuracy: 0.5909\n",
      "Epoch 431/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.5909\n",
      "Epoch 432/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.5909\n",
      "Epoch 433/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.5909\n",
      "Epoch 434/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6344 - accuracy: 0.5909\n",
      "Epoch 435/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6343 - accuracy: 0.5909\n",
      "Epoch 436/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6342 - accuracy: 0.5909\n",
      "Epoch 437/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6342 - accuracy: 0.5909\n",
      "Epoch 438/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6341 - accuracy: 0.5909\n",
      "Epoch 439/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6340 - accuracy: 0.5909\n",
      "Epoch 440/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6339 - accuracy: 0.5909\n",
      "Epoch 441/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6339 - accuracy: 0.5909\n",
      "Epoch 442/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6338 - accuracy: 0.5909\n",
      "Epoch 443/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6337 - accuracy: 0.5909\n",
      "Epoch 444/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.5909\n",
      "Epoch 445/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.5909\n",
      "Epoch 446/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6335 - accuracy: 0.5909\n",
      "Epoch 447/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6334 - accuracy: 0.5909\n",
      "Epoch 448/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6334 - accuracy: 0.5909\n",
      "Epoch 449/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6333 - accuracy: 0.5909\n",
      "Epoch 450/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6332 - accuracy: 0.5909\n",
      "Epoch 451/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6331 - accuracy: 0.5909\n",
      "Epoch 452/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6331 - accuracy: 0.5909\n",
      "Epoch 453/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6330 - accuracy: 0.5909\n",
      "Epoch 454/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6329 - accuracy: 0.5909\n",
      "Epoch 455/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6329 - accuracy: 0.5909\n",
      "Epoch 456/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6328 - accuracy: 0.5909\n",
      "Epoch 457/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6327 - accuracy: 0.5909\n",
      "Epoch 458/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6327 - accuracy: 0.5909\n",
      "Epoch 459/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6326 - accuracy: 0.5909\n",
      "Epoch 460/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6325 - accuracy: 0.5909\n",
      "Epoch 461/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6325 - accuracy: 0.5909\n",
      "Epoch 462/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6324 - accuracy: 0.5909\n",
      "Epoch 463/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6323 - accuracy: 0.5909\n",
      "Epoch 464/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6323 - accuracy: 0.5909\n",
      "Epoch 465/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6322 - accuracy: 0.5909\n",
      "Epoch 466/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6321 - accuracy: 0.5909\n",
      "Epoch 467/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6321 - accuracy: 0.5909\n",
      "Epoch 468/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6320 - accuracy: 0.5909\n",
      "Epoch 469/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6319 - accuracy: 0.5909\n",
      "Epoch 470/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6319 - accuracy: 0.5909\n",
      "Epoch 471/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6318 - accuracy: 0.6364\n",
      "Epoch 472/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6364\n",
      "Epoch 473/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.6364\n",
      "Epoch 474/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6316 - accuracy: 0.6364\n",
      "Epoch 475/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6315 - accuracy: 0.6364\n",
      "Epoch 476/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6315 - accuracy: 0.6364\n",
      "Epoch 477/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6314 - accuracy: 0.6364\n",
      "Epoch 478/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6313 - accuracy: 0.6364\n",
      "Epoch 479/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6313 - accuracy: 0.6364\n",
      "Epoch 480/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 481/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6312 - accuracy: 0.6364\n",
      "Epoch 482/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6311 - accuracy: 0.6364\n",
      "Epoch 483/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6310 - accuracy: 0.6364\n",
      "Epoch 484/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6310 - accuracy: 0.6364\n",
      "Epoch 485/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6309 - accuracy: 0.6364\n",
      "Epoch 486/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6308 - accuracy: 0.6364\n",
      "Epoch 487/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6308 - accuracy: 0.6364\n",
      "Epoch 488/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 489/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6307 - accuracy: 0.6364\n",
      "Epoch 490/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6306 - accuracy: 0.6364\n",
      "Epoch 491/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6305 - accuracy: 0.6364\n",
      "Epoch 492/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6305 - accuracy: 0.6364\n",
      "Epoch 493/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.6364\n",
      "Epoch 494/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.6364\n",
      "Epoch 495/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6303 - accuracy: 0.6364\n",
      "Epoch 496/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6302 - accuracy: 0.6364\n",
      "Epoch 497/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6302 - accuracy: 0.6364\n",
      "Epoch 498/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6301 - accuracy: 0.6364\n",
      "Epoch 499/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6301 - accuracy: 0.6364\n",
      "Epoch 500/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6300 - accuracy: 0.6364\n",
      "Epoch 501/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6299 - accuracy: 0.6364\n",
      "Epoch 502/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6299 - accuracy: 0.6364\n",
      "Epoch 503/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6298 - accuracy: 0.6364\n",
      "Epoch 504/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6298 - accuracy: 0.6364\n",
      "Epoch 505/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6297 - accuracy: 0.6364\n",
      "Epoch 506/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 507/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6296 - accuracy: 0.6364\n",
      "Epoch 508/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6295 - accuracy: 0.6364\n",
      "Epoch 509/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6295 - accuracy: 0.6364\n",
      "Epoch 510/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6294 - accuracy: 0.6818\n",
      "Epoch 511/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6294 - accuracy: 0.6818\n",
      "Epoch 512/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6293 - accuracy: 0.6818\n",
      "Epoch 513/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6292 - accuracy: 0.6818\n",
      "Epoch 514/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6292 - accuracy: 0.6818\n",
      "Epoch 515/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6291 - accuracy: 0.6818\n",
      "Epoch 516/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6291 - accuracy: 0.6818\n",
      "Epoch 517/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6290 - accuracy: 0.6818\n",
      "Epoch 518/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6290 - accuracy: 0.6818\n",
      "Epoch 519/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6289 - accuracy: 0.6818\n",
      "Epoch 520/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6288 - accuracy: 0.6818\n",
      "Epoch 521/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6288 - accuracy: 0.6818\n",
      "Epoch 522/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6287 - accuracy: 0.6818\n",
      "Epoch 523/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6287 - accuracy: 0.6818\n",
      "Epoch 524/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6286 - accuracy: 0.6818\n",
      "Epoch 525/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6286 - accuracy: 0.6818\n",
      "Epoch 526/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6285 - accuracy: 0.6818\n",
      "Epoch 527/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6285 - accuracy: 0.6818\n",
      "Epoch 528/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6284 - accuracy: 0.6818\n",
      "Epoch 529/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6284 - accuracy: 0.6818\n",
      "Epoch 530/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.6818\n",
      "Epoch 531/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6282 - accuracy: 0.6818\n",
      "Epoch 532/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6282 - accuracy: 0.6818\n",
      "Epoch 533/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6281 - accuracy: 0.6818\n",
      "Epoch 534/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6281 - accuracy: 0.6818\n",
      "Epoch 535/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6280 - accuracy: 0.6818\n",
      "Epoch 536/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6280 - accuracy: 0.6818\n",
      "Epoch 537/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6279 - accuracy: 0.6818\n",
      "Epoch 538/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6279 - accuracy: 0.6818\n",
      "Epoch 539/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6278 - accuracy: 0.6818\n",
      "Epoch 540/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6278 - accuracy: 0.6818\n",
      "Epoch 541/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.6818\n",
      "Epoch 542/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.6818\n",
      "Epoch 543/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.6818\n",
      "Epoch 544/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.6818\n",
      "Epoch 545/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6275 - accuracy: 0.6818\n",
      "Epoch 546/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6275 - accuracy: 0.6818\n",
      "Epoch 547/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6274 - accuracy: 0.6818\n",
      "Epoch 548/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6273 - accuracy: 0.6818\n",
      "Epoch 549/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6273 - accuracy: 0.6818\n",
      "Epoch 550/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6272 - accuracy: 0.6818\n",
      "Epoch 551/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6272 - accuracy: 0.6818\n",
      "Epoch 552/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6271 - accuracy: 0.6818\n",
      "Epoch 553/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6271 - accuracy: 0.6818\n",
      "Epoch 554/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6270 - accuracy: 0.6818\n",
      "Epoch 555/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6270 - accuracy: 0.6818\n",
      "Epoch 556/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6269 - accuracy: 0.6818\n",
      "Epoch 557/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6269 - accuracy: 0.6818\n",
      "Epoch 558/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6268 - accuracy: 0.6818\n",
      "Epoch 559/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6268 - accuracy: 0.6818\n",
      "Epoch 560/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6267 - accuracy: 0.6818\n",
      "Epoch 561/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6267 - accuracy: 0.6818\n",
      "Epoch 562/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.6818\n",
      "Epoch 563/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.6818\n",
      "Epoch 564/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6265 - accuracy: 0.6818\n",
      "Epoch 565/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6265 - accuracy: 0.6818\n",
      "Epoch 566/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6264 - accuracy: 0.6818\n",
      "Epoch 567/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6264 - accuracy: 0.6818\n",
      "Epoch 568/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6263 - accuracy: 0.6818\n",
      "Epoch 569/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6263 - accuracy: 0.6818\n",
      "Epoch 570/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6262 - accuracy: 0.6818\n",
      "Epoch 571/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6262 - accuracy: 0.6818\n",
      "Epoch 572/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6261 - accuracy: 0.6818\n",
      "Epoch 573/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6261 - accuracy: 0.6818\n",
      "Epoch 574/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6260 - accuracy: 0.6818\n",
      "Epoch 575/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6260 - accuracy: 0.6818\n",
      "Epoch 576/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.6818\n",
      "Epoch 577/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.6818\n",
      "Epoch 578/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6258 - accuracy: 0.6818\n",
      "Epoch 579/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6258 - accuracy: 0.6818\n",
      "Epoch 580/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6257 - accuracy: 0.6818\n",
      "Epoch 581/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6257 - accuracy: 0.6818\n",
      "Epoch 582/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6256 - accuracy: 0.6818\n",
      "Epoch 583/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6256 - accuracy: 0.6818\n",
      "Epoch 584/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6255 - accuracy: 0.6818\n",
      "Epoch 585/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6255 - accuracy: 0.6818\n",
      "Epoch 586/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6255 - accuracy: 0.6818\n",
      "Epoch 587/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6254 - accuracy: 0.6818\n",
      "Epoch 588/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6254 - accuracy: 0.6818\n",
      "Epoch 589/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6253 - accuracy: 0.6818\n",
      "Epoch 590/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6253 - accuracy: 0.6818\n",
      "Epoch 591/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6252 - accuracy: 0.6818\n",
      "Epoch 592/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6252 - accuracy: 0.6818\n",
      "Epoch 593/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6251 - accuracy: 0.6818\n",
      "Epoch 594/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6251 - accuracy: 0.6818\n",
      "Epoch 595/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6250 - accuracy: 0.6818\n",
      "Epoch 596/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6250 - accuracy: 0.6818\n",
      "Epoch 597/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6249 - accuracy: 0.6818\n",
      "Epoch 598/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6249 - accuracy: 0.6818\n",
      "Epoch 599/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6248 - accuracy: 0.6818\n",
      "Epoch 600/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6248 - accuracy: 0.6818\n",
      "Epoch 601/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6247 - accuracy: 0.6818\n",
      "Epoch 602/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6247 - accuracy: 0.6818\n",
      "Epoch 603/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6246 - accuracy: 0.6818\n",
      "Epoch 604/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6246 - accuracy: 0.6818\n",
      "Epoch 605/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6246 - accuracy: 0.6818\n",
      "Epoch 606/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6245 - accuracy: 0.6818\n",
      "Epoch 607/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6245 - accuracy: 0.6818\n",
      "Epoch 608/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6818\n",
      "Epoch 609/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6818\n",
      "Epoch 610/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6243 - accuracy: 0.6818\n",
      "Epoch 611/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6243 - accuracy: 0.6818\n",
      "Epoch 612/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.6818\n",
      "Epoch 613/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.6818\n",
      "Epoch 614/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6241 - accuracy: 0.6818\n",
      "Epoch 615/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6241 - accuracy: 0.6818\n",
      "Epoch 616/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6240 - accuracy: 0.6818\n",
      "Epoch 617/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6240 - accuracy: 0.6818\n",
      "Epoch 618/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6239 - accuracy: 0.6818\n",
      "Epoch 619/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6239 - accuracy: 0.6818\n",
      "Epoch 620/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6239 - accuracy: 0.6818\n",
      "Epoch 621/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6238 - accuracy: 0.6818\n",
      "Epoch 622/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6238 - accuracy: 0.6818\n",
      "Epoch 623/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6237 - accuracy: 0.6818\n",
      "Epoch 624/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6237 - accuracy: 0.6818\n",
      "Epoch 625/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6236 - accuracy: 0.6818\n",
      "Epoch 626/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6236 - accuracy: 0.6818\n",
      "Epoch 627/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6235 - accuracy: 0.6818\n",
      "Epoch 628/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6235 - accuracy: 0.6818\n",
      "Epoch 629/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6234 - accuracy: 0.6818\n",
      "Epoch 630/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6234 - accuracy: 0.6818\n",
      "Epoch 631/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6234 - accuracy: 0.6818\n",
      "Epoch 632/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6233 - accuracy: 0.6818\n",
      "Epoch 633/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6233 - accuracy: 0.6818\n",
      "Epoch 634/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6232 - accuracy: 0.6818\n",
      "Epoch 635/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6232 - accuracy: 0.6818\n",
      "Epoch 636/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6231 - accuracy: 0.6818\n",
      "Epoch 637/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6231 - accuracy: 0.6818\n",
      "Epoch 638/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6230 - accuracy: 0.6818\n",
      "Epoch 639/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6230 - accuracy: 0.6818\n",
      "Epoch 640/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6229 - accuracy: 0.6818\n",
      "Epoch 641/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6229 - accuracy: 0.6818\n",
      "Epoch 642/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6229 - accuracy: 0.6818\n",
      "Epoch 643/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6228 - accuracy: 0.6818\n",
      "Epoch 644/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6228 - accuracy: 0.6818\n",
      "Epoch 645/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6227 - accuracy: 0.6818\n",
      "Epoch 646/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6227 - accuracy: 0.6818\n",
      "Epoch 647/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6226 - accuracy: 0.6818\n",
      "Epoch 648/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6226 - accuracy: 0.6818\n",
      "Epoch 649/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.6818\n",
      "Epoch 650/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.6818\n",
      "Epoch 651/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6224 - accuracy: 0.6818\n",
      "Epoch 652/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6224 - accuracy: 0.6818\n",
      "Epoch 653/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6224 - accuracy: 0.6818\n",
      "Epoch 654/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6223 - accuracy: 0.6818\n",
      "Epoch 655/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6223 - accuracy: 0.6818\n",
      "Epoch 656/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6222 - accuracy: 0.6818\n",
      "Epoch 657/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6222 - accuracy: 0.6818\n",
      "Epoch 658/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6221 - accuracy: 0.6818\n",
      "Epoch 659/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6221 - accuracy: 0.6818\n",
      "Epoch 660/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6220 - accuracy: 0.6818\n",
      "Epoch 661/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6220 - accuracy: 0.6818\n",
      "Epoch 662/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6220 - accuracy: 0.6818\n",
      "Epoch 663/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6219 - accuracy: 0.6818\n",
      "Epoch 664/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6219 - accuracy: 0.6818\n",
      "Epoch 665/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6218 - accuracy: 0.6818\n",
      "Epoch 666/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6218 - accuracy: 0.6818\n",
      "Epoch 667/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6217 - accuracy: 0.6818\n",
      "Epoch 668/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6217 - accuracy: 0.6818\n",
      "Epoch 669/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6216 - accuracy: 0.6818\n",
      "Epoch 670/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6216 - accuracy: 0.6818\n",
      "Epoch 671/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6216 - accuracy: 0.6818\n",
      "Epoch 672/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6215 - accuracy: 0.6818\n",
      "Epoch 673/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6215 - accuracy: 0.6818\n",
      "Epoch 674/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6214 - accuracy: 0.6818\n",
      "Epoch 675/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6214 - accuracy: 0.6818\n",
      "Epoch 676/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6213 - accuracy: 0.6818\n",
      "Epoch 677/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6213 - accuracy: 0.6818\n",
      "Epoch 678/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6212 - accuracy: 0.6818\n",
      "Epoch 679/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6212 - accuracy: 0.6818\n",
      "Epoch 680/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6212 - accuracy: 0.6818\n",
      "Epoch 681/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6211 - accuracy: 0.6818\n",
      "Epoch 682/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6211 - accuracy: 0.6818\n",
      "Epoch 683/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.6818\n",
      "Epoch 684/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6210 - accuracy: 0.6818\n",
      "Epoch 685/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6209 - accuracy: 0.6818\n",
      "Epoch 686/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6209 - accuracy: 0.6818\n",
      "Epoch 687/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6209 - accuracy: 0.6818\n",
      "Epoch 688/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6208 - accuracy: 0.6818\n",
      "Epoch 689/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6208 - accuracy: 0.6818\n",
      "Epoch 690/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6207 - accuracy: 0.6818\n",
      "Epoch 691/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6207 - accuracy: 0.6818\n",
      "Epoch 692/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6818\n",
      "Epoch 693/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6818\n",
      "Epoch 694/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6818\n",
      "Epoch 695/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6818\n",
      "Epoch 696/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6818\n",
      "Epoch 697/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6204 - accuracy: 0.6818\n",
      "Epoch 698/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6204 - accuracy: 0.6818\n",
      "Epoch 699/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6203 - accuracy: 0.6818\n",
      "Epoch 700/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6203 - accuracy: 0.6818\n",
      "Epoch 701/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6202 - accuracy: 0.6818\n",
      "Epoch 702/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6202 - accuracy: 0.6818\n",
      "Epoch 703/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6202 - accuracy: 0.6818\n",
      "Epoch 704/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6201 - accuracy: 0.6818\n",
      "Epoch 705/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6201 - accuracy: 0.6818\n",
      "Epoch 706/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6200 - accuracy: 0.6818\n",
      "Epoch 707/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6200 - accuracy: 0.6818\n",
      "Epoch 708/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6199 - accuracy: 0.6818\n",
      "Epoch 709/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6199 - accuracy: 0.6818\n",
      "Epoch 710/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6198 - accuracy: 0.6818\n",
      "Epoch 711/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6198 - accuracy: 0.6818\n",
      "Epoch 712/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6198 - accuracy: 0.6818\n",
      "Epoch 713/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6197 - accuracy: 0.6818\n",
      "Epoch 714/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6197 - accuracy: 0.6818\n",
      "Epoch 715/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6196 - accuracy: 0.6818\n",
      "Epoch 716/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6196 - accuracy: 0.6818\n",
      "Epoch 717/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6195 - accuracy: 0.6818\n",
      "Epoch 718/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6195 - accuracy: 0.6818\n",
      "Epoch 719/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6195 - accuracy: 0.6818\n",
      "Epoch 720/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6194 - accuracy: 0.6818\n",
      "Epoch 721/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6194 - accuracy: 0.6818\n",
      "Epoch 722/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6193 - accuracy: 0.6818\n",
      "Epoch 723/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6193 - accuracy: 0.6818\n",
      "Epoch 724/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6192 - accuracy: 0.6818\n",
      "Epoch 725/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6192 - accuracy: 0.6818\n",
      "Epoch 726/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.6818\n",
      "Epoch 727/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.6818\n",
      "Epoch 728/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6191 - accuracy: 0.6818\n",
      "Epoch 729/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6190 - accuracy: 0.6818\n",
      "Epoch 730/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6190 - accuracy: 0.6818\n",
      "Epoch 731/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6189 - accuracy: 0.6818\n",
      "Epoch 732/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6189 - accuracy: 0.6818\n",
      "Epoch 733/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6188 - accuracy: 0.6818\n",
      "Epoch 734/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6188 - accuracy: 0.6818\n",
      "Epoch 735/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6188 - accuracy: 0.6818\n",
      "Epoch 736/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6187 - accuracy: 0.6818\n",
      "Epoch 737/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6187 - accuracy: 0.6818\n",
      "Epoch 738/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6186 - accuracy: 0.6818\n",
      "Epoch 739/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6186 - accuracy: 0.6818\n",
      "Epoch 740/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6185 - accuracy: 0.6818\n",
      "Epoch 741/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6185 - accuracy: 0.6818\n",
      "Epoch 742/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6184 - accuracy: 0.6818\n",
      "Epoch 743/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6184 - accuracy: 0.6818\n",
      "Epoch 744/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6184 - accuracy: 0.6818\n",
      "Epoch 745/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6183 - accuracy: 0.6818\n",
      "Epoch 746/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6183 - accuracy: 0.6818\n",
      "Epoch 747/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6182 - accuracy: 0.6818\n",
      "Epoch 748/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6182 - accuracy: 0.6818\n",
      "Epoch 749/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6181 - accuracy: 0.6818\n",
      "Epoch 750/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6181 - accuracy: 0.6818\n",
      "Epoch 751/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6181 - accuracy: 0.6818\n",
      "Epoch 752/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6180 - accuracy: 0.6818\n",
      "Epoch 753/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6180 - accuracy: 0.6818\n",
      "Epoch 754/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6179 - accuracy: 0.6818\n",
      "Epoch 755/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6179 - accuracy: 0.6818\n",
      "Epoch 756/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6178 - accuracy: 0.6818\n",
      "Epoch 757/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6178 - accuracy: 0.6818\n",
      "Epoch 758/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6178 - accuracy: 0.6818\n",
      "Epoch 759/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6177 - accuracy: 0.6818\n",
      "Epoch 760/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6177 - accuracy: 0.6818\n",
      "Epoch 761/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6176 - accuracy: 0.6818\n",
      "Epoch 762/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6176 - accuracy: 0.6818\n",
      "Epoch 763/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6175 - accuracy: 0.6818\n",
      "Epoch 764/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6175 - accuracy: 0.6818\n",
      "Epoch 765/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6174 - accuracy: 0.6818\n",
      "Epoch 766/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6174 - accuracy: 0.6818\n",
      "Epoch 767/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6174 - accuracy: 0.6818\n",
      "Epoch 768/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6173 - accuracy: 0.6818\n",
      "Epoch 769/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6173 - accuracy: 0.6818\n",
      "Epoch 770/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6172 - accuracy: 0.6818\n",
      "Epoch 771/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6172 - accuracy: 0.6818\n",
      "Epoch 772/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6171 - accuracy: 0.6818\n",
      "Epoch 773/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6171 - accuracy: 0.6818\n",
      "Epoch 774/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6171 - accuracy: 0.6818\n",
      "Epoch 775/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6170 - accuracy: 0.6818\n",
      "Epoch 776/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6170 - accuracy: 0.6818\n",
      "Epoch 777/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6169 - accuracy: 0.6818\n",
      "Epoch 778/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6169 - accuracy: 0.6818\n",
      "Epoch 779/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.6818\n",
      "Epoch 780/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.6818\n",
      "Epoch 781/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6168 - accuracy: 0.6818\n",
      "Epoch 782/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6167 - accuracy: 0.6818\n",
      "Epoch 783/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6167 - accuracy: 0.6818\n",
      "Epoch 784/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6166 - accuracy: 0.6818\n",
      "Epoch 785/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6166 - accuracy: 0.6818\n",
      "Epoch 786/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.6818\n",
      "Epoch 787/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.6818\n",
      "Epoch 788/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6164 - accuracy: 0.6818\n",
      "Epoch 789/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6164 - accuracy: 0.6818\n",
      "Epoch 790/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6164 - accuracy: 0.6818\n",
      "Epoch 791/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6163 - accuracy: 0.6818\n",
      "Epoch 792/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6163 - accuracy: 0.6818\n",
      "Epoch 793/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6162 - accuracy: 0.6818\n",
      "Epoch 794/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6162 - accuracy: 0.6818\n",
      "Epoch 795/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6161 - accuracy: 0.6818\n",
      "Epoch 796/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6161 - accuracy: 0.6818\n",
      "Epoch 797/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6161 - accuracy: 0.6818\n",
      "Epoch 798/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6160 - accuracy: 0.6818\n",
      "Epoch 799/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6160 - accuracy: 0.6818\n",
      "Epoch 800/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6159 - accuracy: 0.6818\n",
      "Epoch 801/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6159 - accuracy: 0.6818\n",
      "Epoch 802/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6158 - accuracy: 0.6818\n",
      "Epoch 803/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6158 - accuracy: 0.6818\n",
      "Epoch 804/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6157 - accuracy: 0.6818\n",
      "Epoch 805/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6157 - accuracy: 0.6818\n",
      "Epoch 806/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6157 - accuracy: 0.6818\n",
      "Epoch 807/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6156 - accuracy: 0.6818\n",
      "Epoch 808/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6156 - accuracy: 0.6818\n",
      "Epoch 809/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6155 - accuracy: 0.6818\n",
      "Epoch 810/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6155 - accuracy: 0.6818\n",
      "Epoch 811/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6154 - accuracy: 0.6818\n",
      "Epoch 812/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.6818\n",
      "Epoch 813/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.6818\n",
      "Epoch 814/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6153 - accuracy: 0.6818\n",
      "Epoch 815/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6153 - accuracy: 0.6818\n",
      "Epoch 816/5000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6152 - accuracy: 0.6818\n",
      "Epoch 817/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6152 - accuracy: 0.6818\n",
      "Epoch 818/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.6818\n",
      "Epoch 819/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.6818\n",
      "Epoch 820/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6150 - accuracy: 0.6818\n",
      "Epoch 821/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6150 - accuracy: 0.6818\n",
      "Epoch 822/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6150 - accuracy: 0.6818\n",
      "Epoch 823/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6149 - accuracy: 0.6818\n",
      "Epoch 824/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6149 - accuracy: 0.6818\n",
      "Epoch 825/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6148 - accuracy: 0.6818\n",
      "Epoch 826/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6148 - accuracy: 0.6818\n",
      "Epoch 827/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6147 - accuracy: 0.6818\n",
      "Epoch 828/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6147 - accuracy: 0.6818\n",
      "Epoch 829/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6147 - accuracy: 0.6818\n",
      "Epoch 830/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6146 - accuracy: 0.6818\n",
      "Epoch 831/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6146 - accuracy: 0.6818\n",
      "Epoch 832/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6145 - accuracy: 0.6818\n",
      "Epoch 833/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6145 - accuracy: 0.6818\n",
      "Epoch 834/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6144 - accuracy: 0.6818\n",
      "Epoch 835/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.6818\n",
      "Epoch 836/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6143 - accuracy: 0.6818\n",
      "Epoch 837/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6143 - accuracy: 0.6818\n",
      "Epoch 838/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6143 - accuracy: 0.6818\n",
      "Epoch 839/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6142 - accuracy: 0.6818\n",
      "Epoch 840/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6142 - accuracy: 0.6818\n",
      "Epoch 841/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6141 - accuracy: 0.6818\n",
      "Epoch 842/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6141 - accuracy: 0.6818\n",
      "Epoch 843/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6140 - accuracy: 0.6818\n",
      "Epoch 844/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6140 - accuracy: 0.6818\n",
      "Epoch 845/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6139 - accuracy: 0.6818\n",
      "Epoch 846/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6139 - accuracy: 0.6818\n",
      "Epoch 847/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6139 - accuracy: 0.6818\n",
      "Epoch 848/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6138 - accuracy: 0.6818\n",
      "Epoch 849/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6138 - accuracy: 0.6818\n",
      "Epoch 850/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.6818\n",
      "Epoch 851/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.6818\n",
      "Epoch 852/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6136 - accuracy: 0.6818\n",
      "Epoch 853/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6136 - accuracy: 0.6818\n",
      "Epoch 854/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6136 - accuracy: 0.6818\n",
      "Epoch 855/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6135 - accuracy: 0.6818\n",
      "Epoch 856/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6135 - accuracy: 0.6818\n",
      "Epoch 857/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6134 - accuracy: 0.6818\n",
      "Epoch 858/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6134 - accuracy: 0.6818\n",
      "Epoch 859/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6133 - accuracy: 0.6818\n",
      "Epoch 860/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6133 - accuracy: 0.6818\n",
      "Epoch 861/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.6818\n",
      "Epoch 862/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.6818\n",
      "Epoch 863/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.6818\n",
      "Epoch 864/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6131 - accuracy: 0.6818\n",
      "Epoch 865/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6131 - accuracy: 0.6818\n",
      "Epoch 866/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6130 - accuracy: 0.6818\n",
      "Epoch 867/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6130 - accuracy: 0.6818\n",
      "Epoch 868/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6129 - accuracy: 0.6818\n",
      "Epoch 869/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6129 - accuracy: 0.6818\n",
      "Epoch 870/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6818\n",
      "Epoch 871/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6818\n",
      "Epoch 872/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6818\n",
      "Epoch 873/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.6818\n",
      "Epoch 874/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.6818\n",
      "Epoch 875/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6126 - accuracy: 0.6818\n",
      "Epoch 876/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6126 - accuracy: 0.6818\n",
      "Epoch 877/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6125 - accuracy: 0.6818\n",
      "Epoch 878/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6125 - accuracy: 0.6818\n",
      "Epoch 879/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6124 - accuracy: 0.6818\n",
      "Epoch 880/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6124 - accuracy: 0.6818\n",
      "Epoch 881/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6124 - accuracy: 0.6818\n",
      "Epoch 882/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6123 - accuracy: 0.6818\n",
      "Epoch 883/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6123 - accuracy: 0.6818\n",
      "Epoch 884/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6122 - accuracy: 0.6818\n",
      "Epoch 885/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6122 - accuracy: 0.6818\n",
      "Epoch 886/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6121 - accuracy: 0.6818\n",
      "Epoch 887/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6121 - accuracy: 0.6818\n",
      "Epoch 888/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6120 - accuracy: 0.6818\n",
      "Epoch 889/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6120 - accuracy: 0.6818\n",
      "Epoch 890/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6120 - accuracy: 0.6818\n",
      "Epoch 891/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6119 - accuracy: 0.6818\n",
      "Epoch 892/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.6818\n",
      "Epoch 893/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6118 - accuracy: 0.6818\n",
      "Epoch 894/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6118 - accuracy: 0.6818\n",
      "Epoch 895/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6117 - accuracy: 0.6818\n",
      "Epoch 896/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6117 - accuracy: 0.6818\n",
      "Epoch 897/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6116 - accuracy: 0.6818\n",
      "Epoch 898/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6116 - accuracy: 0.6818\n",
      "Epoch 899/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6116 - accuracy: 0.6818\n",
      "Epoch 900/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6115 - accuracy: 0.6818\n",
      "Epoch 901/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6115 - accuracy: 0.6818\n",
      "Epoch 902/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6114 - accuracy: 0.6818\n",
      "Epoch 903/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6114 - accuracy: 0.6818\n",
      "Epoch 904/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6113 - accuracy: 0.6818\n",
      "Epoch 905/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6113 - accuracy: 0.6818\n",
      "Epoch 906/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6112 - accuracy: 0.6818\n",
      "Epoch 907/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6112 - accuracy: 0.6818\n",
      "Epoch 908/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6112 - accuracy: 0.6818\n",
      "Epoch 909/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6111 - accuracy: 0.6818\n",
      "Epoch 910/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6111 - accuracy: 0.6818\n",
      "Epoch 911/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6110 - accuracy: 0.6818\n",
      "Epoch 912/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6110 - accuracy: 0.6818\n",
      "Epoch 913/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6109 - accuracy: 0.6818\n",
      "Epoch 914/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6109 - accuracy: 0.6818\n",
      "Epoch 915/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6108 - accuracy: 0.6818\n",
      "Epoch 916/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6108 - accuracy: 0.6818\n",
      "Epoch 917/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6108 - accuracy: 0.6818\n",
      "Epoch 918/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6107 - accuracy: 0.6818\n",
      "Epoch 919/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6107 - accuracy: 0.6818\n",
      "Epoch 920/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6106 - accuracy: 0.6818\n",
      "Epoch 921/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6106 - accuracy: 0.6818\n",
      "Epoch 922/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.6818\n",
      "Epoch 923/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.6818\n",
      "Epoch 924/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6104 - accuracy: 0.6818\n",
      "Epoch 925/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6104 - accuracy: 0.6818\n",
      "Epoch 926/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6104 - accuracy: 0.6818\n",
      "Epoch 927/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6103 - accuracy: 0.6818\n",
      "Epoch 928/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6103 - accuracy: 0.6818\n",
      "Epoch 929/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6102 - accuracy: 0.6818\n",
      "Epoch 930/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6102 - accuracy: 0.6818\n",
      "Epoch 931/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6101 - accuracy: 0.6818\n",
      "Epoch 932/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6101 - accuracy: 0.6818\n",
      "Epoch 933/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6100 - accuracy: 0.6818\n",
      "Epoch 934/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6100 - accuracy: 0.6818\n",
      "Epoch 935/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6099 - accuracy: 0.6818\n",
      "Epoch 936/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6099 - accuracy: 0.6818\n",
      "Epoch 937/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6099 - accuracy: 0.6818\n",
      "Epoch 938/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6098 - accuracy: 0.6818\n",
      "Epoch 939/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6098 - accuracy: 0.6818\n",
      "Epoch 940/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6097 - accuracy: 0.6818\n",
      "Epoch 941/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6097 - accuracy: 0.6818\n",
      "Epoch 942/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6096 - accuracy: 0.6818\n",
      "Epoch 943/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6096 - accuracy: 0.6818\n",
      "Epoch 944/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6095 - accuracy: 0.6818\n",
      "Epoch 945/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6095 - accuracy: 0.6818\n",
      "Epoch 946/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6095 - accuracy: 0.6818\n",
      "Epoch 947/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6094 - accuracy: 0.6818\n",
      "Epoch 948/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6094 - accuracy: 0.6818\n",
      "Epoch 949/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6093 - accuracy: 0.6818\n",
      "Epoch 950/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6093 - accuracy: 0.6818\n",
      "Epoch 951/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6092 - accuracy: 0.6818\n",
      "Epoch 952/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6092 - accuracy: 0.6818\n",
      "Epoch 953/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6091 - accuracy: 0.6818\n",
      "Epoch 954/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6091 - accuracy: 0.6818\n",
      "Epoch 955/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6091 - accuracy: 0.6818\n",
      "Epoch 956/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6090 - accuracy: 0.6818\n",
      "Epoch 957/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6090 - accuracy: 0.6818\n",
      "Epoch 958/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.6818\n",
      "Epoch 959/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.6818\n",
      "Epoch 960/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6088 - accuracy: 0.6818\n",
      "Epoch 961/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6088 - accuracy: 0.6818\n",
      "Epoch 962/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6087 - accuracy: 0.6818\n",
      "Epoch 963/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6087 - accuracy: 0.6818\n",
      "Epoch 964/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6086 - accuracy: 0.6818\n",
      "Epoch 965/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6086 - accuracy: 0.6818\n",
      "Epoch 966/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6086 - accuracy: 0.6818\n",
      "Epoch 967/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6085 - accuracy: 0.6818\n",
      "Epoch 968/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6085 - accuracy: 0.6818\n",
      "Epoch 969/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6084 - accuracy: 0.6818\n",
      "Epoch 970/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6084 - accuracy: 0.6818\n",
      "Epoch 971/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6083 - accuracy: 0.6818\n",
      "Epoch 972/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6083 - accuracy: 0.6818\n",
      "Epoch 973/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6082 - accuracy: 0.6818\n",
      "Epoch 974/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6082 - accuracy: 0.6818\n",
      "Epoch 975/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6081 - accuracy: 0.6818\n",
      "Epoch 976/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6081 - accuracy: 0.6818\n",
      "Epoch 977/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6081 - accuracy: 0.6818\n",
      "Epoch 978/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6080 - accuracy: 0.6818\n",
      "Epoch 979/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6080 - accuracy: 0.6818\n",
      "Epoch 980/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6079 - accuracy: 0.6818\n",
      "Epoch 981/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6079 - accuracy: 0.6818\n",
      "Epoch 982/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.6818\n",
      "Epoch 983/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.6818\n",
      "Epoch 984/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6818\n",
      "Epoch 985/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6818\n",
      "Epoch 986/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6818\n",
      "Epoch 987/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6076 - accuracy: 0.6818\n",
      "Epoch 988/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6076 - accuracy: 0.6818\n",
      "Epoch 989/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6075 - accuracy: 0.6818\n",
      "Epoch 990/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6075 - accuracy: 0.6818\n",
      "Epoch 991/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6074 - accuracy: 0.6818\n",
      "Epoch 992/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6074 - accuracy: 0.6818\n",
      "Epoch 993/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6073 - accuracy: 0.6818\n",
      "Epoch 994/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6073 - accuracy: 0.6818\n",
      "Epoch 995/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6072 - accuracy: 0.6818\n",
      "Epoch 996/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6072 - accuracy: 0.6818\n",
      "Epoch 997/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6072 - accuracy: 0.6818\n",
      "Epoch 998/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6071 - accuracy: 0.6818\n",
      "Epoch 999/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6071 - accuracy: 0.6818\n",
      "Epoch 1000/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.6818\n",
      "Epoch 1001/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.6818\n",
      "Epoch 1002/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.6818\n",
      "Epoch 1003/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.6818\n",
      "Epoch 1004/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6068 - accuracy: 0.6818\n",
      "Epoch 1005/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6068 - accuracy: 0.6818\n",
      "Epoch 1006/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6067 - accuracy: 0.6818\n",
      "Epoch 1007/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6067 - accuracy: 0.6818\n",
      "Epoch 1008/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6067 - accuracy: 0.6818\n",
      "Epoch 1009/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6066 - accuracy: 0.6818\n",
      "Epoch 1010/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6066 - accuracy: 0.6818\n",
      "Epoch 1011/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6065 - accuracy: 0.6818\n",
      "Epoch 1012/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6065 - accuracy: 0.6818\n",
      "Epoch 1013/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6064 - accuracy: 0.6818\n",
      "Epoch 1014/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6064 - accuracy: 0.6818\n",
      "Epoch 1015/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6063 - accuracy: 0.6818\n",
      "Epoch 1016/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6063 - accuracy: 0.6818\n",
      "Epoch 1017/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.6818\n",
      "Epoch 1018/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.6818\n",
      "Epoch 1019/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.6818\n",
      "Epoch 1020/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6061 - accuracy: 0.6818\n",
      "Epoch 1021/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6061 - accuracy: 0.6818\n",
      "Epoch 1022/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6060 - accuracy: 0.6818\n",
      "Epoch 1023/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6060 - accuracy: 0.6818\n",
      "Epoch 1024/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6059 - accuracy: 0.6818\n",
      "Epoch 1025/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6059 - accuracy: 0.6818\n",
      "Epoch 1026/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6058 - accuracy: 0.6818\n",
      "Epoch 1027/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6058 - accuracy: 0.6818\n",
      "Epoch 1028/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6057 - accuracy: 0.6818\n",
      "Epoch 1029/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6057 - accuracy: 0.6818\n",
      "Epoch 1030/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6057 - accuracy: 0.6818\n",
      "Epoch 1031/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6056 - accuracy: 0.6818\n",
      "Epoch 1032/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6056 - accuracy: 0.6818\n",
      "Epoch 1033/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6055 - accuracy: 0.6818\n",
      "Epoch 1034/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6055 - accuracy: 0.6818\n",
      "Epoch 1035/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 0.6818\n",
      "Epoch 1036/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6054 - accuracy: 0.6818\n",
      "Epoch 1037/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6053 - accuracy: 0.6818\n",
      "Epoch 1038/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6053 - accuracy: 0.6818\n",
      "Epoch 1039/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6052 - accuracy: 0.6818\n",
      "Epoch 1040/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6052 - accuracy: 0.6818\n",
      "Epoch 1041/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6052 - accuracy: 0.6818\n",
      "Epoch 1042/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6051 - accuracy: 0.6818\n",
      "Epoch 1043/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6051 - accuracy: 0.6818\n",
      "Epoch 1044/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6050 - accuracy: 0.6818\n",
      "Epoch 1045/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6050 - accuracy: 0.6818\n",
      "Epoch 1046/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6049 - accuracy: 0.6818\n",
      "Epoch 1047/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6049 - accuracy: 0.6818\n",
      "Epoch 1048/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6048 - accuracy: 0.6818\n",
      "Epoch 1049/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6048 - accuracy: 0.6818\n",
      "Epoch 1050/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.6818\n",
      "Epoch 1051/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6047 - accuracy: 0.6818\n",
      "Epoch 1052/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.6818\n",
      "Epoch 1053/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.6818\n",
      "Epoch 1054/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6046 - accuracy: 0.6818\n",
      "Epoch 1055/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6045 - accuracy: 0.6818\n",
      "Epoch 1056/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6045 - accuracy: 0.6818\n",
      "Epoch 1057/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6044 - accuracy: 0.6818\n",
      "Epoch 1058/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6044 - accuracy: 0.6818\n",
      "Epoch 1059/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6043 - accuracy: 0.6818\n",
      "Epoch 1060/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6043 - accuracy: 0.6818\n",
      "Epoch 1061/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6042 - accuracy: 0.6818\n",
      "Epoch 1062/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6042 - accuracy: 0.6818\n",
      "Epoch 1063/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6041 - accuracy: 0.6818\n",
      "Epoch 1064/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6041 - accuracy: 0.6818\n",
      "Epoch 1065/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6041 - accuracy: 0.6818\n",
      "Epoch 1066/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6040 - accuracy: 0.6818\n",
      "Epoch 1067/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6040 - accuracy: 0.6818\n",
      "Epoch 1068/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6039 - accuracy: 0.6818\n",
      "Epoch 1069/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6039 - accuracy: 0.6818\n",
      "Epoch 1070/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6038 - accuracy: 0.6818\n",
      "Epoch 1071/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6038 - accuracy: 0.6818\n",
      "Epoch 1072/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6037 - accuracy: 0.6818\n",
      "Epoch 1073/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6037 - accuracy: 0.6818\n",
      "Epoch 1074/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6036 - accuracy: 0.6818\n",
      "Epoch 1075/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6036 - accuracy: 0.6818\n",
      "Epoch 1076/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6036 - accuracy: 0.6818\n",
      "Epoch 1077/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6035 - accuracy: 0.6818\n",
      "Epoch 1078/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6035 - accuracy: 0.6818\n",
      "Epoch 1079/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6034 - accuracy: 0.6818\n",
      "Epoch 1080/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6034 - accuracy: 0.6818\n",
      "Epoch 1081/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6033 - accuracy: 0.6818\n",
      "Epoch 1082/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6033 - accuracy: 0.6818\n",
      "Epoch 1083/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6032 - accuracy: 0.6818\n",
      "Epoch 1084/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6032 - accuracy: 0.6818\n",
      "Epoch 1085/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6031 - accuracy: 0.6818\n",
      "Epoch 1086/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6031 - accuracy: 0.6818\n",
      "Epoch 1087/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6030 - accuracy: 0.6818\n",
      "Epoch 1088/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6030 - accuracy: 0.6818\n",
      "Epoch 1089/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6030 - accuracy: 0.6818\n",
      "Epoch 1090/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6029 - accuracy: 0.6818\n",
      "Epoch 1091/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6029 - accuracy: 0.6818\n",
      "Epoch 1092/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6028 - accuracy: 0.6818\n",
      "Epoch 1093/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6028 - accuracy: 0.6818\n",
      "Epoch 1094/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6027 - accuracy: 0.6818\n",
      "Epoch 1095/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6027 - accuracy: 0.6818\n",
      "Epoch 1096/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6026 - accuracy: 0.6818\n",
      "Epoch 1097/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6026 - accuracy: 0.6818\n",
      "Epoch 1098/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6025 - accuracy: 0.6818\n",
      "Epoch 1099/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6025 - accuracy: 0.6818\n",
      "Epoch 1100/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6024 - accuracy: 0.6818\n",
      "Epoch 1101/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6024 - accuracy: 0.6818\n",
      "Epoch 1102/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6024 - accuracy: 0.6818\n",
      "Epoch 1103/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6023 - accuracy: 0.6818\n",
      "Epoch 1104/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6023 - accuracy: 0.6818\n",
      "Epoch 1105/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6022 - accuracy: 0.6818\n",
      "Epoch 1106/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6022 - accuracy: 0.6818\n",
      "Epoch 1107/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6021 - accuracy: 0.6818\n",
      "Epoch 1108/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6021 - accuracy: 0.6818\n",
      "Epoch 1109/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6020 - accuracy: 0.6818\n",
      "Epoch 1110/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6020 - accuracy: 0.6818\n",
      "Epoch 1111/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6019 - accuracy: 0.6818\n",
      "Epoch 1112/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6019 - accuracy: 0.6818\n",
      "Epoch 1113/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6019 - accuracy: 0.6818\n",
      "Epoch 1114/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6018 - accuracy: 0.6818\n",
      "Epoch 1115/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6018 - accuracy: 0.6818\n",
      "Epoch 1116/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6017 - accuracy: 0.6818\n",
      "Epoch 1117/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6017 - accuracy: 0.6818\n",
      "Epoch 1118/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6016 - accuracy: 0.6818\n",
      "Epoch 1119/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6016 - accuracy: 0.6818\n",
      "Epoch 1120/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6015 - accuracy: 0.6818\n",
      "Epoch 1121/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6015 - accuracy: 0.6818\n",
      "Epoch 1122/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6014 - accuracy: 0.6818\n",
      "Epoch 1123/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6014 - accuracy: 0.6818\n",
      "Epoch 1124/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6013 - accuracy: 0.6818\n",
      "Epoch 1125/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6013 - accuracy: 0.6818\n",
      "Epoch 1126/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6013 - accuracy: 0.6818\n",
      "Epoch 1127/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6012 - accuracy: 0.6818\n",
      "Epoch 1128/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6012 - accuracy: 0.6818\n",
      "Epoch 1129/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6011 - accuracy: 0.6818\n",
      "Epoch 1130/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6011 - accuracy: 0.6818\n",
      "Epoch 1131/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6010 - accuracy: 0.6818\n",
      "Epoch 1132/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6010 - accuracy: 0.6818\n",
      "Epoch 1133/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6009 - accuracy: 0.6818\n",
      "Epoch 1134/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6009 - accuracy: 0.6818\n",
      "Epoch 1135/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6008 - accuracy: 0.6818\n",
      "Epoch 1136/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6008 - accuracy: 0.6818\n",
      "Epoch 1137/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.6818\n",
      "Epoch 1138/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.6818\n",
      "Epoch 1139/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6007 - accuracy: 0.6818\n",
      "Epoch 1140/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6006 - accuracy: 0.6818\n",
      "Epoch 1141/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6006 - accuracy: 0.6818\n",
      "Epoch 1142/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6005 - accuracy: 0.6818\n",
      "Epoch 1143/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6005 - accuracy: 0.6818\n",
      "Epoch 1144/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6004 - accuracy: 0.6818\n",
      "Epoch 1145/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6004 - accuracy: 0.6818\n",
      "Epoch 1146/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6003 - accuracy: 0.6818\n",
      "Epoch 1147/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6003 - accuracy: 0.6818\n",
      "Epoch 1148/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6002 - accuracy: 0.6818\n",
      "Epoch 1149/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.6002 - accuracy: 0.6818\n",
      "Epoch 1150/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6001 - accuracy: 0.6818\n",
      "Epoch 1151/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6001 - accuracy: 0.6818\n",
      "Epoch 1152/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6001 - accuracy: 0.6818\n",
      "Epoch 1153/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6000 - accuracy: 0.6818\n",
      "Epoch 1154/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6000 - accuracy: 0.6818\n",
      "Epoch 1155/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5999 - accuracy: 0.6818\n",
      "Epoch 1156/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5999 - accuracy: 0.6818\n",
      "Epoch 1157/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5998 - accuracy: 0.6818\n",
      "Epoch 1158/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5998 - accuracy: 0.6818\n",
      "Epoch 1159/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5997 - accuracy: 0.6818\n",
      "Epoch 1160/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5997 - accuracy: 0.6818\n",
      "Epoch 1161/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5996 - accuracy: 0.6818\n",
      "Epoch 1162/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5996 - accuracy: 0.6818\n",
      "Epoch 1163/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5995 - accuracy: 0.6818\n",
      "Epoch 1164/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5995 - accuracy: 0.6818\n",
      "Epoch 1165/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5995 - accuracy: 0.6818\n",
      "Epoch 1166/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5994 - accuracy: 0.6818\n",
      "Epoch 1167/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5994 - accuracy: 0.6818\n",
      "Epoch 1168/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5993 - accuracy: 0.6818\n",
      "Epoch 1169/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5993 - accuracy: 0.6818\n",
      "Epoch 1170/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5992 - accuracy: 0.6818\n",
      "Epoch 1171/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5992 - accuracy: 0.6818\n",
      "Epoch 1172/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5991 - accuracy: 0.6818\n",
      "Epoch 1173/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5991 - accuracy: 0.6818\n",
      "Epoch 1174/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5990 - accuracy: 0.6818\n",
      "Epoch 1175/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5990 - accuracy: 0.6818\n",
      "Epoch 1176/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5989 - accuracy: 0.6818\n",
      "Epoch 1177/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5989 - accuracy: 0.6818\n",
      "Epoch 1178/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5988 - accuracy: 0.6818\n",
      "Epoch 1179/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5988 - accuracy: 0.6818\n",
      "Epoch 1180/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5988 - accuracy: 0.6818\n",
      "Epoch 1181/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5987 - accuracy: 0.6818\n",
      "Epoch 1182/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5987 - accuracy: 0.6818\n",
      "Epoch 1183/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.6818\n",
      "Epoch 1184/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.6818\n",
      "Epoch 1185/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.6818\n",
      "Epoch 1186/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.6818\n",
      "Epoch 1187/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5984 - accuracy: 0.6818\n",
      "Epoch 1188/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5984 - accuracy: 0.6818\n",
      "Epoch 1189/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5983 - accuracy: 0.6818\n",
      "Epoch 1190/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5983 - accuracy: 0.6818\n",
      "Epoch 1191/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5982 - accuracy: 0.6818\n",
      "Epoch 1192/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5982 - accuracy: 0.6818\n",
      "Epoch 1193/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5982 - accuracy: 0.6818\n",
      "Epoch 1194/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5981 - accuracy: 0.6818\n",
      "Epoch 1195/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5981 - accuracy: 0.6818\n",
      "Epoch 1196/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5980 - accuracy: 0.6818\n",
      "Epoch 1197/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5980 - accuracy: 0.6818\n",
      "Epoch 1198/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5979 - accuracy: 0.6818\n",
      "Epoch 1199/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5979 - accuracy: 0.6818\n",
      "Epoch 1200/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5978 - accuracy: 0.6818\n",
      "Epoch 1201/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5978 - accuracy: 0.6818\n",
      "Epoch 1202/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5977 - accuracy: 0.6818\n",
      "Epoch 1203/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5977 - accuracy: 0.6818\n",
      "Epoch 1204/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5976 - accuracy: 0.6818\n",
      "Epoch 1205/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5976 - accuracy: 0.6818\n",
      "Epoch 1206/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5976 - accuracy: 0.6818\n",
      "Epoch 1207/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5975 - accuracy: 0.6818\n",
      "Epoch 1208/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5975 - accuracy: 0.6818\n",
      "Epoch 1209/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5974 - accuracy: 0.6818\n",
      "Epoch 1210/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5974 - accuracy: 0.6818\n",
      "Epoch 1211/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5973 - accuracy: 0.6818\n",
      "Epoch 1212/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5973 - accuracy: 0.6818\n",
      "Epoch 1213/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5972 - accuracy: 0.6818\n",
      "Epoch 1214/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5972 - accuracy: 0.6818\n",
      "Epoch 1215/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5971 - accuracy: 0.6818\n",
      "Epoch 1216/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5971 - accuracy: 0.6818\n",
      "Epoch 1217/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5970 - accuracy: 0.6818\n",
      "Epoch 1218/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5970 - accuracy: 0.6818\n",
      "Epoch 1219/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5969 - accuracy: 0.6818\n",
      "Epoch 1220/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5969 - accuracy: 0.6818\n",
      "Epoch 1221/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5969 - accuracy: 0.6818\n",
      "Epoch 1222/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5968 - accuracy: 0.6818\n",
      "Epoch 1223/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5968 - accuracy: 0.6818\n",
      "Epoch 1224/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5967 - accuracy: 0.6818\n",
      "Epoch 1225/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5967 - accuracy: 0.6818\n",
      "Epoch 1226/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5966 - accuracy: 0.6818\n",
      "Epoch 1227/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5966 - accuracy: 0.6818\n",
      "Epoch 1228/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5965 - accuracy: 0.6818\n",
      "Epoch 1229/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5965 - accuracy: 0.6818\n",
      "Epoch 1230/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 0.6818\n",
      "Epoch 1231/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5964 - accuracy: 0.6818\n",
      "Epoch 1232/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5963 - accuracy: 0.6818\n",
      "Epoch 1233/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5963 - accuracy: 0.6818\n",
      "Epoch 1234/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5963 - accuracy: 0.6818\n",
      "Epoch 1235/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5962 - accuracy: 0.6818\n",
      "Epoch 1236/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5962 - accuracy: 0.6818\n",
      "Epoch 1237/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5961 - accuracy: 0.6818\n",
      "Epoch 1238/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5961 - accuracy: 0.6818\n",
      "Epoch 1239/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5960 - accuracy: 0.6818\n",
      "Epoch 1240/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5960 - accuracy: 0.6818\n",
      "Epoch 1241/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5959 - accuracy: 0.6818\n",
      "Epoch 1242/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5959 - accuracy: 0.6818\n",
      "Epoch 1243/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5958 - accuracy: 0.6818\n",
      "Epoch 1244/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5958 - accuracy: 0.6818\n",
      "Epoch 1245/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5957 - accuracy: 0.6818\n",
      "Epoch 1246/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5957 - accuracy: 0.6818\n",
      "Epoch 1247/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5956 - accuracy: 0.6818\n",
      "Epoch 1248/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5956 - accuracy: 0.6818\n",
      "Epoch 1249/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5956 - accuracy: 0.6818\n",
      "Epoch 1250/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5955 - accuracy: 0.6818\n",
      "Epoch 1251/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5955 - accuracy: 0.6818\n",
      "Epoch 1252/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.6818\n",
      "Epoch 1253/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.6818\n",
      "Epoch 1254/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5953 - accuracy: 0.6818\n",
      "Epoch 1255/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5953 - accuracy: 0.6818\n",
      "Epoch 1256/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5952 - accuracy: 0.6818\n",
      "Epoch 1257/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5952 - accuracy: 0.6818\n",
      "Epoch 1258/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5951 - accuracy: 0.6818\n",
      "Epoch 1259/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5951 - accuracy: 0.6818\n",
      "Epoch 1260/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5950 - accuracy: 0.6818\n",
      "Epoch 1261/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5950 - accuracy: 0.6818\n",
      "Epoch 1262/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5949 - accuracy: 0.6818\n",
      "Epoch 1263/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5949 - accuracy: 0.6818\n",
      "Epoch 1264/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5949 - accuracy: 0.6818\n",
      "Epoch 1265/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.6818\n",
      "Epoch 1266/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.6818\n",
      "Epoch 1267/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5947 - accuracy: 0.6818\n",
      "Epoch 1268/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5947 - accuracy: 0.6818\n",
      "Epoch 1269/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5946 - accuracy: 0.6818\n",
      "Epoch 1270/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5946 - accuracy: 0.6818\n",
      "Epoch 1271/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.6818\n",
      "Epoch 1272/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.6818\n",
      "Epoch 1273/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5944 - accuracy: 0.6818\n",
      "Epoch 1274/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5944 - accuracy: 0.6818\n",
      "Epoch 1275/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5943 - accuracy: 0.6818\n",
      "Epoch 1276/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5943 - accuracy: 0.6818\n",
      "Epoch 1277/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5943 - accuracy: 0.6818\n",
      "Epoch 1278/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5942 - accuracy: 0.6818\n",
      "Epoch 1279/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5942 - accuracy: 0.6818\n",
      "Epoch 1280/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5941 - accuracy: 0.6818\n",
      "Epoch 1281/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5941 - accuracy: 0.6818\n",
      "Epoch 1282/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5940 - accuracy: 0.6818\n",
      "Epoch 1283/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5940 - accuracy: 0.6818\n",
      "Epoch 1284/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5939 - accuracy: 0.6818\n",
      "Epoch 1285/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5939 - accuracy: 0.6818\n",
      "Epoch 1286/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5938 - accuracy: 0.6818\n",
      "Epoch 1287/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5938 - accuracy: 0.6818\n",
      "Epoch 1288/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5937 - accuracy: 0.6818\n",
      "Epoch 1289/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5937 - accuracy: 0.6818\n",
      "Epoch 1290/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5936 - accuracy: 0.6818\n",
      "Epoch 1291/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5936 - accuracy: 0.6818\n",
      "Epoch 1292/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5936 - accuracy: 0.6818\n",
      "Epoch 1293/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5935 - accuracy: 0.6818\n",
      "Epoch 1294/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5935 - accuracy: 0.6818\n",
      "Epoch 1295/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5934 - accuracy: 0.6818\n",
      "Epoch 1296/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5934 - accuracy: 0.6818\n",
      "Epoch 1297/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5933 - accuracy: 0.6818\n",
      "Epoch 1298/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5933 - accuracy: 0.6818\n",
      "Epoch 1299/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5932 - accuracy: 0.6818\n",
      "Epoch 1300/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5932 - accuracy: 0.6818\n",
      "Epoch 1301/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5931 - accuracy: 0.6818\n",
      "Epoch 1302/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5931 - accuracy: 0.6818\n",
      "Epoch 1303/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5930 - accuracy: 0.6818\n",
      "Epoch 1304/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5930 - accuracy: 0.6818\n",
      "Epoch 1305/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5929 - accuracy: 0.6818\n",
      "Epoch 1306/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5929 - accuracy: 0.6818\n",
      "Epoch 1307/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5929 - accuracy: 0.6818\n",
      "Epoch 1308/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.6818\n",
      "Epoch 1309/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.6818\n",
      "Epoch 1310/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5927 - accuracy: 0.6818\n",
      "Epoch 1311/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5927 - accuracy: 0.6818\n",
      "Epoch 1312/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5926 - accuracy: 0.6818\n",
      "Epoch 1313/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5926 - accuracy: 0.6818\n",
      "Epoch 1314/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5925 - accuracy: 0.6818\n",
      "Epoch 1315/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5925 - accuracy: 0.6818\n",
      "Epoch 1316/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5924 - accuracy: 0.6818\n",
      "Epoch 1317/5000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5924 - accuracy: 0.6818\n",
      "Epoch 1318/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5923 - accuracy: 0.6818\n",
      "Epoch 1319/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5923 - accuracy: 0.6818\n",
      "Epoch 1320/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5922 - accuracy: 0.6818\n",
      "Epoch 1321/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5922 - accuracy: 0.6818\n",
      "Epoch 1322/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5922 - accuracy: 0.6818\n",
      "Epoch 1323/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5921 - accuracy: 0.6818\n",
      "Epoch 1324/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5921 - accuracy: 0.6818\n",
      "Epoch 1325/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5920 - accuracy: 0.6818\n",
      "Epoch 1326/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5920 - accuracy: 0.6818\n",
      "Epoch 1327/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5919 - accuracy: 0.6818\n",
      "Epoch 1328/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5919 - accuracy: 0.6818\n",
      "Epoch 1329/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5918 - accuracy: 0.6818\n",
      "Epoch 1330/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5918 - accuracy: 0.6818\n",
      "Epoch 1331/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5917 - accuracy: 0.6818\n",
      "Epoch 1332/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5917 - accuracy: 0.6818\n",
      "Epoch 1333/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.6818\n",
      "Epoch 1334/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.6818\n",
      "Epoch 1335/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.6818\n",
      "Epoch 1336/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5915 - accuracy: 0.6818\n",
      "Epoch 1337/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5915 - accuracy: 0.6818\n",
      "Epoch 1338/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5914 - accuracy: 0.6818\n",
      "Epoch 1339/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5914 - accuracy: 0.6818\n",
      "Epoch 1340/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5913 - accuracy: 0.6818\n",
      "Epoch 1341/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5913 - accuracy: 0.6818\n",
      "Epoch 1342/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5912 - accuracy: 0.6818\n",
      "Epoch 1343/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5912 - accuracy: 0.6818\n",
      "Epoch 1344/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5911 - accuracy: 0.6818\n",
      "Epoch 1345/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5911 - accuracy: 0.6818\n",
      "Epoch 1346/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5910 - accuracy: 0.6818\n",
      "Epoch 1347/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5910 - accuracy: 0.6818\n",
      "Epoch 1348/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5909 - accuracy: 0.6818\n",
      "Epoch 1349/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5909 - accuracy: 0.6818\n",
      "Epoch 1350/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5909 - accuracy: 0.6818\n",
      "Epoch 1351/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5908 - accuracy: 0.6818\n",
      "Epoch 1352/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5908 - accuracy: 0.6818\n",
      "Epoch 1353/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5907 - accuracy: 0.6818\n",
      "Epoch 1354/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5907 - accuracy: 0.6818\n",
      "Epoch 1355/5000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5906 - accuracy: 0.6818\n",
      "Epoch 1356/5000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5906 - accuracy: 0.6818\n",
      "Epoch 1357/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5905 - accuracy: 0.6818\n",
      "Epoch 1358/5000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5905 - accuracy: 0.6818\n",
      "Epoch 1359/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5904 - accuracy: 0.6818\n",
      "Epoch 1360/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5904 - accuracy: 0.6818\n",
      "Epoch 1361/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.6818\n",
      "Epoch 1362/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.6818\n",
      "Epoch 1363/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5902 - accuracy: 0.6818\n",
      "Epoch 1364/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5902 - accuracy: 0.6818\n",
      "Epoch 1365/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5902 - accuracy: 0.6818\n",
      "Epoch 1366/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5901 - accuracy: 0.6818\n",
      "Epoch 1367/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5901 - accuracy: 0.6818\n",
      "Epoch 1368/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5900 - accuracy: 0.6818\n",
      "Epoch 1369/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5900 - accuracy: 0.6818\n",
      "Epoch 1370/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5899 - accuracy: 0.6818\n",
      "Epoch 1371/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5899 - accuracy: 0.6818\n",
      "Epoch 1372/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6818\n",
      "Epoch 1373/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5898 - accuracy: 0.6818\n",
      "Epoch 1374/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5897 - accuracy: 0.6818\n",
      "Epoch 1375/5000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5897 - accuracy: 0.6818\n",
      "Epoch 1376/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5896 - accuracy: 0.6818\n",
      "Epoch 1377/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5896 - accuracy: 0.6818\n",
      "Epoch 1378/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5895 - accuracy: 0.6818\n",
      "Epoch 1379/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5895 - accuracy: 0.6818\n",
      "Epoch 1380/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5895 - accuracy: 0.6818\n",
      "Epoch 1381/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5894 - accuracy: 0.6818\n",
      "Epoch 1382/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5894 - accuracy: 0.6818\n",
      "Epoch 1383/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5893 - accuracy: 0.6818\n",
      "Epoch 1384/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5893 - accuracy: 0.6818\n",
      "Epoch 1385/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5892 - accuracy: 0.6818\n",
      "Epoch 1386/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5892 - accuracy: 0.6818\n",
      "Epoch 1387/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5891 - accuracy: 0.6818\n",
      "Epoch 1388/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5891 - accuracy: 0.6818\n",
      "Epoch 1389/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5890 - accuracy: 0.6818\n",
      "Epoch 1390/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5890 - accuracy: 0.6818\n",
      "Epoch 1391/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5889 - accuracy: 0.6818\n",
      "Epoch 1392/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5889 - accuracy: 0.6818\n",
      "Epoch 1393/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5888 - accuracy: 0.6818\n",
      "Epoch 1394/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5888 - accuracy: 0.6818\n",
      "Epoch 1395/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5888 - accuracy: 0.6818\n",
      "Epoch 1396/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5887 - accuracy: 0.6818\n",
      "Epoch 1397/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5887 - accuracy: 0.6818\n",
      "Epoch 1398/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5886 - accuracy: 0.6818\n",
      "Epoch 1399/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5886 - accuracy: 0.6818\n",
      "Epoch 1400/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5885 - accuracy: 0.6818\n",
      "Epoch 1401/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5885 - accuracy: 0.6818\n",
      "Epoch 1402/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5884 - accuracy: 0.6818\n",
      "Epoch 1403/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5884 - accuracy: 0.6818\n",
      "Epoch 1404/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5883 - accuracy: 0.6818\n",
      "Epoch 1405/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5883 - accuracy: 0.6818\n",
      "Epoch 1406/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5882 - accuracy: 0.6818\n",
      "Epoch 1407/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5882 - accuracy: 0.6818\n",
      "Epoch 1408/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5882 - accuracy: 0.6818\n",
      "Epoch 1409/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5881 - accuracy: 0.6818\n",
      "Epoch 1410/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5881 - accuracy: 0.6818\n",
      "Epoch 1411/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5880 - accuracy: 0.6818\n",
      "Epoch 1412/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5880 - accuracy: 0.6818\n",
      "Epoch 1413/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.6818\n",
      "Epoch 1414/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5879 - accuracy: 0.6818\n",
      "Epoch 1415/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5878 - accuracy: 0.6818\n",
      "Epoch 1416/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5878 - accuracy: 0.6818\n",
      "Epoch 1417/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5877 - accuracy: 0.6818\n",
      "Epoch 1418/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5877 - accuracy: 0.6818\n",
      "Epoch 1419/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5876 - accuracy: 0.6818\n",
      "Epoch 1420/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5876 - accuracy: 0.6818\n",
      "Epoch 1421/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5875 - accuracy: 0.6818\n",
      "Epoch 1422/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5875 - accuracy: 0.6818\n",
      "Epoch 1423/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5875 - accuracy: 0.6818\n",
      "Epoch 1424/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5874 - accuracy: 0.6818\n",
      "Epoch 1425/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5874 - accuracy: 0.6818\n",
      "Epoch 1426/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5873 - accuracy: 0.6818\n",
      "Epoch 1427/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5873 - accuracy: 0.6818\n",
      "Epoch 1428/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5872 - accuracy: 0.6818\n",
      "Epoch 1429/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5872 - accuracy: 0.6818\n",
      "Epoch 1430/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5871 - accuracy: 0.6818\n",
      "Epoch 1431/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5871 - accuracy: 0.6818\n",
      "Epoch 1432/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5870 - accuracy: 0.6818\n",
      "Epoch 1433/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5870 - accuracy: 0.6818\n",
      "Epoch 1434/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5869 - accuracy: 0.6818\n",
      "Epoch 1435/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5869 - accuracy: 0.6818\n",
      "Epoch 1436/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5868 - accuracy: 0.6818\n",
      "Epoch 1437/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5868 - accuracy: 0.6818\n",
      "Epoch 1438/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5868 - accuracy: 0.6818\n",
      "Epoch 1439/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5867 - accuracy: 0.6818\n",
      "Epoch 1440/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5867 - accuracy: 0.6818\n",
      "Epoch 1441/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5866 - accuracy: 0.6818\n",
      "Epoch 1442/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5866 - accuracy: 0.6818\n",
      "Epoch 1443/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5865 - accuracy: 0.6818\n",
      "Epoch 1444/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5865 - accuracy: 0.6818\n",
      "Epoch 1445/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5864 - accuracy: 0.6818\n",
      "Epoch 1446/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5864 - accuracy: 0.6818\n",
      "Epoch 1447/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5863 - accuracy: 0.6818\n",
      "Epoch 1448/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5863 - accuracy: 0.6818\n",
      "Epoch 1449/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5862 - accuracy: 0.6818\n",
      "Epoch 1450/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5862 - accuracy: 0.6818\n",
      "Epoch 1451/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5862 - accuracy: 0.6818\n",
      "Epoch 1452/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5861 - accuracy: 0.6818\n",
      "Epoch 1453/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5861 - accuracy: 0.6818\n",
      "Epoch 1454/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5860 - accuracy: 0.6818\n",
      "Epoch 1455/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5860 - accuracy: 0.6818\n",
      "Epoch 1456/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5859 - accuracy: 0.6818\n",
      "Epoch 1457/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5859 - accuracy: 0.6818\n",
      "Epoch 1458/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5858 - accuracy: 0.6818\n",
      "Epoch 1459/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5858 - accuracy: 0.6818\n",
      "Epoch 1460/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5857 - accuracy: 0.6818\n",
      "Epoch 1461/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5857 - accuracy: 0.6818\n",
      "Epoch 1462/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5856 - accuracy: 0.6818\n",
      "Epoch 1463/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5856 - accuracy: 0.6818\n",
      "Epoch 1464/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5855 - accuracy: 0.6818\n",
      "Epoch 1465/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5855 - accuracy: 0.6818\n",
      "Epoch 1466/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5855 - accuracy: 0.6818\n",
      "Epoch 1467/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5854 - accuracy: 0.6818\n",
      "Epoch 1468/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5854 - accuracy: 0.6818\n",
      "Epoch 1469/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5853 - accuracy: 0.6818\n",
      "Epoch 1470/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5853 - accuracy: 0.6818\n",
      "Epoch 1471/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5852 - accuracy: 0.6818\n",
      "Epoch 1472/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5852 - accuracy: 0.6818\n",
      "Epoch 1473/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5851 - accuracy: 0.6818\n",
      "Epoch 1474/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5851 - accuracy: 0.6818\n",
      "Epoch 1475/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.6818\n",
      "Epoch 1476/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5850 - accuracy: 0.6818\n",
      "Epoch 1477/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5849 - accuracy: 0.6818\n",
      "Epoch 1478/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5849 - accuracy: 0.6818\n",
      "Epoch 1479/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5848 - accuracy: 0.6818\n",
      "Epoch 1480/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5848 - accuracy: 0.6818\n",
      "Epoch 1481/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5848 - accuracy: 0.6818\n",
      "Epoch 1482/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5847 - accuracy: 0.6818\n",
      "Epoch 1483/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5847 - accuracy: 0.6818\n",
      "Epoch 1484/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5846 - accuracy: 0.6818\n",
      "Epoch 1485/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5846 - accuracy: 0.6818\n",
      "Epoch 1486/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5845 - accuracy: 0.6818\n",
      "Epoch 1487/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5845 - accuracy: 0.6818\n",
      "Epoch 1488/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5844 - accuracy: 0.6818\n",
      "Epoch 1489/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5844 - accuracy: 0.6818\n",
      "Epoch 1490/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5843 - accuracy: 0.6818\n",
      "Epoch 1491/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5843 - accuracy: 0.6818\n",
      "Epoch 1492/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5842 - accuracy: 0.6818\n",
      "Epoch 1493/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5842 - accuracy: 0.6818\n",
      "Epoch 1494/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5842 - accuracy: 0.6818\n",
      "Epoch 1495/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5841 - accuracy: 0.6818\n",
      "Epoch 1496/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5841 - accuracy: 0.6818\n",
      "Epoch 1497/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5840 - accuracy: 0.6818\n",
      "Epoch 1498/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5840 - accuracy: 0.6818\n",
      "Epoch 1499/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5839 - accuracy: 0.6818\n",
      "Epoch 1500/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5839 - accuracy: 0.6818\n",
      "Epoch 1501/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5838 - accuracy: 0.6818\n",
      "Epoch 1502/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5838 - accuracy: 0.6818\n",
      "Epoch 1503/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5837 - accuracy: 0.6818\n",
      "Epoch 1504/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5837 - accuracy: 0.6818\n",
      "Epoch 1505/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5836 - accuracy: 0.6818\n",
      "Epoch 1506/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5836 - accuracy: 0.6818\n",
      "Epoch 1507/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5835 - accuracy: 0.6818\n",
      "Epoch 1508/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5835 - accuracy: 0.6818\n",
      "Epoch 1509/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5835 - accuracy: 0.6818\n",
      "Epoch 1510/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5834 - accuracy: 0.6818\n",
      "Epoch 1511/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5834 - accuracy: 0.6818\n",
      "Epoch 1512/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5833 - accuracy: 0.6818\n",
      "Epoch 1513/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5833 - accuracy: 0.6818\n",
      "Epoch 1514/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5832 - accuracy: 0.6818\n",
      "Epoch 1515/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5832 - accuracy: 0.6818\n",
      "Epoch 1516/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5831 - accuracy: 0.6818\n",
      "Epoch 1517/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5831 - accuracy: 0.6818\n",
      "Epoch 1518/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5830 - accuracy: 0.6818\n",
      "Epoch 1519/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5830 - accuracy: 0.6818\n",
      "Epoch 1520/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.6818\n",
      "Epoch 1521/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.6818\n",
      "Epoch 1522/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.6818\n",
      "Epoch 1523/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5828 - accuracy: 0.6818\n",
      "Epoch 1524/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5828 - accuracy: 0.6818\n",
      "Epoch 1525/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5827 - accuracy: 0.6818\n",
      "Epoch 1526/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5827 - accuracy: 0.6818\n",
      "Epoch 1527/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5826 - accuracy: 0.6818\n",
      "Epoch 1528/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5826 - accuracy: 0.6818\n",
      "Epoch 1529/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5825 - accuracy: 0.6818\n",
      "Epoch 1530/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5825 - accuracy: 0.6818\n",
      "Epoch 1531/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5824 - accuracy: 0.6818\n",
      "Epoch 1532/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5824 - accuracy: 0.6818\n",
      "Epoch 1533/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.6818\n",
      "Epoch 1534/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.6818\n",
      "Epoch 1535/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.6818\n",
      "Epoch 1536/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5822 - accuracy: 0.6818\n",
      "Epoch 1537/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5822 - accuracy: 0.6818\n",
      "Epoch 1538/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5821 - accuracy: 0.6818\n",
      "Epoch 1539/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5821 - accuracy: 0.6818\n",
      "Epoch 1540/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5820 - accuracy: 0.6818\n",
      "Epoch 1541/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5820 - accuracy: 0.6818\n",
      "Epoch 1542/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5819 - accuracy: 0.6818\n",
      "Epoch 1543/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5819 - accuracy: 0.6818\n",
      "Epoch 1544/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5818 - accuracy: 0.6818\n",
      "Epoch 1545/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5818 - accuracy: 0.6818\n",
      "Epoch 1546/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5817 - accuracy: 0.6818\n",
      "Epoch 1547/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5817 - accuracy: 0.6818\n",
      "Epoch 1548/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5817 - accuracy: 0.6818\n",
      "Epoch 1549/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5816 - accuracy: 0.6818\n",
      "Epoch 1550/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5816 - accuracy: 0.6818\n",
      "Epoch 1551/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5815 - accuracy: 0.6818\n",
      "Epoch 1552/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5815 - accuracy: 0.6818\n",
      "Epoch 1553/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5814 - accuracy: 0.6818\n",
      "Epoch 1554/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5814 - accuracy: 0.6818\n",
      "Epoch 1555/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5813 - accuracy: 0.6818\n",
      "Epoch 1556/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5813 - accuracy: 0.6818\n",
      "Epoch 1557/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5812 - accuracy: 0.6818\n",
      "Epoch 1558/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5812 - accuracy: 0.6818\n",
      "Epoch 1559/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5811 - accuracy: 0.6818\n",
      "Epoch 1560/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5811 - accuracy: 0.6818\n",
      "Epoch 1561/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5811 - accuracy: 0.6818\n",
      "Epoch 1562/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5810 - accuracy: 0.6818\n",
      "Epoch 1563/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5810 - accuracy: 0.6818\n",
      "Epoch 1564/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5809 - accuracy: 0.6818\n",
      "Epoch 1565/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5809 - accuracy: 0.6818\n",
      "Epoch 1566/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5808 - accuracy: 0.6818\n",
      "Epoch 1567/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5808 - accuracy: 0.6818\n",
      "Epoch 1568/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5807 - accuracy: 0.6818\n",
      "Epoch 1569/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5807 - accuracy: 0.6818\n",
      "Epoch 1570/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5806 - accuracy: 0.6818\n",
      "Epoch 1571/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5806 - accuracy: 0.6818\n",
      "Epoch 1572/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5805 - accuracy: 0.6818\n",
      "Epoch 1573/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5805 - accuracy: 0.6818\n",
      "Epoch 1574/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5804 - accuracy: 0.6818\n",
      "Epoch 1575/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5804 - accuracy: 0.6818\n",
      "Epoch 1576/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5804 - accuracy: 0.6818\n",
      "Epoch 1577/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5803 - accuracy: 0.6818\n",
      "Epoch 1578/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5803 - accuracy: 0.6818\n",
      "Epoch 1579/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5802 - accuracy: 0.6818\n",
      "Epoch 1580/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5802 - accuracy: 0.6818\n",
      "Epoch 1581/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5801 - accuracy: 0.6818\n",
      "Epoch 1582/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5801 - accuracy: 0.6818\n",
      "Epoch 1583/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5800 - accuracy: 0.6818\n",
      "Epoch 1584/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5800 - accuracy: 0.6818\n",
      "Epoch 1585/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5799 - accuracy: 0.6818\n",
      "Epoch 1586/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5799 - accuracy: 0.6818\n",
      "Epoch 1587/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5798 - accuracy: 0.6818\n",
      "Epoch 1588/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5798 - accuracy: 0.6818\n",
      "Epoch 1589/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5798 - accuracy: 0.6818\n",
      "Epoch 1590/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5797 - accuracy: 0.6818\n",
      "Epoch 1591/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5797 - accuracy: 0.6818\n",
      "Epoch 1592/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5796 - accuracy: 0.6818\n",
      "Epoch 1593/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5796 - accuracy: 0.6818\n",
      "Epoch 1594/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5795 - accuracy: 0.6818\n",
      "Epoch 1595/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5795 - accuracy: 0.6818\n",
      "Epoch 1596/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5794 - accuracy: 0.6818\n",
      "Epoch 1597/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5794 - accuracy: 0.6818\n",
      "Epoch 1598/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5793 - accuracy: 0.6818\n",
      "Epoch 1599/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5793 - accuracy: 0.6818\n",
      "Epoch 1600/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5793 - accuracy: 0.6818\n",
      "Epoch 1601/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5792 - accuracy: 0.6818\n",
      "Epoch 1602/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5792 - accuracy: 0.6818\n",
      "Epoch 1603/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5791 - accuracy: 0.6818\n",
      "Epoch 1604/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5791 - accuracy: 0.6818\n",
      "Epoch 1605/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5790 - accuracy: 0.6818\n",
      "Epoch 1606/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5790 - accuracy: 0.6818\n",
      "Epoch 1607/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5789 - accuracy: 0.6818\n",
      "Epoch 1608/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5789 - accuracy: 0.6818\n",
      "Epoch 1609/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5788 - accuracy: 0.6818\n",
      "Epoch 1610/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5788 - accuracy: 0.6818\n",
      "Epoch 1611/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5787 - accuracy: 0.6818\n",
      "Epoch 1612/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5787 - accuracy: 0.6818\n",
      "Epoch 1613/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5787 - accuracy: 0.6818\n",
      "Epoch 1614/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5786 - accuracy: 0.6818\n",
      "Epoch 1615/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5786 - accuracy: 0.6818\n",
      "Epoch 1616/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5785 - accuracy: 0.6818\n",
      "Epoch 1617/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5785 - accuracy: 0.6818\n",
      "Epoch 1618/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5784 - accuracy: 0.6818\n",
      "Epoch 1619/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5784 - accuracy: 0.6818\n",
      "Epoch 1620/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.6818\n",
      "Epoch 1621/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5783 - accuracy: 0.6818\n",
      "Epoch 1622/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5782 - accuracy: 0.6818\n",
      "Epoch 1623/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5782 - accuracy: 0.6818\n",
      "Epoch 1624/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5781 - accuracy: 0.6818\n",
      "Epoch 1625/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5781 - accuracy: 0.6818\n",
      "Epoch 1626/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5781 - accuracy: 0.6818\n",
      "Epoch 1627/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5780 - accuracy: 0.6818\n",
      "Epoch 1628/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5780 - accuracy: 0.6818\n",
      "Epoch 1629/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5779 - accuracy: 0.6818\n",
      "Epoch 1630/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5779 - accuracy: 0.6818\n",
      "Epoch 1631/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5778 - accuracy: 0.6818\n",
      "Epoch 1632/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5778 - accuracy: 0.6818\n",
      "Epoch 1633/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5777 - accuracy: 0.6818\n",
      "Epoch 1634/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5777 - accuracy: 0.6818\n",
      "Epoch 1635/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5776 - accuracy: 0.6818\n",
      "Epoch 1636/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5776 - accuracy: 0.6818\n",
      "Epoch 1637/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5775 - accuracy: 0.6818\n",
      "Epoch 1638/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5775 - accuracy: 0.6818\n",
      "Epoch 1639/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5775 - accuracy: 0.6818\n",
      "Epoch 1640/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5774 - accuracy: 0.6818\n",
      "Epoch 1641/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5774 - accuracy: 0.6818\n",
      "Epoch 1642/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5773 - accuracy: 0.6818\n",
      "Epoch 1643/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5773 - accuracy: 0.6818\n",
      "Epoch 1644/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5772 - accuracy: 0.6818\n",
      "Epoch 1645/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5772 - accuracy: 0.6818\n",
      "Epoch 1646/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5771 - accuracy: 0.6818\n",
      "Epoch 1647/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5771 - accuracy: 0.6818\n",
      "Epoch 1648/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5770 - accuracy: 0.6818\n",
      "Epoch 1649/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5770 - accuracy: 0.6818\n",
      "Epoch 1650/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5770 - accuracy: 0.6818\n",
      "Epoch 1651/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5769 - accuracy: 0.6818\n",
      "Epoch 1652/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5769 - accuracy: 0.6818\n",
      "Epoch 1653/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5768 - accuracy: 0.6818\n",
      "Epoch 1654/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5768 - accuracy: 0.6818\n",
      "Epoch 1655/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5767 - accuracy: 0.6818\n",
      "Epoch 1656/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5767 - accuracy: 0.6818\n",
      "Epoch 1657/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5766 - accuracy: 0.6818\n",
      "Epoch 1658/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5766 - accuracy: 0.6818\n",
      "Epoch 1659/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5765 - accuracy: 0.6818\n",
      "Epoch 1660/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5765 - accuracy: 0.6818\n",
      "Epoch 1661/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5764 - accuracy: 0.6818\n",
      "Epoch 1662/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5764 - accuracy: 0.6818\n",
      "Epoch 1663/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5764 - accuracy: 0.6818\n",
      "Epoch 1664/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.6818\n",
      "Epoch 1665/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.6818\n",
      "Epoch 1666/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5762 - accuracy: 0.6818\n",
      "Epoch 1667/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5762 - accuracy: 0.6818\n",
      "Epoch 1668/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5761 - accuracy: 0.6818\n",
      "Epoch 1669/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5761 - accuracy: 0.6818\n",
      "Epoch 1670/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5760 - accuracy: 0.6818\n",
      "Epoch 1671/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5760 - accuracy: 0.6818\n",
      "Epoch 1672/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5759 - accuracy: 0.6818\n",
      "Epoch 1673/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5759 - accuracy: 0.6818\n",
      "Epoch 1674/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5759 - accuracy: 0.6818\n",
      "Epoch 1675/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5758 - accuracy: 0.6818\n",
      "Epoch 1676/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5758 - accuracy: 0.6818\n",
      "Epoch 1677/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5757 - accuracy: 0.6818\n",
      "Epoch 1678/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5757 - accuracy: 0.6818\n",
      "Epoch 1679/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5756 - accuracy: 0.6818\n",
      "Epoch 1680/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5756 - accuracy: 0.6818\n",
      "Epoch 1681/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5755 - accuracy: 0.6818\n",
      "Epoch 1682/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5755 - accuracy: 0.6818\n",
      "Epoch 1683/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5754 - accuracy: 0.6818\n",
      "Epoch 1684/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5754 - accuracy: 0.6818\n",
      "Epoch 1685/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5753 - accuracy: 0.6818\n",
      "Epoch 1686/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5753 - accuracy: 0.6818\n",
      "Epoch 1687/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5753 - accuracy: 0.6818\n",
      "Epoch 1688/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5752 - accuracy: 0.6818\n",
      "Epoch 1689/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5752 - accuracy: 0.6818\n",
      "Epoch 1690/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5751 - accuracy: 0.6818\n",
      "Epoch 1691/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5751 - accuracy: 0.6818\n",
      "Epoch 1692/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5750 - accuracy: 0.6818\n",
      "Epoch 1693/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5750 - accuracy: 0.6818\n",
      "Epoch 1694/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5749 - accuracy: 0.6818\n",
      "Epoch 1695/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5749 - accuracy: 0.6818\n",
      "Epoch 1696/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.6818\n",
      "Epoch 1697/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.6818\n",
      "Epoch 1698/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.6818\n",
      "Epoch 1699/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5747 - accuracy: 0.6818\n",
      "Epoch 1700/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.6818\n",
      "Epoch 1701/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5746 - accuracy: 0.6818\n",
      "Epoch 1702/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5746 - accuracy: 0.6818\n",
      "Epoch 1703/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5745 - accuracy: 0.6818\n",
      "Epoch 1704/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5745 - accuracy: 0.6818\n",
      "Epoch 1705/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5744 - accuracy: 0.6818\n",
      "Epoch 1706/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5744 - accuracy: 0.6818\n",
      "Epoch 1707/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5743 - accuracy: 0.6818\n",
      "Epoch 1708/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5743 - accuracy: 0.6818\n",
      "Epoch 1709/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5743 - accuracy: 0.6818\n",
      "Epoch 1710/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5742 - accuracy: 0.6818\n",
      "Epoch 1711/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5742 - accuracy: 0.6818\n",
      "Epoch 1712/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5741 - accuracy: 0.6818\n",
      "Epoch 1713/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5741 - accuracy: 0.6818\n",
      "Epoch 1714/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5740 - accuracy: 0.6818\n",
      "Epoch 1715/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5740 - accuracy: 0.6818\n",
      "Epoch 1716/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 0.6818\n",
      "Epoch 1717/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 0.6818\n",
      "Epoch 1718/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5738 - accuracy: 0.6818\n",
      "Epoch 1719/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5738 - accuracy: 0.6818\n",
      "Epoch 1720/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5738 - accuracy: 0.6818\n",
      "Epoch 1721/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5737 - accuracy: 0.6818\n",
      "Epoch 1722/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5737 - accuracy: 0.6818\n",
      "Epoch 1723/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5736 - accuracy: 0.6818\n",
      "Epoch 1724/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5736 - accuracy: 0.6818\n",
      "Epoch 1725/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5735 - accuracy: 0.6818\n",
      "Epoch 1726/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5735 - accuracy: 0.6818\n",
      "Epoch 1727/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5734 - accuracy: 0.6818\n",
      "Epoch 1728/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5734 - accuracy: 0.6818\n",
      "Epoch 1729/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5733 - accuracy: 0.6818\n",
      "Epoch 1730/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5733 - accuracy: 0.6818\n",
      "Epoch 1731/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5733 - accuracy: 0.6818\n",
      "Epoch 1732/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5732 - accuracy: 0.6818\n",
      "Epoch 1733/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5732 - accuracy: 0.6818\n",
      "Epoch 1734/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5731 - accuracy: 0.6818\n",
      "Epoch 1735/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5731 - accuracy: 0.6818\n",
      "Epoch 1736/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5730 - accuracy: 0.6818\n",
      "Epoch 1737/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5730 - accuracy: 0.6818\n",
      "Epoch 1738/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5729 - accuracy: 0.6818\n",
      "Epoch 1739/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5729 - accuracy: 0.6818\n",
      "Epoch 1740/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5728 - accuracy: 0.6818\n",
      "Epoch 1741/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5728 - accuracy: 0.6818\n",
      "Epoch 1742/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5728 - accuracy: 0.6818\n",
      "Epoch 1743/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5727 - accuracy: 0.6818\n",
      "Epoch 1744/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5727 - accuracy: 0.6818\n",
      "Epoch 1745/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5726 - accuracy: 0.6818\n",
      "Epoch 1746/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5726 - accuracy: 0.6818\n",
      "Epoch 1747/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.6818\n",
      "Epoch 1748/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.6818\n",
      "Epoch 1749/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5724 - accuracy: 0.6818\n",
      "Epoch 1750/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5724 - accuracy: 0.6818\n",
      "Epoch 1751/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5723 - accuracy: 0.6818\n",
      "Epoch 1752/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5723 - accuracy: 0.6818\n",
      "Epoch 1753/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5723 - accuracy: 0.6818\n",
      "Epoch 1754/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5722 - accuracy: 0.6818\n",
      "Epoch 1755/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5722 - accuracy: 0.6818\n",
      "Epoch 1756/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5721 - accuracy: 0.6818\n",
      "Epoch 1757/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5721 - accuracy: 0.6818\n",
      "Epoch 1758/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5720 - accuracy: 0.6818\n",
      "Epoch 1759/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5720 - accuracy: 0.6818\n",
      "Epoch 1760/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5719 - accuracy: 0.6818\n",
      "Epoch 1761/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5719 - accuracy: 0.6818\n",
      "Epoch 1762/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5718 - accuracy: 0.6818\n",
      "Epoch 1763/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5718 - accuracy: 0.6818\n",
      "Epoch 1764/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5718 - accuracy: 0.6818\n",
      "Epoch 1765/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5717 - accuracy: 0.6818\n",
      "Epoch 1766/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5717 - accuracy: 0.6818\n",
      "Epoch 1767/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5716 - accuracy: 0.6818\n",
      "Epoch 1768/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5716 - accuracy: 0.6818\n",
      "Epoch 1769/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5715 - accuracy: 0.6818\n",
      "Epoch 1770/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5715 - accuracy: 0.6818\n",
      "Epoch 1771/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5714 - accuracy: 0.6818\n",
      "Epoch 1772/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5714 - accuracy: 0.6818\n",
      "Epoch 1773/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.6818\n",
      "Epoch 1774/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.6818\n",
      "Epoch 1775/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.6818\n",
      "Epoch 1776/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5712 - accuracy: 0.6818\n",
      "Epoch 1777/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5712 - accuracy: 0.6818\n",
      "Epoch 1778/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5711 - accuracy: 0.6818\n",
      "Epoch 1779/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5711 - accuracy: 0.6818\n",
      "Epoch 1780/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5710 - accuracy: 0.6818\n",
      "Epoch 1781/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5710 - accuracy: 0.6818\n",
      "Epoch 1782/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5709 - accuracy: 0.6818\n",
      "Epoch 1783/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5709 - accuracy: 0.6818\n",
      "Epoch 1784/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5708 - accuracy: 0.6818\n",
      "Epoch 1785/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5708 - accuracy: 0.6818\n",
      "Epoch 1786/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5708 - accuracy: 0.6818\n",
      "Epoch 1787/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5707 - accuracy: 0.6818\n",
      "Epoch 1788/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5707 - accuracy: 0.6818\n",
      "Epoch 1789/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5706 - accuracy: 0.6818\n",
      "Epoch 1790/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5706 - accuracy: 0.6818\n",
      "Epoch 1791/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5705 - accuracy: 0.6818\n",
      "Epoch 1792/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5705 - accuracy: 0.6818\n",
      "Epoch 1793/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5704 - accuracy: 0.6818\n",
      "Epoch 1794/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5704 - accuracy: 0.6818\n",
      "Epoch 1795/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5704 - accuracy: 0.6818\n",
      "Epoch 1796/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5703 - accuracy: 0.6818\n",
      "Epoch 1797/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5703 - accuracy: 0.6818\n",
      "Epoch 1798/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5702 - accuracy: 0.6818\n",
      "Epoch 1799/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5702 - accuracy: 0.6818\n",
      "Epoch 1800/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5701 - accuracy: 0.6818\n",
      "Epoch 1801/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5701 - accuracy: 0.6818\n",
      "Epoch 1802/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5700 - accuracy: 0.6818\n",
      "Epoch 1803/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5700 - accuracy: 0.6818\n",
      "Epoch 1804/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5699 - accuracy: 0.6818\n",
      "Epoch 1805/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5699 - accuracy: 0.6818\n",
      "Epoch 1806/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5699 - accuracy: 0.6818\n",
      "Epoch 1807/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5698 - accuracy: 0.6818\n",
      "Epoch 1808/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5698 - accuracy: 0.6818\n",
      "Epoch 1809/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5697 - accuracy: 0.6818\n",
      "Epoch 1810/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5697 - accuracy: 0.6818\n",
      "Epoch 1811/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5696 - accuracy: 0.6818\n",
      "Epoch 1812/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5696 - accuracy: 0.6818\n",
      "Epoch 1813/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5695 - accuracy: 0.6818\n",
      "Epoch 1814/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5695 - accuracy: 0.6818\n",
      "Epoch 1815/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5695 - accuracy: 0.6818\n",
      "Epoch 1816/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5694 - accuracy: 0.6818\n",
      "Epoch 1817/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5694 - accuracy: 0.6818\n",
      "Epoch 1818/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5693 - accuracy: 0.6818\n",
      "Epoch 1819/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5693 - accuracy: 0.6818\n",
      "Epoch 1820/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5692 - accuracy: 0.6818\n",
      "Epoch 1821/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5692 - accuracy: 0.6818\n",
      "Epoch 1822/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5691 - accuracy: 0.6818\n",
      "Epoch 1823/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5691 - accuracy: 0.6818\n",
      "Epoch 1824/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5690 - accuracy: 0.6818\n",
      "Epoch 1825/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5690 - accuracy: 0.6818\n",
      "Epoch 1826/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5690 - accuracy: 0.6818\n",
      "Epoch 1827/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5689 - accuracy: 0.6818\n",
      "Epoch 1828/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5689 - accuracy: 0.6818\n",
      "Epoch 1829/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5688 - accuracy: 0.6818\n",
      "Epoch 1830/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5688 - accuracy: 0.6818\n",
      "Epoch 1831/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5687 - accuracy: 0.6818\n",
      "Epoch 1832/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5687 - accuracy: 0.6818\n",
      "Epoch 1833/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5686 - accuracy: 0.6818\n",
      "Epoch 1834/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5686 - accuracy: 0.6818\n",
      "Epoch 1835/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5686 - accuracy: 0.6818\n",
      "Epoch 1836/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5685 - accuracy: 0.6818\n",
      "Epoch 1837/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5685 - accuracy: 0.6818\n",
      "Epoch 1838/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5684 - accuracy: 0.6818\n",
      "Epoch 1839/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5684 - accuracy: 0.6818\n",
      "Epoch 1840/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5683 - accuracy: 0.6818\n",
      "Epoch 1841/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5683 - accuracy: 0.6818\n",
      "Epoch 1842/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5682 - accuracy: 0.6818\n",
      "Epoch 1843/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5682 - accuracy: 0.6818\n",
      "Epoch 1844/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5681 - accuracy: 0.6818\n",
      "Epoch 1845/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5681 - accuracy: 0.6818\n",
      "Epoch 1846/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5681 - accuracy: 0.6818\n",
      "Epoch 1847/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5680 - accuracy: 0.6818\n",
      "Epoch 1848/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5680 - accuracy: 0.6818\n",
      "Epoch 1849/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5679 - accuracy: 0.6818\n",
      "Epoch 1850/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5679 - accuracy: 0.6818\n",
      "Epoch 1851/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5678 - accuracy: 0.6818\n",
      "Epoch 1852/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5678 - accuracy: 0.6818\n",
      "Epoch 1853/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5677 - accuracy: 0.6818\n",
      "Epoch 1854/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5677 - accuracy: 0.6818\n",
      "Epoch 1855/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5677 - accuracy: 0.6818\n",
      "Epoch 1856/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5676 - accuracy: 0.6818\n",
      "Epoch 1857/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5676 - accuracy: 0.6818\n",
      "Epoch 1858/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5675 - accuracy: 0.6818\n",
      "Epoch 1859/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5675 - accuracy: 0.6818\n",
      "Epoch 1860/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5674 - accuracy: 0.6818\n",
      "Epoch 1861/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5674 - accuracy: 0.6818\n",
      "Epoch 1862/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5673 - accuracy: 0.6818\n",
      "Epoch 1863/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5673 - accuracy: 0.6818\n",
      "Epoch 1864/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5673 - accuracy: 0.6818\n",
      "Epoch 1865/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5672 - accuracy: 0.6818\n",
      "Epoch 1866/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5672 - accuracy: 0.6818\n",
      "Epoch 1867/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5671 - accuracy: 0.6818\n",
      "Epoch 1868/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5671 - accuracy: 0.6818\n",
      "Epoch 1869/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5670 - accuracy: 0.6818\n",
      "Epoch 1870/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5670 - accuracy: 0.6818\n",
      "Epoch 1871/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5669 - accuracy: 0.6818\n",
      "Epoch 1872/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5669 - accuracy: 0.6818\n",
      "Epoch 1873/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5669 - accuracy: 0.6818\n",
      "Epoch 1874/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.6818\n",
      "Epoch 1875/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.6818\n",
      "Epoch 1876/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5667 - accuracy: 0.6818\n",
      "Epoch 1877/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5667 - accuracy: 0.6818\n",
      "Epoch 1878/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5666 - accuracy: 0.6818\n",
      "Epoch 1879/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5666 - accuracy: 0.6818\n",
      "Epoch 1880/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5665 - accuracy: 0.6818\n",
      "Epoch 1881/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5665 - accuracy: 0.6818\n",
      "Epoch 1882/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5664 - accuracy: 0.6818\n",
      "Epoch 1883/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5664 - accuracy: 0.6818\n",
      "Epoch 1884/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5664 - accuracy: 0.6818\n",
      "Epoch 1885/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5663 - accuracy: 0.6818\n",
      "Epoch 1886/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5663 - accuracy: 0.6818\n",
      "Epoch 1887/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5662 - accuracy: 0.6818\n",
      "Epoch 1888/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5662 - accuracy: 0.6818\n",
      "Epoch 1889/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5661 - accuracy: 0.6818\n",
      "Epoch 1890/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5661 - accuracy: 0.6818\n",
      "Epoch 1891/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5660 - accuracy: 0.6818\n",
      "Epoch 1892/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5660 - accuracy: 0.6818\n",
      "Epoch 1893/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5660 - accuracy: 0.6818\n",
      "Epoch 1894/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5659 - accuracy: 0.6818\n",
      "Epoch 1895/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5659 - accuracy: 0.6818\n",
      "Epoch 1896/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5658 - accuracy: 0.6818\n",
      "Epoch 1897/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5658 - accuracy: 0.6818\n",
      "Epoch 1898/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5657 - accuracy: 0.6818\n",
      "Epoch 1899/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5657 - accuracy: 0.6818\n",
      "Epoch 1900/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5656 - accuracy: 0.6818\n",
      "Epoch 1901/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5656 - accuracy: 0.6818\n",
      "Epoch 1902/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5656 - accuracy: 0.6818\n",
      "Epoch 1903/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5655 - accuracy: 0.6818\n",
      "Epoch 1904/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5655 - accuracy: 0.6818\n",
      "Epoch 1905/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5654 - accuracy: 0.6818\n",
      "Epoch 1906/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5654 - accuracy: 0.6818\n",
      "Epoch 1907/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5653 - accuracy: 0.6818\n",
      "Epoch 1908/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5653 - accuracy: 0.6818\n",
      "Epoch 1909/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5652 - accuracy: 0.6818\n",
      "Epoch 1910/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5652 - accuracy: 0.6818\n",
      "Epoch 1911/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5652 - accuracy: 0.6818\n",
      "Epoch 1912/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5651 - accuracy: 0.6818\n",
      "Epoch 1913/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5651 - accuracy: 0.6818\n",
      "Epoch 1914/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5650 - accuracy: 0.6818\n",
      "Epoch 1915/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5650 - accuracy: 0.6818\n",
      "Epoch 1916/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5649 - accuracy: 0.6818\n",
      "Epoch 1917/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5649 - accuracy: 0.6818\n",
      "Epoch 1918/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5648 - accuracy: 0.6818\n",
      "Epoch 1919/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5648 - accuracy: 0.6818\n",
      "Epoch 1920/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5648 - accuracy: 0.6818\n",
      "Epoch 1921/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5647 - accuracy: 0.6818\n",
      "Epoch 1922/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5647 - accuracy: 0.6818\n",
      "Epoch 1923/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5646 - accuracy: 0.6818\n",
      "Epoch 1924/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5646 - accuracy: 0.6818\n",
      "Epoch 1925/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5645 - accuracy: 0.6818\n",
      "Epoch 1926/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5645 - accuracy: 0.6818\n",
      "Epoch 1927/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.6818\n",
      "Epoch 1928/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.6818\n",
      "Epoch 1929/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5644 - accuracy: 0.6818\n",
      "Epoch 1930/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5643 - accuracy: 0.6818\n",
      "Epoch 1931/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5643 - accuracy: 0.6818\n",
      "Epoch 1932/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5642 - accuracy: 0.6818\n",
      "Epoch 1933/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5642 - accuracy: 0.6818\n",
      "Epoch 1934/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5641 - accuracy: 0.6818\n",
      "Epoch 1935/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5641 - accuracy: 0.6818\n",
      "Epoch 1936/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5641 - accuracy: 0.6818\n",
      "Epoch 1937/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5640 - accuracy: 0.6818\n",
      "Epoch 1938/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5640 - accuracy: 0.6818\n",
      "Epoch 1939/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5639 - accuracy: 0.6818\n",
      "Epoch 1940/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5639 - accuracy: 0.6818\n",
      "Epoch 1941/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5638 - accuracy: 0.6818\n",
      "Epoch 1942/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5638 - accuracy: 0.6818\n",
      "Epoch 1943/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5637 - accuracy: 0.6818\n",
      "Epoch 1944/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5637 - accuracy: 0.6818\n",
      "Epoch 1945/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5637 - accuracy: 0.6818\n",
      "Epoch 1946/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5636 - accuracy: 0.6818\n",
      "Epoch 1947/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5636 - accuracy: 0.6818\n",
      "Epoch 1948/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5635 - accuracy: 0.6818\n",
      "Epoch 1949/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5635 - accuracy: 0.6818\n",
      "Epoch 1950/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5634 - accuracy: 0.6818\n",
      "Epoch 1951/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5634 - accuracy: 0.6818\n",
      "Epoch 1952/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5633 - accuracy: 0.6818\n",
      "Epoch 1953/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5633 - accuracy: 0.6818\n",
      "Epoch 1954/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5633 - accuracy: 0.6818\n",
      "Epoch 1955/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5632 - accuracy: 0.6818\n",
      "Epoch 1956/5000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5632 - accuracy: 0.6818\n",
      "Epoch 1957/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5631 - accuracy: 0.6818\n",
      "Epoch 1958/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5631 - accuracy: 0.6818\n",
      "Epoch 1959/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5630 - accuracy: 0.6818\n",
      "Epoch 1960/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5630 - accuracy: 0.6818\n",
      "Epoch 1961/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5629 - accuracy: 0.6818\n",
      "Epoch 1962/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5629 - accuracy: 0.6818\n",
      "Epoch 1963/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5629 - accuracy: 0.6818\n",
      "Epoch 1964/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5628 - accuracy: 0.6818\n",
      "Epoch 1965/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5628 - accuracy: 0.6818\n",
      "Epoch 1966/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5627 - accuracy: 0.6818\n",
      "Epoch 1967/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5627 - accuracy: 0.6818\n",
      "Epoch 1968/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5626 - accuracy: 0.6818\n",
      "Epoch 1969/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5626 - accuracy: 0.6818\n",
      "Epoch 1970/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5626 - accuracy: 0.6818\n",
      "Epoch 1971/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5625 - accuracy: 0.6818\n",
      "Epoch 1972/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5625 - accuracy: 0.6818\n",
      "Epoch 1973/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5624 - accuracy: 0.6818\n",
      "Epoch 1974/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5624 - accuracy: 0.6818\n",
      "Epoch 1975/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5623 - accuracy: 0.6818\n",
      "Epoch 1976/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5623 - accuracy: 0.6818\n",
      "Epoch 1977/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5622 - accuracy: 0.6818\n",
      "Epoch 1978/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5622 - accuracy: 0.6818\n",
      "Epoch 1979/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5622 - accuracy: 0.6818\n",
      "Epoch 1980/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5621 - accuracy: 0.6818\n",
      "Epoch 1981/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5621 - accuracy: 0.6818\n",
      "Epoch 1982/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5620 - accuracy: 0.6818\n",
      "Epoch 1983/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.6818\n",
      "Epoch 1984/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5619 - accuracy: 0.6818\n",
      "Epoch 1985/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5619 - accuracy: 0.6818\n",
      "Epoch 1986/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5618 - accuracy: 0.6818\n",
      "Epoch 1987/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5618 - accuracy: 0.6818\n",
      "Epoch 1988/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5618 - accuracy: 0.6818\n",
      "Epoch 1989/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5617 - accuracy: 0.6818\n",
      "Epoch 1990/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5617 - accuracy: 0.6818\n",
      "Epoch 1991/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5616 - accuracy: 0.6818\n",
      "Epoch 1992/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5616 - accuracy: 0.6818\n",
      "Epoch 1993/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5615 - accuracy: 0.6818\n",
      "Epoch 1994/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5615 - accuracy: 0.6818\n",
      "Epoch 1995/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5615 - accuracy: 0.6818\n",
      "Epoch 1996/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5614 - accuracy: 0.6818\n",
      "Epoch 1997/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5614 - accuracy: 0.6818\n",
      "Epoch 1998/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5613 - accuracy: 0.6818\n",
      "Epoch 1999/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5613 - accuracy: 0.6818\n",
      "Epoch 2000/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5612 - accuracy: 0.6818\n",
      "Epoch 2001/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5612 - accuracy: 0.6818\n",
      "Epoch 2002/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5611 - accuracy: 0.6818\n",
      "Epoch 2003/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5611 - accuracy: 0.6818\n",
      "Epoch 2004/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5611 - accuracy: 0.6818\n",
      "Epoch 2005/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5610 - accuracy: 0.6818\n",
      "Epoch 2006/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5610 - accuracy: 0.6818\n",
      "Epoch 2007/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5609 - accuracy: 0.6818\n",
      "Epoch 2008/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5609 - accuracy: 0.6818\n",
      "Epoch 2009/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.6818\n",
      "Epoch 2010/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5608 - accuracy: 0.6818\n",
      "Epoch 2011/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.6818\n",
      "Epoch 2012/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5607 - accuracy: 0.6818\n",
      "Epoch 2013/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5607 - accuracy: 0.6818\n",
      "Epoch 2014/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5606 - accuracy: 0.6818\n",
      "Epoch 2015/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5606 - accuracy: 0.6818\n",
      "Epoch 2016/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5605 - accuracy: 0.6818\n",
      "Epoch 2017/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5605 - accuracy: 0.6818\n",
      "Epoch 2018/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5604 - accuracy: 0.6818\n",
      "Epoch 2019/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5604 - accuracy: 0.6818\n",
      "Epoch 2020/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5604 - accuracy: 0.6818\n",
      "Epoch 2021/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5603 - accuracy: 0.6818\n",
      "Epoch 2022/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5603 - accuracy: 0.6818\n",
      "Epoch 2023/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.6818\n",
      "Epoch 2024/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.6818\n",
      "Epoch 2025/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.6818\n",
      "Epoch 2026/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.6818\n",
      "Epoch 2027/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.6818\n",
      "Epoch 2028/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5600 - accuracy: 0.6818\n",
      "Epoch 2029/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5600 - accuracy: 0.6818\n",
      "Epoch 2030/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5599 - accuracy: 0.6818\n",
      "Epoch 2031/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5599 - accuracy: 0.6818\n",
      "Epoch 2032/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5598 - accuracy: 0.6818\n",
      "Epoch 2033/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5598 - accuracy: 0.6818\n",
      "Epoch 2034/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5598 - accuracy: 0.6818\n",
      "Epoch 2035/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5597 - accuracy: 0.6818\n",
      "Epoch 2036/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5597 - accuracy: 0.6818\n",
      "Epoch 2037/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5596 - accuracy: 0.6818\n",
      "Epoch 2038/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5596 - accuracy: 0.6818\n",
      "Epoch 2039/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5595 - accuracy: 0.6818\n",
      "Epoch 2040/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5595 - accuracy: 0.6818\n",
      "Epoch 2041/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5594 - accuracy: 0.6818\n",
      "Epoch 2042/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5594 - accuracy: 0.6818\n",
      "Epoch 2043/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5594 - accuracy: 0.6818\n",
      "Epoch 2044/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5593 - accuracy: 0.6818\n",
      "Epoch 2045/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5593 - accuracy: 0.6818\n",
      "Epoch 2046/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5592 - accuracy: 0.6818\n",
      "Epoch 2047/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5592 - accuracy: 0.6818\n",
      "Epoch 2048/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.6818\n",
      "Epoch 2049/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.6818\n",
      "Epoch 2050/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.6818\n",
      "Epoch 2051/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5590 - accuracy: 0.6818\n",
      "Epoch 2052/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5590 - accuracy: 0.6818\n",
      "Epoch 2053/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5589 - accuracy: 0.6818\n",
      "Epoch 2054/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5589 - accuracy: 0.6818\n",
      "Epoch 2055/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5588 - accuracy: 0.6818\n",
      "Epoch 2056/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5588 - accuracy: 0.6818\n",
      "Epoch 2057/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5588 - accuracy: 0.6818\n",
      "Epoch 2058/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5587 - accuracy: 0.6818\n",
      "Epoch 2059/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5587 - accuracy: 0.6818\n",
      "Epoch 2060/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5586 - accuracy: 0.6818\n",
      "Epoch 2061/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5586 - accuracy: 0.6818\n",
      "Epoch 2062/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5585 - accuracy: 0.6818\n",
      "Epoch 2063/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5585 - accuracy: 0.6818\n",
      "Epoch 2064/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5584 - accuracy: 0.6818\n",
      "Epoch 2065/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5584 - accuracy: 0.6818\n",
      "Epoch 2066/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5584 - accuracy: 0.6818\n",
      "Epoch 2067/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5583 - accuracy: 0.6818\n",
      "Epoch 2068/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5583 - accuracy: 0.6818\n",
      "Epoch 2069/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5582 - accuracy: 0.6818\n",
      "Epoch 2070/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5582 - accuracy: 0.6818\n",
      "Epoch 2071/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5581 - accuracy: 0.6818\n",
      "Epoch 2072/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5581 - accuracy: 0.6818\n",
      "Epoch 2073/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5581 - accuracy: 0.6818\n",
      "Epoch 2074/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5580 - accuracy: 0.6818\n",
      "Epoch 2075/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5580 - accuracy: 0.6818\n",
      "Epoch 2076/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5579 - accuracy: 0.6818\n",
      "Epoch 2077/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5579 - accuracy: 0.6818\n",
      "Epoch 2078/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5578 - accuracy: 0.6818\n",
      "Epoch 2079/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5578 - accuracy: 0.6818\n",
      "Epoch 2080/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5578 - accuracy: 0.6818\n",
      "Epoch 2081/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5577 - accuracy: 0.6818\n",
      "Epoch 2082/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5577 - accuracy: 0.6818\n",
      "Epoch 2083/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5576 - accuracy: 0.6818\n",
      "Epoch 2084/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5576 - accuracy: 0.6818\n",
      "Epoch 2085/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5575 - accuracy: 0.6818\n",
      "Epoch 2086/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5575 - accuracy: 0.6818\n",
      "Epoch 2087/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5575 - accuracy: 0.6818\n",
      "Epoch 2088/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5574 - accuracy: 0.6818\n",
      "Epoch 2089/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5574 - accuracy: 0.6818\n",
      "Epoch 2090/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.6818\n",
      "Epoch 2091/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5573 - accuracy: 0.6818\n",
      "Epoch 2092/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5572 - accuracy: 0.6818\n",
      "Epoch 2093/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5572 - accuracy: 0.6818\n",
      "Epoch 2094/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5572 - accuracy: 0.6818\n",
      "Epoch 2095/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5571 - accuracy: 0.6818\n",
      "Epoch 2096/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5571 - accuracy: 0.6818\n",
      "Epoch 2097/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.6818\n",
      "Epoch 2098/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.6818\n",
      "Epoch 2099/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.6818\n",
      "Epoch 2100/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.6818\n",
      "Epoch 2101/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.6818\n",
      "Epoch 2102/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5568 - accuracy: 0.6818\n",
      "Epoch 2103/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5568 - accuracy: 0.6818\n",
      "Epoch 2104/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5567 - accuracy: 0.6818\n",
      "Epoch 2105/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5567 - accuracy: 0.6818\n",
      "Epoch 2106/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5566 - accuracy: 0.6818\n",
      "Epoch 2107/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5566 - accuracy: 0.6818\n",
      "Epoch 2108/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5566 - accuracy: 0.6818\n",
      "Epoch 2109/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5565 - accuracy: 0.6818\n",
      "Epoch 2110/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5565 - accuracy: 0.6818\n",
      "Epoch 2111/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5564 - accuracy: 0.6818\n",
      "Epoch 2112/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5564 - accuracy: 0.6818\n",
      "Epoch 2113/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5563 - accuracy: 0.6818\n",
      "Epoch 2114/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5563 - accuracy: 0.6818\n",
      "Epoch 2115/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5563 - accuracy: 0.6818\n",
      "Epoch 2116/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5562 - accuracy: 0.6818\n",
      "Epoch 2117/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5562 - accuracy: 0.6818\n",
      "Epoch 2118/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5561 - accuracy: 0.6818\n",
      "Epoch 2119/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5561 - accuracy: 0.6818\n",
      "Epoch 2120/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5560 - accuracy: 0.6818\n",
      "Epoch 2121/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5560 - accuracy: 0.6818\n",
      "Epoch 2122/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5560 - accuracy: 0.6818\n",
      "Epoch 2123/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5559 - accuracy: 0.6818\n",
      "Epoch 2124/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5559 - accuracy: 0.6818\n",
      "Epoch 2125/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5558 - accuracy: 0.6818\n",
      "Epoch 2126/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5558 - accuracy: 0.6818\n",
      "Epoch 2127/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5557 - accuracy: 0.6818\n",
      "Epoch 2128/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5557 - accuracy: 0.6818\n",
      "Epoch 2129/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5557 - accuracy: 0.6818\n",
      "Epoch 2130/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5556 - accuracy: 0.6818\n",
      "Epoch 2131/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5556 - accuracy: 0.6818\n",
      "Epoch 2132/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5555 - accuracy: 0.6818\n",
      "Epoch 2133/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5555 - accuracy: 0.6818\n",
      "Epoch 2134/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5554 - accuracy: 0.6818\n",
      "Epoch 2135/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5554 - accuracy: 0.6818\n",
      "Epoch 2136/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5554 - accuracy: 0.6818\n",
      "Epoch 2137/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5553 - accuracy: 0.6818\n",
      "Epoch 2138/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5553 - accuracy: 0.6818\n",
      "Epoch 2139/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5552 - accuracy: 0.6818\n",
      "Epoch 2140/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5552 - accuracy: 0.6818\n",
      "Epoch 2141/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5551 - accuracy: 0.6818\n",
      "Epoch 2142/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5551 - accuracy: 0.6818\n",
      "Epoch 2143/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5551 - accuracy: 0.6818\n",
      "Epoch 2144/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5550 - accuracy: 0.6818\n",
      "Epoch 2145/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5550 - accuracy: 0.6818\n",
      "Epoch 2146/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5549 - accuracy: 0.6818\n",
      "Epoch 2147/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5549 - accuracy: 0.6818\n",
      "Epoch 2148/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5548 - accuracy: 0.6818\n",
      "Epoch 2149/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5548 - accuracy: 0.6818\n",
      "Epoch 2150/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5548 - accuracy: 0.7273\n",
      "Epoch 2151/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5547 - accuracy: 0.7273\n",
      "Epoch 2152/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5547 - accuracy: 0.7273\n",
      "Epoch 2153/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5546 - accuracy: 0.7273\n",
      "Epoch 2154/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5546 - accuracy: 0.7273\n",
      "Epoch 2155/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5545 - accuracy: 0.7273\n",
      "Epoch 2156/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5545 - accuracy: 0.7273\n",
      "Epoch 2157/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5545 - accuracy: 0.7273\n",
      "Epoch 2158/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.7273\n",
      "Epoch 2159/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.7273\n",
      "Epoch 2160/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5543 - accuracy: 0.7273\n",
      "Epoch 2161/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5543 - accuracy: 0.7273\n",
      "Epoch 2162/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5542 - accuracy: 0.7273\n",
      "Epoch 2163/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5542 - accuracy: 0.7273\n",
      "Epoch 2164/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5542 - accuracy: 0.7273\n",
      "Epoch 2165/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5541 - accuracy: 0.7273\n",
      "Epoch 2166/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5541 - accuracy: 0.7273\n",
      "Epoch 2167/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5540 - accuracy: 0.7273\n",
      "Epoch 2168/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5540 - accuracy: 0.7273\n",
      "Epoch 2169/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5539 - accuracy: 0.7273\n",
      "Epoch 2170/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5539 - accuracy: 0.7273\n",
      "Epoch 2171/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5539 - accuracy: 0.7273\n",
      "Epoch 2172/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5538 - accuracy: 0.7273\n",
      "Epoch 2173/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5538 - accuracy: 0.7273\n",
      "Epoch 2174/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5537 - accuracy: 0.7273\n",
      "Epoch 2175/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5537 - accuracy: 0.7273\n",
      "Epoch 2176/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5536 - accuracy: 0.7273\n",
      "Epoch 2177/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5536 - accuracy: 0.7273\n",
      "Epoch 2178/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5536 - accuracy: 0.7273\n",
      "Epoch 2179/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5535 - accuracy: 0.7273\n",
      "Epoch 2180/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5535 - accuracy: 0.7273\n",
      "Epoch 2181/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.7273\n",
      "Epoch 2182/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.7273\n",
      "Epoch 2183/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5534 - accuracy: 0.7273\n",
      "Epoch 2184/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.7273\n",
      "Epoch 2185/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5533 - accuracy: 0.7273\n",
      "Epoch 2186/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5532 - accuracy: 0.7273\n",
      "Epoch 2187/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5532 - accuracy: 0.7273\n",
      "Epoch 2188/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5531 - accuracy: 0.7273\n",
      "Epoch 2189/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5531 - accuracy: 0.7273\n",
      "Epoch 2190/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5531 - accuracy: 0.7273\n",
      "Epoch 2191/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5530 - accuracy: 0.7273\n",
      "Epoch 2192/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5530 - accuracy: 0.7273\n",
      "Epoch 2193/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5529 - accuracy: 0.7273\n",
      "Epoch 2194/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5529 - accuracy: 0.7273\n",
      "Epoch 2195/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5528 - accuracy: 0.7273\n",
      "Epoch 2196/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5528 - accuracy: 0.7273\n",
      "Epoch 2197/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5528 - accuracy: 0.7273\n",
      "Epoch 2198/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5527 - accuracy: 0.7273\n",
      "Epoch 2199/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5527 - accuracy: 0.7273\n",
      "Epoch 2200/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5526 - accuracy: 0.7273\n",
      "Epoch 2201/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5526 - accuracy: 0.7273\n",
      "Epoch 2202/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5525 - accuracy: 0.7273\n",
      "Epoch 2203/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5525 - accuracy: 0.7273\n",
      "Epoch 2204/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5525 - accuracy: 0.7273\n",
      "Epoch 2205/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5524 - accuracy: 0.7273\n",
      "Epoch 2206/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5524 - accuracy: 0.7273\n",
      "Epoch 2207/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5523 - accuracy: 0.7273\n",
      "Epoch 2208/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5523 - accuracy: 0.7273\n",
      "Epoch 2209/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5523 - accuracy: 0.7273\n",
      "Epoch 2210/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5522 - accuracy: 0.7273\n",
      "Epoch 2211/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5522 - accuracy: 0.7273\n",
      "Epoch 2212/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5521 - accuracy: 0.7273\n",
      "Epoch 2213/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5521 - accuracy: 0.7273\n",
      "Epoch 2214/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5520 - accuracy: 0.7273\n",
      "Epoch 2215/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5520 - accuracy: 0.7273\n",
      "Epoch 2216/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5520 - accuracy: 0.7273\n",
      "Epoch 2217/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5519 - accuracy: 0.7273\n",
      "Epoch 2218/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5519 - accuracy: 0.7273\n",
      "Epoch 2219/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5518 - accuracy: 0.7273\n",
      "Epoch 2220/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5518 - accuracy: 0.7273\n",
      "Epoch 2221/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7273\n",
      "Epoch 2222/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7273\n",
      "Epoch 2223/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5517 - accuracy: 0.7273\n",
      "Epoch 2224/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5516 - accuracy: 0.7273\n",
      "Epoch 2225/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5516 - accuracy: 0.7273\n",
      "Epoch 2226/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.7273\n",
      "Epoch 2227/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.7273\n",
      "Epoch 2228/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.7273\n",
      "Epoch 2229/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5514 - accuracy: 0.7273\n",
      "Epoch 2230/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5514 - accuracy: 0.7273\n",
      "Epoch 2231/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5513 - accuracy: 0.7273\n",
      "Epoch 2232/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5513 - accuracy: 0.7273\n",
      "Epoch 2233/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5512 - accuracy: 0.7273\n",
      "Epoch 2234/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5512 - accuracy: 0.7273\n",
      "Epoch 2235/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5512 - accuracy: 0.7273\n",
      "Epoch 2236/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5511 - accuracy: 0.7273\n",
      "Epoch 2237/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5511 - accuracy: 0.7273\n",
      "Epoch 2238/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5510 - accuracy: 0.7273\n",
      "Epoch 2239/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5510 - accuracy: 0.7273\n",
      "Epoch 2240/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5510 - accuracy: 0.7273\n",
      "Epoch 2241/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5509 - accuracy: 0.7273\n",
      "Epoch 2242/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5509 - accuracy: 0.7273\n",
      "Epoch 2243/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5508 - accuracy: 0.7273\n",
      "Epoch 2244/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5508 - accuracy: 0.7273\n",
      "Epoch 2245/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5507 - accuracy: 0.7273\n",
      "Epoch 2246/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5507 - accuracy: 0.7273\n",
      "Epoch 2247/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5507 - accuracy: 0.7273\n",
      "Epoch 2248/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5506 - accuracy: 0.7273\n",
      "Epoch 2249/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5506 - accuracy: 0.7273\n",
      "Epoch 2250/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5505 - accuracy: 0.7273\n",
      "Epoch 2251/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5505 - accuracy: 0.7273\n",
      "Epoch 2252/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5505 - accuracy: 0.7273\n",
      "Epoch 2253/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.7273\n",
      "Epoch 2254/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.7273\n",
      "Epoch 2255/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5503 - accuracy: 0.7273\n",
      "Epoch 2256/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5503 - accuracy: 0.7273\n",
      "Epoch 2257/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5502 - accuracy: 0.7273\n",
      "Epoch 2258/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5502 - accuracy: 0.7273\n",
      "Epoch 2259/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5502 - accuracy: 0.7273\n",
      "Epoch 2260/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5501 - accuracy: 0.7273\n",
      "Epoch 2261/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5501 - accuracy: 0.7273\n",
      "Epoch 2262/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5500 - accuracy: 0.7273\n",
      "Epoch 2263/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5500 - accuracy: 0.7273\n",
      "Epoch 2264/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.7273\n",
      "Epoch 2265/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.7273\n",
      "Epoch 2266/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5499 - accuracy: 0.7273\n",
      "Epoch 2267/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5498 - accuracy: 0.7273\n",
      "Epoch 2268/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5498 - accuracy: 0.7273\n",
      "Epoch 2269/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5497 - accuracy: 0.7273\n",
      "Epoch 2270/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5497 - accuracy: 0.7273\n",
      "Epoch 2271/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5497 - accuracy: 0.7273\n",
      "Epoch 2272/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5496 - accuracy: 0.7273\n",
      "Epoch 2273/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5496 - accuracy: 0.7273\n",
      "Epoch 2274/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5495 - accuracy: 0.7273\n",
      "Epoch 2275/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5495 - accuracy: 0.7273\n",
      "Epoch 2276/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5495 - accuracy: 0.7273\n",
      "Epoch 2277/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.7273\n",
      "Epoch 2278/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.7273\n",
      "Epoch 2279/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5493 - accuracy: 0.7273\n",
      "Epoch 2280/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5493 - accuracy: 0.7273\n",
      "Epoch 2281/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5492 - accuracy: 0.7273\n",
      "Epoch 2282/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5492 - accuracy: 0.7273\n",
      "Epoch 2283/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5492 - accuracy: 0.7273\n",
      "Epoch 2284/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5491 - accuracy: 0.7273\n",
      "Epoch 2285/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5491 - accuracy: 0.7273\n",
      "Epoch 2286/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5490 - accuracy: 0.7273\n",
      "Epoch 2287/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5490 - accuracy: 0.7273\n",
      "Epoch 2288/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5490 - accuracy: 0.7273\n",
      "Epoch 2289/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5489 - accuracy: 0.7273\n",
      "Epoch 2290/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5489 - accuracy: 0.7273\n",
      "Epoch 2291/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5488 - accuracy: 0.7273\n",
      "Epoch 2292/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5488 - accuracy: 0.7273\n",
      "Epoch 2293/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5487 - accuracy: 0.7273\n",
      "Epoch 2294/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5487 - accuracy: 0.7273\n",
      "Epoch 2295/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5487 - accuracy: 0.7273\n",
      "Epoch 2296/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5486 - accuracy: 0.7273\n",
      "Epoch 2297/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5486 - accuracy: 0.7273\n",
      "Epoch 2298/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5485 - accuracy: 0.7273\n",
      "Epoch 2299/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5485 - accuracy: 0.7273\n",
      "Epoch 2300/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5485 - accuracy: 0.7273\n",
      "Epoch 2301/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5484 - accuracy: 0.7273\n",
      "Epoch 2302/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5484 - accuracy: 0.7273\n",
      "Epoch 2303/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5483 - accuracy: 0.7273\n",
      "Epoch 2304/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5483 - accuracy: 0.7273\n",
      "Epoch 2305/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5482 - accuracy: 0.7273\n",
      "Epoch 2306/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5482 - accuracy: 0.7273\n",
      "Epoch 2307/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5482 - accuracy: 0.7273\n",
      "Epoch 2308/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5481 - accuracy: 0.7273\n",
      "Epoch 2309/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5481 - accuracy: 0.7273\n",
      "Epoch 2310/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5480 - accuracy: 0.7273\n",
      "Epoch 2311/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5480 - accuracy: 0.7273\n",
      "Epoch 2312/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5480 - accuracy: 0.7273\n",
      "Epoch 2313/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5479 - accuracy: 0.7273\n",
      "Epoch 2314/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5479 - accuracy: 0.7273\n",
      "Epoch 2315/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.7273\n",
      "Epoch 2316/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.7273\n",
      "Epoch 2317/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.7273\n",
      "Epoch 2318/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.7273\n",
      "Epoch 2319/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5477 - accuracy: 0.7273\n",
      "Epoch 2320/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5476 - accuracy: 0.7273\n",
      "Epoch 2321/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5476 - accuracy: 0.7273\n",
      "Epoch 2322/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5475 - accuracy: 0.7273\n",
      "Epoch 2323/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5475 - accuracy: 0.7273\n",
      "Epoch 2324/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5475 - accuracy: 0.7273\n",
      "Epoch 2325/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5474 - accuracy: 0.7273\n",
      "Epoch 2326/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5474 - accuracy: 0.7273\n",
      "Epoch 2327/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5473 - accuracy: 0.7273\n",
      "Epoch 2328/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5473 - accuracy: 0.7273\n",
      "Epoch 2329/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5473 - accuracy: 0.7273\n",
      "Epoch 2330/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5472 - accuracy: 0.7273\n",
      "Epoch 2331/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5472 - accuracy: 0.7273\n",
      "Epoch 2332/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5471 - accuracy: 0.7273\n",
      "Epoch 2333/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5471 - accuracy: 0.7273\n",
      "Epoch 2334/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5471 - accuracy: 0.7273\n",
      "Epoch 2335/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5470 - accuracy: 0.7273\n",
      "Epoch 2336/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5470 - accuracy: 0.7273\n",
      "Epoch 2337/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5469 - accuracy: 0.7273\n",
      "Epoch 2338/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5469 - accuracy: 0.7273\n",
      "Epoch 2339/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5468 - accuracy: 0.7273\n",
      "Epoch 2340/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5468 - accuracy: 0.7273\n",
      "Epoch 2341/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5468 - accuracy: 0.7273\n",
      "Epoch 2342/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5467 - accuracy: 0.7273\n",
      "Epoch 2343/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5467 - accuracy: 0.7273\n",
      "Epoch 2344/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5466 - accuracy: 0.7273\n",
      "Epoch 2345/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5466 - accuracy: 0.7273\n",
      "Epoch 2346/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5466 - accuracy: 0.7273\n",
      "Epoch 2347/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5465 - accuracy: 0.7273\n",
      "Epoch 2348/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5465 - accuracy: 0.7273\n",
      "Epoch 2349/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5464 - accuracy: 0.7273\n",
      "Epoch 2350/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5464 - accuracy: 0.7273\n",
      "Epoch 2351/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5464 - accuracy: 0.7273\n",
      "Epoch 2352/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5463 - accuracy: 0.7273\n",
      "Epoch 2353/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5463 - accuracy: 0.7273\n",
      "Epoch 2354/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5462 - accuracy: 0.7273\n",
      "Epoch 2355/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.7273\n",
      "Epoch 2356/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.7273\n",
      "Epoch 2357/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5461 - accuracy: 0.7273\n",
      "Epoch 2358/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5461 - accuracy: 0.7273\n",
      "Epoch 2359/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5460 - accuracy: 0.7273\n",
      "Epoch 2360/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5460 - accuracy: 0.7273\n",
      "Epoch 2361/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5459 - accuracy: 0.7273\n",
      "Epoch 2362/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5459 - accuracy: 0.7273\n",
      "Epoch 2363/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5459 - accuracy: 0.7273\n",
      "Epoch 2364/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5458 - accuracy: 0.7273\n",
      "Epoch 2365/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5458 - accuracy: 0.7273\n",
      "Epoch 2366/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5457 - accuracy: 0.7273\n",
      "Epoch 2367/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5457 - accuracy: 0.7273\n",
      "Epoch 2368/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5457 - accuracy: 0.7273\n",
      "Epoch 2369/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5456 - accuracy: 0.7273\n",
      "Epoch 2370/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5456 - accuracy: 0.7273\n",
      "Epoch 2371/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5455 - accuracy: 0.7273\n",
      "Epoch 2372/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5455 - accuracy: 0.7273\n",
      "Epoch 2373/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5455 - accuracy: 0.7273\n",
      "Epoch 2374/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5454 - accuracy: 0.7273\n",
      "Epoch 2375/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5454 - accuracy: 0.7273\n",
      "Epoch 2376/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5453 - accuracy: 0.7273\n",
      "Epoch 2377/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5453 - accuracy: 0.7273\n",
      "Epoch 2378/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5453 - accuracy: 0.7273\n",
      "Epoch 2379/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5452 - accuracy: 0.7273\n",
      "Epoch 2380/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5452 - accuracy: 0.7273\n",
      "Epoch 2381/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5451 - accuracy: 0.7273\n",
      "Epoch 2382/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5451 - accuracy: 0.7273\n",
      "Epoch 2383/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5451 - accuracy: 0.7273\n",
      "Epoch 2384/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5450 - accuracy: 0.7273\n",
      "Epoch 2385/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5450 - accuracy: 0.7273\n",
      "Epoch 2386/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5449 - accuracy: 0.7273\n",
      "Epoch 2387/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5449 - accuracy: 0.7273\n",
      "Epoch 2388/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5448 - accuracy: 0.7273\n",
      "Epoch 2389/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5448 - accuracy: 0.7273\n",
      "Epoch 2390/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5448 - accuracy: 0.7273\n",
      "Epoch 2391/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5447 - accuracy: 0.7273\n",
      "Epoch 2392/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5447 - accuracy: 0.7273\n",
      "Epoch 2393/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5446 - accuracy: 0.7273\n",
      "Epoch 2394/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5446 - accuracy: 0.7273\n",
      "Epoch 2395/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5446 - accuracy: 0.7273\n",
      "Epoch 2396/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5445 - accuracy: 0.7273\n",
      "Epoch 2397/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5445 - accuracy: 0.7273\n",
      "Epoch 2398/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.7273\n",
      "Epoch 2399/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.7273\n",
      "Epoch 2400/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5444 - accuracy: 0.7273\n",
      "Epoch 2401/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5443 - accuracy: 0.7273\n",
      "Epoch 2402/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5443 - accuracy: 0.7273\n",
      "Epoch 2403/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.7273\n",
      "Epoch 2404/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.7273\n",
      "Epoch 2405/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.7273\n",
      "Epoch 2406/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5441 - accuracy: 0.7273\n",
      "Epoch 2407/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5441 - accuracy: 0.7273\n",
      "Epoch 2408/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5440 - accuracy: 0.7273\n",
      "Epoch 2409/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5440 - accuracy: 0.7273\n",
      "Epoch 2410/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5440 - accuracy: 0.7273\n",
      "Epoch 2411/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5439 - accuracy: 0.7273\n",
      "Epoch 2412/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5439 - accuracy: 0.7273\n",
      "Epoch 2413/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5438 - accuracy: 0.7273\n",
      "Epoch 2414/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5438 - accuracy: 0.7273\n",
      "Epoch 2415/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5438 - accuracy: 0.7273\n",
      "Epoch 2416/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5437 - accuracy: 0.7273\n",
      "Epoch 2417/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5437 - accuracy: 0.7273\n",
      "Epoch 2418/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5436 - accuracy: 0.7273\n",
      "Epoch 2419/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5436 - accuracy: 0.7273\n",
      "Epoch 2420/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5436 - accuracy: 0.7273\n",
      "Epoch 2421/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5435 - accuracy: 0.7273\n",
      "Epoch 2422/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5435 - accuracy: 0.7273\n",
      "Epoch 2423/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.7273\n",
      "Epoch 2424/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.7273\n",
      "Epoch 2425/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.7273\n",
      "Epoch 2426/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5433 - accuracy: 0.7273\n",
      "Epoch 2427/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5433 - accuracy: 0.7273\n",
      "Epoch 2428/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5432 - accuracy: 0.7273\n",
      "Epoch 2429/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5432 - accuracy: 0.7273\n",
      "Epoch 2430/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5432 - accuracy: 0.7273\n",
      "Epoch 2431/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5431 - accuracy: 0.7273\n",
      "Epoch 2432/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5431 - accuracy: 0.7273\n",
      "Epoch 2433/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5430 - accuracy: 0.7273\n",
      "Epoch 2434/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5430 - accuracy: 0.7273\n",
      "Epoch 2435/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5430 - accuracy: 0.7273\n",
      "Epoch 2436/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5429 - accuracy: 0.7273\n",
      "Epoch 2437/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5429 - accuracy: 0.7273\n",
      "Epoch 2438/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5428 - accuracy: 0.7273\n",
      "Epoch 2439/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5428 - accuracy: 0.7273\n",
      "Epoch 2440/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5428 - accuracy: 0.7273\n",
      "Epoch 2441/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5427 - accuracy: 0.7273\n",
      "Epoch 2442/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5427 - accuracy: 0.7273\n",
      "Epoch 2443/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5426 - accuracy: 0.7273\n",
      "Epoch 2444/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5426 - accuracy: 0.7273\n",
      "Epoch 2445/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5425 - accuracy: 0.7273\n",
      "Epoch 2446/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5425 - accuracy: 0.7273\n",
      "Epoch 2447/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5425 - accuracy: 0.7273\n",
      "Epoch 2448/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5424 - accuracy: 0.7273\n",
      "Epoch 2449/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5424 - accuracy: 0.7273\n",
      "Epoch 2450/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5423 - accuracy: 0.7273\n",
      "Epoch 2451/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5423 - accuracy: 0.7273\n",
      "Epoch 2452/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5423 - accuracy: 0.7273\n",
      "Epoch 2453/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5422 - accuracy: 0.7273\n",
      "Epoch 2454/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5422 - accuracy: 0.7273\n",
      "Epoch 2455/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5421 - accuracy: 0.7273\n",
      "Epoch 2456/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5421 - accuracy: 0.7273\n",
      "Epoch 2457/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5421 - accuracy: 0.7273\n",
      "Epoch 2458/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7273\n",
      "Epoch 2459/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5420 - accuracy: 0.7273\n",
      "Epoch 2460/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5419 - accuracy: 0.7273\n",
      "Epoch 2461/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5419 - accuracy: 0.7273\n",
      "Epoch 2462/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5419 - accuracy: 0.7273\n",
      "Epoch 2463/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5418 - accuracy: 0.7273\n",
      "Epoch 2464/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5418 - accuracy: 0.7273\n",
      "Epoch 2465/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5417 - accuracy: 0.7273\n",
      "Epoch 2466/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5417 - accuracy: 0.7273\n",
      "Epoch 2467/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5417 - accuracy: 0.7273\n",
      "Epoch 2468/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5416 - accuracy: 0.7273\n",
      "Epoch 2469/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5416 - accuracy: 0.7273\n",
      "Epoch 2470/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5416 - accuracy: 0.7273\n",
      "Epoch 2471/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5415 - accuracy: 0.7273\n",
      "Epoch 2472/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5415 - accuracy: 0.7273\n",
      "Epoch 2473/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.7273\n",
      "Epoch 2474/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.7273\n",
      "Epoch 2475/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5414 - accuracy: 0.7273\n",
      "Epoch 2476/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5413 - accuracy: 0.7273\n",
      "Epoch 2477/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5413 - accuracy: 0.7273\n",
      "Epoch 2478/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5412 - accuracy: 0.7273\n",
      "Epoch 2479/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5412 - accuracy: 0.7273\n",
      "Epoch 2480/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5412 - accuracy: 0.7273\n",
      "Epoch 2481/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5411 - accuracy: 0.7273\n",
      "Epoch 2482/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5411 - accuracy: 0.7273\n",
      "Epoch 2483/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.7273\n",
      "Epoch 2484/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.7273\n",
      "Epoch 2485/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.7273\n",
      "Epoch 2486/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5409 - accuracy: 0.7273\n",
      "Epoch 2487/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5409 - accuracy: 0.7273\n",
      "Epoch 2488/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5408 - accuracy: 0.7273\n",
      "Epoch 2489/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5408 - accuracy: 0.7273\n",
      "Epoch 2490/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5408 - accuracy: 0.7727\n",
      "Epoch 2491/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5407 - accuracy: 0.7727\n",
      "Epoch 2492/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5407 - accuracy: 0.7727\n",
      "Epoch 2493/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5406 - accuracy: 0.7727\n",
      "Epoch 2494/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5406 - accuracy: 0.7727\n",
      "Epoch 2495/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5406 - accuracy: 0.7727\n",
      "Epoch 2496/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.7727\n",
      "Epoch 2497/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.7727\n",
      "Epoch 2498/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5404 - accuracy: 0.7727\n",
      "Epoch 2499/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5404 - accuracy: 0.7727\n",
      "Epoch 2500/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5404 - accuracy: 0.7727\n",
      "Epoch 2501/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5403 - accuracy: 0.7727\n",
      "Epoch 2502/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5403 - accuracy: 0.7727\n",
      "Epoch 2503/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5402 - accuracy: 0.7727\n",
      "Epoch 2504/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5402 - accuracy: 0.7727\n",
      "Epoch 2505/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5402 - accuracy: 0.7727\n",
      "Epoch 2506/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5401 - accuracy: 0.7727\n",
      "Epoch 2507/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5401 - accuracy: 0.7727\n",
      "Epoch 2508/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.7727\n",
      "Epoch 2509/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.7727\n",
      "Epoch 2510/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5400 - accuracy: 0.7727\n",
      "Epoch 2511/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5399 - accuracy: 0.7727\n",
      "Epoch 2512/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5399 - accuracy: 0.7727\n",
      "Epoch 2513/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5398 - accuracy: 0.7727\n",
      "Epoch 2514/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5398 - accuracy: 0.7727\n",
      "Epoch 2515/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5398 - accuracy: 0.7727\n",
      "Epoch 2516/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5397 - accuracy: 0.7727\n",
      "Epoch 2517/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5397 - accuracy: 0.7727\n",
      "Epoch 2518/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5396 - accuracy: 0.7727\n",
      "Epoch 2519/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5396 - accuracy: 0.7727\n",
      "Epoch 2520/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5396 - accuracy: 0.7727\n",
      "Epoch 2521/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5395 - accuracy: 0.7727\n",
      "Epoch 2522/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5395 - accuracy: 0.7727\n",
      "Epoch 2523/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5395 - accuracy: 0.7727\n",
      "Epoch 2524/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5394 - accuracy: 0.7727\n",
      "Epoch 2525/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5394 - accuracy: 0.7727\n",
      "Epoch 2526/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5393 - accuracy: 0.7727\n",
      "Epoch 2527/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5393 - accuracy: 0.7727\n",
      "Epoch 2528/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5393 - accuracy: 0.7727\n",
      "Epoch 2529/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5392 - accuracy: 0.7727\n",
      "Epoch 2530/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5392 - accuracy: 0.7727\n",
      "Epoch 2531/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5391 - accuracy: 0.7727\n",
      "Epoch 2532/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5391 - accuracy: 0.7727\n",
      "Epoch 2533/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5391 - accuracy: 0.7727\n",
      "Epoch 2534/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5390 - accuracy: 0.7727\n",
      "Epoch 2535/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5390 - accuracy: 0.7727\n",
      "Epoch 2536/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7727\n",
      "Epoch 2537/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5389 - accuracy: 0.7727\n",
      "Epoch 2538/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5389 - accuracy: 0.7727\n",
      "Epoch 2539/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5388 - accuracy: 0.7727\n",
      "Epoch 2540/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5388 - accuracy: 0.7727\n",
      "Epoch 2541/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5387 - accuracy: 0.7727\n",
      "Epoch 2542/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5387 - accuracy: 0.7727\n",
      "Epoch 2543/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5387 - accuracy: 0.7727\n",
      "Epoch 2544/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5386 - accuracy: 0.7727\n",
      "Epoch 2545/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5386 - accuracy: 0.7727\n",
      "Epoch 2546/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.7727\n",
      "Epoch 2547/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.7727\n",
      "Epoch 2548/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5385 - accuracy: 0.7727\n",
      "Epoch 2549/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5384 - accuracy: 0.7727\n",
      "Epoch 2550/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5384 - accuracy: 0.7727\n",
      "Epoch 2551/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5384 - accuracy: 0.7727\n",
      "Epoch 2552/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5383 - accuracy: 0.7727\n",
      "Epoch 2553/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5383 - accuracy: 0.7727\n",
      "Epoch 2554/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.7727\n",
      "Epoch 2555/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.7727\n",
      "Epoch 2556/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.7727\n",
      "Epoch 2557/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5381 - accuracy: 0.7727\n",
      "Epoch 2558/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5381 - accuracy: 0.7727\n",
      "Epoch 2559/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5380 - accuracy: 0.7727\n",
      "Epoch 2560/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5380 - accuracy: 0.7727\n",
      "Epoch 2561/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5380 - accuracy: 0.7727\n",
      "Epoch 2562/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5379 - accuracy: 0.7727\n",
      "Epoch 2563/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5379 - accuracy: 0.7727\n",
      "Epoch 2564/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5378 - accuracy: 0.7727\n",
      "Epoch 2565/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5378 - accuracy: 0.7727\n",
      "Epoch 2566/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5378 - accuracy: 0.7727\n",
      "Epoch 2567/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5377 - accuracy: 0.7727\n",
      "Epoch 2568/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5377 - accuracy: 0.7727\n",
      "Epoch 2569/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5376 - accuracy: 0.7727\n",
      "Epoch 2570/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5376 - accuracy: 0.7727\n",
      "Epoch 2571/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5376 - accuracy: 0.7727\n",
      "Epoch 2572/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5375 - accuracy: 0.7727\n",
      "Epoch 2573/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5375 - accuracy: 0.7727\n",
      "Epoch 2574/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5375 - accuracy: 0.7727\n",
      "Epoch 2575/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5374 - accuracy: 0.7727\n",
      "Epoch 2576/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5374 - accuracy: 0.7727\n",
      "Epoch 2577/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5373 - accuracy: 0.7727\n",
      "Epoch 2578/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5373 - accuracy: 0.7727\n",
      "Epoch 2579/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5373 - accuracy: 0.7727\n",
      "Epoch 2580/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5372 - accuracy: 0.7727\n",
      "Epoch 2581/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5372 - accuracy: 0.7727\n",
      "Epoch 2582/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5371 - accuracy: 0.7727\n",
      "Epoch 2583/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5371 - accuracy: 0.7727\n",
      "Epoch 2584/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5371 - accuracy: 0.7727\n",
      "Epoch 2585/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7727\n",
      "Epoch 2586/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7727\n",
      "Epoch 2587/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.7727\n",
      "Epoch 2588/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.7727\n",
      "Epoch 2589/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.7727\n",
      "Epoch 2590/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5368 - accuracy: 0.7727\n",
      "Epoch 2591/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5368 - accuracy: 0.7727\n",
      "Epoch 2592/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5368 - accuracy: 0.7727\n",
      "Epoch 2593/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5367 - accuracy: 0.7727\n",
      "Epoch 2594/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5367 - accuracy: 0.7727\n",
      "Epoch 2595/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5366 - accuracy: 0.7727\n",
      "Epoch 2596/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5366 - accuracy: 0.7727\n",
      "Epoch 2597/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5366 - accuracy: 0.7727\n",
      "Epoch 2598/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5365 - accuracy: 0.7727\n",
      "Epoch 2599/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5365 - accuracy: 0.7727\n",
      "Epoch 2600/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5364 - accuracy: 0.7727\n",
      "Epoch 2601/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5364 - accuracy: 0.7727\n",
      "Epoch 2602/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5364 - accuracy: 0.7727\n",
      "Epoch 2603/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5363 - accuracy: 0.7727\n",
      "Epoch 2604/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5363 - accuracy: 0.7727\n",
      "Epoch 2605/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5363 - accuracy: 0.7727\n",
      "Epoch 2606/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5362 - accuracy: 0.7727\n",
      "Epoch 2607/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5362 - accuracy: 0.7727\n",
      "Epoch 2608/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.7727\n",
      "Epoch 2609/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.7727\n",
      "Epoch 2610/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5361 - accuracy: 0.7727\n",
      "Epoch 2611/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5360 - accuracy: 0.7727\n",
      "Epoch 2612/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5360 - accuracy: 0.7727\n",
      "Epoch 2613/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5359 - accuracy: 0.7727\n",
      "Epoch 2614/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5359 - accuracy: 0.7727\n",
      "Epoch 2615/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5359 - accuracy: 0.7727\n",
      "Epoch 2616/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5358 - accuracy: 0.7727\n",
      "Epoch 2617/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5358 - accuracy: 0.7727\n",
      "Epoch 2618/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.7727\n",
      "Epoch 2619/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.7727\n",
      "Epoch 2620/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.7727\n",
      "Epoch 2621/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.7727\n",
      "Epoch 2622/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.7727\n",
      "Epoch 2623/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.7727\n",
      "Epoch 2624/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5355 - accuracy: 0.7727\n",
      "Epoch 2625/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5355 - accuracy: 0.7727\n",
      "Epoch 2626/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.7727\n",
      "Epoch 2627/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.8182\n",
      "Epoch 2628/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.8182\n",
      "Epoch 2629/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.8182\n",
      "Epoch 2630/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.8182\n",
      "Epoch 2631/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5352 - accuracy: 0.8182\n",
      "Epoch 2632/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5352 - accuracy: 0.8182\n",
      "Epoch 2633/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5352 - accuracy: 0.8182\n",
      "Epoch 2634/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5351 - accuracy: 0.8182\n",
      "Epoch 2635/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5351 - accuracy: 0.8182\n",
      "Epoch 2636/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5351 - accuracy: 0.8182\n",
      "Epoch 2637/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5350 - accuracy: 0.8182\n",
      "Epoch 2638/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5350 - accuracy: 0.8182\n",
      "Epoch 2639/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.8182\n",
      "Epoch 2640/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5349 - accuracy: 0.8182\n",
      "Epoch 2641/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5349 - accuracy: 0.8182\n",
      "Epoch 2642/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5348 - accuracy: 0.8182\n",
      "Epoch 2643/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5348 - accuracy: 0.8182\n",
      "Epoch 2644/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5348 - accuracy: 0.8182\n",
      "Epoch 2645/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 0.8182\n",
      "Epoch 2646/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 0.8182\n",
      "Epoch 2647/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5346 - accuracy: 0.8182\n",
      "Epoch 2648/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5346 - accuracy: 0.8182\n",
      "Epoch 2649/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5346 - accuracy: 0.8182\n",
      "Epoch 2650/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5345 - accuracy: 0.8182\n",
      "Epoch 2651/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5345 - accuracy: 0.8182\n",
      "Epoch 2652/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.8182\n",
      "Epoch 2653/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.8182\n",
      "Epoch 2654/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5344 - accuracy: 0.8182\n",
      "Epoch 2655/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5343 - accuracy: 0.8182\n",
      "Epoch 2656/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5343 - accuracy: 0.8182\n",
      "Epoch 2657/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5343 - accuracy: 0.8182\n",
      "Epoch 2658/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5342 - accuracy: 0.8182\n",
      "Epoch 2659/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5342 - accuracy: 0.8182\n",
      "Epoch 2660/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5341 - accuracy: 0.8182\n",
      "Epoch 2661/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5341 - accuracy: 0.8182\n",
      "Epoch 2662/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5341 - accuracy: 0.8182\n",
      "Epoch 2663/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5340 - accuracy: 0.8182\n",
      "Epoch 2664/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5340 - accuracy: 0.8182\n",
      "Epoch 2665/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5339 - accuracy: 0.8182\n",
      "Epoch 2666/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5339 - accuracy: 0.8182\n",
      "Epoch 2667/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5339 - accuracy: 0.8182\n",
      "Epoch 2668/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5338 - accuracy: 0.8182\n",
      "Epoch 2669/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5338 - accuracy: 0.8182\n",
      "Epoch 2670/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5338 - accuracy: 0.8182\n",
      "Epoch 2671/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5337 - accuracy: 0.8182\n",
      "Epoch 2672/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5337 - accuracy: 0.8182\n",
      "Epoch 2673/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5336 - accuracy: 0.8182\n",
      "Epoch 2674/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5336 - accuracy: 0.8182\n",
      "Epoch 2675/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5336 - accuracy: 0.8182\n",
      "Epoch 2676/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5335 - accuracy: 0.8182\n",
      "Epoch 2677/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5335 - accuracy: 0.8182\n",
      "Epoch 2678/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5335 - accuracy: 0.8182\n",
      "Epoch 2679/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5334 - accuracy: 0.8182\n",
      "Epoch 2680/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5334 - accuracy: 0.8182\n",
      "Epoch 2681/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5333 - accuracy: 0.8182\n",
      "Epoch 2682/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5333 - accuracy: 0.8182\n",
      "Epoch 2683/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5333 - accuracy: 0.8182\n",
      "Epoch 2684/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.8182\n",
      "Epoch 2685/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.8182\n",
      "Epoch 2686/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.8182\n",
      "Epoch 2687/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.8182\n",
      "Epoch 2688/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5331 - accuracy: 0.8182\n",
      "Epoch 2689/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5330 - accuracy: 0.8182\n",
      "Epoch 2690/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5330 - accuracy: 0.8182\n",
      "Epoch 2691/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5330 - accuracy: 0.8182\n",
      "Epoch 2692/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.8182\n",
      "Epoch 2693/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.8182\n",
      "Epoch 2694/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5328 - accuracy: 0.8182\n",
      "Epoch 2695/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5328 - accuracy: 0.8182\n",
      "Epoch 2696/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5328 - accuracy: 0.8182\n",
      "Epoch 2697/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5327 - accuracy: 0.8182\n",
      "Epoch 2698/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5327 - accuracy: 0.8182\n",
      "Epoch 2699/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5327 - accuracy: 0.8182\n",
      "Epoch 2700/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5326 - accuracy: 0.8182\n",
      "Epoch 2701/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5326 - accuracy: 0.8182\n",
      "Epoch 2702/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5325 - accuracy: 0.8182\n",
      "Epoch 2703/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5325 - accuracy: 0.8182\n",
      "Epoch 2704/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5325 - accuracy: 0.8182\n",
      "Epoch 2705/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.8182\n",
      "Epoch 2706/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.8182\n",
      "Epoch 2707/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5324 - accuracy: 0.8182\n",
      "Epoch 2708/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5323 - accuracy: 0.8182\n",
      "Epoch 2709/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5323 - accuracy: 0.8182\n",
      "Epoch 2710/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5322 - accuracy: 0.8182\n",
      "Epoch 2711/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.8182\n",
      "Epoch 2712/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.8182\n",
      "Epoch 2713/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.8182\n",
      "Epoch 2714/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.8182\n",
      "Epoch 2715/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.8182\n",
      "Epoch 2716/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5320 - accuracy: 0.8182\n",
      "Epoch 2717/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5320 - accuracy: 0.8182\n",
      "Epoch 2718/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5319 - accuracy: 0.8182\n",
      "Epoch 2719/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5319 - accuracy: 0.8182\n",
      "Epoch 2720/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5319 - accuracy: 0.8182\n",
      "Epoch 2721/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.8182\n",
      "Epoch 2722/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.8182\n",
      "Epoch 2723/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.8182\n",
      "Epoch 2724/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5317 - accuracy: 0.8182\n",
      "Epoch 2725/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5317 - accuracy: 0.8182\n",
      "Epoch 2726/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5316 - accuracy: 0.8182\n",
      "Epoch 2727/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5316 - accuracy: 0.8182\n",
      "Epoch 2728/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5316 - accuracy: 0.8182\n",
      "Epoch 2729/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.8182\n",
      "Epoch 2730/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.8182\n",
      "Epoch 2731/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.8182\n",
      "Epoch 2732/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5314 - accuracy: 0.8182\n",
      "Epoch 2733/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5314 - accuracy: 0.8182\n",
      "Epoch 2734/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.8182\n",
      "Epoch 2735/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.8182\n",
      "Epoch 2736/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5313 - accuracy: 0.8182\n",
      "Epoch 2737/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5312 - accuracy: 0.8182\n",
      "Epoch 2738/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5312 - accuracy: 0.8182\n",
      "Epoch 2739/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5312 - accuracy: 0.8182\n",
      "Epoch 2740/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.8182\n",
      "Epoch 2741/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.8182\n",
      "Epoch 2742/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5310 - accuracy: 0.8182\n",
      "Epoch 2743/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5310 - accuracy: 0.8182\n",
      "Epoch 2744/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5310 - accuracy: 0.8182\n",
      "Epoch 2745/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.8182\n",
      "Epoch 2746/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.8182\n",
      "Epoch 2747/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5309 - accuracy: 0.8182\n",
      "Epoch 2748/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5308 - accuracy: 0.8182\n",
      "Epoch 2749/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5308 - accuracy: 0.8182\n",
      "Epoch 2750/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.8182\n",
      "Epoch 2751/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.8182\n",
      "Epoch 2752/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5307 - accuracy: 0.8182\n",
      "Epoch 2753/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5306 - accuracy: 0.8182\n",
      "Epoch 2754/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5306 - accuracy: 0.8182\n",
      "Epoch 2755/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5306 - accuracy: 0.8182\n",
      "Epoch 2756/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5305 - accuracy: 0.8182\n",
      "Epoch 2757/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.8182\n",
      "Epoch 2758/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.8182\n",
      "Epoch 2759/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.8182\n",
      "Epoch 2760/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.8182\n",
      "Epoch 2761/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5303 - accuracy: 0.8182\n",
      "Epoch 2762/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5303 - accuracy: 0.8182\n",
      "Epoch 2763/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5303 - accuracy: 0.8182\n",
      "Epoch 2764/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.8182\n",
      "Epoch 2765/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.8182\n",
      "Epoch 2766/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.8182\n",
      "Epoch 2767/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5301 - accuracy: 0.8182\n",
      "Epoch 2768/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5301 - accuracy: 0.8182\n",
      "Epoch 2769/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5300 - accuracy: 0.8182\n",
      "Epoch 2770/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5300 - accuracy: 0.8182\n",
      "Epoch 2771/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5300 - accuracy: 0.8182\n",
      "Epoch 2772/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5299 - accuracy: 0.8182\n",
      "Epoch 2773/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5299 - accuracy: 0.8182\n",
      "Epoch 2774/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5299 - accuracy: 0.8182\n",
      "Epoch 2775/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.8182\n",
      "Epoch 2776/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.8182\n",
      "Epoch 2777/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5297 - accuracy: 0.8182\n",
      "Epoch 2778/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5297 - accuracy: 0.8182\n",
      "Epoch 2779/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5297 - accuracy: 0.8636\n",
      "Epoch 2780/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.8636\n",
      "Epoch 2781/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.8636\n",
      "Epoch 2782/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.8636\n",
      "Epoch 2783/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5295 - accuracy: 0.8636\n",
      "Epoch 2784/5000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5295 - accuracy: 0.8636\n",
      "Epoch 2785/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5294 - accuracy: 0.8636\n",
      "Epoch 2786/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5294 - accuracy: 0.8636\n",
      "Epoch 2787/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5294 - accuracy: 0.8636\n",
      "Epoch 2788/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.8636\n",
      "Epoch 2789/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.8636\n",
      "Epoch 2790/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.8636\n",
      "Epoch 2791/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5292 - accuracy: 0.8636\n",
      "Epoch 2792/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5292 - accuracy: 0.8636\n",
      "Epoch 2793/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.8636\n",
      "Epoch 2794/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.8636\n",
      "Epoch 2795/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5291 - accuracy: 0.8636\n",
      "Epoch 2796/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.8636\n",
      "Epoch 2797/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.8636\n",
      "Epoch 2798/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.8636\n",
      "Epoch 2799/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5289 - accuracy: 0.8636\n",
      "Epoch 2800/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5289 - accuracy: 0.8636\n",
      "Epoch 2801/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5289 - accuracy: 0.8636\n",
      "Epoch 2802/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.8636\n",
      "Epoch 2803/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.8636\n",
      "Epoch 2804/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5287 - accuracy: 0.8636\n",
      "Epoch 2805/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5287 - accuracy: 0.8636\n",
      "Epoch 2806/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5287 - accuracy: 0.8636\n",
      "Epoch 2807/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5286 - accuracy: 0.8636\n",
      "Epoch 2808/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5286 - accuracy: 0.8636\n",
      "Epoch 2809/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5286 - accuracy: 0.8636\n",
      "Epoch 2810/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.8636\n",
      "Epoch 2811/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5285 - accuracy: 0.8636\n",
      "Epoch 2812/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5284 - accuracy: 0.8636\n",
      "Epoch 2813/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5284 - accuracy: 0.8636\n",
      "Epoch 2814/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5284 - accuracy: 0.8636\n",
      "Epoch 2815/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5283 - accuracy: 0.8636\n",
      "Epoch 2816/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5283 - accuracy: 0.8636\n",
      "Epoch 2817/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5283 - accuracy: 0.8636\n",
      "Epoch 2818/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5282 - accuracy: 0.8636\n",
      "Epoch 2819/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5282 - accuracy: 0.8636\n",
      "Epoch 2820/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5282 - accuracy: 0.8636\n",
      "Epoch 2821/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5281 - accuracy: 0.8636\n",
      "Epoch 2822/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5281 - accuracy: 0.8636\n",
      "Epoch 2823/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5280 - accuracy: 0.8636\n",
      "Epoch 2824/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5280 - accuracy: 0.8636\n",
      "Epoch 2825/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5280 - accuracy: 0.8636\n",
      "Epoch 2826/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5279 - accuracy: 0.8636\n",
      "Epoch 2827/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5279 - accuracy: 0.8636\n",
      "Epoch 2828/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5279 - accuracy: 0.8636\n",
      "Epoch 2829/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5278 - accuracy: 0.8636\n",
      "Epoch 2830/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5278 - accuracy: 0.8636\n",
      "Epoch 2831/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5278 - accuracy: 0.8636\n",
      "Epoch 2832/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5277 - accuracy: 0.8636\n",
      "Epoch 2833/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5277 - accuracy: 0.8636\n",
      "Epoch 2834/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.8636\n",
      "Epoch 2835/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.8636\n",
      "Epoch 2836/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.8636\n",
      "Epoch 2837/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5275 - accuracy: 0.8636\n",
      "Epoch 2838/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5275 - accuracy: 0.8636\n",
      "Epoch 2839/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5275 - accuracy: 0.8636\n",
      "Epoch 2840/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.8636\n",
      "Epoch 2841/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.8636\n",
      "Epoch 2842/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.8636\n",
      "Epoch 2843/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5273 - accuracy: 0.8636\n",
      "Epoch 2844/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5273 - accuracy: 0.8636\n",
      "Epoch 2845/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5272 - accuracy: 0.8636\n",
      "Epoch 2846/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5272 - accuracy: 0.8636\n",
      "Epoch 2847/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5272 - accuracy: 0.8636\n",
      "Epoch 2848/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 0.5271 - accuracy: 0.8636\n",
      "Epoch 2849/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5271 - accuracy: 0.8636\n",
      "Epoch 2850/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5271 - accuracy: 0.8636\n",
      "Epoch 2851/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5270 - accuracy: 0.8636\n",
      "Epoch 2852/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5270 - accuracy: 0.8636\n",
      "Epoch 2853/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5270 - accuracy: 0.8636\n",
      "Epoch 2854/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5269 - accuracy: 0.8636\n",
      "Epoch 2855/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5269 - accuracy: 0.8636\n",
      "Epoch 2856/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.8636\n",
      "Epoch 2857/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.8636\n",
      "Epoch 2858/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.8636\n",
      "Epoch 2859/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5267 - accuracy: 0.8636\n",
      "Epoch 2860/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5267 - accuracy: 0.8636\n",
      "Epoch 2861/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5267 - accuracy: 0.8636\n",
      "Epoch 2862/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5266 - accuracy: 0.8636\n",
      "Epoch 2863/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5266 - accuracy: 0.8636\n",
      "Epoch 2864/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5266 - accuracy: 0.8636\n",
      "Epoch 2865/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5265 - accuracy: 0.8636\n",
      "Epoch 2866/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5265 - accuracy: 0.8636\n",
      "Epoch 2867/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.8636\n",
      "Epoch 2868/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.8636\n",
      "Epoch 2869/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.8636\n",
      "Epoch 2870/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.8636\n",
      "Epoch 2871/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.8636\n",
      "Epoch 2872/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.8636\n",
      "Epoch 2873/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.8636\n",
      "Epoch 2874/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.8636\n",
      "Epoch 2875/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.8636\n",
      "Epoch 2876/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5261 - accuracy: 0.8636\n",
      "Epoch 2877/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5261 - accuracy: 0.8636\n",
      "Epoch 2878/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.8636\n",
      "Epoch 2879/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5260 - accuracy: 0.8636\n",
      "Epoch 2880/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.8636\n",
      "Epoch 2881/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.8636\n",
      "Epoch 2882/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.8636\n",
      "Epoch 2883/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5259 - accuracy: 0.8636\n",
      "Epoch 2884/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5258 - accuracy: 0.8636\n",
      "Epoch 2885/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5258 - accuracy: 0.8636\n",
      "Epoch 2886/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5258 - accuracy: 0.8636\n",
      "Epoch 2887/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5257 - accuracy: 0.8636\n",
      "Epoch 2888/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5257 - accuracy: 0.8636\n",
      "Epoch 2889/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.8636\n",
      "Epoch 2890/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5256 - accuracy: 0.8636\n",
      "Epoch 2891/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.8636\n",
      "Epoch 2892/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5255 - accuracy: 0.8636\n",
      "Epoch 2893/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5255 - accuracy: 0.8636\n",
      "Epoch 2894/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5255 - accuracy: 0.8636\n",
      "Epoch 2895/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.8636\n",
      "Epoch 2896/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.8636\n",
      "Epoch 2897/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5254 - accuracy: 0.8636\n",
      "Epoch 2898/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8636\n",
      "Epoch 2899/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8636\n",
      "Epoch 2900/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8636\n",
      "Epoch 2901/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5252 - accuracy: 0.8636\n",
      "Epoch 2902/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5252 - accuracy: 0.8636\n",
      "Epoch 2903/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.8636\n",
      "Epoch 2904/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.8636\n",
      "Epoch 2905/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5251 - accuracy: 0.8636\n",
      "Epoch 2906/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.8636\n",
      "Epoch 2907/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.8636\n",
      "Epoch 2908/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.8636\n",
      "Epoch 2909/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5249 - accuracy: 0.8636\n",
      "Epoch 2910/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5249 - accuracy: 0.8636\n",
      "Epoch 2911/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5249 - accuracy: 0.8636\n",
      "Epoch 2912/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.8636\n",
      "Epoch 2913/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.8636\n",
      "Epoch 2914/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5247 - accuracy: 0.8636\n",
      "Epoch 2915/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5247 - accuracy: 0.8636\n",
      "Epoch 2916/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5247 - accuracy: 0.8636\n",
      "Epoch 2917/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5246 - accuracy: 0.8636\n",
      "Epoch 2918/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5246 - accuracy: 0.8636\n",
      "Epoch 2919/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5246 - accuracy: 0.8636\n",
      "Epoch 2920/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.8636\n",
      "Epoch 2921/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.8636\n",
      "Epoch 2922/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.8636\n",
      "Epoch 2923/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5244 - accuracy: 0.8636\n",
      "Epoch 2924/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5244 - accuracy: 0.8636\n",
      "Epoch 2925/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5244 - accuracy: 0.8636\n",
      "Epoch 2926/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5243 - accuracy: 0.8636\n",
      "Epoch 2927/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5243 - accuracy: 0.8636\n",
      "Epoch 2928/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5242 - accuracy: 0.8636\n",
      "Epoch 2929/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5242 - accuracy: 0.8636\n",
      "Epoch 2930/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5242 - accuracy: 0.8636\n",
      "Epoch 2931/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5241 - accuracy: 0.8636\n",
      "Epoch 2932/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5241 - accuracy: 0.8636\n",
      "Epoch 2933/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5241 - accuracy: 0.8636\n",
      "Epoch 2934/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5240 - accuracy: 0.8636\n",
      "Epoch 2935/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5240 - accuracy: 0.8636\n",
      "Epoch 2936/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5240 - accuracy: 0.8636\n",
      "Epoch 2937/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.8636\n",
      "Epoch 2938/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.8636\n",
      "Epoch 2939/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5239 - accuracy: 0.8636\n",
      "Epoch 2940/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.8636\n",
      "Epoch 2941/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.8636\n",
      "Epoch 2942/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.8636\n",
      "Epoch 2943/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5237 - accuracy: 0.8636\n",
      "Epoch 2944/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5237 - accuracy: 0.8636\n",
      "Epoch 2945/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5236 - accuracy: 0.8636\n",
      "Epoch 2946/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5236 - accuracy: 0.8636\n",
      "Epoch 2947/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5236 - accuracy: 0.8636\n",
      "Epoch 2948/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5235 - accuracy: 0.8636\n",
      "Epoch 2949/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5235 - accuracy: 0.8636\n",
      "Epoch 2950/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5235 - accuracy: 0.8636\n",
      "Epoch 2951/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5234 - accuracy: 0.8636\n",
      "Epoch 2952/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5234 - accuracy: 0.8636\n",
      "Epoch 2953/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5234 - accuracy: 0.8636\n",
      "Epoch 2954/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.8636\n",
      "Epoch 2955/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.8636\n",
      "Epoch 2956/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.8636\n",
      "Epoch 2957/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5232 - accuracy: 0.8636\n",
      "Epoch 2958/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5232 - accuracy: 0.8636\n",
      "Epoch 2959/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5231 - accuracy: 0.8636\n",
      "Epoch 2960/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5231 - accuracy: 0.8636\n",
      "Epoch 2961/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5231 - accuracy: 0.8636\n",
      "Epoch 2962/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5230 - accuracy: 0.8636\n",
      "Epoch 2963/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5230 - accuracy: 0.8636\n",
      "Epoch 2964/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5230 - accuracy: 0.8636\n",
      "Epoch 2965/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5229 - accuracy: 0.8636\n",
      "Epoch 2966/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5229 - accuracy: 0.8636\n",
      "Epoch 2967/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5229 - accuracy: 0.8636\n",
      "Epoch 2968/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.8636\n",
      "Epoch 2969/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.8636\n",
      "Epoch 2970/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.8636\n",
      "Epoch 2971/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5227 - accuracy: 0.8636\n",
      "Epoch 2972/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5227 - accuracy: 0.8636\n",
      "Epoch 2973/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5227 - accuracy: 0.8636\n",
      "Epoch 2974/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.8636\n",
      "Epoch 2975/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.8636\n",
      "Epoch 2976/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5225 - accuracy: 0.8636\n",
      "Epoch 2977/5000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.8636\n",
      "Epoch 2978/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5225 - accuracy: 0.8636\n",
      "Epoch 2979/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.8636\n",
      "Epoch 2980/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.8636\n",
      "Epoch 2981/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.8636\n",
      "Epoch 2982/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5223 - accuracy: 0.8636\n",
      "Epoch 2983/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5223 - accuracy: 0.8636\n",
      "Epoch 2984/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5223 - accuracy: 0.8636\n",
      "Epoch 2985/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5222 - accuracy: 0.8636\n",
      "Epoch 2986/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5222 - accuracy: 0.8636\n",
      "Epoch 2987/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5222 - accuracy: 0.8636\n",
      "Epoch 2988/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5221 - accuracy: 0.8636\n",
      "Epoch 2989/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5221 - accuracy: 0.8636\n",
      "Epoch 2990/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5221 - accuracy: 0.8636\n",
      "Epoch 2991/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.8636\n",
      "Epoch 2992/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.8636\n",
      "Epoch 2993/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5219 - accuracy: 0.8636\n",
      "Epoch 2994/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5219 - accuracy: 0.8636\n",
      "Epoch 2995/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5219 - accuracy: 0.8636\n",
      "Epoch 2996/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5218 - accuracy: 0.8636\n",
      "Epoch 2997/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5218 - accuracy: 0.8636\n",
      "Epoch 2998/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5218 - accuracy: 0.8636\n",
      "Epoch 2999/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5217 - accuracy: 0.8636\n",
      "Epoch 3000/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5217 - accuracy: 0.8636\n",
      "Epoch 3001/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5217 - accuracy: 0.8636\n",
      "Epoch 3002/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5216 - accuracy: 0.8636\n",
      "Epoch 3003/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5216 - accuracy: 0.8636\n",
      "Epoch 3004/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5216 - accuracy: 0.8636\n",
      "Epoch 3005/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.8636\n",
      "Epoch 3006/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.8636\n",
      "Epoch 3007/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.8636\n",
      "Epoch 3008/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5214 - accuracy: 0.8636\n",
      "Epoch 3009/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5214 - accuracy: 0.8636\n",
      "Epoch 3010/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5214 - accuracy: 0.8636\n",
      "Epoch 3011/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5213 - accuracy: 0.8636\n",
      "Epoch 3012/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5213 - accuracy: 0.8636\n",
      "Epoch 3013/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5213 - accuracy: 0.8636\n",
      "Epoch 3014/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5212 - accuracy: 0.8636\n",
      "Epoch 3015/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5212 - accuracy: 0.8636\n",
      "Epoch 3016/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5211 - accuracy: 0.8636\n",
      "Epoch 3017/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5211 - accuracy: 0.8636\n",
      "Epoch 3018/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5211 - accuracy: 0.8636\n",
      "Epoch 3019/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5210 - accuracy: 0.8636\n",
      "Epoch 3020/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5210 - accuracy: 0.8636\n",
      "Epoch 3021/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5210 - accuracy: 0.8636\n",
      "Epoch 3022/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5209 - accuracy: 0.8636\n",
      "Epoch 3023/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5209 - accuracy: 0.8636\n",
      "Epoch 3024/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5209 - accuracy: 0.8636\n",
      "Epoch 3025/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5208 - accuracy: 0.8636\n",
      "Epoch 3026/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5208 - accuracy: 0.8636\n",
      "Epoch 3027/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5208 - accuracy: 0.8636\n",
      "Epoch 3028/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5207 - accuracy: 0.8636\n",
      "Epoch 3029/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5207 - accuracy: 0.8636\n",
      "Epoch 3030/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5207 - accuracy: 0.8636\n",
      "Epoch 3031/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5206 - accuracy: 0.8636\n",
      "Epoch 3032/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5206 - accuracy: 0.8636\n",
      "Epoch 3033/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5206 - accuracy: 0.8636\n",
      "Epoch 3034/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 0.8636\n",
      "Epoch 3035/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5205 - accuracy: 0.8636\n",
      "Epoch 3036/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5204 - accuracy: 0.8636\n",
      "Epoch 3037/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5204 - accuracy: 0.8636\n",
      "Epoch 3038/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5204 - accuracy: 0.8636\n",
      "Epoch 3039/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5203 - accuracy: 0.8636\n",
      "Epoch 3040/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5203 - accuracy: 0.8636\n",
      "Epoch 3041/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5203 - accuracy: 0.8636\n",
      "Epoch 3042/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.8636\n",
      "Epoch 3043/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.8636\n",
      "Epoch 3044/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.8636\n",
      "Epoch 3045/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5201 - accuracy: 0.8636\n",
      "Epoch 3046/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5201 - accuracy: 0.8636\n",
      "Epoch 3047/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5201 - accuracy: 0.8636\n",
      "Epoch 3048/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5200 - accuracy: 0.8636\n",
      "Epoch 3049/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.8636\n",
      "Epoch 3050/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.8636\n",
      "Epoch 3051/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5199 - accuracy: 0.8636\n",
      "Epoch 3052/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5199 - accuracy: 0.8636\n",
      "Epoch 3053/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5199 - accuracy: 0.8636\n",
      "Epoch 3054/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5198 - accuracy: 0.8636\n",
      "Epoch 3055/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5198 - accuracy: 0.8636\n",
      "Epoch 3056/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5198 - accuracy: 0.8636\n",
      "Epoch 3057/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5197 - accuracy: 0.8636\n",
      "Epoch 3058/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5197 - accuracy: 0.8636\n",
      "Epoch 3059/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5197 - accuracy: 0.8636\n",
      "Epoch 3060/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5196 - accuracy: 0.8636\n",
      "Epoch 3061/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5196 - accuracy: 0.8636\n",
      "Epoch 3062/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5196 - accuracy: 0.8636\n",
      "Epoch 3063/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.8636\n",
      "Epoch 3064/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.8636\n",
      "Epoch 3065/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5194 - accuracy: 0.8636\n",
      "Epoch 3066/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5194 - accuracy: 0.8636\n",
      "Epoch 3067/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5194 - accuracy: 0.8636\n",
      "Epoch 3068/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.8636\n",
      "Epoch 3069/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5193 - accuracy: 0.8636\n",
      "Epoch 3070/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.8636\n",
      "Epoch 3071/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5192 - accuracy: 0.8636\n",
      "Epoch 3072/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5192 - accuracy: 0.8636\n",
      "Epoch 3073/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5192 - accuracy: 0.8636\n",
      "Epoch 3074/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.8636\n",
      "Epoch 3075/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5191 - accuracy: 0.8636\n",
      "Epoch 3076/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.8636\n",
      "Epoch 3077/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5190 - accuracy: 0.8636\n",
      "Epoch 3078/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5190 - accuracy: 0.8636\n",
      "Epoch 3079/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5190 - accuracy: 0.8636\n",
      "Epoch 3080/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5189 - accuracy: 0.8636\n",
      "Epoch 3081/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5189 - accuracy: 0.8636\n",
      "Epoch 3082/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5189 - accuracy: 0.8636\n",
      "Epoch 3083/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5188 - accuracy: 0.8636\n",
      "Epoch 3084/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5188 - accuracy: 0.8636\n",
      "Epoch 3085/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5188 - accuracy: 0.8636\n",
      "Epoch 3086/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5187 - accuracy: 0.8636\n",
      "Epoch 3087/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5187 - accuracy: 0.8636\n",
      "Epoch 3088/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5187 - accuracy: 0.8636\n",
      "Epoch 3089/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5186 - accuracy: 0.8636\n",
      "Epoch 3090/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5186 - accuracy: 0.8636\n",
      "Epoch 3091/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5186 - accuracy: 0.8636\n",
      "Epoch 3092/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5185 - accuracy: 0.8636\n",
      "Epoch 3093/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5185 - accuracy: 0.8636\n",
      "Epoch 3094/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5185 - accuracy: 0.8636\n",
      "Epoch 3095/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.8636\n",
      "Epoch 3096/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.8636\n",
      "Epoch 3097/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5184 - accuracy: 0.8636\n",
      "Epoch 3098/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.8636\n",
      "Epoch 3099/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5183 - accuracy: 0.8636\n",
      "Epoch 3100/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.8636\n",
      "Epoch 3101/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.8636\n",
      "Epoch 3102/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.8636\n",
      "Epoch 3103/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.8636\n",
      "Epoch 3104/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5181 - accuracy: 0.8636\n",
      "Epoch 3105/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5181 - accuracy: 0.8636\n",
      "Epoch 3106/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5180 - accuracy: 0.8636\n",
      "Epoch 3107/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5180 - accuracy: 0.8636\n",
      "Epoch 3108/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5180 - accuracy: 0.8636\n",
      "Epoch 3109/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5179 - accuracy: 0.8636\n",
      "Epoch 3110/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5179 - accuracy: 0.8636\n",
      "Epoch 3111/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5179 - accuracy: 0.8636\n",
      "Epoch 3112/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5178 - accuracy: 0.8636\n",
      "Epoch 3113/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5178 - accuracy: 0.8636\n",
      "Epoch 3114/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5178 - accuracy: 0.8636\n",
      "Epoch 3115/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5177 - accuracy: 0.8636\n",
      "Epoch 3116/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5177 - accuracy: 0.8636\n",
      "Epoch 3117/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5177 - accuracy: 0.8636\n",
      "Epoch 3118/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5176 - accuracy: 0.8636\n",
      "Epoch 3119/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5176 - accuracy: 0.8636\n",
      "Epoch 3120/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5176 - accuracy: 0.8636\n",
      "Epoch 3121/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5175 - accuracy: 0.8636\n",
      "Epoch 3122/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5175 - accuracy: 0.8636\n",
      "Epoch 3123/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5175 - accuracy: 0.8636\n",
      "Epoch 3124/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5174 - accuracy: 0.8636\n",
      "Epoch 3125/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5174 - accuracy: 0.8636\n",
      "Epoch 3126/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5174 - accuracy: 0.8636\n",
      "Epoch 3127/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5173 - accuracy: 0.8636\n",
      "Epoch 3128/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.8636\n",
      "Epoch 3129/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5173 - accuracy: 0.8636\n",
      "Epoch 3130/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5172 - accuracy: 0.8636\n",
      "Epoch 3131/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5172 - accuracy: 0.8636\n",
      "Epoch 3132/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5172 - accuracy: 0.8636\n",
      "Epoch 3133/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.8636\n",
      "Epoch 3134/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.8636\n",
      "Epoch 3135/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.8636\n",
      "Epoch 3136/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5170 - accuracy: 0.8636\n",
      "Epoch 3137/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5170 - accuracy: 0.8636\n",
      "Epoch 3138/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5170 - accuracy: 0.8636\n",
      "Epoch 3139/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5169 - accuracy: 0.8636\n",
      "Epoch 3140/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5169 - accuracy: 0.8636\n",
      "Epoch 3141/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5169 - accuracy: 0.8636\n",
      "Epoch 3142/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5168 - accuracy: 0.8636\n",
      "Epoch 3143/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5168 - accuracy: 0.8636\n",
      "Epoch 3144/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5168 - accuracy: 0.8636\n",
      "Epoch 3145/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5167 - accuracy: 0.8636\n",
      "Epoch 3146/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5167 - accuracy: 0.8636\n",
      "Epoch 3147/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5167 - accuracy: 0.8636\n",
      "Epoch 3148/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5166 - accuracy: 0.8636\n",
      "Epoch 3149/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5166 - accuracy: 0.8636\n",
      "Epoch 3150/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5166 - accuracy: 0.8636\n",
      "Epoch 3151/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.8636\n",
      "Epoch 3152/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.8636\n",
      "Epoch 3153/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.8636\n",
      "Epoch 3154/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5164 - accuracy: 0.8636\n",
      "Epoch 3155/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5164 - accuracy: 0.8636\n",
      "Epoch 3156/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5164 - accuracy: 0.8636\n",
      "Epoch 3157/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5163 - accuracy: 0.8636\n",
      "Epoch 3158/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5163 - accuracy: 0.8636\n",
      "Epoch 3159/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5163 - accuracy: 0.8636\n",
      "Epoch 3160/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5162 - accuracy: 0.8636\n",
      "Epoch 3161/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5162 - accuracy: 0.8636\n",
      "Epoch 3162/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5162 - accuracy: 0.8636\n",
      "Epoch 3163/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5161 - accuracy: 0.8636\n",
      "Epoch 3164/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5161 - accuracy: 0.8636\n",
      "Epoch 3165/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5161 - accuracy: 0.8636\n",
      "Epoch 3166/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5160 - accuracy: 0.8636\n",
      "Epoch 3167/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5160 - accuracy: 0.8636\n",
      "Epoch 3168/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8636\n",
      "Epoch 3169/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8636\n",
      "Epoch 3170/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5159 - accuracy: 0.8636\n",
      "Epoch 3171/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5158 - accuracy: 0.8636\n",
      "Epoch 3172/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5158 - accuracy: 0.8636\n",
      "Epoch 3173/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5158 - accuracy: 0.8636\n",
      "Epoch 3174/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5157 - accuracy: 0.8636\n",
      "Epoch 3175/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5157 - accuracy: 0.8636\n",
      "Epoch 3176/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5157 - accuracy: 0.8636\n",
      "Epoch 3177/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.8636\n",
      "Epoch 3178/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.8636\n",
      "Epoch 3179/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5156 - accuracy: 0.8636\n",
      "Epoch 3180/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5155 - accuracy: 0.8636\n",
      "Epoch 3181/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5155 - accuracy: 0.8636\n",
      "Epoch 3182/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5155 - accuracy: 0.8636\n",
      "Epoch 3183/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 0.8636\n",
      "Epoch 3184/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 0.8636\n",
      "Epoch 3185/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 0.8636\n",
      "Epoch 3186/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5153 - accuracy: 0.8636\n",
      "Epoch 3187/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5153 - accuracy: 0.8636\n",
      "Epoch 3188/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5153 - accuracy: 0.8636\n",
      "Epoch 3189/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5152 - accuracy: 0.8636\n",
      "Epoch 3190/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5152 - accuracy: 0.8636\n",
      "Epoch 3191/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5152 - accuracy: 0.8636\n",
      "Epoch 3192/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5151 - accuracy: 0.8636\n",
      "Epoch 3193/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5151 - accuracy: 0.8636\n",
      "Epoch 3194/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5151 - accuracy: 0.8636\n",
      "Epoch 3195/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5150 - accuracy: 0.8636\n",
      "Epoch 3196/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5150 - accuracy: 0.8636\n",
      "Epoch 3197/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5150 - accuracy: 0.8636\n",
      "Epoch 3198/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5149 - accuracy: 0.8636\n",
      "Epoch 3199/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5149 - accuracy: 0.8636\n",
      "Epoch 3200/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5149 - accuracy: 0.8636\n",
      "Epoch 3201/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5148 - accuracy: 0.8636\n",
      "Epoch 3202/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5148 - accuracy: 0.8636\n",
      "Epoch 3203/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5148 - accuracy: 0.8636\n",
      "Epoch 3204/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5147 - accuracy: 0.8636\n",
      "Epoch 3205/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5147 - accuracy: 0.8636\n",
      "Epoch 3206/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5147 - accuracy: 0.8636\n",
      "Epoch 3207/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5147 - accuracy: 0.8636\n",
      "Epoch 3208/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5146 - accuracy: 0.8636\n",
      "Epoch 3209/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5146 - accuracy: 0.8636\n",
      "Epoch 3210/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5146 - accuracy: 0.8636\n",
      "Epoch 3211/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5145 - accuracy: 0.8636\n",
      "Epoch 3212/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5145 - accuracy: 0.8636\n",
      "Epoch 3213/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5145 - accuracy: 0.8636\n",
      "Epoch 3214/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5144 - accuracy: 0.8636\n",
      "Epoch 3215/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5144 - accuracy: 0.8636\n",
      "Epoch 3216/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5144 - accuracy: 0.8636\n",
      "Epoch 3217/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5143 - accuracy: 0.8636\n",
      "Epoch 3218/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5143 - accuracy: 0.8636\n",
      "Epoch 3219/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5143 - accuracy: 0.8636\n",
      "Epoch 3220/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.8636\n",
      "Epoch 3221/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.8636\n",
      "Epoch 3222/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.8636\n",
      "Epoch 3223/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5141 - accuracy: 0.8636\n",
      "Epoch 3224/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5141 - accuracy: 0.8636\n",
      "Epoch 3225/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5141 - accuracy: 0.8636\n",
      "Epoch 3226/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.8636\n",
      "Epoch 3227/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5140 - accuracy: 0.8636\n",
      "Epoch 3228/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.8636\n",
      "Epoch 3229/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.8636\n",
      "Epoch 3230/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.8636\n",
      "Epoch 3231/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5139 - accuracy: 0.8636\n",
      "Epoch 3232/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5138 - accuracy: 0.8636\n",
      "Epoch 3233/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5138 - accuracy: 0.8636\n",
      "Epoch 3234/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5138 - accuracy: 0.8636\n",
      "Epoch 3235/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5137 - accuracy: 0.8636\n",
      "Epoch 3236/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5137 - accuracy: 0.8636\n",
      "Epoch 3237/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5137 - accuracy: 0.8636\n",
      "Epoch 3238/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5136 - accuracy: 0.8636\n",
      "Epoch 3239/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5136 - accuracy: 0.8636\n",
      "Epoch 3240/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5136 - accuracy: 0.8636\n",
      "Epoch 3241/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5135 - accuracy: 0.8636\n",
      "Epoch 3242/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5135 - accuracy: 0.8636\n",
      "Epoch 3243/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5135 - accuracy: 0.8636\n",
      "Epoch 3244/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5134 - accuracy: 0.8636\n",
      "Epoch 3245/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5134 - accuracy: 0.8636\n",
      "Epoch 3246/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5134 - accuracy: 0.8636\n",
      "Epoch 3247/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5133 - accuracy: 0.8636\n",
      "Epoch 3248/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5133 - accuracy: 0.8636\n",
      "Epoch 3249/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5133 - accuracy: 0.8636\n",
      "Epoch 3250/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5132 - accuracy: 0.8636\n",
      "Epoch 3251/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5132 - accuracy: 0.8636\n",
      "Epoch 3252/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5132 - accuracy: 0.8636\n",
      "Epoch 3253/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5131 - accuracy: 0.8636\n",
      "Epoch 3254/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5131 - accuracy: 0.8636\n",
      "Epoch 3255/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5131 - accuracy: 0.8636\n",
      "Epoch 3256/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5130 - accuracy: 0.8636\n",
      "Epoch 3257/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5130 - accuracy: 0.8636\n",
      "Epoch 3258/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5130 - accuracy: 0.8636\n",
      "Epoch 3259/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5129 - accuracy: 0.8636\n",
      "Epoch 3260/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5129 - accuracy: 0.8636\n",
      "Epoch 3261/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5129 - accuracy: 0.8636\n",
      "Epoch 3262/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.8636\n",
      "Epoch 3263/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.8636\n",
      "Epoch 3264/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5128 - accuracy: 0.8636\n",
      "Epoch 3265/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5127 - accuracy: 0.8636\n",
      "Epoch 3266/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5127 - accuracy: 0.8636\n",
      "Epoch 3267/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5127 - accuracy: 0.8636\n",
      "Epoch 3268/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.8636\n",
      "Epoch 3269/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5126 - accuracy: 0.8636\n",
      "Epoch 3270/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.8636\n",
      "Epoch 3271/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.8636\n",
      "Epoch 3272/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.8636\n",
      "Epoch 3273/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5125 - accuracy: 0.8636\n",
      "Epoch 3274/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5124 - accuracy: 0.8636\n",
      "Epoch 3275/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5124 - accuracy: 0.8636\n",
      "Epoch 3276/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5124 - accuracy: 0.8636\n",
      "Epoch 3277/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5124 - accuracy: 0.8636\n",
      "Epoch 3278/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5123 - accuracy: 0.8636\n",
      "Epoch 3279/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5123 - accuracy: 0.8636\n",
      "Epoch 3280/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5123 - accuracy: 0.8636\n",
      "Epoch 3281/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.8636\n",
      "Epoch 3282/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.8636\n",
      "Epoch 3283/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.8636\n",
      "Epoch 3284/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5121 - accuracy: 0.8636\n",
      "Epoch 3285/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5121 - accuracy: 0.8636\n",
      "Epoch 3286/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5121 - accuracy: 0.8636\n",
      "Epoch 3287/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5120 - accuracy: 0.8636\n",
      "Epoch 3288/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.8636\n",
      "Epoch 3289/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.8636\n",
      "Epoch 3290/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.8636\n",
      "Epoch 3291/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.8636\n",
      "Epoch 3292/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.8636\n",
      "Epoch 3293/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5118 - accuracy: 0.8636\n",
      "Epoch 3294/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5118 - accuracy: 0.8636\n",
      "Epoch 3295/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5118 - accuracy: 0.8636\n",
      "Epoch 3296/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.8636\n",
      "Epoch 3297/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.8636\n",
      "Epoch 3298/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.8636\n",
      "Epoch 3299/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5116 - accuracy: 0.8636\n",
      "Epoch 3300/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5116 - accuracy: 0.8636\n",
      "Epoch 3301/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5116 - accuracy: 0.8636\n",
      "Epoch 3302/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5115 - accuracy: 0.8636\n",
      "Epoch 3303/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5115 - accuracy: 0.8636\n",
      "Epoch 3304/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5115 - accuracy: 0.8636\n",
      "Epoch 3305/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5114 - accuracy: 0.8636\n",
      "Epoch 3306/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5114 - accuracy: 0.8636\n",
      "Epoch 3307/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5114 - accuracy: 0.8636\n",
      "Epoch 3308/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8636\n",
      "Epoch 3309/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8636\n",
      "Epoch 3310/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8636\n",
      "Epoch 3311/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.8636\n",
      "Epoch 3312/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.8636\n",
      "Epoch 3313/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.8636\n",
      "Epoch 3314/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.8636\n",
      "Epoch 3315/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5111 - accuracy: 0.8636\n",
      "Epoch 3316/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5111 - accuracy: 0.8636\n",
      "Epoch 3317/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5111 - accuracy: 0.8636\n",
      "Epoch 3318/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5110 - accuracy: 0.8636\n",
      "Epoch 3319/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5110 - accuracy: 0.8636\n",
      "Epoch 3320/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5110 - accuracy: 0.8636\n",
      "Epoch 3321/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5109 - accuracy: 0.8636\n",
      "Epoch 3322/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5109 - accuracy: 0.8636\n",
      "Epoch 3323/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5109 - accuracy: 0.8636\n",
      "Epoch 3324/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.8636\n",
      "Epoch 3325/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5108 - accuracy: 0.8636\n",
      "Epoch 3326/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.8636\n",
      "Epoch 3327/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5107 - accuracy: 0.8636\n",
      "Epoch 3328/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5107 - accuracy: 0.8636\n",
      "Epoch 3329/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5107 - accuracy: 0.8636\n",
      "Epoch 3330/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5106 - accuracy: 0.8636\n",
      "Epoch 3331/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5106 - accuracy: 0.8636\n",
      "Epoch 3332/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5106 - accuracy: 0.8636\n",
      "Epoch 3333/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5105 - accuracy: 0.8636\n",
      "Epoch 3334/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5105 - accuracy: 0.8636\n",
      "Epoch 3335/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8636\n",
      "Epoch 3336/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.8636\n",
      "Epoch 3337/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.8636\n",
      "Epoch 3338/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5104 - accuracy: 0.8636\n",
      "Epoch 3339/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.8636\n",
      "Epoch 3340/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.8636\n",
      "Epoch 3341/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.8636\n",
      "Epoch 3342/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.8636\n",
      "Epoch 3343/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5102 - accuracy: 0.8636\n",
      "Epoch 3344/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5102 - accuracy: 0.8636\n",
      "Epoch 3345/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5102 - accuracy: 0.8636\n",
      "Epoch 3346/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5101 - accuracy: 0.8636\n",
      "Epoch 3347/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5101 - accuracy: 0.8636\n",
      "Epoch 3348/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5101 - accuracy: 0.8636\n",
      "Epoch 3349/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5100 - accuracy: 0.8636\n",
      "Epoch 3350/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5100 - accuracy: 0.8636\n",
      "Epoch 3351/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5100 - accuracy: 0.8636\n",
      "Epoch 3352/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5099 - accuracy: 0.8636\n",
      "Epoch 3353/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5099 - accuracy: 0.8636\n",
      "Epoch 3354/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5099 - accuracy: 0.8636\n",
      "Epoch 3355/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5098 - accuracy: 0.8636\n",
      "Epoch 3356/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5098 - accuracy: 0.8636\n",
      "Epoch 3357/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5098 - accuracy: 0.8636\n",
      "Epoch 3358/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5097 - accuracy: 0.8636\n",
      "Epoch 3359/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5097 - accuracy: 0.8636\n",
      "Epoch 3360/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5097 - accuracy: 0.8636\n",
      "Epoch 3361/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5097 - accuracy: 0.8636\n",
      "Epoch 3362/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5096 - accuracy: 0.8636\n",
      "Epoch 3363/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5096 - accuracy: 0.8636\n",
      "Epoch 3364/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5096 - accuracy: 0.8636\n",
      "Epoch 3365/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5095 - accuracy: 0.8636\n",
      "Epoch 3366/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5095 - accuracy: 0.8636\n",
      "Epoch 3367/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5095 - accuracy: 0.8636\n",
      "Epoch 3368/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5094 - accuracy: 0.8636\n",
      "Epoch 3369/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5094 - accuracy: 0.8636\n",
      "Epoch 3370/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5094 - accuracy: 0.8636\n",
      "Epoch 3371/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5093 - accuracy: 0.8636\n",
      "Epoch 3372/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5093 - accuracy: 0.8636\n",
      "Epoch 3373/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5093 - accuracy: 0.8636\n",
      "Epoch 3374/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5092 - accuracy: 0.8636\n",
      "Epoch 3375/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5092 - accuracy: 0.8636\n",
      "Epoch 3376/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5092 - accuracy: 0.8636\n",
      "Epoch 3377/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.8636\n",
      "Epoch 3378/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.8636\n",
      "Epoch 3379/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.8636\n",
      "Epoch 3380/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.8636\n",
      "Epoch 3381/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.8636\n",
      "Epoch 3382/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5090 - accuracy: 0.8636\n",
      "Epoch 3383/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.8636\n",
      "Epoch 3384/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5089 - accuracy: 0.8636\n",
      "Epoch 3385/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5089 - accuracy: 0.8636\n",
      "Epoch 3386/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5089 - accuracy: 0.8636\n",
      "Epoch 3387/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5088 - accuracy: 0.8636\n",
      "Epoch 3388/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5088 - accuracy: 0.8636\n",
      "Epoch 3389/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5088 - accuracy: 0.8636\n",
      "Epoch 3390/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5087 - accuracy: 0.8636\n",
      "Epoch 3391/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5087 - accuracy: 0.8636\n",
      "Epoch 3392/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5087 - accuracy: 0.8636\n",
      "Epoch 3393/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5086 - accuracy: 0.8636\n",
      "Epoch 3394/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5086 - accuracy: 0.8636\n",
      "Epoch 3395/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5086 - accuracy: 0.8636\n",
      "Epoch 3396/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5085 - accuracy: 0.8636\n",
      "Epoch 3397/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5085 - accuracy: 0.8636\n",
      "Epoch 3398/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5085 - accuracy: 0.8636\n",
      "Epoch 3399/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.8636\n",
      "Epoch 3400/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.8636\n",
      "Epoch 3401/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.8636\n",
      "Epoch 3402/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.8636\n",
      "Epoch 3403/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5083 - accuracy: 0.8636\n",
      "Epoch 3404/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5083 - accuracy: 0.8636\n",
      "Epoch 3405/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5083 - accuracy: 0.8636\n",
      "Epoch 3406/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5082 - accuracy: 0.8636\n",
      "Epoch 3407/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5082 - accuracy: 0.8636\n",
      "Epoch 3408/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5082 - accuracy: 0.8636\n",
      "Epoch 3409/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5081 - accuracy: 0.8636\n",
      "Epoch 3410/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5081 - accuracy: 0.8636\n",
      "Epoch 3411/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5081 - accuracy: 0.8636\n",
      "Epoch 3412/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5080 - accuracy: 0.8636\n",
      "Epoch 3413/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5080 - accuracy: 0.8636\n",
      "Epoch 3414/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5080 - accuracy: 0.8636\n",
      "Epoch 3415/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5079 - accuracy: 0.8636\n",
      "Epoch 3416/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5079 - accuracy: 0.8636\n",
      "Epoch 3417/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5079 - accuracy: 0.8636\n",
      "Epoch 3418/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5079 - accuracy: 0.8636\n",
      "Epoch 3419/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5078 - accuracy: 0.8636\n",
      "Epoch 3420/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5078 - accuracy: 0.8636\n",
      "Epoch 3421/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5078 - accuracy: 0.8636\n",
      "Epoch 3422/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5077 - accuracy: 0.8636\n",
      "Epoch 3423/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5077 - accuracy: 0.8636\n",
      "Epoch 3424/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5077 - accuracy: 0.8636\n",
      "Epoch 3425/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5076 - accuracy: 0.8636\n",
      "Epoch 3426/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5076 - accuracy: 0.8636\n",
      "Epoch 3427/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5076 - accuracy: 0.8636\n",
      "Epoch 3428/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.8636\n",
      "Epoch 3429/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5075 - accuracy: 0.8636\n",
      "Epoch 3430/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5075 - accuracy: 0.8636\n",
      "Epoch 3431/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5074 - accuracy: 0.8636\n",
      "Epoch 3432/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5074 - accuracy: 0.8636\n",
      "Epoch 3433/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5074 - accuracy: 0.8636\n",
      "Epoch 3434/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5074 - accuracy: 0.8636\n",
      "Epoch 3435/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5073 - accuracy: 0.8636\n",
      "Epoch 3436/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5073 - accuracy: 0.8636\n",
      "Epoch 3437/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5073 - accuracy: 0.8636\n",
      "Epoch 3438/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5072 - accuracy: 0.8636\n",
      "Epoch 3439/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5072 - accuracy: 0.8636\n",
      "Epoch 3440/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5072 - accuracy: 0.8636\n",
      "Epoch 3441/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.8636\n",
      "Epoch 3442/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.8636\n",
      "Epoch 3443/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.8636\n",
      "Epoch 3444/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.8636\n",
      "Epoch 3445/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.8636\n",
      "Epoch 3446/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.8636\n",
      "Epoch 3447/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.8636\n",
      "Epoch 3448/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5069 - accuracy: 0.8636\n",
      "Epoch 3449/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.8636\n",
      "Epoch 3450/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.8636\n",
      "Epoch 3451/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.8636\n",
      "Epoch 3452/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5068 - accuracy: 0.8636\n",
      "Epoch 3453/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.8636\n",
      "Epoch 3454/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5067 - accuracy: 0.8636\n",
      "Epoch 3455/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5067 - accuracy: 0.8636\n",
      "Epoch 3456/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5067 - accuracy: 0.8636\n",
      "Epoch 3457/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5066 - accuracy: 0.8636\n",
      "Epoch 3458/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5066 - accuracy: 0.8636\n",
      "Epoch 3459/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5066 - accuracy: 0.8636\n",
      "Epoch 3460/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.8636\n",
      "Epoch 3461/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.8636\n",
      "Epoch 3462/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.8636\n",
      "Epoch 3463/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.8636\n",
      "Epoch 3464/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.8636\n",
      "Epoch 3465/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.8636\n",
      "Epoch 3466/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.8636\n",
      "Epoch 3467/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5063 - accuracy: 0.8636\n",
      "Epoch 3468/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5063 - accuracy: 0.8636\n",
      "Epoch 3469/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5063 - accuracy: 0.8636\n",
      "Epoch 3470/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5062 - accuracy: 0.8636\n",
      "Epoch 3471/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5062 - accuracy: 0.8636\n",
      "Epoch 3472/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5062 - accuracy: 0.8636\n",
      "Epoch 3473/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5061 - accuracy: 0.8636\n",
      "Epoch 3474/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5061 - accuracy: 0.8636\n",
      "Epoch 3475/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5061 - accuracy: 0.8636\n",
      "Epoch 3476/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5061 - accuracy: 0.8636\n",
      "Epoch 3477/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.8636\n",
      "Epoch 3478/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.8636\n",
      "Epoch 3479/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.8636\n",
      "Epoch 3480/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5059 - accuracy: 0.8636\n",
      "Epoch 3481/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5059 - accuracy: 0.8636\n",
      "Epoch 3482/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5059 - accuracy: 0.8636\n",
      "Epoch 3483/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.8636\n",
      "Epoch 3484/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.8636\n",
      "Epoch 3485/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.8636\n",
      "Epoch 3486/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5057 - accuracy: 0.8636\n",
      "Epoch 3487/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5057 - accuracy: 0.8636\n",
      "Epoch 3488/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5057 - accuracy: 0.8636\n",
      "Epoch 3489/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5057 - accuracy: 0.8636\n",
      "Epoch 3490/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5056 - accuracy: 0.8636\n",
      "Epoch 3491/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5056 - accuracy: 0.8636\n",
      "Epoch 3492/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5056 - accuracy: 0.8636\n",
      "Epoch 3493/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5055 - accuracy: 0.8636\n",
      "Epoch 3494/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5055 - accuracy: 0.8636\n",
      "Epoch 3495/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5055 - accuracy: 0.8636\n",
      "Epoch 3496/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5054 - accuracy: 0.8636\n",
      "Epoch 3497/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5054 - accuracy: 0.8636\n",
      "Epoch 3498/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5054 - accuracy: 0.8636\n",
      "Epoch 3499/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5053 - accuracy: 0.8636\n",
      "Epoch 3500/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5053 - accuracy: 0.8636\n",
      "Epoch 3501/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5053 - accuracy: 0.8636\n",
      "Epoch 3502/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5053 - accuracy: 0.8636\n",
      "Epoch 3503/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5052 - accuracy: 0.8636\n",
      "Epoch 3504/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5052 - accuracy: 0.8636\n",
      "Epoch 3505/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5052 - accuracy: 0.8636\n",
      "Epoch 3506/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5051 - accuracy: 0.8636\n",
      "Epoch 3507/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5051 - accuracy: 0.8636\n",
      "Epoch 3508/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5051 - accuracy: 0.8636\n",
      "Epoch 3509/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5050 - accuracy: 0.8636\n",
      "Epoch 3510/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5050 - accuracy: 0.8636\n",
      "Epoch 3511/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5050 - accuracy: 0.8636\n",
      "Epoch 3512/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5049 - accuracy: 0.8636\n",
      "Epoch 3513/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5049 - accuracy: 0.8636\n",
      "Epoch 3514/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5049 - accuracy: 0.8636\n",
      "Epoch 3515/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5049 - accuracy: 0.8636\n",
      "Epoch 3516/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5048 - accuracy: 0.8636\n",
      "Epoch 3517/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5048 - accuracy: 0.8636\n",
      "Epoch 3518/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5048 - accuracy: 0.8636\n",
      "Epoch 3519/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5047 - accuracy: 0.8636\n",
      "Epoch 3520/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5047 - accuracy: 0.8636\n",
      "Epoch 3521/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5047 - accuracy: 0.8636\n",
      "Epoch 3522/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.8636\n",
      "Epoch 3523/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.8636\n",
      "Epoch 3524/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.8636\n",
      "Epoch 3525/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5046 - accuracy: 0.8636\n",
      "Epoch 3526/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5045 - accuracy: 0.8636\n",
      "Epoch 3527/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5045 - accuracy: 0.8636\n",
      "Epoch 3528/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5045 - accuracy: 0.8636\n",
      "Epoch 3529/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5044 - accuracy: 0.8636\n",
      "Epoch 3530/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.8636\n",
      "Epoch 3531/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.8636\n",
      "Epoch 3532/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.8636\n",
      "Epoch 3533/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.8636\n",
      "Epoch 3534/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.8636\n",
      "Epoch 3535/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5042 - accuracy: 0.8636\n",
      "Epoch 3536/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5042 - accuracy: 0.8636\n",
      "Epoch 3537/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5042 - accuracy: 0.8636\n",
      "Epoch 3538/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5042 - accuracy: 0.8636\n",
      "Epoch 3539/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5041 - accuracy: 0.8636\n",
      "Epoch 3540/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5041 - accuracy: 0.8636\n",
      "Epoch 3541/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5041 - accuracy: 0.8636\n",
      "Epoch 3542/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5040 - accuracy: 0.8636\n",
      "Epoch 3543/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5040 - accuracy: 0.8636\n",
      "Epoch 3544/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5040 - accuracy: 0.8636\n",
      "Epoch 3545/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.8636\n",
      "Epoch 3546/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5039 - accuracy: 0.8636\n",
      "Epoch 3547/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.8636\n",
      "Epoch 3548/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.8636\n",
      "Epoch 3549/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5038 - accuracy: 0.8636\n",
      "Epoch 3550/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5038 - accuracy: 0.8636\n",
      "Epoch 3551/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5038 - accuracy: 0.8636\n",
      "Epoch 3552/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5037 - accuracy: 0.8636\n",
      "Epoch 3553/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5037 - accuracy: 0.8636\n",
      "Epoch 3554/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5037 - accuracy: 0.8636\n",
      "Epoch 3555/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.8636\n",
      "Epoch 3556/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.8636\n",
      "Epoch 3557/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.8636\n",
      "Epoch 3558/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.8636\n",
      "Epoch 3559/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5035 - accuracy: 0.8636\n",
      "Epoch 3560/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5035 - accuracy: 0.8636\n",
      "Epoch 3561/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5035 - accuracy: 0.8636\n",
      "Epoch 3562/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5034 - accuracy: 0.8636\n",
      "Epoch 3563/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5034 - accuracy: 0.8636\n",
      "Epoch 3564/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5034 - accuracy: 0.8636\n",
      "Epoch 3565/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.8636\n",
      "Epoch 3566/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5033 - accuracy: 0.8636\n",
      "Epoch 3567/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.8636\n",
      "Epoch 3568/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.8636\n",
      "Epoch 3569/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5032 - accuracy: 0.8636\n",
      "Epoch 3570/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5032 - accuracy: 0.8636\n",
      "Epoch 3571/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5032 - accuracy: 0.8636\n",
      "Epoch 3572/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5031 - accuracy: 0.8636\n",
      "Epoch 3573/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5031 - accuracy: 0.8636\n",
      "Epoch 3574/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5031 - accuracy: 0.8636\n",
      "Epoch 3575/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.8636\n",
      "Epoch 3576/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.8636\n",
      "Epoch 3577/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.8636\n",
      "Epoch 3578/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.8636\n",
      "Epoch 3579/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5029 - accuracy: 0.8636\n",
      "Epoch 3580/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5029 - accuracy: 0.8636\n",
      "Epoch 3581/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5029 - accuracy: 0.8636\n",
      "Epoch 3582/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.8636\n",
      "Epoch 3583/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.8636\n",
      "Epoch 3584/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.8636\n",
      "Epoch 3585/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8636\n",
      "Epoch 3586/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5027 - accuracy: 0.8636\n",
      "Epoch 3587/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8636\n",
      "Epoch 3588/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8636\n",
      "Epoch 3589/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5026 - accuracy: 0.8636\n",
      "Epoch 3590/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5026 - accuracy: 0.8636\n",
      "Epoch 3591/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5026 - accuracy: 0.8636\n",
      "Epoch 3592/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.8636\n",
      "Epoch 3593/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.8636\n",
      "Epoch 3594/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.8636\n",
      "Epoch 3595/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.8636\n",
      "Epoch 3596/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.8636\n",
      "Epoch 3597/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.8636\n",
      "Epoch 3598/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5024 - accuracy: 0.8636\n",
      "Epoch 3599/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.8636\n",
      "Epoch 3600/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5023 - accuracy: 0.8636\n",
      "Epoch 3601/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.8636\n",
      "Epoch 3602/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5022 - accuracy: 0.8636\n",
      "Epoch 3603/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5022 - accuracy: 0.8636\n",
      "Epoch 3604/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5022 - accuracy: 0.8636\n",
      "Epoch 3605/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.8636\n",
      "Epoch 3606/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.8636\n",
      "Epoch 3607/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5021 - accuracy: 0.8636\n",
      "Epoch 3608/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.8636\n",
      "Epoch 3609/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5020 - accuracy: 0.8636\n",
      "Epoch 3610/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5020 - accuracy: 0.8636\n",
      "Epoch 3611/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5020 - accuracy: 0.8636\n",
      "Epoch 3612/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.8636\n",
      "Epoch 3613/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.8636\n",
      "Epoch 3614/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5019 - accuracy: 0.8636\n",
      "Epoch 3615/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5019 - accuracy: 0.8636\n",
      "Epoch 3616/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5018 - accuracy: 0.8636\n",
      "Epoch 3617/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5018 - accuracy: 0.8636\n",
      "Epoch 3618/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5018 - accuracy: 0.8636\n",
      "Epoch 3619/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.8636\n",
      "Epoch 3620/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.8636\n",
      "Epoch 3621/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.8636\n",
      "Epoch 3622/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5016 - accuracy: 0.8636\n",
      "Epoch 3623/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5016 - accuracy: 0.8636\n",
      "Epoch 3624/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5016 - accuracy: 0.8636\n",
      "Epoch 3625/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5016 - accuracy: 0.8636\n",
      "Epoch 3626/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5015 - accuracy: 0.8636\n",
      "Epoch 3627/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5015 - accuracy: 0.8636\n",
      "Epoch 3628/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5015 - accuracy: 0.8636\n",
      "Epoch 3629/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.8636\n",
      "Epoch 3630/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.8636\n",
      "Epoch 3631/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5014 - accuracy: 0.8636\n",
      "Epoch 3632/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8636\n",
      "Epoch 3633/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8636\n",
      "Epoch 3634/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8636\n",
      "Epoch 3635/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.8636\n",
      "Epoch 3636/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5012 - accuracy: 0.8636\n",
      "Epoch 3637/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5012 - accuracy: 0.8636\n",
      "Epoch 3638/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5012 - accuracy: 0.8636\n",
      "Epoch 3639/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.8636\n",
      "Epoch 3640/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.8636\n",
      "Epoch 3641/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.8636\n",
      "Epoch 3642/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.8636\n",
      "Epoch 3643/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.8636\n",
      "Epoch 3644/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.8636\n",
      "Epoch 3645/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.8636\n",
      "Epoch 3646/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5009 - accuracy: 0.8636\n",
      "Epoch 3647/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5009 - accuracy: 0.8636\n",
      "Epoch 3648/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5009 - accuracy: 0.8636\n",
      "Epoch 3649/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.8636\n",
      "Epoch 3650/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.8636\n",
      "Epoch 3651/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.8636\n",
      "Epoch 3652/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5008 - accuracy: 0.8636\n",
      "Epoch 3653/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5007 - accuracy: 0.8636\n",
      "Epoch 3654/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5007 - accuracy: 0.8636\n",
      "Epoch 3655/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5007 - accuracy: 0.8636\n",
      "Epoch 3656/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.8636\n",
      "Epoch 3657/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.8636\n",
      "Epoch 3658/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.8636\n",
      "Epoch 3659/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5006 - accuracy: 0.8636\n",
      "Epoch 3660/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5005 - accuracy: 0.8636\n",
      "Epoch 3661/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5005 - accuracy: 0.8636\n",
      "Epoch 3662/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5005 - accuracy: 0.8636\n",
      "Epoch 3663/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5004 - accuracy: 0.8636\n",
      "Epoch 3664/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5004 - accuracy: 0.8636\n",
      "Epoch 3665/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5004 - accuracy: 0.8636\n",
      "Epoch 3666/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5004 - accuracy: 0.8636\n",
      "Epoch 3667/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5003 - accuracy: 0.8636\n",
      "Epoch 3668/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5003 - accuracy: 0.8636\n",
      "Epoch 3669/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5003 - accuracy: 0.8636\n",
      "Epoch 3670/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5002 - accuracy: 0.8636\n",
      "Epoch 3671/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5002 - accuracy: 0.8636\n",
      "Epoch 3672/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5002 - accuracy: 0.8636\n",
      "Epoch 3673/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.8636\n",
      "Epoch 3674/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.8636\n",
      "Epoch 3675/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.8636\n",
      "Epoch 3676/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.8636\n",
      "Epoch 3677/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.8636\n",
      "Epoch 3678/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.8636\n",
      "Epoch 3679/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.8636\n",
      "Epoch 3680/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4999 - accuracy: 0.8636\n",
      "Epoch 3681/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.8636\n",
      "Epoch 3682/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4999 - accuracy: 0.8636\n",
      "Epoch 3683/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4999 - accuracy: 0.8636\n",
      "Epoch 3684/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4998 - accuracy: 0.8636\n",
      "Epoch 3685/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4998 - accuracy: 0.8636\n",
      "Epoch 3686/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4998 - accuracy: 0.8636\n",
      "Epoch 3687/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.8636\n",
      "Epoch 3688/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4997 - accuracy: 0.8636\n",
      "Epoch 3689/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.8636\n",
      "Epoch 3690/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.8636\n",
      "Epoch 3691/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.8636\n",
      "Epoch 3692/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.8636\n",
      "Epoch 3693/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.8636\n",
      "Epoch 3694/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4995 - accuracy: 0.8636\n",
      "Epoch 3695/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4995 - accuracy: 0.8636\n",
      "Epoch 3696/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4995 - accuracy: 0.8636\n",
      "Epoch 3697/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.8636\n",
      "Epoch 3698/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4994 - accuracy: 0.8636\n",
      "Epoch 3699/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.8636\n",
      "Epoch 3700/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.8636\n",
      "Epoch 3701/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4993 - accuracy: 0.8636\n",
      "Epoch 3702/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4993 - accuracy: 0.8636\n",
      "Epoch 3703/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4993 - accuracy: 0.8636\n",
      "Epoch 3704/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4992 - accuracy: 0.8636\n",
      "Epoch 3705/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4992 - accuracy: 0.8636\n",
      "Epoch 3706/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4992 - accuracy: 0.8636\n",
      "Epoch 3707/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4992 - accuracy: 0.8636\n",
      "Epoch 3708/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4991 - accuracy: 0.8636\n",
      "Epoch 3709/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4991 - accuracy: 0.8636\n",
      "Epoch 3710/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4991 - accuracy: 0.8636\n",
      "Epoch 3711/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.8636\n",
      "Epoch 3712/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.8636\n",
      "Epoch 3713/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4990 - accuracy: 0.8636\n",
      "Epoch 3714/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.8636\n",
      "Epoch 3715/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4989 - accuracy: 0.8636\n",
      "Epoch 3716/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4989 - accuracy: 0.8636\n",
      "Epoch 3717/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4989 - accuracy: 0.8636\n",
      "Epoch 3718/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4988 - accuracy: 0.8636\n",
      "Epoch 3719/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4988 - accuracy: 0.8636\n",
      "Epoch 3720/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4988 - accuracy: 0.8636\n",
      "Epoch 3721/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4988 - accuracy: 0.8636\n",
      "Epoch 3722/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8636\n",
      "Epoch 3723/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8636\n",
      "Epoch 3724/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4987 - accuracy: 0.8636\n",
      "Epoch 3725/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.8636\n",
      "Epoch 3726/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.8636\n",
      "Epoch 3727/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4986 - accuracy: 0.8636\n",
      "Epoch 3728/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4986 - accuracy: 0.8636\n",
      "Epoch 3729/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4985 - accuracy: 0.8636\n",
      "Epoch 3730/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4985 - accuracy: 0.8636\n",
      "Epoch 3731/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4985 - accuracy: 0.8636\n",
      "Epoch 3732/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4984 - accuracy: 0.8636\n",
      "Epoch 3733/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4984 - accuracy: 0.8636\n",
      "Epoch 3734/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4984 - accuracy: 0.8636\n",
      "Epoch 3735/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4984 - accuracy: 0.8636\n",
      "Epoch 3736/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4983 - accuracy: 0.8636\n",
      "Epoch 3737/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4983 - accuracy: 0.8636\n",
      "Epoch 3738/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4983 - accuracy: 0.8636\n",
      "Epoch 3739/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.8636\n",
      "Epoch 3740/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.8636\n",
      "Epoch 3741/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.8636\n",
      "Epoch 3742/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.8636\n",
      "Epoch 3743/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.8636\n",
      "Epoch 3744/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.8636\n",
      "Epoch 3745/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.8636\n",
      "Epoch 3746/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4980 - accuracy: 0.8636\n",
      "Epoch 3747/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4980 - accuracy: 0.8636\n",
      "Epoch 3748/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4980 - accuracy: 0.8636\n",
      "Epoch 3749/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4980 - accuracy: 0.8636\n",
      "Epoch 3750/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4979 - accuracy: 0.8636\n",
      "Epoch 3751/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4979 - accuracy: 0.8636\n",
      "Epoch 3752/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4979 - accuracy: 0.8636\n",
      "Epoch 3753/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.8636\n",
      "Epoch 3754/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.8636\n",
      "Epoch 3755/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.8636\n",
      "Epoch 3756/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.8636\n",
      "Epoch 3757/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4977 - accuracy: 0.8636\n",
      "Epoch 3758/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4977 - accuracy: 0.8636\n",
      "Epoch 3759/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4977 - accuracy: 0.8636\n",
      "Epoch 3760/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4976 - accuracy: 0.8636\n",
      "Epoch 3761/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4976 - accuracy: 0.8636\n",
      "Epoch 3762/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4976 - accuracy: 0.8636\n",
      "Epoch 3763/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4976 - accuracy: 0.8636\n",
      "Epoch 3764/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4975 - accuracy: 0.8636\n",
      "Epoch 3765/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4975 - accuracy: 0.8636\n",
      "Epoch 3766/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4975 - accuracy: 0.8636\n",
      "Epoch 3767/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.8636\n",
      "Epoch 3768/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.8636\n",
      "Epoch 3769/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.8636\n",
      "Epoch 3770/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.8636\n",
      "Epoch 3771/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4973 - accuracy: 0.8636\n",
      "Epoch 3772/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4973 - accuracy: 0.8636\n",
      "Epoch 3773/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4973 - accuracy: 0.8636\n",
      "Epoch 3774/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4972 - accuracy: 0.8636\n",
      "Epoch 3775/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4972 - accuracy: 0.8636\n",
      "Epoch 3776/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4972 - accuracy: 0.8636\n",
      "Epoch 3777/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4972 - accuracy: 0.8636\n",
      "Epoch 3778/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4971 - accuracy: 0.8636\n",
      "Epoch 3779/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4971 - accuracy: 0.8636\n",
      "Epoch 3780/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4971 - accuracy: 0.8636\n",
      "Epoch 3781/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4970 - accuracy: 0.8636\n",
      "Epoch 3782/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4970 - accuracy: 0.8636\n",
      "Epoch 3783/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4970 - accuracy: 0.8636\n",
      "Epoch 3784/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4970 - accuracy: 0.8636\n",
      "Epoch 3785/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4969 - accuracy: 0.8636\n",
      "Epoch 3786/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4969 - accuracy: 0.8636\n",
      "Epoch 3787/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4969 - accuracy: 0.8636\n",
      "Epoch 3788/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4968 - accuracy: 0.8636\n",
      "Epoch 3789/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4968 - accuracy: 0.8636\n",
      "Epoch 3790/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4968 - accuracy: 0.8636\n",
      "Epoch 3791/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4968 - accuracy: 0.8636\n",
      "Epoch 3792/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4967 - accuracy: 0.8636\n",
      "Epoch 3793/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4967 - accuracy: 0.8636\n",
      "Epoch 3794/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4967 - accuracy: 0.8636\n",
      "Epoch 3795/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.8636\n",
      "Epoch 3796/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.8636\n",
      "Epoch 3797/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.8636\n",
      "Epoch 3798/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.8636\n",
      "Epoch 3799/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4965 - accuracy: 0.8636\n",
      "Epoch 3800/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4965 - accuracy: 0.8636\n",
      "Epoch 3801/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4965 - accuracy: 0.8636\n",
      "Epoch 3802/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4965 - accuracy: 0.8636\n",
      "Epoch 3803/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.8636\n",
      "Epoch 3804/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4964 - accuracy: 0.8636\n",
      "Epoch 3805/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.8636\n",
      "Epoch 3806/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4963 - accuracy: 0.8636\n",
      "Epoch 3807/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4963 - accuracy: 0.8636\n",
      "Epoch 3808/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4963 - accuracy: 0.8636\n",
      "Epoch 3809/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4963 - accuracy: 0.8636\n",
      "Epoch 3810/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4962 - accuracy: 0.8636\n",
      "Epoch 3811/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4962 - accuracy: 0.8636\n",
      "Epoch 3812/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4962 - accuracy: 0.8636\n",
      "Epoch 3813/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4961 - accuracy: 0.8636\n",
      "Epoch 3814/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4961 - accuracy: 0.8636\n",
      "Epoch 3815/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4961 - accuracy: 0.8636\n",
      "Epoch 3816/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4961 - accuracy: 0.8636\n",
      "Epoch 3817/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4960 - accuracy: 0.8636\n",
      "Epoch 3818/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4960 - accuracy: 0.8636\n",
      "Epoch 3819/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4960 - accuracy: 0.8636\n",
      "Epoch 3820/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.8636\n",
      "Epoch 3821/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.8636\n",
      "Epoch 3822/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.8636\n",
      "Epoch 3823/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4959 - accuracy: 0.8636\n",
      "Epoch 3824/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.8636\n",
      "Epoch 3825/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.8636\n",
      "Epoch 3826/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.8636\n",
      "Epoch 3827/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.8636\n",
      "Epoch 3828/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4957 - accuracy: 0.8636\n",
      "Epoch 3829/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4957 - accuracy: 0.8636\n",
      "Epoch 3830/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4957 - accuracy: 0.8636\n",
      "Epoch 3831/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8636\n",
      "Epoch 3832/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8636\n",
      "Epoch 3833/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.8636\n",
      "Epoch 3834/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4956 - accuracy: 0.8636\n",
      "Epoch 3835/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4955 - accuracy: 0.8636\n",
      "Epoch 3836/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4955 - accuracy: 0.8636\n",
      "Epoch 3837/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4955 - accuracy: 0.8636\n",
      "Epoch 3838/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4954 - accuracy: 0.8636\n",
      "Epoch 3839/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.8636\n",
      "Epoch 3840/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.8636\n",
      "Epoch 3841/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4954 - accuracy: 0.8636\n",
      "Epoch 3842/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.8636\n",
      "Epoch 3843/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.8636\n",
      "Epoch 3844/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.8636\n",
      "Epoch 3845/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.8636\n",
      "Epoch 3846/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4952 - accuracy: 0.8636\n",
      "Epoch 3847/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4952 - accuracy: 0.8636\n",
      "Epoch 3848/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4952 - accuracy: 0.8636\n",
      "Epoch 3849/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8636\n",
      "Epoch 3850/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8636\n",
      "Epoch 3851/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8636\n",
      "Epoch 3852/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4951 - accuracy: 0.8636\n",
      "Epoch 3853/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4950 - accuracy: 0.8636\n",
      "Epoch 3854/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4950 - accuracy: 0.8636\n",
      "Epoch 3855/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4950 - accuracy: 0.8636\n",
      "Epoch 3856/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.8636\n",
      "Epoch 3857/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.8636\n",
      "Epoch 3858/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.8636\n",
      "Epoch 3859/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.8636\n",
      "Epoch 3860/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8636\n",
      "Epoch 3861/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8636\n",
      "Epoch 3862/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4948 - accuracy: 0.8636\n",
      "Epoch 3863/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8636\n",
      "Epoch 3864/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4947 - accuracy: 0.8636\n",
      "Epoch 3865/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4947 - accuracy: 0.8636\n",
      "Epoch 3866/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4947 - accuracy: 0.8636\n",
      "Epoch 3867/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8636\n",
      "Epoch 3868/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8636\n",
      "Epoch 3869/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8636\n",
      "Epoch 3870/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.8636\n",
      "Epoch 3871/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4945 - accuracy: 0.8636\n",
      "Epoch 3872/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4945 - accuracy: 0.8636\n",
      "Epoch 3873/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4945 - accuracy: 0.8636\n",
      "Epoch 3874/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.8636\n",
      "Epoch 3875/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.8636\n",
      "Epoch 3876/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.8636\n",
      "Epoch 3877/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4944 - accuracy: 0.8636\n",
      "Epoch 3878/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4943 - accuracy: 0.8636\n",
      "Epoch 3879/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4943 - accuracy: 0.8636\n",
      "Epoch 3880/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4943 - accuracy: 0.8636\n",
      "Epoch 3881/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4943 - accuracy: 0.8636\n",
      "Epoch 3882/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4942 - accuracy: 0.8636\n",
      "Epoch 3883/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4942 - accuracy: 0.8636\n",
      "Epoch 3884/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4942 - accuracy: 0.8636\n",
      "Epoch 3885/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4941 - accuracy: 0.8636\n",
      "Epoch 3886/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4941 - accuracy: 0.8636\n",
      "Epoch 3887/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4941 - accuracy: 0.8636\n",
      "Epoch 3888/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4941 - accuracy: 0.8636\n",
      "Epoch 3889/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.8636\n",
      "Epoch 3890/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4940 - accuracy: 0.8636\n",
      "Epoch 3891/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.8636\n",
      "Epoch 3892/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4940 - accuracy: 0.8636\n",
      "Epoch 3893/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.8636\n",
      "Epoch 3894/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.8636\n",
      "Epoch 3895/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.8636\n",
      "Epoch 3896/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4938 - accuracy: 0.8636\n",
      "Epoch 3897/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4938 - accuracy: 0.8636\n",
      "Epoch 3898/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4938 - accuracy: 0.8636\n",
      "Epoch 3899/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4938 - accuracy: 0.8636\n",
      "Epoch 3900/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4937 - accuracy: 0.8636\n",
      "Epoch 3901/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4937 - accuracy: 0.8636\n",
      "Epoch 3902/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4937 - accuracy: 0.8636\n",
      "Epoch 3903/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4937 - accuracy: 0.8636\n",
      "Epoch 3904/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4936 - accuracy: 0.8636\n",
      "Epoch 3905/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.8636\n",
      "Epoch 3906/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.9091\n",
      "Epoch 3907/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.9091\n",
      "Epoch 3908/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.9091\n",
      "Epoch 3909/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.9091\n",
      "Epoch 3910/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.9091\n",
      "Epoch 3911/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.9091\n",
      "Epoch 3912/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.9091\n",
      "Epoch 3913/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.9091\n",
      "Epoch 3914/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.9091\n",
      "Epoch 3915/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.9091\n",
      "Epoch 3916/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.9091\n",
      "Epoch 3917/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.9091\n",
      "Epoch 3918/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4932 - accuracy: 0.9091\n",
      "Epoch 3919/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4932 - accuracy: 0.9091\n",
      "Epoch 3920/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4932 - accuracy: 0.9091\n",
      "Epoch 3921/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4932 - accuracy: 0.9091\n",
      "Epoch 3922/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.9091\n",
      "Epoch 3923/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.9091\n",
      "Epoch 3924/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.9091\n",
      "Epoch 3925/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4931 - accuracy: 0.9091\n",
      "Epoch 3926/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.9091\n",
      "Epoch 3927/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.9091\n",
      "Epoch 3928/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.9091\n",
      "Epoch 3929/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.9091\n",
      "Epoch 3930/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.9091\n",
      "Epoch 3931/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.9091\n",
      "Epoch 3932/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.9091\n",
      "Epoch 3933/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4928 - accuracy: 0.9091\n",
      "Epoch 3934/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4928 - accuracy: 0.9091\n",
      "Epoch 3935/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4928 - accuracy: 0.9091\n",
      "Epoch 3936/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4928 - accuracy: 0.9091\n",
      "Epoch 3937/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.9091\n",
      "Epoch 3938/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.9091\n",
      "Epoch 3939/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.9091\n",
      "Epoch 3940/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.9091\n",
      "Epoch 3941/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.9091\n",
      "Epoch 3942/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.9091\n",
      "Epoch 3943/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4926 - accuracy: 0.9091\n",
      "Epoch 3944/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.9091\n",
      "Epoch 3945/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.9091\n",
      "Epoch 3946/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.9091\n",
      "Epoch 3947/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4925 - accuracy: 0.9091\n",
      "Epoch 3948/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.9091\n",
      "Epoch 3949/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.9091\n",
      "Epoch 3950/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4924 - accuracy: 0.9091\n",
      "Epoch 3951/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.9091\n",
      "Epoch 3952/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4923 - accuracy: 0.9091\n",
      "Epoch 3953/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4923 - accuracy: 0.9091\n",
      "Epoch 3954/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4923 - accuracy: 0.9091\n",
      "Epoch 3955/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4922 - accuracy: 0.9091\n",
      "Epoch 3956/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4922 - accuracy: 0.9091\n",
      "Epoch 3957/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.9091\n",
      "Epoch 3958/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.9091\n",
      "Epoch 3959/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4921 - accuracy: 0.9091\n",
      "Epoch 3960/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.9091\n",
      "Epoch 3961/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.9091\n",
      "Epoch 3962/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.9091\n",
      "Epoch 3963/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4920 - accuracy: 0.9091\n",
      "Epoch 3964/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4920 - accuracy: 0.9091\n",
      "Epoch 3965/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4920 - accuracy: 0.9091\n",
      "Epoch 3966/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.9091\n",
      "Epoch 3967/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.9091\n",
      "Epoch 3968/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.9091\n",
      "Epoch 3969/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4919 - accuracy: 0.9091\n",
      "Epoch 3970/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.9091\n",
      "Epoch 3971/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4918 - accuracy: 0.9091\n",
      "Epoch 3972/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.9091\n",
      "Epoch 3973/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4918 - accuracy: 0.9091\n",
      "Epoch 3974/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.9091\n",
      "Epoch 3975/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.9091\n",
      "Epoch 3976/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.9091\n",
      "Epoch 3977/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4917 - accuracy: 0.9091\n",
      "Epoch 3978/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.9091\n",
      "Epoch 3979/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.9091\n",
      "Epoch 3980/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.9091\n",
      "Epoch 3981/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.9091\n",
      "Epoch 3982/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4915 - accuracy: 0.9091\n",
      "Epoch 3983/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.9091\n",
      "Epoch 3984/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.9091\n",
      "Epoch 3985/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.9091\n",
      "Epoch 3986/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.9091\n",
      "Epoch 3987/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.9091\n",
      "Epoch 3988/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.9091\n",
      "Epoch 3989/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.9091\n",
      "Epoch 3990/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.9091\n",
      "Epoch 3991/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.9091\n",
      "Epoch 3992/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.9091\n",
      "Epoch 3993/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4912 - accuracy: 0.9091\n",
      "Epoch 3994/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4912 - accuracy: 0.9091\n",
      "Epoch 3995/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4912 - accuracy: 0.9091\n",
      "Epoch 3996/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.9091\n",
      "Epoch 3997/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4911 - accuracy: 0.9091\n",
      "Epoch 3998/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.9091\n",
      "Epoch 3999/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.9091\n",
      "Epoch 4000/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.9091\n",
      "Epoch 4001/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.9091\n",
      "Epoch 4002/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.9091\n",
      "Epoch 4003/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4910 - accuracy: 0.9091\n",
      "Epoch 4004/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.9091\n",
      "Epoch 4005/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.9091\n",
      "Epoch 4006/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.9091\n",
      "Epoch 4007/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.9091\n",
      "Epoch 4008/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4908 - accuracy: 0.9091\n",
      "Epoch 4009/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4908 - accuracy: 0.9091\n",
      "Epoch 4010/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4908 - accuracy: 0.9091\n",
      "Epoch 4011/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4907 - accuracy: 0.9091\n",
      "Epoch 4012/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4907 - accuracy: 0.9091\n",
      "Epoch 4013/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4907 - accuracy: 0.9091\n",
      "Epoch 4014/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4907 - accuracy: 0.9091\n",
      "Epoch 4015/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4906 - accuracy: 0.9091\n",
      "Epoch 4016/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4906 - accuracy: 0.9091\n",
      "Epoch 4017/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4906 - accuracy: 0.9091\n",
      "Epoch 4018/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4906 - accuracy: 0.9091\n",
      "Epoch 4019/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.9091\n",
      "Epoch 4020/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4905 - accuracy: 0.9091\n",
      "Epoch 4021/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.9091\n",
      "Epoch 4022/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.9091\n",
      "Epoch 4023/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.9091\n",
      "Epoch 4024/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.9091\n",
      "Epoch 4025/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.9091\n",
      "Epoch 4026/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.9091\n",
      "Epoch 4027/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4903 - accuracy: 0.9091\n",
      "Epoch 4028/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4903 - accuracy: 0.9091\n",
      "Epoch 4029/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4903 - accuracy: 0.9091\n",
      "Epoch 4030/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.9091\n",
      "Epoch 4031/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.9091\n",
      "Epoch 4032/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.9091\n",
      "Epoch 4033/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4902 - accuracy: 0.9091\n",
      "Epoch 4034/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.9091\n",
      "Epoch 4035/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.9091\n",
      "Epoch 4036/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.9091\n",
      "Epoch 4037/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.9091\n",
      "Epoch 4038/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4900 - accuracy: 0.9091\n",
      "Epoch 4039/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4900 - accuracy: 0.9091\n",
      "Epoch 4040/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4900 - accuracy: 0.9091\n",
      "Epoch 4041/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4900 - accuracy: 0.9091\n",
      "Epoch 4042/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.9091\n",
      "Epoch 4043/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.9091\n",
      "Epoch 4044/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.9091\n",
      "Epoch 4045/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4899 - accuracy: 0.9091\n",
      "Epoch 4046/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.9091\n",
      "Epoch 4047/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.9091\n",
      "Epoch 4048/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.9091\n",
      "Epoch 4049/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.9091\n",
      "Epoch 4050/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.9091\n",
      "Epoch 4051/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.9091\n",
      "Epoch 4052/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.9091\n",
      "Epoch 4053/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4896 - accuracy: 0.9091\n",
      "Epoch 4054/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.9091\n",
      "Epoch 4055/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.9091\n",
      "Epoch 4056/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.9091\n",
      "Epoch 4057/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4895 - accuracy: 0.9091\n",
      "Epoch 4058/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4895 - accuracy: 0.9091\n",
      "Epoch 4059/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4895 - accuracy: 0.9091\n",
      "Epoch 4060/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4895 - accuracy: 0.9091\n",
      "Epoch 4061/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.9091\n",
      "Epoch 4062/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.9091\n",
      "Epoch 4063/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.9091\n",
      "Epoch 4064/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4894 - accuracy: 0.9091\n",
      "Epoch 4065/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4893 - accuracy: 0.9091\n",
      "Epoch 4066/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4893 - accuracy: 0.9091\n",
      "Epoch 4067/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4893 - accuracy: 0.9091\n",
      "Epoch 4068/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4893 - accuracy: 0.9091\n",
      "Epoch 4069/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.9091\n",
      "Epoch 4070/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.9091\n",
      "Epoch 4071/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.9091\n",
      "Epoch 4072/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4891 - accuracy: 0.9091\n",
      "Epoch 4073/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4891 - accuracy: 0.9091\n",
      "Epoch 4074/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4891 - accuracy: 0.9091\n",
      "Epoch 4075/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4891 - accuracy: 0.9091\n",
      "Epoch 4076/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.9091\n",
      "Epoch 4077/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.9091\n",
      "Epoch 4078/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.9091\n",
      "Epoch 4079/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.9091\n",
      "Epoch 4080/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.9091\n",
      "Epoch 4081/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.9091\n",
      "Epoch 4082/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.9091\n",
      "Epoch 4083/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.9091\n",
      "Epoch 4084/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.9091\n",
      "Epoch 4085/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.9091\n",
      "Epoch 4086/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4888 - accuracy: 0.9091\n",
      "Epoch 4087/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.9091\n",
      "Epoch 4088/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.9091\n",
      "Epoch 4089/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.9091\n",
      "Epoch 4090/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4887 - accuracy: 0.9091\n",
      "Epoch 4091/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.9091\n",
      "Epoch 4092/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4886 - accuracy: 0.9091\n",
      "Epoch 4093/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4886 - accuracy: 0.9091\n",
      "Epoch 4094/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4886 - accuracy: 0.9091\n",
      "Epoch 4095/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.9091\n",
      "Epoch 4096/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.9091\n",
      "Epoch 4097/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.9091\n",
      "Epoch 4098/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4885 - accuracy: 0.9091\n",
      "Epoch 4099/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4884 - accuracy: 0.9091\n",
      "Epoch 4100/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.9091\n",
      "Epoch 4101/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4884 - accuracy: 0.9091\n",
      "Epoch 4102/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4884 - accuracy: 0.9091\n",
      "Epoch 4103/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.9091\n",
      "Epoch 4104/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 0.9091\n",
      "Epoch 4105/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.9091\n",
      "Epoch 4106/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4883 - accuracy: 0.9091\n",
      "Epoch 4107/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4882 - accuracy: 0.9091\n",
      "Epoch 4108/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4882 - accuracy: 0.9091\n",
      "Epoch 4109/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4882 - accuracy: 0.9091\n",
      "Epoch 4110/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4882 - accuracy: 0.9091\n",
      "Epoch 4111/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.9091\n",
      "Epoch 4112/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.9091\n",
      "Epoch 4113/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4881 - accuracy: 0.9091\n",
      "Epoch 4114/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4881 - accuracy: 0.9091\n",
      "Epoch 4115/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.9091\n",
      "Epoch 4116/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.9091\n",
      "Epoch 4117/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.9091\n",
      "Epoch 4118/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.9091\n",
      "Epoch 4119/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.9091\n",
      "Epoch 4120/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.9091\n",
      "Epoch 4121/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.9091\n",
      "Epoch 4122/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4879 - accuracy: 0.9091\n",
      "Epoch 4123/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4878 - accuracy: 0.9091\n",
      "Epoch 4124/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4878 - accuracy: 0.9091\n",
      "Epoch 4125/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4878 - accuracy: 0.9091\n",
      "Epoch 4126/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4878 - accuracy: 0.9091\n",
      "Epoch 4127/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4877 - accuracy: 0.9091\n",
      "Epoch 4128/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.9091\n",
      "Epoch 4129/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.9091\n",
      "Epoch 4130/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4876 - accuracy: 0.9091\n",
      "Epoch 4131/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.9091\n",
      "Epoch 4132/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.9091\n",
      "Epoch 4133/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4876 - accuracy: 0.9091\n",
      "Epoch 4134/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.9091\n",
      "Epoch 4135/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.9091\n",
      "Epoch 4136/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.9091\n",
      "Epoch 4137/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.9091\n",
      "Epoch 4138/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4874 - accuracy: 0.9091\n",
      "Epoch 4139/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4874 - accuracy: 0.9091\n",
      "Epoch 4140/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4874 - accuracy: 0.9091\n",
      "Epoch 4141/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4874 - accuracy: 0.9091\n",
      "Epoch 4142/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.9091\n",
      "Epoch 4143/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.9091\n",
      "Epoch 4144/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.9091\n",
      "Epoch 4145/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.9091\n",
      "Epoch 4146/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.9091\n",
      "Epoch 4147/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.9091\n",
      "Epoch 4148/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.9091\n",
      "Epoch 4149/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.9091\n",
      "Epoch 4150/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4871 - accuracy: 0.9091\n",
      "Epoch 4151/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4871 - accuracy: 0.9091\n",
      "Epoch 4152/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4871 - accuracy: 0.9091\n",
      "Epoch 4153/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4871 - accuracy: 0.9091\n",
      "Epoch 4154/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4870 - accuracy: 0.9091\n",
      "Epoch 4155/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4870 - accuracy: 0.9091\n",
      "Epoch 4156/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4870 - accuracy: 0.9091\n",
      "Epoch 4157/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4870 - accuracy: 0.9091\n",
      "Epoch 4158/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4869 - accuracy: 0.9091\n",
      "Epoch 4159/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.9091\n",
      "Epoch 4160/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.9091\n",
      "Epoch 4161/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4869 - accuracy: 0.9091\n",
      "Epoch 4162/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4868 - accuracy: 0.9091\n",
      "Epoch 4163/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4868 - accuracy: 0.9091\n",
      "Epoch 4164/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4868 - accuracy: 0.9091\n",
      "Epoch 4165/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4868 - accuracy: 0.9091\n",
      "Epoch 4166/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.9091\n",
      "Epoch 4167/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.9091\n",
      "Epoch 4168/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.9091\n",
      "Epoch 4169/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.9091\n",
      "Epoch 4170/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.9091\n",
      "Epoch 4171/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.9091\n",
      "Epoch 4172/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.9091\n",
      "Epoch 4173/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4866 - accuracy: 0.9091\n",
      "Epoch 4174/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4865 - accuracy: 0.9091\n",
      "Epoch 4175/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.9091\n",
      "Epoch 4176/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.9091\n",
      "Epoch 4177/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.9091\n",
      "Epoch 4178/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4864 - accuracy: 0.9091\n",
      "Epoch 4179/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4864 - accuracy: 0.9091\n",
      "Epoch 4180/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4864 - accuracy: 0.9091\n",
      "Epoch 4181/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4864 - accuracy: 0.9091\n",
      "Epoch 4182/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.9091\n",
      "Epoch 4183/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.9091\n",
      "Epoch 4184/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.9091\n",
      "Epoch 4185/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4863 - accuracy: 0.9091\n",
      "Epoch 4186/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.9091\n",
      "Epoch 4187/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4862 - accuracy: 0.9091\n",
      "Epoch 4188/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.9091\n",
      "Epoch 4189/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.9091\n",
      "Epoch 4190/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.9091\n",
      "Epoch 4191/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.9091\n",
      "Epoch 4192/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.9091\n",
      "Epoch 4193/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.9091\n",
      "Epoch 4194/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4860 - accuracy: 0.9091\n",
      "Epoch 4195/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4860 - accuracy: 0.9091\n",
      "Epoch 4196/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4860 - accuracy: 0.9091\n",
      "Epoch 4197/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.9091\n",
      "Epoch 4198/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.9091\n",
      "Epoch 4199/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.9091\n",
      "Epoch 4200/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.9091\n",
      "Epoch 4201/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.9091\n",
      "Epoch 4202/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.9091\n",
      "Epoch 4203/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.9091\n",
      "Epoch 4204/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4858 - accuracy: 0.9091\n",
      "Epoch 4205/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.9091\n",
      "Epoch 4206/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.9091\n",
      "Epoch 4207/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.9091\n",
      "Epoch 4208/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.9091\n",
      "Epoch 4209/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.9091\n",
      "Epoch 4210/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.9091\n",
      "Epoch 4211/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.9091\n",
      "Epoch 4212/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.9091\n",
      "Epoch 4213/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4855 - accuracy: 0.9091\n",
      "Epoch 4214/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.9091\n",
      "Epoch 4215/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.9091\n",
      "Epoch 4216/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.9091\n",
      "Epoch 4217/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.9091\n",
      "Epoch 4218/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.9091\n",
      "Epoch 4219/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.9091\n",
      "Epoch 4220/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.9091\n",
      "Epoch 4221/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4853 - accuracy: 0.9091\n",
      "Epoch 4222/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4853 - accuracy: 0.9091\n",
      "Epoch 4223/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4853 - accuracy: 0.9091\n",
      "Epoch 4224/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4853 - accuracy: 0.9091\n",
      "Epoch 4225/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.9091\n",
      "Epoch 4226/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4852 - accuracy: 0.9091\n",
      "Epoch 4227/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.9091\n",
      "Epoch 4228/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.9091\n",
      "Epoch 4229/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4851 - accuracy: 0.9091\n",
      "Epoch 4230/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4851 - accuracy: 0.9091\n",
      "Epoch 4231/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4851 - accuracy: 0.9091\n",
      "Epoch 4232/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4851 - accuracy: 0.9091\n",
      "Epoch 4233/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4851 - accuracy: 0.9091\n",
      "Epoch 4234/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4850 - accuracy: 0.9091\n",
      "Epoch 4235/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.9091\n",
      "Epoch 4236/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.9091\n",
      "Epoch 4237/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.9091\n",
      "Epoch 4238/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4849 - accuracy: 0.9091\n",
      "Epoch 4239/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4849 - accuracy: 0.9091\n",
      "Epoch 4240/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4849 - accuracy: 0.9091\n",
      "Epoch 4241/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4849 - accuracy: 0.9091\n",
      "Epoch 4242/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4848 - accuracy: 0.9091\n",
      "Epoch 4243/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4848 - accuracy: 0.9091\n",
      "Epoch 4244/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4848 - accuracy: 0.9091\n",
      "Epoch 4245/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4848 - accuracy: 0.9091\n",
      "Epoch 4246/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.9091\n",
      "Epoch 4247/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.9091\n",
      "Epoch 4248/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.9091\n",
      "Epoch 4249/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.9091\n",
      "Epoch 4250/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.9091\n",
      "Epoch 4251/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.9091\n",
      "Epoch 4252/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.9091\n",
      "Epoch 4253/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.9091\n",
      "Epoch 4254/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4845 - accuracy: 0.9091\n",
      "Epoch 4255/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4845 - accuracy: 0.9091\n",
      "Epoch 4256/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4845 - accuracy: 0.9091\n",
      "Epoch 4257/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4845 - accuracy: 0.9091\n",
      "Epoch 4258/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4844 - accuracy: 0.9091\n",
      "Epoch 4259/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4844 - accuracy: 0.9091\n",
      "Epoch 4260/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4844 - accuracy: 0.9091\n",
      "Epoch 4261/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4844 - accuracy: 0.9091\n",
      "Epoch 4262/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4843 - accuracy: 0.9091\n",
      "Epoch 4263/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4843 - accuracy: 0.9091\n",
      "Epoch 4264/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4843 - accuracy: 0.9091\n",
      "Epoch 4265/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4843 - accuracy: 0.9091\n",
      "Epoch 4266/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4842 - accuracy: 0.9091\n",
      "Epoch 4267/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.9091\n",
      "Epoch 4268/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.9091\n",
      "Epoch 4269/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.9091\n",
      "Epoch 4270/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.9091\n",
      "Epoch 4271/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4841 - accuracy: 0.9091\n",
      "Epoch 4272/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.9091\n",
      "Epoch 4273/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.9091\n",
      "Epoch 4274/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.9091\n",
      "Epoch 4275/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.9091\n",
      "Epoch 4276/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.9091\n",
      "Epoch 4277/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.9091\n",
      "Epoch 4278/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.9091\n",
      "Epoch 4279/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.9091\n",
      "Epoch 4280/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.9091\n",
      "Epoch 4281/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.9091\n",
      "Epoch 4282/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.9091\n",
      "Epoch 4283/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.9091\n",
      "Epoch 4284/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4838 - accuracy: 0.9091\n",
      "Epoch 4285/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.9091\n",
      "Epoch 4286/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4837 - accuracy: 0.9091\n",
      "Epoch 4287/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4837 - accuracy: 0.9091\n",
      "Epoch 4288/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4837 - accuracy: 0.9091\n",
      "Epoch 4289/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4837 - accuracy: 0.9091\n",
      "Epoch 4290/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.9091\n",
      "Epoch 4291/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4836 - accuracy: 0.9091\n",
      "Epoch 4292/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.9091\n",
      "Epoch 4293/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.9091\n",
      "Epoch 4294/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4835 - accuracy: 0.9091\n",
      "Epoch 4295/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4835 - accuracy: 0.9091\n",
      "Epoch 4296/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4835 - accuracy: 0.9091\n",
      "Epoch 4297/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4835 - accuracy: 0.9091\n",
      "Epoch 4298/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4835 - accuracy: 0.9091\n",
      "Epoch 4299/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.9091\n",
      "Epoch 4300/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.9091\n",
      "Epoch 4301/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.9091\n",
      "Epoch 4302/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.9091\n",
      "Epoch 4303/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4833 - accuracy: 0.9091\n",
      "Epoch 4304/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.9091\n",
      "Epoch 4305/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.9091\n",
      "Epoch 4306/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.9091\n",
      "Epoch 4307/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.9091\n",
      "Epoch 4308/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.9091\n",
      "Epoch 4309/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.9091\n",
      "Epoch 4310/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.9091\n",
      "Epoch 4311/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4831 - accuracy: 0.9091\n",
      "Epoch 4312/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4831 - accuracy: 0.9091\n",
      "Epoch 4313/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4831 - accuracy: 0.9091\n",
      "Epoch 4314/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4831 - accuracy: 0.9091\n",
      "Epoch 4315/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.9091\n",
      "Epoch 4316/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.9091\n",
      "Epoch 4317/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.9091\n",
      "Epoch 4318/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.9091\n",
      "Epoch 4319/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4829 - accuracy: 0.9091\n",
      "Epoch 4320/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4829 - accuracy: 0.9091\n",
      "Epoch 4321/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4829 - accuracy: 0.9091\n",
      "Epoch 4322/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4829 - accuracy: 0.9091\n",
      "Epoch 4323/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.9091\n",
      "Epoch 4324/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.9091\n",
      "Epoch 4325/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.9091\n",
      "Epoch 4326/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.9091\n",
      "Epoch 4327/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.9091\n",
      "Epoch 4328/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.9091\n",
      "Epoch 4329/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.9091\n",
      "Epoch 4330/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4827 - accuracy: 0.9091\n",
      "Epoch 4331/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.9091\n",
      "Epoch 4332/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.9091\n",
      "Epoch 4333/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.9091\n",
      "Epoch 4334/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.9091\n",
      "Epoch 4335/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.9091\n",
      "Epoch 4336/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4825 - accuracy: 0.9091\n",
      "Epoch 4337/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4825 - accuracy: 0.9091\n",
      "Epoch 4338/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4825 - accuracy: 0.9091\n",
      "Epoch 4339/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4825 - accuracy: 0.9091\n",
      "Epoch 4340/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.9091\n",
      "Epoch 4341/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.9091\n",
      "Epoch 4342/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.9091\n",
      "Epoch 4343/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4824 - accuracy: 0.9091\n",
      "Epoch 4344/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.9091\n",
      "Epoch 4345/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.9091\n",
      "Epoch 4346/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.9091\n",
      "Epoch 4347/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.9091\n",
      "Epoch 4348/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4822 - accuracy: 0.9091\n",
      "Epoch 4349/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4822 - accuracy: 0.9091\n",
      "Epoch 4350/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4822 - accuracy: 0.9091\n",
      "Epoch 4351/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4822 - accuracy: 0.9091\n",
      "Epoch 4352/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4821 - accuracy: 0.9091\n",
      "Epoch 4353/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4821 - accuracy: 0.9091\n",
      "Epoch 4354/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4821 - accuracy: 0.9091\n",
      "Epoch 4355/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4821 - accuracy: 0.9091\n",
      "Epoch 4356/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.9091\n",
      "Epoch 4357/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.9091\n",
      "Epoch 4358/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.9091\n",
      "Epoch 4359/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4820 - accuracy: 0.9091\n",
      "Epoch 4360/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.9091\n",
      "Epoch 4361/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4819 - accuracy: 0.9091\n",
      "Epoch 4362/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4819 - accuracy: 0.9091\n",
      "Epoch 4363/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4819 - accuracy: 0.9091\n",
      "Epoch 4364/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4819 - accuracy: 0.9091\n",
      "Epoch 4365/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4818 - accuracy: 0.9091\n",
      "Epoch 4366/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4818 - accuracy: 0.9091\n",
      "Epoch 4367/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4818 - accuracy: 0.9091\n",
      "Epoch 4368/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4818 - accuracy: 0.9091\n",
      "Epoch 4369/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.9091\n",
      "Epoch 4370/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.9091\n",
      "Epoch 4371/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.9091\n",
      "Epoch 4372/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.9091\n",
      "Epoch 4373/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4816 - accuracy: 0.9091\n",
      "Epoch 4374/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4816 - accuracy: 0.9091\n",
      "Epoch 4375/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4816 - accuracy: 0.9091\n",
      "Epoch 4376/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4816 - accuracy: 0.9091\n",
      "Epoch 4377/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4815 - accuracy: 0.9091\n",
      "Epoch 4378/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4815 - accuracy: 0.9091\n",
      "Epoch 4379/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4815 - accuracy: 0.9091\n",
      "Epoch 4380/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4815 - accuracy: 0.9091\n",
      "Epoch 4381/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4814 - accuracy: 0.9091\n",
      "Epoch 4382/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4814 - accuracy: 0.9091\n",
      "Epoch 4383/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4814 - accuracy: 0.9091\n",
      "Epoch 4384/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4814 - accuracy: 0.9091\n",
      "Epoch 4385/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4814 - accuracy: 0.9091\n",
      "Epoch 4386/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.9091\n",
      "Epoch 4387/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.9091\n",
      "Epoch 4388/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.9091\n",
      "Epoch 4389/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4813 - accuracy: 0.9091\n",
      "Epoch 4390/5000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4812 - accuracy: 0.9091\n",
      "Epoch 4391/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.9091\n",
      "Epoch 4392/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.9091\n",
      "Epoch 4393/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4812 - accuracy: 0.9091\n",
      "Epoch 4394/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.9091\n",
      "Epoch 4395/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4811 - accuracy: 0.9091\n",
      "Epoch 4396/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.9091\n",
      "Epoch 4397/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.9091\n",
      "Epoch 4398/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.9091\n",
      "Epoch 4399/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.9091\n",
      "Epoch 4400/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.9091\n",
      "Epoch 4401/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.9091\n",
      "Epoch 4402/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.9091\n",
      "Epoch 4403/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4809 - accuracy: 0.9091\n",
      "Epoch 4404/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4809 - accuracy: 0.9091\n",
      "Epoch 4405/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4809 - accuracy: 0.9091\n",
      "Epoch 4406/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4809 - accuracy: 0.9091\n",
      "Epoch 4407/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.9091\n",
      "Epoch 4408/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.9091\n",
      "Epoch 4409/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.9091\n",
      "Epoch 4410/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.9091\n",
      "Epoch 4411/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.9091\n",
      "Epoch 4412/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.9091\n",
      "Epoch 4413/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.9091\n",
      "Epoch 4414/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.9091\n",
      "Epoch 4415/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.9091\n",
      "Epoch 4416/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.9091\n",
      "Epoch 4417/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4806 - accuracy: 0.9091\n",
      "Epoch 4418/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4806 - accuracy: 0.9091\n",
      "Epoch 4419/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4805 - accuracy: 0.9091\n",
      "Epoch 4420/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.9091\n",
      "Epoch 4421/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.9091\n",
      "Epoch 4422/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.9091\n",
      "Epoch 4423/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.9091\n",
      "Epoch 4424/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4804 - accuracy: 0.9091\n",
      "Epoch 4425/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4804 - accuracy: 0.9091\n",
      "Epoch 4426/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4804 - accuracy: 0.9091\n",
      "Epoch 4427/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4804 - accuracy: 0.9091\n",
      "Epoch 4428/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.9091\n",
      "Epoch 4429/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.9091\n",
      "Epoch 4430/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.9091\n",
      "Epoch 4431/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.9091\n",
      "Epoch 4432/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4802 - accuracy: 0.9091\n",
      "Epoch 4433/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4802 - accuracy: 0.9091\n",
      "Epoch 4434/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4802 - accuracy: 0.9091\n",
      "Epoch 4435/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4802 - accuracy: 0.9091\n",
      "Epoch 4436/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4802 - accuracy: 0.9091\n",
      "Epoch 4437/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4801 - accuracy: 0.9091\n",
      "Epoch 4438/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4801 - accuracy: 0.9091\n",
      "Epoch 4439/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4801 - accuracy: 0.9091\n",
      "Epoch 4440/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4801 - accuracy: 0.9091\n",
      "Epoch 4441/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4800 - accuracy: 0.9091\n",
      "Epoch 4442/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.9091\n",
      "Epoch 4443/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.9091\n",
      "Epoch 4444/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.9091\n",
      "Epoch 4445/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.9091\n",
      "Epoch 4446/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.9091\n",
      "Epoch 4447/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.9091\n",
      "Epoch 4448/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.9091\n",
      "Epoch 4449/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.9091\n",
      "Epoch 4450/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.9091\n",
      "Epoch 4451/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.9091\n",
      "Epoch 4452/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.9091\n",
      "Epoch 4453/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4798 - accuracy: 0.9091\n",
      "Epoch 4454/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.9091\n",
      "Epoch 4455/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.9091\n",
      "Epoch 4456/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.9091\n",
      "Epoch 4457/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.9091\n",
      "Epoch 4458/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4796 - accuracy: 0.9091\n",
      "Epoch 4459/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4796 - accuracy: 0.9091\n",
      "Epoch 4460/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4796 - accuracy: 0.9091\n",
      "Epoch 4461/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4796 - accuracy: 0.9091\n",
      "Epoch 4462/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.9091\n",
      "Epoch 4463/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.9091\n",
      "Epoch 4464/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.9091\n",
      "Epoch 4465/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.9091\n",
      "Epoch 4466/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4795 - accuracy: 0.9091\n",
      "Epoch 4467/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4794 - accuracy: 0.9091\n",
      "Epoch 4468/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.9091\n",
      "Epoch 4469/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.9091\n",
      "Epoch 4470/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.9091\n",
      "Epoch 4471/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4793 - accuracy: 0.9091\n",
      "Epoch 4472/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4793 - accuracy: 0.9091\n",
      "Epoch 4473/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4793 - accuracy: 0.9091\n",
      "Epoch 4474/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4793 - accuracy: 0.9091\n",
      "Epoch 4475/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.9091\n",
      "Epoch 4476/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.9091\n",
      "Epoch 4477/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.9091\n",
      "Epoch 4478/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.9091\n",
      "Epoch 4479/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.9091\n",
      "Epoch 4480/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.9091\n",
      "Epoch 4481/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.9091\n",
      "Epoch 4482/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4791 - accuracy: 0.9091\n",
      "Epoch 4483/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4791 - accuracy: 0.9091\n",
      "Epoch 4484/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.9091\n",
      "Epoch 4485/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.9091\n",
      "Epoch 4486/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.9091\n",
      "Epoch 4487/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.9091\n",
      "Epoch 4488/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4789 - accuracy: 0.9091\n",
      "Epoch 4489/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.9091\n",
      "Epoch 4490/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.9091\n",
      "Epoch 4491/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4789 - accuracy: 0.9091\n",
      "Epoch 4492/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.9091\n",
      "Epoch 4493/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.9091\n",
      "Epoch 4494/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.9091\n",
      "Epoch 4495/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4788 - accuracy: 0.9091\n",
      "Epoch 4496/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4788 - accuracy: 0.9091\n",
      "Epoch 4497/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.9091\n",
      "Epoch 4498/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4787 - accuracy: 0.9091\n",
      "Epoch 4499/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.9091\n",
      "Epoch 4500/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.9091\n",
      "Epoch 4501/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4786 - accuracy: 0.9091\n",
      "Epoch 4502/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.9091\n",
      "Epoch 4503/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.9091\n",
      "Epoch 4504/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.9091\n",
      "Epoch 4505/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.9091\n",
      "Epoch 4506/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.9091\n",
      "Epoch 4507/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.9091\n",
      "Epoch 4508/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.9091\n",
      "Epoch 4509/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.9091\n",
      "Epoch 4510/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4784 - accuracy: 0.9091\n",
      "Epoch 4511/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4784 - accuracy: 0.9091\n",
      "Epoch 4512/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4784 - accuracy: 0.9091\n",
      "Epoch 4513/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4784 - accuracy: 0.9091\n",
      "Epoch 4514/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4783 - accuracy: 0.9091\n",
      "Epoch 4515/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4783 - accuracy: 0.9091\n",
      "Epoch 4516/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4783 - accuracy: 0.9091\n",
      "Epoch 4517/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4783 - accuracy: 0.9091\n",
      "Epoch 4518/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4783 - accuracy: 0.9091\n",
      "Epoch 4519/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.9091\n",
      "Epoch 4520/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.9091\n",
      "Epoch 4521/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.9091\n",
      "Epoch 4522/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.9091\n",
      "Epoch 4523/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4781 - accuracy: 0.9091\n",
      "Epoch 4524/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4781 - accuracy: 0.9091\n",
      "Epoch 4525/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4781 - accuracy: 0.9091\n",
      "Epoch 4526/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4781 - accuracy: 0.9091\n",
      "Epoch 4527/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4780 - accuracy: 0.9091\n",
      "Epoch 4528/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4780 - accuracy: 0.9091\n",
      "Epoch 4529/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4780 - accuracy: 0.9091\n",
      "Epoch 4530/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4780 - accuracy: 0.9091\n",
      "Epoch 4531/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4780 - accuracy: 0.9091\n",
      "Epoch 4532/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.9091\n",
      "Epoch 4533/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4779 - accuracy: 0.9091\n",
      "Epoch 4534/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.9091\n",
      "Epoch 4535/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.9091\n",
      "Epoch 4536/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4778 - accuracy: 0.9091\n",
      "Epoch 4537/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4778 - accuracy: 0.9091\n",
      "Epoch 4538/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4778 - accuracy: 0.9091\n",
      "Epoch 4539/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4778 - accuracy: 0.9091\n",
      "Epoch 4540/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4777 - accuracy: 0.9091\n",
      "Epoch 4541/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.9091\n",
      "Epoch 4542/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.9091\n",
      "Epoch 4543/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.9091\n",
      "Epoch 4544/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4777 - accuracy: 0.9091\n",
      "Epoch 4545/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.9091\n",
      "Epoch 4546/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.9091\n",
      "Epoch 4547/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.9091\n",
      "Epoch 4548/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.9091\n",
      "Epoch 4549/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4775 - accuracy: 0.9091\n",
      "Epoch 4550/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.9091\n",
      "Epoch 4551/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.9091\n",
      "Epoch 4552/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.9091\n",
      "Epoch 4553/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.9091\n",
      "Epoch 4554/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.9091\n",
      "Epoch 4555/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.9091\n",
      "Epoch 4556/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.9091\n",
      "Epoch 4557/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.9091\n",
      "Epoch 4558/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.9091\n",
      "Epoch 4559/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4773 - accuracy: 0.9091\n",
      "Epoch 4560/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.9091\n",
      "Epoch 4561/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.9091\n",
      "Epoch 4562/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.9091\n",
      "Epoch 4563/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4772 - accuracy: 0.9091\n",
      "Epoch 4564/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.9091\n",
      "Epoch 4565/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.9091\n",
      "Epoch 4566/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.9091\n",
      "Epoch 4567/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.9091\n",
      "Epoch 4568/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.9091\n",
      "Epoch 4569/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.9091\n",
      "Epoch 4570/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.9091\n",
      "Epoch 4571/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4770 - accuracy: 0.9091\n",
      "Epoch 4572/5000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4770 - accuracy: 0.9091\n",
      "Epoch 4573/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4770 - accuracy: 0.9091\n",
      "Epoch 4574/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4770 - accuracy: 0.9091\n",
      "Epoch 4575/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4770 - accuracy: 0.9091\n",
      "Epoch 4576/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.9091\n",
      "Epoch 4577/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.9091\n",
      "Epoch 4578/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.9091\n",
      "Epoch 4579/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.9091\n",
      "Epoch 4580/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4768 - accuracy: 0.9091\n",
      "Epoch 4581/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.9091\n",
      "Epoch 4582/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.9091\n",
      "Epoch 4583/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.9091\n",
      "Epoch 4584/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4768 - accuracy: 0.9091\n",
      "Epoch 4585/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.9091\n",
      "Epoch 4586/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.9091\n",
      "Epoch 4587/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.9091\n",
      "Epoch 4588/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.9091\n",
      "Epoch 4589/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4766 - accuracy: 0.9091\n",
      "Epoch 4590/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.9091\n",
      "Epoch 4591/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4766 - accuracy: 0.9091\n",
      "Epoch 4592/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.9091\n",
      "Epoch 4593/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.9091\n",
      "Epoch 4594/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.9091\n",
      "Epoch 4595/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.9091\n",
      "Epoch 4596/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.9091\n",
      "Epoch 4597/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4765 - accuracy: 0.9091\n",
      "Epoch 4598/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4764 - accuracy: 0.9091\n",
      "Epoch 4599/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4764 - accuracy: 0.9091\n",
      "Epoch 4600/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4764 - accuracy: 0.9091\n",
      "Epoch 4601/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4764 - accuracy: 0.9091\n",
      "Epoch 4602/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4764 - accuracy: 0.9091\n",
      "Epoch 4603/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4763 - accuracy: 0.9091\n",
      "Epoch 4604/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4763 - accuracy: 0.9091\n",
      "Epoch 4605/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4763 - accuracy: 0.9091\n",
      "Epoch 4606/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4763 - accuracy: 0.9091\n",
      "Epoch 4607/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.9091\n",
      "Epoch 4608/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4762 - accuracy: 0.9091\n",
      "Epoch 4609/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.9091\n",
      "Epoch 4610/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.9091\n",
      "Epoch 4611/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.9091\n",
      "Epoch 4612/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.9091\n",
      "Epoch 4613/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.9091\n",
      "Epoch 4614/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.9091\n",
      "Epoch 4615/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.9091\n",
      "Epoch 4616/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.9091\n",
      "Epoch 4617/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.9091\n",
      "Epoch 4618/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.9091\n",
      "Epoch 4619/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4760 - accuracy: 0.9091\n",
      "Epoch 4620/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.9091\n",
      "Epoch 4621/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4759 - accuracy: 0.9091\n",
      "Epoch 4622/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4759 - accuracy: 0.9091\n",
      "Epoch 4623/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4759 - accuracy: 0.9091\n",
      "Epoch 4624/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4759 - accuracy: 0.9091\n",
      "Epoch 4625/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.9091\n",
      "Epoch 4626/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.9091\n",
      "Epoch 4627/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.9091\n",
      "Epoch 4628/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.9091\n",
      "Epoch 4629/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.9091\n",
      "Epoch 4630/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4757 - accuracy: 0.9091\n",
      "Epoch 4631/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4757 - accuracy: 0.9091\n",
      "Epoch 4632/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4757 - accuracy: 0.9091\n",
      "Epoch 4633/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4757 - accuracy: 0.9091\n",
      "Epoch 4634/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.9091\n",
      "Epoch 4635/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.9091\n",
      "Epoch 4636/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.9091\n",
      "Epoch 4637/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.9091\n",
      "Epoch 4638/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.9091\n",
      "Epoch 4639/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.9091\n",
      "Epoch 4640/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4755 - accuracy: 0.9091\n",
      "Epoch 4641/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.9091\n",
      "Epoch 4642/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.9091\n",
      "Epoch 4643/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.9091\n",
      "Epoch 4644/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.9091\n",
      "Epoch 4645/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.9091\n",
      "Epoch 4646/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.9091\n",
      "Epoch 4647/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4754 - accuracy: 0.9091\n",
      "Epoch 4648/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4753 - accuracy: 0.9091\n",
      "Epoch 4649/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4753 - accuracy: 0.9091\n",
      "Epoch 4650/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4753 - accuracy: 0.9091\n",
      "Epoch 4651/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4753 - accuracy: 0.9091\n",
      "Epoch 4652/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4752 - accuracy: 0.9091\n",
      "Epoch 4653/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4752 - accuracy: 0.9091\n",
      "Epoch 4654/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4752 - accuracy: 0.9091\n",
      "Epoch 4655/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4752 - accuracy: 0.9091\n",
      "Epoch 4656/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4752 - accuracy: 0.9091\n",
      "Epoch 4657/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.9091\n",
      "Epoch 4658/5000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4751 - accuracy: 0.9091\n",
      "Epoch 4659/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.9091\n",
      "Epoch 4660/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.9091\n",
      "Epoch 4661/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.9091\n",
      "Epoch 4662/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.9091\n",
      "Epoch 4663/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.9091\n",
      "Epoch 4664/5000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4750 - accuracy: 0.9091\n",
      "Epoch 4665/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.9091\n",
      "Epoch 4666/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.9091\n",
      "Epoch 4667/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.9091\n",
      "Epoch 4668/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.9091\n",
      "Epoch 4669/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4749 - accuracy: 0.9091\n",
      "Epoch 4670/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.9091\n",
      "Epoch 4671/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.9091\n",
      "Epoch 4672/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4748 - accuracy: 0.9091\n",
      "Epoch 4673/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.9091\n",
      "Epoch 4674/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.9091\n",
      "Epoch 4675/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4747 - accuracy: 0.9091\n",
      "Epoch 4676/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.9091\n",
      "Epoch 4677/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.9091\n",
      "Epoch 4678/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.9091\n",
      "Epoch 4679/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.9091\n",
      "Epoch 4680/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.9091\n",
      "Epoch 4681/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.9091\n",
      "Epoch 4682/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.9091\n",
      "Epoch 4683/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.9091\n",
      "Epoch 4684/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4745 - accuracy: 0.9091\n",
      "Epoch 4685/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.9091\n",
      "Epoch 4686/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.9091\n",
      "Epoch 4687/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.9091\n",
      "Epoch 4688/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4745 - accuracy: 0.9091\n",
      "Epoch 4689/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.9091\n",
      "Epoch 4690/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.9091\n",
      "Epoch 4691/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4744 - accuracy: 0.9091\n",
      "Epoch 4692/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4744 - accuracy: 0.9091\n",
      "Epoch 4693/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.9091\n",
      "Epoch 4694/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.9091\n",
      "Epoch 4695/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.9091\n",
      "Epoch 4696/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.9091\n",
      "Epoch 4697/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4743 - accuracy: 0.9091\n",
      "Epoch 4698/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4742 - accuracy: 0.9091\n",
      "Epoch 4699/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4742 - accuracy: 0.9091\n",
      "Epoch 4700/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4742 - accuracy: 0.9091\n",
      "Epoch 4701/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4742 - accuracy: 0.9091\n",
      "Epoch 4702/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4742 - accuracy: 0.9091\n",
      "Epoch 4703/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.9091\n",
      "Epoch 4704/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.9091\n",
      "Epoch 4705/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.9091\n",
      "Epoch 4706/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4741 - accuracy: 0.9091\n",
      "Epoch 4707/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.9091\n",
      "Epoch 4708/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4740 - accuracy: 0.9091\n",
      "Epoch 4709/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.9091\n",
      "Epoch 4710/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4740 - accuracy: 0.9091\n",
      "Epoch 4711/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.9091\n",
      "Epoch 4712/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.9091\n",
      "Epoch 4713/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.9091\n",
      "Epoch 4714/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.9091\n",
      "Epoch 4715/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.9091\n",
      "Epoch 4716/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.9091\n",
      "Epoch 4717/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.9091\n",
      "Epoch 4718/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.9091\n",
      "Epoch 4719/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4738 - accuracy: 0.9091\n",
      "Epoch 4720/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.9091\n",
      "Epoch 4721/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4737 - accuracy: 0.9091\n",
      "Epoch 4722/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4737 - accuracy: 0.9091\n",
      "Epoch 4723/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.9091\n",
      "Epoch 4724/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.9091\n",
      "Epoch 4725/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.9091\n",
      "Epoch 4726/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4736 - accuracy: 0.9091\n",
      "Epoch 4727/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.9091\n",
      "Epoch 4728/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.9091\n",
      "Epoch 4729/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.9091\n",
      "Epoch 4730/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.9091\n",
      "Epoch 4731/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.9091\n",
      "Epoch 4732/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.9091\n",
      "Epoch 4733/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4735 - accuracy: 0.9091\n",
      "Epoch 4734/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.9091\n",
      "Epoch 4735/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.9091\n",
      "Epoch 4736/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.9091\n",
      "Epoch 4737/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.9091\n",
      "Epoch 4738/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.9091\n",
      "Epoch 4739/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4734 - accuracy: 0.9091\n",
      "Epoch 4740/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.9091\n",
      "Epoch 4741/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.9091\n",
      "Epoch 4742/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.9091\n",
      "Epoch 4743/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.9091\n",
      "Epoch 4744/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4732 - accuracy: 0.9091\n",
      "Epoch 4745/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.9091\n",
      "Epoch 4746/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.9091\n",
      "Epoch 4747/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4732 - accuracy: 0.9091\n",
      "Epoch 4748/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.9091\n",
      "Epoch 4749/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.9091\n",
      "Epoch 4750/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.9091\n",
      "Epoch 4751/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.9091\n",
      "Epoch 4752/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.9091\n",
      "Epoch 4753/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.9091\n",
      "Epoch 4754/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.9091\n",
      "Epoch 4755/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.9091\n",
      "Epoch 4756/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.9091\n",
      "Epoch 4757/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.9091\n",
      "Epoch 4758/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.9091\n",
      "Epoch 4759/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.9091\n",
      "Epoch 4760/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.9091\n",
      "Epoch 4761/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.9091\n",
      "Epoch 4762/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.9091\n",
      "Epoch 4763/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.9091\n",
      "Epoch 4764/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.9091\n",
      "Epoch 4765/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.9091\n",
      "Epoch 4766/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4728 - accuracy: 0.9091\n",
      "Epoch 4767/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.9091\n",
      "Epoch 4768/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.9091\n",
      "Epoch 4769/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.9091\n",
      "Epoch 4770/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.9091\n",
      "Epoch 4771/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.9091\n",
      "Epoch 4772/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4726 - accuracy: 0.9091\n",
      "Epoch 4773/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.9091\n",
      "Epoch 4774/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.9091\n",
      "Epoch 4775/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4726 - accuracy: 0.9091\n",
      "Epoch 4776/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4726 - accuracy: 0.9091\n",
      "Epoch 4777/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.9091\n",
      "Epoch 4778/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4725 - accuracy: 0.9091\n",
      "Epoch 4779/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.9091\n",
      "Epoch 4780/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.9091\n",
      "Epoch 4781/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.9091\n",
      "Epoch 4782/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.9091\n",
      "Epoch 4783/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4724 - accuracy: 0.9091\n",
      "Epoch 4784/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.9091\n",
      "Epoch 4785/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.9091\n",
      "Epoch 4786/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4724 - accuracy: 0.9091\n",
      "Epoch 4787/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.9091\n",
      "Epoch 4788/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.9091\n",
      "Epoch 4789/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.9091\n",
      "Epoch 4790/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.9091\n",
      "Epoch 4791/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.9091\n",
      "Epoch 4792/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.9091\n",
      "Epoch 4793/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.9091\n",
      "Epoch 4794/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.9091\n",
      "Epoch 4795/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.9091\n",
      "Epoch 4796/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.9091\n",
      "Epoch 4797/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.9091\n",
      "Epoch 4798/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4721 - accuracy: 0.9091\n",
      "Epoch 4799/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.9091\n",
      "Epoch 4800/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.9091\n",
      "Epoch 4801/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.9091\n",
      "Epoch 4802/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.9091\n",
      "Epoch 4803/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.9091\n",
      "Epoch 4804/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.9091\n",
      "Epoch 4805/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.9091\n",
      "Epoch 4806/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.9091\n",
      "Epoch 4807/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.9091\n",
      "Epoch 4808/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.9091\n",
      "Epoch 4809/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.9091\n",
      "Epoch 4810/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.9091\n",
      "Epoch 4811/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.9091\n",
      "Epoch 4812/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.9091\n",
      "Epoch 4813/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.9091\n",
      "Epoch 4814/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.9091\n",
      "Epoch 4815/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.9091\n",
      "Epoch 4816/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.9091\n",
      "Epoch 4817/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.9091\n",
      "Epoch 4818/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.9091\n",
      "Epoch 4819/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.9091\n",
      "Epoch 4820/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.9091\n",
      "Epoch 4821/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.9091\n",
      "Epoch 4822/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.9091\n",
      "Epoch 4823/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4716 - accuracy: 0.9091\n",
      "Epoch 4824/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.9091\n",
      "Epoch 4825/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.9091\n",
      "Epoch 4826/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.9091\n",
      "Epoch 4827/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.9091\n",
      "Epoch 4828/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4715 - accuracy: 0.9091\n",
      "Epoch 4829/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.9091\n",
      "Epoch 4830/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.9091\n",
      "Epoch 4831/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.9091\n",
      "Epoch 4832/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.9091\n",
      "Epoch 4833/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4714 - accuracy: 0.9091\n",
      "Epoch 4834/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.9091\n",
      "Epoch 4835/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.9091\n",
      "Epoch 4836/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4713 - accuracy: 0.9091\n",
      "Epoch 4837/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.9091\n",
      "Epoch 4838/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.9091\n",
      "Epoch 4839/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4712 - accuracy: 0.9091\n",
      "Epoch 4840/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.9091\n",
      "Epoch 4841/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.9091\n",
      "Epoch 4842/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.9091\n",
      "Epoch 4843/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.9091\n",
      "Epoch 4844/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.9091\n",
      "Epoch 4845/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.9091\n",
      "Epoch 4846/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.9091\n",
      "Epoch 4847/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.9091\n",
      "Epoch 4848/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.9091\n",
      "Epoch 4849/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.9091\n",
      "Epoch 4850/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.9091\n",
      "Epoch 4851/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.9091\n",
      "Epoch 4852/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4710 - accuracy: 0.9091\n",
      "Epoch 4853/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.9091\n",
      "Epoch 4854/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.9091\n",
      "Epoch 4855/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.9091\n",
      "Epoch 4856/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.9091\n",
      "Epoch 4857/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.9091\n",
      "Epoch 4858/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.9091\n",
      "Epoch 4859/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.9091\n",
      "Epoch 4860/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.9091\n",
      "Epoch 4861/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.9091\n",
      "Epoch 4862/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4708 - accuracy: 0.9091\n",
      "Epoch 4863/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.9091\n",
      "Epoch 4864/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4707 - accuracy: 0.9091\n",
      "Epoch 4865/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.9091\n",
      "Epoch 4866/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.9091\n",
      "Epoch 4867/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.9091\n",
      "Epoch 4868/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4706 - accuracy: 0.9091\n",
      "Epoch 4869/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4706 - accuracy: 0.9091\n",
      "Epoch 4870/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4706 - accuracy: 0.9091\n",
      "Epoch 4871/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.9091\n",
      "Epoch 4872/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.9091\n",
      "Epoch 4873/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.9091\n",
      "Epoch 4874/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.9091\n",
      "Epoch 4875/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.9091\n",
      "Epoch 4876/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4705 - accuracy: 0.9091\n",
      "Epoch 4877/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.9091\n",
      "Epoch 4878/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.9091\n",
      "Epoch 4879/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.9091\n",
      "Epoch 4880/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.9091\n",
      "Epoch 4881/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.9091\n",
      "Epoch 4882/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.9091\n",
      "Epoch 4883/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.9091\n",
      "Epoch 4884/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.9091\n",
      "Epoch 4885/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4703 - accuracy: 0.9091\n",
      "Epoch 4886/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4703 - accuracy: 0.9091\n",
      "Epoch 4887/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.9091\n",
      "Epoch 4888/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4702 - accuracy: 0.9091\n",
      "Epoch 4889/5000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4702 - accuracy: 0.9091\n",
      "Epoch 4890/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.9091\n",
      "Epoch 4891/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4702 - accuracy: 0.9091\n",
      "Epoch 4892/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4701 - accuracy: 0.9091\n",
      "Epoch 4893/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.9091\n",
      "Epoch 4894/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.9091\n",
      "Epoch 4895/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.9091\n",
      "Epoch 4896/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4701 - accuracy: 0.9091\n",
      "Epoch 4897/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.9091\n",
      "Epoch 4898/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.9091\n",
      "Epoch 4899/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.9091\n",
      "Epoch 4900/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.9091\n",
      "Epoch 4901/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4700 - accuracy: 0.9091\n",
      "Epoch 4902/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.9091\n",
      "Epoch 4903/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.9091\n",
      "Epoch 4904/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.9091\n",
      "Epoch 4905/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4699 - accuracy: 0.9091\n",
      "Epoch 4906/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.9091\n",
      "Epoch 4907/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.9091\n",
      "Epoch 4908/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.9091\n",
      "Epoch 4909/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.9091\n",
      "Epoch 4910/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4698 - accuracy: 0.9091\n",
      "Epoch 4911/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.9091\n",
      "Epoch 4912/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.9091\n",
      "Epoch 4913/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.9091\n",
      "Epoch 4914/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4697 - accuracy: 0.9091\n",
      "Epoch 4915/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.9091\n",
      "Epoch 4916/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4697 - accuracy: 0.9091\n",
      "Epoch 4917/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.9091\n",
      "Epoch 4918/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.9091\n",
      "Epoch 4919/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.9091\n",
      "Epoch 4920/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4696 - accuracy: 0.9091\n",
      "Epoch 4921/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.9091\n",
      "Epoch 4922/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.9091\n",
      "Epoch 4923/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.9091\n",
      "Epoch 4924/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.9091\n",
      "Epoch 4925/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.9091\n",
      "Epoch 4926/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4694 - accuracy: 0.9091\n",
      "Epoch 4927/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.9091\n",
      "Epoch 4928/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.9091\n",
      "Epoch 4929/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.9091\n",
      "Epoch 4930/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4694 - accuracy: 0.9091\n",
      "Epoch 4931/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4693 - accuracy: 0.9091\n",
      "Epoch 4932/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.9091\n",
      "Epoch 4933/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4693 - accuracy: 0.9091\n",
      "Epoch 4934/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.9091\n",
      "Epoch 4935/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.9091\n",
      "Epoch 4936/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.9091\n",
      "Epoch 4937/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.9091\n",
      "Epoch 4938/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.9091\n",
      "Epoch 4939/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.9091\n",
      "Epoch 4940/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.9091\n",
      "Epoch 4941/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4691 - accuracy: 0.9091\n",
      "Epoch 4942/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.9091\n",
      "Epoch 4943/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.9091\n",
      "Epoch 4944/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.9091\n",
      "Epoch 4945/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4691 - accuracy: 0.9091\n",
      "Epoch 4946/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.9091\n",
      "Epoch 4947/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.9091\n",
      "Epoch 4948/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.9091\n",
      "Epoch 4949/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.9091\n",
      "Epoch 4950/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4690 - accuracy: 0.9091\n",
      "Epoch 4951/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.9091\n",
      "Epoch 4952/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.9091\n",
      "Epoch 4953/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4689 - accuracy: 0.9091\n",
      "Epoch 4954/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.9091\n",
      "Epoch 4955/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4689 - accuracy: 0.9091\n",
      "Epoch 4956/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.9091\n",
      "Epoch 4957/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.9091\n",
      "Epoch 4958/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.9091\n",
      "Epoch 4959/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.9091\n",
      "Epoch 4960/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.9091\n",
      "Epoch 4961/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.9091\n",
      "Epoch 4962/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.9091\n",
      "Epoch 4963/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.9091\n",
      "Epoch 4964/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.9091\n",
      "Epoch 4965/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4687 - accuracy: 0.9091\n",
      "Epoch 4966/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.9091\n",
      "Epoch 4967/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.9091\n",
      "Epoch 4968/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.9091\n",
      "Epoch 4969/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4686 - accuracy: 0.9091\n",
      "Epoch 4970/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.9091\n",
      "Epoch 4971/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.9091\n",
      "Epoch 4972/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.9091\n",
      "Epoch 4973/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4685 - accuracy: 0.9091\n",
      "Epoch 4974/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.9091\n",
      "Epoch 4975/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.9091\n",
      "Epoch 4976/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4684 - accuracy: 0.9091\n",
      "Epoch 4977/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.9091\n",
      "Epoch 4978/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.9091\n",
      "Epoch 4979/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.9091\n",
      "Epoch 4980/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.9091\n",
      "Epoch 4981/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4683 - accuracy: 0.9091\n",
      "Epoch 4982/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.9091\n",
      "Epoch 4983/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.9091\n",
      "Epoch 4984/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.9091\n",
      "Epoch 4985/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.9091\n",
      "Epoch 4986/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.9091\n",
      "Epoch 4987/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4682 - accuracy: 0.9091\n",
      "Epoch 4988/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.9091\n",
      "Epoch 4989/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.9091\n",
      "Epoch 4990/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4682 - accuracy: 0.9091\n",
      "Epoch 4991/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.9091\n",
      "Epoch 4992/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.9091\n",
      "Epoch 4993/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4681 - accuracy: 0.9091\n",
      "Epoch 4994/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.9091\n",
      "Epoch 4995/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.9091\n",
      "Epoch 4996/5000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4680 - accuracy: 0.9091\n",
      "Epoch 4997/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.9091\n",
      "Epoch 4998/5000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4680 - accuracy: 0.9091\n",
      "Epoch 4999/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.9091\n",
      "Epoch 5000/5000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209caa857f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(1,input_shape=(2,),activation='sigmoid',kernel_initializer='ones',\n",
    "                      bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(X_train,y_train,epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a91ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 467ms/step - loss: 0.3649 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3648953139781952, 0.8333333134651184]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29edb54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.745832 ],\n",
       "        [1.5486312]], dtype=float32),\n",
       " array([-3.0031297], dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef,intercept=model.get_weights()\n",
    "coef,intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b07b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(age,affrodability):\n",
    "    weighted_sum=age*coef[0]+ affrodability*coef[1] + intercept\n",
    "    return sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8f70650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39881251757179914"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba(0.22,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ffe40d",
   "metadata": {},
   "source": [
    "### GREDIENT DESENT BY SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d91d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_numpy(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29987dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(true,predicted):\n",
    "    true=true.astype(np.float64,copy=False)\n",
    "    predicted=predicted.astype(np.float64,copy=False)\n",
    "    epsilon=1e-15\n",
    "    predicted[predicted==0]=epsilon\n",
    "    predicted[predicted==1]=1-epsilon\n",
    "    return -np.mean(true*np.log(predicted)+(1-true)*np.log(1-predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d2eb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=0\n",
    "def gredient_desent(age,affordibility,y_true,epochs,loss_threshold=0):\n",
    "    w1=w2=1\n",
    "    bias=0\n",
    "    rate=.5\n",
    "    n=len(age)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        y_predicted=sigmoid_numpy(w1*age + w2*affordibility + bias)\n",
    "    \n",
    "        loss=log_loss(y_true,y_predicted)\n",
    "        \n",
    "        print(f\"epoch= {i} {w1 = } {w2 = } { bias = } { loss = }\")\n",
    "        \n",
    "        if loss<loss_threshold:\n",
    "            break\n",
    "        \n",
    "        diff=y_predicted-y_true\n",
    "        w1=w1-rate*np.mean(age*diff)\n",
    "        w2=w2-rate*np.mean(affordibility*diff)\n",
    "        bias=bias - rate*np.mean(diff)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0466847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 w1 = 1 w2 = 1  bias = 0  loss = 0.71595572538616\n",
      "epoch= 1 w1 = 0.9762849575718682 w2 = 0.9413816587881323  bias = -0.11723219144694776  loss = 0.6829875086265863\n",
      "epoch= 2 w1 = 0.9585899606042918 w2 = 0.8931885694836231  bias = -0.2191259515368365  loss = 0.6589217086986395\n",
      "epoch= 3 w1 = 0.9464149777228181 w2 = 0.8547036125789471  bias = -0.30702265178471283  loss = 0.6416822511323294\n",
      "epoch= 4 w1 = 0.9391383692699615 w2 = 0.8249187940412019  bias = -0.38253896783203234  loss = 0.6294529652627155\n",
      "epoch= 5 w1 = 0.9360948301666506 w2 = 0.8026921496785079  bias = -0.4473753028623717  loss = 0.6207751606893134\n",
      "epoch= 6 w1 = 0.9366346644985458 w2 = 0.7868725699850446  bias = -0.5031736709956828  loss = 0.6145491275476828\n",
      "epoch= 7 w1 = 0.9401607708239514 w2 = 0.7763814668731136  bias = -0.5514315265930735  loss = 0.6099834810303708\n",
      "epoch= 8 w1 = 0.9461466946820075 w2 = 0.7702560384753816  bias = -0.5934618343566833  loss = 0.6065276757013168\n",
      "epoch= 9 w1 = 0.954141456340729 w2 = 0.7676648564070271  bias = -0.6303847592529248  loss = 0.6038079530817342\n",
      "epoch= 10 w1 = 0.9637664517522821 w2 = 0.7679063148049593  bias = -0.6631378798968053  loss = 0.6015749693364817\n",
      "epoch= 11 w1 = 0.9747083310088303 w2 = 0.7703979331115388  bias = -0.6924954774838189  loss = 0.5996644256615059\n",
      "epoch= 12 w1 = 0.9867103584261395 w2 = 0.7746617534011894  bias = -0.7190909476098314  loss = 0.5979689848393459\n",
      "epoch= 13 w1 = 0.9995636937987874 w2 = 0.7803089200364081  bias = -0.7434389789778153  loss = 0.5964189169716717\n",
      "epoch= 14 w1 = 1.013099330277909 w2 = 0.7870250787974431  bias = -0.7659558320778166  loss = 0.5949690691974582\n",
      "epoch= 15 w1 = 1.0271809992881886 w2 = 0.7945573421598613  bias = -0.7869770551959033  loss = 0.5935902340209912\n",
      "epoch= 16 w1 = 1.041699115120877 w2 = 0.8027030592497458  bias = -0.8067725273857667  loss = 0.5922634963089803\n",
      "epoch= 17 w1 = 1.056565709679365 w2 = 0.811300360093811  bias = -0.8255589949994384  loss = 0.5909765610643756\n",
      "epoch= 18 w1 = 1.0717102529851525 w2 = 0.8202203159938759  bias = -0.8435103872263123  loss = 0.5897213818339175\n",
      "epoch= 19 w1 = 1.0870762373292722 w2 = 0.829360509285329  bias = -0.8607662290025561  loss = 0.5884926355293281\n",
      "epoch= 20 w1 = 1.1026184044934702 w2 = 0.8386397992758672  bias = -0.8774384589438693  loss = 0.5872867445382833\n",
      "epoch= 21 w1 = 1.118300506056648 w2 = 0.8479940853731877  bias = -0.8936169294930595  loss = 0.5861012510685376\n",
      "epoch= 22 w1 = 1.1340935008285877 w2 = 0.8573728913365835  bias = -0.9093738292060501  loss = 0.5849344174217753\n",
      "epoch= 23 w1 = 1.149974107965514 w2 = 0.8667366198121977  bias = -0.9247672296944903  loss = 0.5837849708279206\n",
      "epoch= 24 w1 = 1.1659236478819142 w2 = 0.8760543505926366  bias = -0.9398439253530086  loss = 0.5826519406126269\n",
      "epoch= 25 w1 = 1.181927115075068 w2 = 0.8853020779095937  bias = -0.9546417038628  loss = 0.5815345542661167\n",
      "epoch= 26 w1 = 1.1979724372618215 w2 = 0.8944613010162256  bias = -0.9691911598165756  loss = 0.5804321710549764\n",
      "epoch= 27 w1 = 1.2140498838539258 w2 = 0.9035178983365906  bias = -0.9835171423971466  loss = 0.5793442395511553\n",
      "epoch= 28 w1 = 1.230151593932721 w2 = 0.9124612287839201  bias = -0.9976399103957357  loss = 0.5782702703942325\n",
      "epoch= 29 w1 = 1.2462711997251532 w2 = 0.9212834148051872  bias = -1.0115760534470377  loss = 0.5772098187563245\n",
      "epoch= 30 w1 = 1.2624035263309465 w2 = 0.9299787706437078  bias = -1.0253392266700307  loss = 0.5761624729888272\n",
      "epoch= 31 w1 = 1.2785443522893492 w2 = 0.9385433465536164  bias = -1.038940736468746  loss = 0.575127847210206\n",
      "epoch= 32 w1 = 1.294690218665101 w2 = 0.9469745655443319  bias = -1.0523900076587498  loss = 0.5741055764087999\n",
      "epoch= 33 w1 = 1.3108382768152496 w2 = 0.955270933933614  bias = -1.0656949559981581  loss = 0.573095313153089\n",
      "epoch= 34 w1 = 1.3269861669867828 w2 = 0.9634318107588047  bias = -1.0788622853294034  loss = 0.572096725331731\n",
      "epoch= 35 w1 = 1.3431319214852515 w2 = 0.9714572241154046  bias = -1.091897724643425  loss = 0.5711094945555183\n",
      "epoch= 36 w1 = 1.3592738874247023 w2 = 0.979347724906476  bias = -1.1048062172686965  loss = 0.5701333149869384\n",
      "epoch= 37 w1 = 1.3754106650828122 w2 = 0.9871042704147334  bias = -1.1175920719073082  loss = 0.5691678924479512\n",
      "epoch= 38 w1 = 1.391541058693342 w2 = 0.9947281316481378  bias = -1.1302590832631496  loss = 0.5682129437106813\n",
      "epoch= 39 w1 = 1.4076640371522062 w2 = 1.002220819637284  bias = -1.1428106284317694  loss = 0.567268195910123\n",
      "epoch= 40 w1 = 1.4237787026266866 w2 = 1.0095840268414777  bias = -1.1552497439664873  loss = 0.5663333860398768\n",
      "epoch= 41 w1 = 1.4398842654661337 w2 = 1.016819580600401  bias = -1.1675791875358126  loss = 0.5654082605058878\n",
      "epoch= 42 w1 = 1.45598002413809 w2 = 1.0239294061898248  bias = -1.1798014872912554  loss = 0.5644925747220518\n",
      "epoch= 43 w1 = 1.4720653491730682 w2 = 1.0309154975351178  bias = -1.1919189814307745  loss = 0.5635860927372274\n",
      "epoch= 44 w1 = 1.4881396703077112 w2 = 1.0377798940309326  bias = -1.2039338499383556  loss = 0.5626885868868012\n",
      "epoch= 45 w1 = 1.504202466180524 w2 = 1.0445246622299096  bias = -1.2158481400782477  loss = 0.5617998374642752\n",
      "epoch= 46 w1 = 1.5202532560653506 w2 = 1.051151881413821  bias = -1.2276637869022196  loss = 0.5609196324098137\n",
      "epoch= 47 w1 = 1.5362915932321137 w2 = 1.0576636322602815  bias = -1.2393826297731931  loss = 0.5600477670136363\n",
      "epoch= 48 w1 = 1.552317059607461 w2 = 1.0640619879773263  bias = -1.2510064257054307  loss = 0.5591840436327559\n",
      "epoch= 49 w1 = 1.568329261474194 w2 = 1.0703490074050517  bias = -1.262536860159576  loss = 0.5583282714199483\n",
      "epoch= 50 w1 = 1.5843278260011513 w2 = 1.0765267296846839  bias = -1.2739755558018289  loss = 0.5574802660641018\n",
      "epoch= 51 w1 = 1.600312398437282 w2 = 1.0825971701761263  bias = -1.2853240796337064  loss = 0.5566398495412577\n",
      "epoch= 52 w1 = 1.6162826398372019 w2 = 1.0885623173693868  bias = -1.2965839488168436  loss = 0.5558068498757676\n",
      "epoch= 53 w1 = 1.6322382252122667 w2 = 1.0944241305866267  bias = -1.3077566354519186  loss = 0.5549811009110736\n",
      "epoch= 54 w1 = 1.648178842022536 w2 = 1.1001845383125366  bias = -1.3188435705186372  loss = 0.5541624420896621\n",
      "epoch= 55 w1 = 1.66410418894202 w2 = 1.1058454370234425  bias = -1.3298461471421121  loss = 0.5533507182417893\n",
      "epoch= 56 w1 = 1.6800139748431828 w2 = 1.1114086904116431  bias = -1.340765723317776  loss = 0.5525457793826016\n",
      "epoch= 57 w1 = 1.6959079179575176 w2 = 1.1168761289223184  bias = -1.3516036242004785  loss = 0.5517474805172988\n",
      "epoch= 58 w1 = 1.71178574517766 w2 = 1.1222495495369946  bias = -1.3623611440422583  loss = 0.5509556814540068\n",
      "epoch= 59 w1 = 1.727647191473415 w2 = 1.127530715750842  bias = -1.373039547846403  loss = 0.5501702466240413\n",
      "epoch= 60 w1 = 1.743491999399596 w2 = 1.1327213577017066  bias = -1.3836400727919107  loss = 0.5493910449092638\n",
      "epoch= 61 w1 = 1.7593199186779787 w2 = 1.137823172417261  bias = -1.3941639294716976  loss = 0.5486179494762363\n",
      "epoch= 62 w1 = 1.7751307058391972 w2 = 1.1428378241534503  bias = -1.4046123029792807  loss = 0.5478508376169026\n",
      "epoch= 63 w1 = 1.7909241239132292 w2 = 1.1477669448028254  bias = -1.414986353871782  loss = 0.5470895905955274\n",
      "epoch= 64 w1 = 1.806699942159362 w2 = 1.1526121343556983  bias = -1.4252872190315977  loss = 0.5463340935016423\n",
      "epoch= 65 w1 = 1.8224579358283375 w2 = 1.157374961400522  bias = -1.4355160124446757  loss = 0.545584235108752\n",
      "epoch= 66 w1 = 1.8381978859508141 w2 = 1.1620569636526688  bias = -1.4456738259098199  loss = 0.5448399077385693\n",
      "epoch= 67 w1 = 1.8539195791474312 w2 = 1.1666596485030025  bias = -1.455761729690625  loss = 0.5441010071305533\n",
      "epoch= 68 w1 = 1.8696228074566916 w2 = 1.171184493579418  bias = -1.4657807731193904  loss = 0.5433674323165382\n",
      "epoch= 69 w1 = 1.8853073681776114 w2 = 1.1756329473159355  bias = -1.4757319851605522  loss = 0.5426390855002413\n",
      "epoch= 70 w1 = 1.9009730637246798 w2 = 1.1800064295250816  bias = -1.485616374939728  loss = 0.5419158719414601\n",
      "epoch= 71 w1 = 1.9166197014931468 w2 = 1.1843063319701936  bias = -1.4954349322433091  loss = 0.5411976998447616\n",
      "epoch= 72 w1 = 1.9322470937330352 w2 = 1.188534018935014  bias = -1.5051886279926034  loss = 0.5404844802524873\n",
      "epoch= 73 w1 = 1.9478550574305793 w2 = 1.1926908277885213  bias = -1.5148784146957868  loss = 0.5397761269418961\n",
      "epoch= 74 w1 = 1.9634434141960369 w2 = 1.1967780695434145  bias = -1.5245052268803239  loss = 0.5390725563262807\n",
      "epoch= 75 w1 = 1.9790119901570187 w2 = 1.2007970294070347  bias = -1.5340699815080343  loss = 0.5383736873598947\n",
      "epoch= 76 w1 = 1.9945606158566362 w2 = 1.204748967323808  bias = -1.5435735783745976  loss = 0.5376794414465402\n",
      "epoch= 77 w1 = 2.0100891261558953 w2 = 1.2086351185085324  bias = -1.5530169004949752  loss = 0.5369897423516635\n",
      "epoch= 78 w1 = 2.0255973601398667 w2 = 1.2124566939700172  bias = -1.5624008144759807  loss = 0.5363045161178243\n",
      "epoch= 79 w1 = 2.0410851610272465 w2 = 1.2162148810247393  bias = -1.571726170877026  loss = 0.5356236909833978\n",
      "epoch= 80 w1 = 2.0565523760829834 w2 = 1.2199108438002961  bias = -1.580993804559907  loss = 0.5349471973043814\n",
      "epoch= 81 w1 = 2.0719988565337077 w2 = 1.223545723728533  bias = -1.590204535028361  loss = 0.5342749674791848\n",
      "epoch= 82 w1 = 2.087424457485736 w2 = 1.2271206400282986  bias = -1.5993591667580227  loss = 0.5336069358762775\n",
      "epoch= 83 w1 = 2.102829037845463 w2 = 1.2306366901778387  bias = -1.6084584895173175  loss = 0.5329430387645885\n",
      "epoch= 84 w1 = 2.11821246024198 w2 = 1.2340949503768905  bias = -1.6175032786797578  loss = 0.5322832142465398\n",
      "epoch= 85 w1 = 2.13357459095178 w2 = 1.2374964759985694  bias = -1.6264942955280564  loss = 0.5316274021936149\n",
      "epoch= 86 w1 = 2.148915299825435 w2 = 1.240842302031174  bias = -1.6354322875504157  loss = 0.5309755441843597\n",
      "epoch= 87 w1 = 2.1642344602161376 w2 = 1.244133443510056  bias = -1.6443179887293216  loss = 0.5303275834447163\n",
      "epoch= 88 w1 = 2.1795319489100193 w2 = 1.247370895939713  bias = -1.6531521198231298  loss = 0.5296834647906044\n",
      "epoch= 89 w1 = 2.1948076460581616 w2 = 1.2505556357062833  bias = -1.661935388640714  loss = 0.5290431345726528\n",
      "epoch= 90 w1 = 2.210061435110231 w2 = 1.2536886204806224  bias = -1.6706684903094138  loss = 0.528406540623004\n",
      "epoch= 91 w1 = 2.225293202749673 w2 = 1.25677078961215  bias = -1.6793521075365123  loss = 0.5277736322041034\n",
      "epoch= 92 w1 = 2.240502838830404 w2 = 1.2598030645136626  bias = -1.687986910864449  loss = 0.5271443599594009\n",
      "epoch= 93 w1 = 2.255690236314951 w2 = 1.2627863490373048  bias = -1.6965735589199615  loss = 0.5265186758658851\n",
      "epoch= 94 w1 = 2.270855291213984 w2 = 1.2657215298418962  bias = -1.7051126986573433  loss = 0.5258965331883829\n",
      "epoch= 95 w1 = 2.2859979025272015 w2 = 1.2686094767518092  bias = -1.713604965595987  loss = 0.5252778864355495\n",
      "epoch= 96 w1 = 2.3011179721855206 w2 = 1.2714510431075914  bias = -1.72205098405238  loss = 0.5246626913174889\n",
      "epoch= 97 w1 = 2.3162154049945376 w2 = 1.2742470661085266  bias = -1.7304513673667086  loss = 0.5240509047049378\n",
      "epoch= 98 w1 = 2.331290108579214 w2 = 1.2769983671473242  bias = -1.7388067181242182  loss = 0.5234424845899525\n",
      "epoch= 99 w1 = 2.3463419933297582 w2 = 1.2797057521371238  bias = -1.7471176283714775  loss = 0.5228373900480412\n",
      "epoch= 100 w1 = 2.361370972348664 w2 = 1.2823700118309995  bias = -1.75538467982768  loss = 0.5222355812016856\n",
      "epoch= 101 w1 = 2.37637696139888 w2 = 1.2849919221341461  bias = -1.7636084440911166  loss = 0.521637019185197\n",
      "epoch= 102 w1 = 2.3913598788530694 w2 = 1.287572244408924  bias = -1.7717894828409502  loss = 0.5210416661108578\n",
      "epoch= 103 w1 = 2.4063196456439404 w2 = 1.2901117257729364  bias = -1.7799283480344106  loss = 0.520449485036295\n",
      "epoch= 104 w1 = 2.421256185215612 w2 = 1.292611099390311  bias = -1.7880255820995339  loss = 0.5198604399330428\n",
      "epoch= 105 w1 = 2.4361694234759907 w2 = 1.2950710847563498  bias = -1.7960817181235582  loss = 0.5192744956562453\n",
      "epoch= 106 w1 = 2.451059288750132 w2 = 1.2974923879757123  bias = -1.80409728003709  loss = 0.5186916179154573\n",
      "epoch= 107 w1 = 2.465925711734559 w2 = 1.299875702034291  bias = -1.8120727827941474  loss = 0.5181117732465002\n",
      "epoch= 108 w1 = 2.4807686254525154 w2 = 1.3022217070649336  bias = -1.8200087325481875  loss = 0.517534928984334\n",
      "epoch= 109 w1 = 2.4955879652101305 w2 = 1.304531070607163  bias = -1.8279056268242182  loss = 0.5169610532369054\n",
      "epoch= 110 w1 = 2.5103836685534704 w2 = 1.3068044478610452  bias = -1.8357639546870945  loss = 0.5163901148599375\n",
      "epoch= 111 w1 = 2.525155675226455 w2 = 1.3090424819353483  bias = -1.8435841969060938  loss = 0.5158220834326188\n",
      "epoch= 112 w1 = 2.5399039271296195 w2 = 1.3112458040901318  bias = -1.8513668261158651  loss = 0.5152569292341681\n",
      "epoch= 113 w1 = 2.554628368279699 w2 = 1.3134150339739064  bias = -1.8591123069738433  loss = 0.5146946232212323\n",
      "epoch= 114 w1 = 2.5693289447700156 w2 = 1.315550779855496  bias = -1.8668210963142136  loss = 0.5141351370060901\n",
      "epoch= 115 w1 = 2.5840056047316526 w2 = 1.3176536388507332  bias = -1.8744936432985144  loss = 0.5135784428356321\n",
      "epoch= 116 w1 = 2.598658298295389 w2 = 1.3197241971441147  bias = -1.8821303895629624  loss = 0.5130245135710865\n",
      "epoch= 117 w1 = 2.613286977554385 w2 = 1.3217630302055414  bias = -1.8897317693625777  loss = 0.5124733226684618\n",
      "epoch= 118 w1 = 2.627891596527592 w2 = 1.3237707030022634  bias = -1.8972982097121907  loss = 0.5119248441596823\n",
      "epoch= 119 w1 = 2.64247211112388 w2 = 1.3257477702061469  bias = -1.9048301305244053  loss = 0.5113790526343877\n",
      "epoch= 120 w1 = 2.6570284791068546 w2 = 1.3276947763963787  bias = -1.9123279447445942  loss = 0.5108359232223747\n",
      "epoch= 121 w1 = 2.671560660060356 w2 = 1.3296122562577195  bias = -1.9197920584829977  loss = 0.5102954315766538\n",
      "epoch= 122 w1 = 2.68606861535462 w2 = 1.3315007347744134  bias = -1.9272228711439967  loss = 0.5097575538571013\n",
      "epoch= 123 w1 = 2.7005523081130853 w2 = 1.3333607274198624  bias = -1.9346207755526292  loss = 0.5092222667146837\n",
      "epoch= 124 w1 = 2.7150117031798375 w2 = 1.3351927403421657  bias = -1.9419861580784152  loss = 0.5086895472762307\n",
      "epoch= 125 w1 = 2.7294467670876665 w2 = 1.3369972705456263  bias = -1.9493193987565562  loss = 0.5081593731297416\n",
      "epoch= 126 w1 = 2.7438574680267314 w2 = 1.3387748060683229  bias = -1.9566208714065731  loss = 0.5076317223102\n",
      "epoch= 127 w1 = 2.758243775813815 w2 = 1.3405258261558408  bias = -1.963890943748441  loss = 0.5071065732858836\n",
      "epoch= 128 w1 = 2.772605661862156 w2 = 1.3422508014312557  bias = -1.9711299775162847  loss = 0.5065839049451449\n",
      "epoch= 129 w1 = 2.7869430991518445 w2 = 1.343950194061462  bias = -1.9783383285696883  loss = 0.5060636965836518\n",
      "epoch= 130 w1 = 2.8012560622007703 w2 = 1.3456244579199295  bias = -1.9855163470026809  loss = 0.5055459278920663\n",
      "epoch= 131 w1 = 2.8155445270361112 w2 = 1.34727403874598  bias = -1.9926643772504484  loss = 0.5050305789441486\n",
      "epoch= 132 w1 = 2.8298084711663476 w2 = 1.3488993743006628  bias = -1.9997827581938292  loss = 0.5045176301852685\n",
      "epoch= 133 w1 = 2.844047873553795 w2 = 1.350500894519311  bias = -2.0068718232616423  loss = 0.5040070624213123\n",
      "epoch= 134 w1 = 2.8582627145876387 w2 = 1.3520790216608614  bias = -2.013931900530902  loss = 0.5034988568079679\n",
      "epoch= 135 w1 = 2.8724529760574664 w2 = 1.3536341704540096  bias = -2.0209633128249678  loss = 0.5029929948403764\n",
      "epoch= 136 w1 = 2.88661864112728 w2 = 1.3551667482402807  bias = -2.027966377809673  loss = 0.5024894583431359\n",
      "epoch= 137 w1 = 2.9007596943099845 w2 = 1.3566771551140846  bias = -2.034941408087489  loss = 0.5019882294606461\n",
      "epoch= 138 w1 = 2.9148761214423344 w2 = 1.3581657840598296  bias = -2.0418887112897606  loss = 0.5014892906477795\n",
      "epoch= 139 w1 = 2.9289679096603396 w2 = 1.359633021086164  bias = -2.0488085901670634  loss = 0.5009926246608691\n",
      "epoch= 140 w1 = 2.943035047375108 w2 = 1.3610792453574108  bias = -2.055701342677724  loss = 0.5004982145490008\n",
      "epoch= 141 w1 = 2.9570775242491276 w2 = 1.362504829322264  bias = -2.0625672620745443  loss = 0.5000060436455989\n",
      "epoch= 142 w1 = 2.971095331172971 w2 = 1.36391013883981  bias = -2.069406636989776  loss = 0.4995160955602955\n",
      "epoch= 143 w1 = 2.9850884602424155 w2 = 1.3652955333029355  bias = -2.076219751518378  loss = 0.49902835417107294\n",
      "epoch= 144 w1 = 2.999056904735973 w2 = 1.3666613657591837  bias = -2.0830068852996013  loss = 0.49854280361666853\n",
      "epoch= 145 w1 = 3.0130006590928176 w2 = 1.368007983029118  bias = -2.08976831359694  loss = 0.4980594282892355\n",
      "epoch= 146 w1 = 3.026919718891103 w2 = 1.369335725822252  bias = -2.0965043073764775  loss = 0.49757821282724635\n",
      "epoch= 147 w1 = 3.0408140808266655 w2 = 1.3706449288505995  bias = -2.1032151333836766  loss = 0.4970991421086351\n",
      "epoch= 148 w1 = 3.054683742692099 w2 = 1.3719359209399018  bias = -2.1099010542186356  loss = 0.4966222012441651\n",
      "epoch= 149 w1 = 3.0685287033562023 w2 = 1.3732090251385858  bias = -2.1165623284098563  loss = 0.4961473755710193\n",
      "epoch= 150 w1 = 3.0823489627437795 w2 = 1.374464558824502  bias = -2.123199210486547  loss = 0.4956746506466003\n",
      "epoch= 151 w1 = 3.0961445218158 w2 = 1.3757028338094974  bias = -2.1298119510495024  loss = 0.4952040122425369\n",
      "epoch= 152 w1 = 3.1099153825499024 w2 = 1.37692415644187  bias = -2.136400796840585  loss = 0.49473544633888794\n",
      "epoch= 153 w1 = 3.123661547921234 w2 = 1.378128827706753  bias = -2.142965990810843  loss = 0.4942689391185352\n",
      "epoch= 154 w1 = 3.1373830218836276 w2 = 1.379317143324477  bias = -2.1495077721872917  loss = 0.4938044769617633\n",
      "epoch= 155 w1 = 3.1510798093511023 w2 = 1.380489393846957  bias = -2.156026376538394  loss = 0.4933420464410137\n",
      "epoch= 156 w1 = 3.1647519161796813 w2 = 1.3816458647521435  bias = -2.16252203583826  loss = 0.49288163431581306\n",
      "epoch= 157 w1 = 3.178399349149527 w2 = 1.3827868365365892  bias = -2.1689949785295997  loss = 0.4924232275278645\n",
      "epoch= 158 w1 = 3.1920221159473794 w2 = 1.3839125848061669  bias = -2.1754454295854564  loss = 0.4919668131963007\n",
      "epoch= 159 w1 = 3.2056202251492993 w2 = 1.3850233803649834  bias = -2.1818736105697423  loss = 0.4915123786130894\n",
      "epoch= 160 w1 = 3.219193686203704 w2 = 1.3861194893025286  bias = -2.188279739696609  loss = 0.4910599112385888\n",
      "epoch= 161 w1 = 3.2327425094146927 w2 = 1.3872011730790998  bias = -2.1946640318886708  loss = 0.49060939869724535\n",
      "epoch= 162 w1 = 3.2462667059256605 w2 = 1.3882686886095388  bias = -2.201026698834114  loss = 0.490160828773432\n",
      "epoch= 163 w1 = 3.2597662877031848 w2 = 1.389322288345319  bias = -2.2073679490427067  loss = 0.4897141894074188\n",
      "epoch= 164 w1 = 3.2732412675211897 w2 = 1.3903622203550199  bias = -2.2136879879007427  loss = 0.489269468691473\n",
      "epoch= 165 w1 = 3.2866916589453776 w2 = 1.3913887284032243  bias = -2.2199870177249337  loss = 0.48882665486608473\n",
      "epoch= 166 w1 = 3.3001174763179235 w2 = 1.3924020520278717  bias = -2.2262652378152765  loss = 0.4883857363163126\n",
      "epoch= 167 w1 = 3.3135187347424293 w2 = 1.3934024266161031  bias = -2.2325228445069185  loss = 0.48794670156824566\n",
      "epoch= 168 w1 = 3.3268954500691295 w2 = 1.3943900834786294  bias = -2.238760031221038  loss = 0.4875095392855782\n",
      "epoch= 169 w1 = 3.3402476388803484 w2 = 1.3953652499226554  bias = -2.2449769885147637  loss = 0.487074238266293\n",
      "epoch= 170 w1 = 3.3535753184762003 w2 = 1.3963281493233926  bias = -2.2511739041301544  loss = 0.4866407874394492\n",
      "epoch= 171 w1 = 3.366878506860529 w2 = 1.397279001194187  bias = -2.257350963042255  loss = 0.4862091758620716\n",
      "epoch= 172 w1 = 3.380157222727084 w2 = 1.398218021255298  bias = -2.2635083475062507  loss = 0.4857793927161386\n",
      "epoch= 173 w1 = 3.3934114854459283 w2 = 1.3991454215013515  bias = -2.2696462371037383  loss = 0.48535142730566294\n",
      "epoch= 174 w1 = 3.406641315050071 w2 = 1.4000614102675  bias = -2.275764808788133  loss = 0.4849252690538656\n",
      "epoch= 175 w1 = 3.419846732222325 w2 = 1.4009661922943148  bias = -2.281864236929228  loss = 0.4845009075004372\n",
      "epoch= 176 w1 = 3.433027758282383 w2 = 1.4018599687914381  bias = -2.2879446933569225  loss = 0.48407833229888386\n",
      "epoch= 177 w1 = 3.4461844151741086 w2 = 1.4027429375000224  bias = -2.2940063474041423  loss = 0.4836575332139573\n",
      "epoch= 178 w1 = 3.459316725453037 w2 = 1.4036152927539818  bias = -2.3000493659489605  loss = 0.4832385001191627\n",
      "epoch= 179 w1 = 3.4724247122740857 w2 = 1.4044772255400797  bias = -2.3060739134559403  loss = 0.48282122299434443\n",
      "epoch= 180 w1 = 3.485508399379467 w2 = 1.4053289235568802  bias = -2.3120801520167173  loss = 0.4824056919233461\n",
      "epoch= 181 w1 = 3.4985678110868013 w2 = 1.4061705712725843  bias = -2.3180682413898315  loss = 0.48199189709174217\n",
      "epoch= 182 w1 = 3.511602972277427 w2 = 1.407002349981775  bias = -2.324038339039827  loss = 0.4815798287846394\n",
      "epoch= 183 w1 = 3.5246139083849033 w2 = 1.407824437861096  bias = -2.3299906001756376  loss = 0.48116947738454435\n",
      "epoch= 184 w1 = 3.537600645383703 w2 = 1.4086370100238832  bias = -2.3359251777882655  loss = 0.48076083336929765\n",
      "epoch= 185 w1 = 3.550563209778091 w2 = 1.4094402385737737  bias = -2.3418422226877755  loss = 0.48035388731006895\n",
      "epoch= 186 w1 = 3.563501628591187 w2 = 1.4102342926573115  bias = -2.3477418835396118  loss = 0.47994862986941406\n",
      "epoch= 187 w1 = 3.5764159293542095 w2 = 1.4110193385155723  bias = -2.353624306900255  loss = 0.47954505179938917\n",
      "epoch= 188 w1 = 3.589306140095892 w2 = 1.4117955395348252  bias = -2.3594896372522314  loss = 0.4791431439397235\n",
      "epoch= 189 w1 = 3.6021722893320782 w2 = 1.4125630562962552  bias = -2.365338017038488  loss = 0.478742897216045\n",
      "epoch= 190 w1 = 3.615014406055486 w2 = 1.4133220466247611  bias = -2.3711695866961437  loss = 0.47834430263816036\n",
      "epoch= 191 w1 = 3.6278325197256396 w2 = 1.4140726656368512  bias = -2.3769844846896344  loss = 0.4779473512983851\n",
      "epoch= 192 w1 = 3.6406266602589654 w2 = 1.4148150657876535  bias = -2.3827828475432558  loss = 0.4775520343699241\n",
      "epoch= 193 w1 = 3.6533968580190535 w2 = 1.41554939691706  bias = -2.3885648098731256  loss = 0.47715834310529964\n",
      "epoch= 194 w1 = 3.6661431438070755 w2 = 1.4162758062950205  bias = -2.394330504418568  loss = 0.47676626883482476\n",
      "epoch= 195 w1 = 3.6788655488523605 w2 = 1.4169944386660047  bias = -2.4000800620729366  loss = 0.4763758029651239\n",
      "epoch= 196 w1 = 3.6915641048031267 w2 = 1.41770543629265  bias = -2.4058136119138873  loss = 0.47598693697769373\n",
      "epoch= 197 w1 = 3.704238843717361 w2 = 1.4184089389986088  bias = -2.411531281233108  loss = 0.4755996624275083\n",
      "epoch= 198 w1 = 3.7168897980538524 w2 = 1.4191050842106143  bias = -2.417233195565519  loss = 0.4752139709416632\n",
      "epoch= 199 w1 = 3.7295170006633676 w2 = 1.4197940069997796  bias = -2.4229194787179535  loss = 0.47482985421805973\n",
      "epoch= 200 w1 = 3.7421204847799734 w2 = 1.420475840122144  bias = -2.4285902527973304  loss = 0.4744473040241271\n",
      "epoch= 201 w1 = 3.754700284012501 w2 = 1.4211507140584831  bias = -2.4342456382383233  loss = 0.4740663121955794\n",
      "epoch= 202 w1 = 3.767256432336149 w2 = 1.4218187570533973  bias = -2.4398857538305427  loss = 0.4736868706352115\n",
      "epoch= 203 w1 = 3.779788964084221 w2 = 1.4224800951536924  bias = -2.4455107167452375  loss = 0.47330897131172567\n",
      "epoch= 204 w1 = 3.792297913940004 w2 = 1.423134852246066  bias = -2.451120642561522  loss = 0.4729326062585938\n",
      "epoch= 205 w1 = 3.804783316928775 w2 = 1.4237831500941154  bias = -2.456715645292146  loss = 0.4725577675729503\n",
      "epoch= 206 w1 = 3.817245208409936 w2 = 1.4244251083746768  bias = -2.4622958374088055  loss = 0.47218444741451726\n",
      "epoch= 207 w1 = 3.829683624069286 w2 = 1.4250608447135138  bias = -2.467861329867015  loss = 0.4718126380045586\n",
      "epoch= 208 w1 = 3.842098599911409 w2 = 1.425690474720363  bias = -2.473412232130538  loss = 0.4714423316248643\n",
      "epoch= 209 w1 = 3.8544901722521927 w2 = 1.426314112023352  bias = -2.478948652195393  loss = 0.4710735206167618\n",
      "epoch= 210 w1 = 3.866858377711468 w2 = 1.4269318683028034  bias = -2.4844706966134407  loss = 0.47070619738015534\n",
      "epoch= 211 w1 = 3.879203253205768 w2 = 1.4275438533244325  bias = -2.4899784705155543  loss = 0.47034035437259114\n",
      "epoch= 212 w1 = 3.891524835941204 w2 = 1.428150174971954  bias = -2.4954720776343944  loss = 0.4699759841083489\n",
      "epoch= 213 w1 = 3.9038231634064613 w2 = 1.428750939279109  bias = -2.5009516203267785  loss = 0.4696130791575576\n",
      "epoch= 214 w1 = 3.9160982733659067 w2 = 1.4293462504611203  bias = -2.5064171995956697  loss = 0.46925163214533416\n",
      "epoch= 215 w1 = 3.9283502038528093 w2 = 1.4299362109455924  bias = -2.5118689151117777  loss = 0.46889163575094717\n",
      "epoch= 216 w1 = 3.940578993162672 w2 = 1.430520921402861  bias = -2.517306865234791  loss = 0.4685330827070017\n",
      "epoch= 217 w1 = 3.952784679846673 w2 = 1.4311004807758068  bias = -2.5227311470342366  loss = 0.468175965798646\n",
      "epoch= 218 w1 = 3.9649673027052135 w2 = 1.4316749863091427  bias = -2.5281418563099844  loss = 0.4678202778627996\n"
     ]
    }
   ],
   "source": [
    "gredient_desent(df.age.values,df.affordibility.values,df.bought_insurance.values,5000,0.468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db25b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.0031297], dtype=float32),\n",
       " array([[4.745832 ],\n",
       "        [1.5486312]], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept,coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c3da2",
   "metadata": {},
   "source": [
    "### SIMPLE NURAL NETWORK FOR CLASSIFICATION PROBLEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffae63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN:\n",
    "    def __init__(self):\n",
    "        self.coef=None\n",
    "        self.intercept=0\n",
    "        self.nfeatures=0\n",
    "        self.rate=0.5\n",
    "        \n",
    "    def fit(self,X,y,epochs=10,loss_treshold=0,init_weights=1,init_bias=0):\n",
    "        if X.ndim != 2:\n",
    "            raise \"dimension error\"\n",
    "        \n",
    "        self.nfeatures=X.shape[1]\n",
    "        self.gredient_desent(X,y,epochs,loss_treshold,init_weights,init_bias)\n",
    "  \n",
    "    def gredient_desent(self,X,y_true,epochs,loss_treshold,init_weights,init_bias):\n",
    "        self.coef=np.array([init_weights]*self.nfeatures)\n",
    "        self.intercept=init_bias\n",
    "        self.rate=.5\n",
    "        n=X.shape[0]\n",
    "\n",
    "        for i in range(epochs):\n",
    "            y_predicted=sigmoid_numpy(np.dot(X,np.transpose(self.coef)) + self.intercept)\n",
    "\n",
    "            loss=log_loss(y_true,y_predicted)\n",
    "\n",
    "            print(f\"epoch= {i} {self.coef = } { self.intercept = } { loss = }\")\n",
    "\n",
    "            if loss<loss_treshold:\n",
    "                break\n",
    "\n",
    "            diff=y_predicted-y_true\n",
    "            self.coef=self.coef - (self.rate/n)*np.dot(np.transpose(diff),X)\n",
    "            self.intercept= self.intercept - self.rate*np.mean(diff)\n",
    "            \n",
    "    def predict(self,X):\n",
    "        return sigmoid_numpy(np.dot(X,np.transpose(self.coef)) + self.intercept)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "607aa8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"age\",\"affordibility\"]].values\n",
    "y=df.bought_insurance.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d78ac9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 self.coef = array([1, 1])  self.intercept = 0  loss = 0.71595572538616\n",
      "epoch= 1 self.coef = array([0.97628496, 0.94138166])  self.intercept = -0.11723219144694776  loss = 0.6829875086265863\n",
      "epoch= 2 self.coef = array([0.95858996, 0.89318857])  self.intercept = -0.2191259515368365  loss = 0.6589217086986395\n",
      "epoch= 3 self.coef = array([0.94641498, 0.85470361])  self.intercept = -0.30702265178471283  loss = 0.6416822511323294\n",
      "epoch= 4 self.coef = array([0.93913837, 0.82491879])  self.intercept = -0.38253896783203234  loss = 0.6294529652627155\n",
      "epoch= 5 self.coef = array([0.93609483, 0.80269215])  self.intercept = -0.4473753028623717  loss = 0.6207751606893134\n",
      "epoch= 6 self.coef = array([0.93663466, 0.78687257])  self.intercept = -0.5031736709956828  loss = 0.6145491275476828\n",
      "epoch= 7 self.coef = array([0.94016077, 0.77638147])  self.intercept = -0.5514315265930735  loss = 0.6099834810303708\n",
      "epoch= 8 self.coef = array([0.94614669, 0.77025604])  self.intercept = -0.5934618343566833  loss = 0.6065276757013168\n",
      "epoch= 9 self.coef = array([0.95414146, 0.76766486])  self.intercept = -0.6303847592529248  loss = 0.6038079530817342\n",
      "epoch= 10 self.coef = array([0.96376645, 0.76790631])  self.intercept = -0.6631378798968053  loss = 0.6015749693364817\n",
      "epoch= 11 self.coef = array([0.97470833, 0.77039793])  self.intercept = -0.6924954774838189  loss = 0.5996644256615059\n",
      "epoch= 12 self.coef = array([0.98671036, 0.77466175])  self.intercept = -0.7190909476098314  loss = 0.5979689848393459\n",
      "epoch= 13 self.coef = array([0.99956369, 0.78030892])  self.intercept = -0.7434389789778153  loss = 0.5964189169716717\n",
      "epoch= 14 self.coef = array([1.01309933, 0.78702508])  self.intercept = -0.7659558320778166  loss = 0.5949690691974582\n",
      "epoch= 15 self.coef = array([1.027181  , 0.79455734])  self.intercept = -0.7869770551959033  loss = 0.5935902340209914\n",
      "epoch= 16 self.coef = array([1.04169912, 0.80270306])  self.intercept = -0.8067725273857667  loss = 0.5922634963089803\n",
      "epoch= 17 self.coef = array([1.05656571, 0.81130036])  self.intercept = -0.8255589949994384  loss = 0.5909765610643756\n",
      "epoch= 18 self.coef = array([1.07171025, 0.82022032])  self.intercept = -0.8435103872263123  loss = 0.5897213818339175\n",
      "epoch= 19 self.coef = array([1.08707624, 0.82936051])  self.intercept = -0.8607662290025561  loss = 0.5884926355293281\n",
      "epoch= 20 self.coef = array([1.1026184, 0.8386398])  self.intercept = -0.8774384589438693  loss = 0.5872867445382833\n",
      "epoch= 21 self.coef = array([1.11830051, 0.84799409])  self.intercept = -0.8936169294930595  loss = 0.5861012510685376\n",
      "epoch= 22 self.coef = array([1.1340935 , 0.85737289])  self.intercept = -0.9093738292060501  loss = 0.5849344174217753\n",
      "epoch= 23 self.coef = array([1.14997411, 0.86673662])  self.intercept = -0.9247672296944903  loss = 0.5837849708279206\n",
      "epoch= 24 self.coef = array([1.16592365, 0.87605435])  self.intercept = -0.9398439253530086  loss = 0.5826519406126269\n",
      "epoch= 25 self.coef = array([1.18192712, 0.88530208])  self.intercept = -0.9546417038628  loss = 0.5815345542661167\n",
      "epoch= 26 self.coef = array([1.19797244, 0.8944613 ])  self.intercept = -0.9691911598165756  loss = 0.5804321710549764\n",
      "epoch= 27 self.coef = array([1.21404988, 0.9035179 ])  self.intercept = -0.9835171423971466  loss = 0.5793442395511553\n",
      "epoch= 28 self.coef = array([1.23015159, 0.91246123])  self.intercept = -0.9976399103957357  loss = 0.5782702703942325\n",
      "epoch= 29 self.coef = array([1.2462712 , 0.92128341])  self.intercept = -1.0115760534470377  loss = 0.5772098187563245\n",
      "epoch= 30 self.coef = array([1.26240353, 0.92997877])  self.intercept = -1.0253392266700307  loss = 0.5761624729888272\n",
      "epoch= 31 self.coef = array([1.27854435, 0.93854335])  self.intercept = -1.038940736468746  loss = 0.575127847210206\n",
      "epoch= 32 self.coef = array([1.29469022, 0.94697457])  self.intercept = -1.0523900076587498  loss = 0.5741055764087999\n",
      "epoch= 33 self.coef = array([1.31083828, 0.95527093])  self.intercept = -1.0656949559981581  loss = 0.573095313153089\n",
      "epoch= 34 self.coef = array([1.32698617, 0.96343181])  self.intercept = -1.0788622853294034  loss = 0.572096725331731\n",
      "epoch= 35 self.coef = array([1.34313192, 0.97145722])  self.intercept = -1.091897724643425  loss = 0.5711094945555183\n",
      "epoch= 36 self.coef = array([1.35927389, 0.97934772])  self.intercept = -1.1048062172686965  loss = 0.5701333149869384\n",
      "epoch= 37 self.coef = array([1.37541067, 0.98710427])  self.intercept = -1.1175920719073082  loss = 0.5691678924479512\n",
      "epoch= 38 self.coef = array([1.39154106, 0.99472813])  self.intercept = -1.1302590832631496  loss = 0.5682129437106813\n",
      "epoch= 39 self.coef = array([1.40766404, 1.00222082])  self.intercept = -1.1428106284317694  loss = 0.567268195910123\n",
      "epoch= 40 self.coef = array([1.4237787 , 1.00958403])  self.intercept = -1.1552497439664873  loss = 0.5663333860398768\n",
      "epoch= 41 self.coef = array([1.43988427, 1.01681958])  self.intercept = -1.1675791875358126  loss = 0.5654082605058878\n",
      "epoch= 42 self.coef = array([1.45598002, 1.02392941])  self.intercept = -1.1798014872912554  loss = 0.5644925747220518\n",
      "epoch= 43 self.coef = array([1.47206535, 1.0309155 ])  self.intercept = -1.1919189814307745  loss = 0.5635860927372274\n",
      "epoch= 44 self.coef = array([1.48813967, 1.03777989])  self.intercept = -1.2039338499383556  loss = 0.5626885868868012\n",
      "epoch= 45 self.coef = array([1.50420247, 1.04452466])  self.intercept = -1.2158481400782477  loss = 0.5617998374642752\n",
      "epoch= 46 self.coef = array([1.52025326, 1.05115188])  self.intercept = -1.2276637869022196  loss = 0.5609196324098137\n",
      "epoch= 47 self.coef = array([1.53629159, 1.05766363])  self.intercept = -1.2393826297731931  loss = 0.5600477670136363\n",
      "epoch= 48 self.coef = array([1.55231706, 1.06406199])  self.intercept = -1.2510064257054307  loss = 0.5591840436327559\n",
      "epoch= 49 self.coef = array([1.56832926, 1.07034901])  self.intercept = -1.262536860159576  loss = 0.5583282714199483\n",
      "epoch= 50 self.coef = array([1.58432783, 1.07652673])  self.intercept = -1.2739755558018289  loss = 0.5574802660641018\n",
      "epoch= 51 self.coef = array([1.6003124 , 1.08259717])  self.intercept = -1.2853240796337064  loss = 0.5566398495412577\n",
      "epoch= 52 self.coef = array([1.61628264, 1.08856232])  self.intercept = -1.2965839488168436  loss = 0.5558068498757676\n",
      "epoch= 53 self.coef = array([1.63223823, 1.09442413])  self.intercept = -1.3077566354519186  loss = 0.5549811009110736\n",
      "epoch= 54 self.coef = array([1.64817884, 1.10018454])  self.intercept = -1.3188435705186372  loss = 0.5541624420896621\n",
      "epoch= 55 self.coef = array([1.66410419, 1.10584544])  self.intercept = -1.3298461471421121  loss = 0.5533507182417893\n",
      "epoch= 56 self.coef = array([1.68001397, 1.11140869])  self.intercept = -1.340765723317776  loss = 0.5525457793826016\n",
      "epoch= 57 self.coef = array([1.69590792, 1.11687613])  self.intercept = -1.3516036242004785  loss = 0.5517474805172988\n",
      "epoch= 58 self.coef = array([1.71178575, 1.12224955])  self.intercept = -1.3623611440422583  loss = 0.5509556814540068\n",
      "epoch= 59 self.coef = array([1.72764719, 1.12753072])  self.intercept = -1.373039547846403  loss = 0.5501702466240413\n",
      "epoch= 60 self.coef = array([1.743492  , 1.13272136])  self.intercept = -1.3836400727919107  loss = 0.5493910449092638\n",
      "epoch= 61 self.coef = array([1.75931992, 1.13782317])  self.intercept = -1.3941639294716976  loss = 0.5486179494762363\n",
      "epoch= 62 self.coef = array([1.77513071, 1.14283782])  self.intercept = -1.4046123029792807  loss = 0.5478508376169026\n",
      "epoch= 63 self.coef = array([1.79092412, 1.14776694])  self.intercept = -1.414986353871782  loss = 0.5470895905955274\n",
      "epoch= 64 self.coef = array([1.80669994, 1.15261213])  self.intercept = -1.4252872190315977  loss = 0.5463340935016423\n",
      "epoch= 65 self.coef = array([1.82245794, 1.15737496])  self.intercept = -1.4355160124446757  loss = 0.545584235108752\n",
      "epoch= 66 self.coef = array([1.83819789, 1.16205696])  self.intercept = -1.4456738259098199  loss = 0.5448399077385693\n",
      "epoch= 67 self.coef = array([1.85391958, 1.16665965])  self.intercept = -1.455761729690625  loss = 0.5441010071305533\n",
      "epoch= 68 self.coef = array([1.86962281, 1.17118449])  self.intercept = -1.4657807731193904  loss = 0.5433674323165382\n",
      "epoch= 69 self.coef = array([1.88530737, 1.17563295])  self.intercept = -1.4757319851605522  loss = 0.5426390855002413\n",
      "epoch= 70 self.coef = array([1.90097306, 1.18000643])  self.intercept = -1.485616374939728  loss = 0.5419158719414601\n",
      "epoch= 71 self.coef = array([1.9166197 , 1.18430633])  self.intercept = -1.4954349322433091  loss = 0.5411976998447616\n",
      "epoch= 72 self.coef = array([1.93224709, 1.18853402])  self.intercept = -1.5051886279926034  loss = 0.5404844802524873\n",
      "epoch= 73 self.coef = array([1.94785506, 1.19269083])  self.intercept = -1.5148784146957868  loss = 0.5397761269418961\n",
      "epoch= 74 self.coef = array([1.96344341, 1.19677807])  self.intercept = -1.5245052268803239  loss = 0.5390725563262807\n",
      "epoch= 75 self.coef = array([1.97901199, 1.20079703])  self.intercept = -1.5340699815080343  loss = 0.5383736873598947\n",
      "epoch= 76 self.coef = array([1.99456062, 1.20474897])  self.intercept = -1.5435735783745976  loss = 0.5376794414465402\n",
      "epoch= 77 self.coef = array([2.01008913, 1.20863512])  self.intercept = -1.5530169004949752  loss = 0.5369897423516634\n",
      "epoch= 78 self.coef = array([2.02559736, 1.21245669])  self.intercept = -1.5624008144759807  loss = 0.5363045161178243\n",
      "epoch= 79 self.coef = array([2.04108516, 1.21621488])  self.intercept = -1.571726170877026  loss = 0.5356236909833977\n",
      "epoch= 80 self.coef = array([2.05655238, 1.21991084])  self.intercept = -1.580993804559907  loss = 0.5349471973043814\n",
      "epoch= 81 self.coef = array([2.07199886, 1.22354572])  self.intercept = -1.590204535028361  loss = 0.5342749674791847\n",
      "epoch= 82 self.coef = array([2.08742446, 1.22712064])  self.intercept = -1.5993591667580227  loss = 0.5336069358762775\n",
      "epoch= 83 self.coef = array([2.10282904, 1.23063669])  self.intercept = -1.6084584895173175  loss = 0.5329430387645884\n",
      "epoch= 84 self.coef = array([2.11821246, 1.23409495])  self.intercept = -1.6175032786797578  loss = 0.5322832142465398\n",
      "epoch= 85 self.coef = array([2.13357459, 1.23749648])  self.intercept = -1.6264942955280564  loss = 0.5316274021936149\n",
      "epoch= 86 self.coef = array([2.1489153, 1.2408423])  self.intercept = -1.6354322875504157  loss = 0.5309755441843597\n",
      "epoch= 87 self.coef = array([2.16423446, 1.24413344])  self.intercept = -1.6443179887293216  loss = 0.5303275834447162\n",
      "epoch= 88 self.coef = array([2.17953195, 1.2473709 ])  self.intercept = -1.65315211982313  loss = 0.5296834647906044\n",
      "epoch= 89 self.coef = array([2.19480765, 1.25055564])  self.intercept = -1.6619353886407142  loss = 0.529043134572653\n",
      "epoch= 90 self.coef = array([2.21006144, 1.25368862])  self.intercept = -1.670668490309414  loss = 0.5284065406230041\n",
      "epoch= 91 self.coef = array([2.2252932 , 1.25677079])  self.intercept = -1.6793521075365125  loss = 0.5277736322041034\n",
      "epoch= 92 self.coef = array([2.24050284, 1.25980306])  self.intercept = -1.6879869108644492  loss = 0.5271443599594008\n",
      "epoch= 93 self.coef = array([2.25569024, 1.26278635])  self.intercept = -1.6965735589199618  loss = 0.5265186758658852\n",
      "epoch= 94 self.coef = array([2.27085529, 1.26572153])  self.intercept = -1.7051126986573435  loss = 0.5258965331883829\n",
      "epoch= 95 self.coef = array([2.2859979 , 1.26860948])  self.intercept = -1.7136049655959873  loss = 0.5252778864355495\n",
      "epoch= 96 self.coef = array([2.30111797, 1.27145104])  self.intercept = -1.7220509840523803  loss = 0.5246626913174889\n",
      "epoch= 97 self.coef = array([2.3162154 , 1.27424707])  self.intercept = -1.7304513673667088  loss = 0.5240509047049378\n",
      "epoch= 98 self.coef = array([2.33129011, 1.27699837])  self.intercept = -1.7388067181242184  loss = 0.5234424845899525\n",
      "epoch= 99 self.coef = array([2.34634199, 1.27970575])  self.intercept = -1.7471176283714778  loss = 0.5228373900480411\n",
      "epoch= 100 self.coef = array([2.36137097, 1.28237001])  self.intercept = -1.7553846798276802  loss = 0.5222355812016855\n",
      "epoch= 101 self.coef = array([2.37637696, 1.28499192])  self.intercept = -1.7636084440911168  loss = 0.521637019185197\n",
      "epoch= 102 self.coef = array([2.39135988, 1.28757224])  self.intercept = -1.7717894828409504  loss = 0.5210416661108577\n",
      "epoch= 103 self.coef = array([2.40631965, 1.29011173])  self.intercept = -1.7799283480344108  loss = 0.520449485036295\n",
      "epoch= 104 self.coef = array([2.42125619, 1.2926111 ])  self.intercept = -1.788025582099534  loss = 0.5198604399330427\n",
      "epoch= 105 self.coef = array([2.43616942, 1.29507108])  self.intercept = -1.7960817181235584  loss = 0.5192744956562453\n",
      "epoch= 106 self.coef = array([2.45105929, 1.29749239])  self.intercept = -1.8040972800370902  loss = 0.5186916179154573\n",
      "epoch= 107 self.coef = array([2.46592571, 1.2998757 ])  self.intercept = -1.8120727827941476  loss = 0.5181117732465\n",
      "epoch= 108 self.coef = array([2.48076863, 1.30222171])  self.intercept = -1.8200087325481877  loss = 0.5175349289843337\n",
      "epoch= 109 self.coef = array([2.49558797, 1.30453107])  self.intercept = -1.8279056268242184  loss = 0.5169610532369054\n",
      "epoch= 110 self.coef = array([2.51038367, 1.30680445])  self.intercept = -1.8357639546870947  loss = 0.5163901148599374\n",
      "epoch= 111 self.coef = array([2.52515568, 1.30904248])  self.intercept = -1.843584196906094  loss = 0.5158220834326188\n",
      "epoch= 112 self.coef = array([2.53990393, 1.3112458 ])  self.intercept = -1.8513668261158653  loss = 0.5152569292341682\n",
      "epoch= 113 self.coef = array([2.55462837, 1.31341503])  self.intercept = -1.8591123069738436  loss = 0.5146946232212323\n",
      "epoch= 114 self.coef = array([2.56932894, 1.31555078])  self.intercept = -1.8668210963142138  loss = 0.51413513700609\n",
      "epoch= 115 self.coef = array([2.5840056 , 1.31765364])  self.intercept = -1.8744936432985146  loss = 0.5135784428356321\n",
      "epoch= 116 self.coef = array([2.5986583, 1.3197242])  self.intercept = -1.8821303895629626  loss = 0.5130245135710865\n",
      "epoch= 117 self.coef = array([2.61328698, 1.32176303])  self.intercept = -1.889731769362578  loss = 0.5124733226684618\n",
      "epoch= 118 self.coef = array([2.6278916, 1.3237707])  self.intercept = -1.8972982097121909  loss = 0.5119248441596823\n",
      "epoch= 119 self.coef = array([2.64247211, 1.32574777])  self.intercept = -1.9048301305244055  loss = 0.5113790526343877\n",
      "epoch= 120 self.coef = array([2.65702848, 1.32769478])  self.intercept = -1.9123279447445944  loss = 0.5108359232223747\n",
      "epoch= 121 self.coef = array([2.67156066, 1.32961226])  self.intercept = -1.919792058482998  loss = 0.5102954315766538\n",
      "epoch= 122 self.coef = array([2.68606862, 1.33150073])  self.intercept = -1.927222871143997  loss = 0.5097575538571013\n",
      "epoch= 123 self.coef = array([2.70055231, 1.33336073])  self.intercept = -1.9346207755526295  loss = 0.5092222667146837\n",
      "epoch= 124 self.coef = array([2.7150117 , 1.33519274])  self.intercept = -1.9419861580784155  loss = 0.5086895472762307\n",
      "epoch= 125 self.coef = array([2.72944677, 1.33699727])  self.intercept = -1.9493193987565565  loss = 0.5081593731297416\n",
      "epoch= 126 self.coef = array([2.74385747, 1.33877481])  self.intercept = -1.9566208714065734  loss = 0.5076317223102002\n",
      "epoch= 127 self.coef = array([2.75824378, 1.34052583])  self.intercept = -1.9638909437484413  loss = 0.5071065732858836\n",
      "epoch= 128 self.coef = array([2.77260566, 1.3422508 ])  self.intercept = -1.971129977516285  loss = 0.5065839049451449\n",
      "epoch= 129 self.coef = array([2.7869431 , 1.34395019])  self.intercept = -1.9783383285696885  loss = 0.5060636965836518\n",
      "epoch= 130 self.coef = array([2.80125606, 1.34562446])  self.intercept = -1.985516347002681  loss = 0.5055459278920663\n",
      "epoch= 131 self.coef = array([2.81554453, 1.34727404])  self.intercept = -1.9926643772504486  loss = 0.5050305789441485\n",
      "epoch= 132 self.coef = array([2.82980847, 1.34889937])  self.intercept = -1.9997827581938294  loss = 0.5045176301852685\n",
      "epoch= 133 self.coef = array([2.84404787, 1.35050089])  self.intercept = -2.0068718232616427  loss = 0.5040070624213123\n",
      "epoch= 134 self.coef = array([2.85826271, 1.35207902])  self.intercept = -2.0139319005309027  loss = 0.5034988568079679\n",
      "epoch= 135 self.coef = array([2.87245298, 1.35363417])  self.intercept = -2.020963312824968  loss = 0.5029929948403764\n",
      "epoch= 136 self.coef = array([2.88661864, 1.35516675])  self.intercept = -2.0279663778096735  loss = 0.5024894583431359\n",
      "epoch= 137 self.coef = array([2.90075969, 1.35667716])  self.intercept = -2.0349414080874895  loss = 0.5019882294606461\n",
      "epoch= 138 self.coef = array([2.91487612, 1.35816578])  self.intercept = -2.041888711289761  loss = 0.5014892906477794\n",
      "epoch= 139 self.coef = array([2.92896791, 1.35963302])  self.intercept = -2.048808590167064  loss = 0.5009926246608691\n",
      "epoch= 140 self.coef = array([2.94303505, 1.36107925])  self.intercept = -2.0557013426777244  loss = 0.5004982145490007\n",
      "epoch= 141 self.coef = array([2.95707752, 1.36250483])  self.intercept = -2.0625672620745448  loss = 0.5000060436455989\n",
      "epoch= 142 self.coef = array([2.97109533, 1.36391014])  self.intercept = -2.0694066369897763  loss = 0.4995160955602955\n",
      "epoch= 143 self.coef = array([2.98508846, 1.36529553])  self.intercept = -2.0762197515183782  loss = 0.49902835417107283\n",
      "epoch= 144 self.coef = array([2.9990569 , 1.36666137])  self.intercept = -2.0830068852996018  loss = 0.49854280361666853\n",
      "epoch= 145 self.coef = array([3.01300066, 1.36800798])  self.intercept = -2.0897683135969403  loss = 0.49805942828923533\n",
      "epoch= 146 self.coef = array([3.02691972, 1.36933573])  self.intercept = -2.096504307376478  loss = 0.49757821282724635\n",
      "epoch= 147 self.coef = array([3.04081408, 1.37064493])  self.intercept = -2.103215133383677  loss = 0.4970991421086351\n",
      "epoch= 148 self.coef = array([3.05468374, 1.37193592])  self.intercept = -2.109901054218636  loss = 0.4966222012441651\n",
      "epoch= 149 self.coef = array([3.0685287 , 1.37320903])  self.intercept = -2.1165623284098567  loss = 0.4961473755710193\n",
      "epoch= 150 self.coef = array([3.08234896, 1.37446456])  self.intercept = -2.1231992104865474  loss = 0.49567465064660027\n",
      "epoch= 151 self.coef = array([3.09614452, 1.37570283])  self.intercept = -2.129811951049503  loss = 0.4952040122425369\n",
      "epoch= 152 self.coef = array([3.10991538, 1.37692416])  self.intercept = -2.1364007968405856  loss = 0.4947354463388879\n",
      "epoch= 153 self.coef = array([3.12366155, 1.37812883])  self.intercept = -2.1429659908108434  loss = 0.4942689391185352\n",
      "epoch= 154 self.coef = array([3.13738302, 1.37931714])  self.intercept = -2.149507772187292  loss = 0.4938044769617633\n",
      "epoch= 155 self.coef = array([3.15107981, 1.38048939])  self.intercept = -2.1560263765383945  loss = 0.4933420464410137\n",
      "epoch= 156 self.coef = array([3.16475192, 1.38164586])  self.intercept = -2.1625220358382604  loss = 0.492881634315813\n",
      "epoch= 157 self.coef = array([3.17839935, 1.38278684])  self.intercept = -2.1689949785296  loss = 0.4924232275278645\n",
      "epoch= 158 self.coef = array([3.19202212, 1.38391258])  self.intercept = -2.175445429585457  loss = 0.4919668131963007\n",
      "epoch= 159 self.coef = array([3.20562023, 1.38502338])  self.intercept = -2.1818736105697427  loss = 0.49151237861308933\n",
      "epoch= 160 self.coef = array([3.21919369, 1.38611949])  self.intercept = -2.1882797396966094  loss = 0.4910599112385886\n",
      "epoch= 161 self.coef = array([3.23274251, 1.38720117])  self.intercept = -2.194664031888671  loss = 0.49060939869724535\n",
      "epoch= 162 self.coef = array([3.24626671, 1.38826869])  self.intercept = -2.2010266988341143  loss = 0.490160828773432\n",
      "epoch= 163 self.coef = array([3.25976629, 1.38932229])  self.intercept = -2.207367949042707  loss = 0.4897141894074188\n",
      "epoch= 164 self.coef = array([3.27324127, 1.39036222])  self.intercept = -2.213687987900743  loss = 0.489269468691473\n",
      "epoch= 165 self.coef = array([3.28669166, 1.39138873])  self.intercept = -2.219987017724934  loss = 0.48882665486608473\n",
      "epoch= 166 self.coef = array([3.30011748, 1.39240205])  self.intercept = -2.226265237815277  loss = 0.4883857363163126\n",
      "epoch= 167 self.coef = array([3.31351873, 1.39340243])  self.intercept = -2.232522844506919  loss = 0.4879467015682456\n",
      "epoch= 168 self.coef = array([3.32689545, 1.39439008])  self.intercept = -2.2387600312210383  loss = 0.48750953928557816\n",
      "epoch= 169 self.coef = array([3.34024764, 1.39536525])  self.intercept = -2.244976988514764  loss = 0.48707423826629287\n",
      "epoch= 170 self.coef = array([3.35357532, 1.39632815])  self.intercept = -2.251173904130155  loss = 0.4866407874394491\n",
      "epoch= 171 self.coef = array([3.36687851, 1.397279  ])  self.intercept = -2.2573509630422555  loss = 0.48620917586207163\n",
      "epoch= 172 self.coef = array([3.38015722, 1.39821802])  self.intercept = -2.263508347506251  loss = 0.4857793927161385\n",
      "epoch= 173 self.coef = array([3.39341149, 1.39914542])  self.intercept = -2.2696462371037387  loss = 0.48535142730566294\n",
      "epoch= 174 self.coef = array([3.40664132, 1.40006141])  self.intercept = -2.2757648087881335  loss = 0.4849252690538656\n",
      "epoch= 175 self.coef = array([3.41984673, 1.40096619])  self.intercept = -2.2818642369292284  loss = 0.4845009075004372\n",
      "epoch= 176 self.coef = array([3.43302776, 1.40185997])  self.intercept = -2.287944693356923  loss = 0.48407833229888386\n",
      "epoch= 177 self.coef = array([3.44618442, 1.40274294])  self.intercept = -2.2940063474041428  loss = 0.4836575332139574\n",
      "epoch= 178 self.coef = array([3.45931673, 1.40361529])  self.intercept = -2.300049365948961  loss = 0.4832385001191627\n",
      "epoch= 179 self.coef = array([3.47242471, 1.40447723])  self.intercept = -2.3060739134559407  loss = 0.4828212229943444\n",
      "epoch= 180 self.coef = array([3.4855084 , 1.40532892])  self.intercept = -2.312080152016718  loss = 0.4824056919233461\n",
      "epoch= 181 self.coef = array([3.49856781, 1.40617057])  self.intercept = -2.318068241389832  loss = 0.48199189709174217\n",
      "epoch= 182 self.coef = array([3.51160297, 1.40700235])  self.intercept = -2.3240383390398276  loss = 0.4815798287846394\n",
      "epoch= 183 self.coef = array([3.52461391, 1.40782444])  self.intercept = -2.329990600175638  loss = 0.4811694773845443\n",
      "epoch= 184 self.coef = array([3.53760065, 1.40863701])  self.intercept = -2.335925177788266  loss = 0.4807608333692976\n",
      "epoch= 185 self.coef = array([3.55056321, 1.40944024])  self.intercept = -2.341842222687776  loss = 0.480353887310069\n",
      "epoch= 186 self.coef = array([3.56350163, 1.41023429])  self.intercept = -2.347741883539612  loss = 0.47994862986941395\n",
      "epoch= 187 self.coef = array([3.57641593, 1.41101934])  self.intercept = -2.3536243069002554  loss = 0.47954505179938917\n",
      "epoch= 188 self.coef = array([3.58930614, 1.41179554])  self.intercept = -2.359489637252232  loss = 0.47914314393972346\n",
      "epoch= 189 self.coef = array([3.60217229, 1.41256306])  self.intercept = -2.3653380170384883  loss = 0.478742897216045\n",
      "epoch= 190 self.coef = array([3.61501441, 1.41332205])  self.intercept = -2.371169586696144  loss = 0.47834430263816036\n",
      "epoch= 191 self.coef = array([3.62783252, 1.41407267])  self.intercept = -2.376984484689635  loss = 0.47794735129838506\n",
      "epoch= 192 self.coef = array([3.64062666, 1.41481507])  self.intercept = -2.382782847543256  loss = 0.4775520343699241\n",
      "epoch= 193 self.coef = array([3.65339686, 1.4155494 ])  self.intercept = -2.388564809873126  loss = 0.47715834310529953\n",
      "epoch= 194 self.coef = array([3.66614314, 1.41627581])  self.intercept = -2.3943305044185683  loss = 0.4767662688348248\n",
      "epoch= 195 self.coef = array([3.67886555, 1.41699444])  self.intercept = -2.400080062072937  loss = 0.476375802965124\n",
      "epoch= 196 self.coef = array([3.6915641 , 1.41770544])  self.intercept = -2.4058136119138878  loss = 0.4759869369776936\n",
      "epoch= 197 self.coef = array([3.70423884, 1.41840894])  self.intercept = -2.4115312812331084  loss = 0.4755996624275083\n",
      "epoch= 198 self.coef = array([3.7168898 , 1.41910508])  self.intercept = -2.4172331955655193  loss = 0.4752139709416631\n",
      "epoch= 199 self.coef = array([3.729517  , 1.41979401])  self.intercept = -2.422919478717954  loss = 0.4748298542180597\n",
      "epoch= 200 self.coef = array([3.74212048, 1.42047584])  self.intercept = -2.428590252797331  loss = 0.47444730402412694\n",
      "epoch= 201 self.coef = array([3.75470028, 1.42115071])  self.intercept = -2.4342456382383237  loss = 0.4740663121955794\n",
      "epoch= 202 self.coef = array([3.76725643, 1.42181876])  self.intercept = -2.439885753830543  loss = 0.4736868706352115\n",
      "epoch= 203 self.coef = array([3.77978896, 1.4224801 ])  self.intercept = -2.445510716745238  loss = 0.47330897131172567\n",
      "epoch= 204 self.coef = array([3.79229791, 1.42313485])  self.intercept = -2.4511206425615226  loss = 0.4729326062585938\n",
      "epoch= 205 self.coef = array([3.80478332, 1.42378315])  self.intercept = -2.4567156452921464  loss = 0.4725577675729502\n",
      "epoch= 206 self.coef = array([3.81724521, 1.42442511])  self.intercept = -2.4622958374088064  loss = 0.47218444741451726\n",
      "epoch= 207 self.coef = array([3.82968362, 1.42506084])  self.intercept = -2.467861329867016  loss = 0.4718126380045586\n",
      "epoch= 208 self.coef = array([3.8420986 , 1.42569047])  self.intercept = -2.473412232130539  loss = 0.4714423316248643\n",
      "epoch= 209 self.coef = array([3.85449017, 1.42631411])  self.intercept = -2.478948652195394  loss = 0.4710735206167618\n",
      "epoch= 210 self.coef = array([3.86685838, 1.42693187])  self.intercept = -2.484470696613441  loss = 0.4707061973801553\n",
      "epoch= 211 self.coef = array([3.87920325, 1.42754385])  self.intercept = -2.4899784705155548  loss = 0.4703403543725911\n",
      "epoch= 212 self.coef = array([3.89152484, 1.42815017])  self.intercept = -2.495472077634395  loss = 0.4699759841083489\n",
      "epoch= 213 self.coef = array([3.90382316, 1.42875094])  self.intercept = -2.500951620326779  loss = 0.46961307915755757\n",
      "epoch= 214 self.coef = array([3.91609827, 1.42934625])  self.intercept = -2.50641719959567  loss = 0.46925163214533416\n",
      "epoch= 215 self.coef = array([3.9283502 , 1.42993621])  self.intercept = -2.511868915111778  loss = 0.46889163575094717\n",
      "epoch= 216 self.coef = array([3.94057899, 1.43052092])  self.intercept = -2.5173068652347914  loss = 0.46853308270700167\n",
      "epoch= 217 self.coef = array([3.95278468, 1.43110048])  self.intercept = -2.522731147034237  loss = 0.468175965798646\n",
      "epoch= 218 self.coef = array([3.9649673 , 1.43167499])  self.intercept = -2.528141856309985  loss = 0.4678202778627996\n"
     ]
    }
   ],
   "source": [
    "s=myNN()\n",
    "s.fit(X,y,1000,loss_treshold=0.468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eec79767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44419001, 0.17698637, 0.68288625, 0.38547841, 0.67423843,\n",
       "       0.75471415, 0.41401067, 0.46277862, 0.79605418, 0.78954138,\n",
       "       0.40545832, 0.50343094, 0.18883457, 0.20128195, 0.69980451,\n",
       "       0.74730027, 0.17698637, 0.76909607, 0.14494666, 0.40545832,\n",
       "       0.43442398, 0.18283598, 0.61999336, 0.66547032, 0.70806749,\n",
       "       0.73973958, 0.45399935, 0.67423843])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada16c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e73f7ec",
   "metadata": {},
   "source": [
    "## REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c7834f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056</td>\n",
       "      <td>2</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2600</td>\n",
       "      <td>4</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1521</td>\n",
       "      <td>3</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200</td>\n",
       "      <td>2</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  bedrooms   price\n",
       "0  1056         2   39.07\n",
       "1  2600         4  120.00\n",
       "2  1440         3   62.00\n",
       "3  1521         3   75.00\n",
       "4  1200         2   51.00"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df=pd.read_csv(\"../resources/Excel_sheets/homeprices_banglore.csv\")\n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be19c9",
   "metadata": {},
   "source": [
    "### MINMAX SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4cf17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.nfeatures=0\n",
    "        self.minmax_array=None\n",
    "        self.min_array=None\n",
    "    \n",
    "    def fit_transform(self,X):\n",
    "        self.nfeatures=X.shape[1]\n",
    "        xt=X.T\n",
    "        xt=xt.astype(np.float32)\n",
    "        self.max_array=[]\n",
    "        self.min_array=[]\n",
    "\n",
    "        \n",
    "        for i in range(self.nfeatures):\n",
    "            crr=xt[i]\n",
    "            max_,min_=np.max(crr),np.min(crr)\n",
    "            self.max_array.append(max_)\n",
    "            self.min_array.append(min_)\n",
    "            xt[i]=(crr-min_)/(max_-min_)\n",
    "            \n",
    "            \n",
    "        self.max_array=np.array(self.max_array)\n",
    "        self.min_array=np.array(self.min_array)\n",
    "        return xt.T\n",
    "            \n",
    "    def transform(self,X):\n",
    "        return (X-self.min_array)/(self.max_array-self.min_array)\n",
    "    \n",
    "    def inverse_transform(self,X_scaled):\n",
    "        return X_scaled*(self.max_array-self.min_array) + self.min_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5e800a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08827586, 0.25      ],\n",
       "       [0.62068963, 0.75      ],\n",
       "       [0.22068965, 0.5       ],\n",
       "       [0.24862069, 0.5       ],\n",
       "       [0.13793103, 0.25      ],\n",
       "       [0.1275862 , 0.25      ],\n",
       "       [0.6662069 , 0.75      ],\n",
       "       [0.86206895, 0.75      ],\n",
       "       [0.17586207, 0.5       ],\n",
       "       [1.        , 1.        ],\n",
       "       [0.3448276 , 0.5       ],\n",
       "       [0.68448275, 0.75      ],\n",
       "       [0.06896552, 0.25      ],\n",
       "       [0.10344828, 0.25      ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.12931034, 0.25      ],\n",
       "       [0.13103448, 0.5       ],\n",
       "       [0.2551724 , 0.5       ],\n",
       "       [0.6793103 , 0.5       ],\n",
       "       [0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleX=myMinMaxScaler()\n",
    "regx_scaled=scaleX.fit_transform(reg_df.drop(\"price\",axis=1).values)\n",
    "regx_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb2055d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleY=myMinMaxScaler()\n",
    "regy_scaled=scaleY.fit_transform(reg_df[[\"price\"]].values)\n",
    "regy_scaled=regy_scaled.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1433f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.056e+03, 2.000e+00],\n",
       "       [2.600e+03, 4.000e+00],\n",
       "       [1.440e+03, 3.000e+00],\n",
       "       [1.521e+03, 3.000e+00],\n",
       "       [1.200e+03, 2.000e+00],\n",
       "       [1.170e+03, 2.000e+00],\n",
       "       [2.732e+03, 4.000e+00],\n",
       "       [3.300e+03, 4.000e+00],\n",
       "       [1.310e+03, 3.000e+00],\n",
       "       [3.700e+03, 5.000e+00],\n",
       "       [1.800e+03, 3.000e+00],\n",
       "       [2.785e+03, 4.000e+00],\n",
       "       [1.000e+03, 2.000e+00],\n",
       "       [1.100e+03, 2.000e+00],\n",
       "       [2.250e+03, 3.000e+00],\n",
       "       [1.175e+03, 2.000e+00],\n",
       "       [1.180e+03, 3.000e+00],\n",
       "       [1.540e+03, 3.000e+00],\n",
       "       [2.770e+03, 3.000e+00],\n",
       "       [8.000e+02, 1.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleX.inverse_transform(regx_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df2c7a",
   "metadata": {},
   "source": [
    "### SIMPLE NURAL NETWORK FOR REGRESSION PROBLEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "31fdf40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_track=[]\n",
    "epoch_track=[]\n",
    "\n",
    "class reg_NN:\n",
    "    def __init__(self):\n",
    "        self.coef=None\n",
    "        self.intercept=0\n",
    "        self.nfeatures=0\n",
    "        self.epoch_track=[]\n",
    "        self.cost_track=[]\n",
    "        \n",
    "    def fit(self,X,y,epochs=10,loss_treshold=0,init_weights=1,init_bias=0):\n",
    "        if X.ndim != 2:\n",
    "            raise \"dimension error\"\n",
    "\n",
    "        self.batch_gredient_desent(X,y,epochs,loss_treshold,init_weights,init_bias)\n",
    "  \n",
    "    def batch_gredient_desent(self,X,y_true,epochs,loss_treshold=0,init_weights=1,init_bias=0):\n",
    "        self.cost_track=[]\n",
    "        self.epoch_track=[]\n",
    "        self.nfeatures=X.shape[1]\n",
    "        self.coef=np.array([init_weights]*self.nfeatures)\n",
    "        self.intercept=init_bias\n",
    "        self.rate=.6\n",
    "        n=X.shape[0]\n",
    "\n",
    "        for i in range(epochs):\n",
    "            y_predicted=np.dot(X,np.transpose(self.coef)) + self.intercept\n",
    "\n",
    "            loss=np.mean(np.square(y_true-y_predicted))\n",
    "            self.cost_track.append(loss)\n",
    "            self.epoch_track.append(i)\n",
    "\n",
    "            #print(f\" epoch= {i} {self.coef = } { self.intercept = } { loss = }\")\n",
    "            print(f\"{ loss = }\")\n",
    "\n",
    "            if loss<loss_treshold:\n",
    "                break\n",
    "\n",
    "            diff=y_true-y_predicted  # opposite of classification\n",
    "            \n",
    "            self.coef=self.coef + (self.rate*2/n)*np.dot(np.transpose(diff),X)\n",
    "            self.intercept= self.intercept + (self.rate*2/n)*np.sum(diff)\n",
    "            \n",
    "    def stocastic_batch_gredient_descent(self,X,y_true,epochs,loss_treshold=0,init_weights=1,init_bias=0):\n",
    "            self.cost_track=[]\n",
    "            self.epoch_track=[]\n",
    "            \n",
    "            self.nfeatures=X.shape[1]\n",
    "            self.coef=np.array([init_weights]*self.nfeatures)\n",
    "            self.intercept=init_bias\n",
    "            self.rate=.03\n",
    "            n=X.shape[0]\n",
    "\n",
    "            for i in range(epochs):\n",
    "                crr=randint(self.nfeatures)\n",
    "                crr_sample=X[crr]\n",
    "                crr_true=y_true[crr]\n",
    "                y_predicted=np.sum(self.coef*crr_sample) + self.intercept\n",
    "                                   \n",
    "                diff=crr_true-y_predicted\n",
    "\n",
    "                loss=(diff*diff)/n\n",
    "                if i%100==0:\n",
    "                    self.cost_track.append(loss)\n",
    "                    self.epoch_track.append(i)\n",
    "\n",
    "                #print(f\" epoch= {i} {self.coef = } { self.intercept = } { loss = }\")\n",
    "                print(f\"{ loss = }\")\n",
    "\n",
    "                if loss<loss_treshold:\n",
    "                    break\n",
    "\n",
    "                  \n",
    "\n",
    "                self.coef=self.coef + (self.rate*2/n)*diff*crr_sample\n",
    "                self.intercept= self.intercept + (self.rate*2/n)*diff\n",
    "                \n",
    "    \n",
    "    def mini_batch_gredient_desent(self,X,y_true,epochs,loss_treshold=0,init_weights=1,init_bias=0):\n",
    "        self.cost_track=[]\n",
    "        self.epoch_track=[]\n",
    "        self.nfeatures=X.shape[1]\n",
    "        self.coef=np.array([init_weights]*self.nfeatures)\n",
    "        self.intercept=init_bias\n",
    "        self.rate=.03\n",
    "        n=X.shape[0]\n",
    "        batch_size=int(math.sqrt(n))\n",
    "        \n",
    "\n",
    "        for i in range(epochs):\n",
    "            random_index=randint(self.nfeatures,size=batch_size)\n",
    "            crr_sample=X[random_index]\n",
    "            crr_y=y_true[random_index]\n",
    "            y_predicted=np.dot(crr_sample,np.transpose(self.coef)) + self.intercept\n",
    "            \n",
    "            diff=crr_y-y_predicted\n",
    "\n",
    "            loss=np.mean(np.square(diff))\n",
    "            if i%100==0:\n",
    "                self.cost_track.append(loss)\n",
    "                self.epoch_track.append(i)\n",
    "\n",
    "            #print(f\" epoch= {i} {self.coef = } { self.intercept = } { loss = }\")\n",
    "            print(f\"{ loss = }\")\n",
    "\n",
    "            if loss<loss_treshold:\n",
    "                break\n",
    "            \n",
    "            self.coef=self.coef + (self.rate*2/n)*np.dot(np.transpose(diff),crr_sample)\n",
    "            self.intercept= self.intercept + (self.rate*2/n)*np.sum(diff)\n",
    "                \n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.dot(X,np.transpose(self.coef)) + self.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9b6fb499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.2768777140783993\n",
      " loss = 0.12882808702393178\n",
      " loss = 0.0629819874941202\n",
      " loss = 0.033322629941407333\n",
      " loss = 0.019674713724030134\n",
      " loss = 0.013174530914436444\n",
      " loss = 0.009913837394385271\n",
      " loss = 0.008158455178991064\n",
      " loss = 0.007130454441117163\n",
      " loss = 0.006474396781638245\n",
      " loss = 0.006022973643221274\n",
      " loss = 0.005693775603225875\n",
      " loss = 0.005443568007077963\n",
      " loss = 0.005247842120904156\n",
      " loss = 0.0050915194425530065\n",
      " loss = 0.00496461149065393\n",
      " loss = 0.004860107587771964\n",
      " loss = 0.004772884433171208\n",
      " loss = 0.004699099478672071\n",
      " loss = 0.004635824653218981\n",
      " loss = 0.00458080759296006\n",
      " loss = 0.004532306063066515\n",
      " loss = 0.004488967953377653\n",
      " loss = 0.004449741761327982\n",
      " loss = 0.0044138086229273486\n",
      " loss = 0.004380530160200383\n",
      " loss = 0.004349408220430809\n",
      " loss = 0.0043200536873184954\n",
      " loss = 0.004292162272082254\n",
      " loss = 0.0042654957013725835\n",
      " loss = 0.00423986708962142\n",
      " loss = 0.00421512956095586\n",
      " loss = 0.004191167396927804\n",
      " loss = 0.004167889148496305\n",
      " loss = 0.004145222275986056\n",
      " loss = 0.004123108977836764\n",
      " loss = 0.004101502944336187\n",
      " loss = 0.004080366831109144\n",
      " loss = 0.00405967029268642\n",
      " loss = 0.004039388451909454\n",
      " loss = 0.004019500708492574\n",
      " loss = 0.00399998981151257\n",
      " loss = 0.003980841137284549\n",
      " loss = 0.00396204212706931\n",
      " loss = 0.00394358184916302\n",
      " loss = 0.003925450657783485\n",
      " loss = 0.003907639927286693\n",
      " loss = 0.0038901418450089146\n",
      " loss = 0.0038729492497352304\n",
      " loss = 0.0038560555056788596\n",
      " loss = 0.003839454404099401\n",
      " loss = 0.003823140086434365\n",
      " loss = 0.0038071069841769346\n",
      " loss = 0.0037913497717905137\n",
      " loss = 0.0037758633297731254\n",
      " loss = 0.0037606427156252654\n",
      " loss = 0.0037456831409729296\n",
      " loss = 0.0037309799534852514\n",
      " loss = 0.003716528622528033\n",
      " loss = 0.003702324727729086\n",
      " loss = 0.003688363949814085\n",
      " loss = 0.0036746420632138795\n",
      " loss = 0.003661154930054687\n",
      " loss = 0.0036478984952288745\n",
      " loss = 0.0036348687823108674\n",
      " loss = 0.0036220618901350366\n",
      " loss = 0.003609473989892814\n",
      " loss = 0.0035971013226380128\n",
      " loss = 0.003584940197113789\n",
      " loss = 0.0035729869878338956\n",
      " loss = 0.0035612381333656852\n",
      " loss = 0.0035496901347739328\n",
      " loss = 0.003538339554193598\n",
      " loss = 0.003527183013506575\n",
      " loss = 0.0035162171931030495\n",
      " loss = 0.003505438830712198\n",
      " loss = 0.0034948447202904527\n",
      " loss = 0.0034844317109578907\n",
      " loss = 0.0034741967059756114\n",
      " loss = 0.0034641366617581904\n",
      " loss = 0.003454248586916823\n",
      " loss = 0.0034445295413295116\n",
      " loss = 0.003434976635235494\n",
      " loss = 0.0034255870283515927\n",
      " loss = 0.0034163579290087927\n",
      " loss = 0.0034072865933073996\n",
      " loss = 0.0033983703242897916\n",
      " loss = 0.003389606471129636\n",
      " loss = 0.0033809924283368146\n",
      " loss = 0.0033725256349774147\n",
      " loss = 0.003364203573908135\n",
      " loss = 0.0033560237710246825\n",
      " loss = 0.0033479837945236575\n",
      " loss = 0.003340081254177624\n",
      " loss = 0.003332313800622975\n",
      " loss = 0.003324679124660247\n",
      " loss = 0.0033171749565667112\n",
      " loss = 0.0033097990654208653\n",
      " loss = 0.0033025492584386243\n",
      " loss = 0.003295423380320997\n",
      " loss = 0.003288419312612984\n",
      " loss = 0.003281534973073523\n",
      " loss = 0.0032747683150562397\n",
      " loss = 0.003268117326900852\n",
      " loss = 0.0032615800313349807\n",
      " loss = 0.003255154484886244\n",
      " loss = 0.003248838777304395\n",
      " loss = 0.0032426310309933717\n",
      " loss = 0.003236529400453059\n",
      " loss = 0.0032305320717305962\n",
      " loss = 0.0032246372618810956\n",
      " loss = 0.003218843218437546\n",
      " loss = 0.0032131482188898297\n",
      " loss = 0.003207550570172621\n",
      " loss = 0.003202048608162013\n",
      " loss = 0.0031966406971808206\n",
      " loss = 0.003191325229512307\n",
      " loss = 0.0031861006249221738\n",
      " loss = 0.003180965330188819\n",
      " loss = 0.003175917818641561\n",
      " loss = 0.0031709565897067595\n",
      " loss = 0.0031660801684617267\n",
      " loss = 0.0031612871051962385\n",
      " loss = 0.003156575974981543\n",
      " loss = 0.003151945377246765\n",
      " loss = 0.0031473939353625\n",
      " loss = 0.0031429202962315805\n",
      " loss = 0.0031385231298867978\n",
      " loss = 0.0031342011290955265\n",
      " loss = 0.003129953008971088\n",
      " loss = 0.003125777506590777\n",
      " loss = 0.003121673380620402\n",
      " loss = 0.003117639410945246\n",
      " loss = 0.003113674398307339\n",
      " loss = 0.003109777163948945\n",
      " loss = 0.0031059465492621055\n",
      " loss = 0.003102181415444219\n",
      " loss = 0.0030984806431594734\n",
      " loss = 0.003094843132206081\n",
      " loss = 0.0030912678011892052\n",
      " loss = 0.003087753587199466\n",
      " loss = 0.0030842994454969574\n",
      " loss = 0.003080904349200641\n",
      " loss = 0.0030775672889830825\n",
      " loss = 0.003074287272770376\n",
      " loss = 0.003071063325447218\n",
      " loss = 0.0030678944885670135\n",
      " loss = 0.0030647798200669337\n",
      " loss = 0.003061718393987861\n",
      " loss = 0.003058709300199112\n",
      " loss = 0.0030557516441278385\n",
      " loss = 0.0030528445464931167\n",
      " loss = 0.003049987143044529\n",
      " loss = 0.003047178584305224\n",
      " loss = 0.0030444180353193856\n",
      " loss = 0.0030417046754040115\n",
      " loss = 0.003039037697904921\n",
      " loss = 0.003036416309956955\n",
      " loss = 0.0030338397322482694\n",
      " loss = 0.0030313071987886297\n",
      " loss = 0.0030288179566817217\n",
      " loss = 0.003026371265901301\n",
      " loss = 0.0030239663990711983\n",
      " loss = 0.003021602641249081\n",
      " loss = 0.0030192792897138993\n",
      " loss = 0.003016995653756985\n",
      " loss = 0.0030147510544767005\n",
      " loss = 0.0030125448245766134\n",
      " loss = 0.003010376308167121\n",
      " loss = 0.003008244860570451\n",
      " loss = 0.0030061498481290146\n",
      " loss = 0.003004090648017022\n",
      " loss = 0.003002066648055315\n",
      " loss = 0.0030000772465293896\n",
      " loss = 0.0029981218520105032\n",
      " loss = 0.0029961998831798393\n",
      " loss = 0.002994310768655711\n",
      " loss = 0.0029924539468236654\n",
      " loss = 0.0029906288656695542\n",
      " loss = 0.002988834982615392\n",
      " loss = 0.002987071764358079\n",
      " loss = 0.002985338686710844\n",
      " loss = 0.0029836352344474147\n",
      " loss = 0.002981960901148834\n",
      " loss = 0.0029803151890529234\n",
      " loss = 0.002978697608906296\n",
      " loss = 0.002977107679818896\n",
      " loss = 0.002975544929121056\n",
      " loss = 0.002974008892222965\n",
      " loss = 0.002972499112476543\n",
      " loss = 0.002971015141039699\n",
      " loss = 0.002969556536742893\n",
      " loss = 0.002968122865957967\n",
      " loss = 0.0029667137024692505\n",
      " loss = 0.002965328627346833\n",
      " loss = 0.0029639672288220356\n",
      " loss = 0.0029626291021649875\n",
      " loss = 0.002961313849564305\n",
      " loss = 0.0029600210800088344\n",
      " loss = 0.0029587504091713917\n",
      " loss = 0.002957501459294523\n",
      " loss = 0.0029562738590781915\n",
      " loss = 0.002955067243569396\n",
      " loss = 0.0029538812540536733\n",
      " loss = 0.002952715537948468\n",
      " loss = 0.002951569748698283\n",
      " loss = 0.002950443545671685\n",
      " loss = 0.002949336594060022\n",
      " loss = 0.0029482485647778943\n",
      " loss = 0.0029471791343653104\n",
      " loss = 0.0029461279848915366\n",
      " loss = 0.002945094803860576\n",
      " loss = 0.0029440792841182667\n",
      " loss = 0.002943081123760961\n",
      " loss = 0.0029421000260457892\n",
      " loss = 0.0029411356993024255\n",
      " loss = 0.00294018785684638\n",
      " loss = 0.002939256216893777\n",
      " loss = 0.002938340502477577\n",
      " loss = 0.0029374404413652446\n",
      " loss = 0.002936555765977803\n",
      " loss = 0.002935686213310301\n",
      " loss = 0.002934831524853617\n",
      " loss = 0.002933991446517608\n",
      " loss = 0.0029331657285555633\n",
      " loss = 0.002932354125489975\n",
      " loss = 0.0029315563960395454\n",
      " loss = 0.0029307723030474525\n",
      " loss = 0.002930001613410872\n",
      " loss = 0.002929244098011642\n",
      " loss = 0.002928499531648177\n",
      " loss = 0.0029277676929685107\n",
      " loss = 0.002927048364404471\n",
      " loss = 0.0029263413321070353\n",
      " loss = 0.0029256463858827212\n",
      " loss = 0.0029249633191311187\n",
      " loss = 0.0029242919287834645\n",
      " loss = 0.0029236320152422656\n",
      " loss = 0.0029229833823219684\n",
      " loss = 0.0029223458371906395\n",
      " loss = 0.0029217191903126187\n",
      " loss = 0.002921103255392195\n",
      " loss = 0.0029204978493182097\n",
      " loss = 0.0029199027921096277\n",
      " loss = 0.002919317906862015\n",
      " loss = 0.0029187430196949676\n",
      " loss = 0.0029181779597004043\n",
      " loss = 0.002917622558891762\n",
      " loss = 0.0029170766521540545\n",
      " loss = 0.0029165400771947875\n",
      " loss = 0.002916012674495711\n",
      " loss = 0.0029154942872653914\n",
      " loss = 0.0029149847613925946\n",
      " loss = 0.002914483945400495\n",
      " loss = 0.0029139916904016095\n",
      " loss = 0.0029135078500535606\n",
      " loss = 0.0029130322805155547\n",
      " loss = 0.0029125648404056273\n",
      " loss = 0.002912105390758609\n",
      " loss = 0.0029116537949848177\n",
      " loss = 0.00291120991882944\n",
      " loss = 0.0029107736303326357\n",
      " loss = 0.00291034479979029\n",
      " loss = 0.002909923299715465\n",
      " loss = 0.002909509004800494\n",
      " loss = 0.002909101791879736\n",
      " loss = 0.0029087015398929434\n",
      " loss = 0.0029083081298492955\n",
      " loss = 0.00290792144479201\n",
      " loss = 0.002907541369763562\n",
      " loss = 0.0029071677917715333\n",
      " loss = 0.002906800599755008\n",
      " loss = 0.0029064396845515455\n",
      " loss = 0.002906084938864747\n",
      " loss = 0.002905736257232341\n",
      " loss = 0.002905393535994843\n",
      " loss = 0.0029050566732647365\n",
      " loss = 0.002904725568896165\n",
      " loss = 0.002904400124455192\n",
      " loss = 0.0029040802431905023\n",
      " loss = 0.002903765830004669\n",
      " loss = 0.0029034567914258632\n",
      " loss = 0.0029031530355800726\n",
      " loss = 0.0029028544721637906\n",
      " loss = 0.002902561012417162\n",
      " loss = 0.0029022725690976063\n",
      " loss = 0.0029019890564538683\n",
      " loss = 0.002901710390200536\n",
      " loss = 0.002901436487492982\n",
      " loss = 0.002901167266902728\n",
      " loss = 0.0029009026483932457\n",
      " loss = 0.002900642553296154\n",
      " loss = 0.0029003869042878373\n",
      " loss = 0.0029001356253664625\n",
      " loss = 0.0028998886418293702\n",
      " loss = 0.002899645880250878\n",
      " loss = 0.0028994072684604506\n",
      " loss = 0.0028991727355212405\n",
      " loss = 0.002898942211709003\n",
      " loss = 0.00289871562849136\n",
      " loss = 0.00289849291850744\n",
      " loss = 0.0028982740155478414\n",
      " loss = 0.002898058854534947\n",
      " loss = 0.002897847371503587\n",
      " loss = 0.0028976395035820203\n",
      " loss = 0.0028974351889732367\n",
      " loss = 0.0028972343669365895\n",
      " loss = 0.002897036977769739\n",
      " loss = 0.0028968429627909053\n",
      " loss = 0.0028966522643214124\n",
      " loss = 0.002896464825668561\n",
      " loss = 0.0028962805911087472\n",
      " loss = 0.0028960995058709285\n",
      " loss = 0.0028959215161203063\n",
      " loss = 0.0028957465689423484\n",
      " loss = 0.0028955746123270456\n",
      " loss = 0.0028954055951534554\n",
      " loss = 0.002895239467174497\n",
      " loss = 0.002895076179002024\n",
      " loss = 0.002894915682092126\n",
      " loss = 0.0028947579287307134\n",
      " loss = 0.002894602872019326\n",
      " loss = 0.0028944504658611823\n",
      " loss = 0.002894300664947499\n",
      " loss = 0.002894153424743984\n",
      " loss = 0.002894008701477634\n",
      " loss = 0.002893866452123703\n",
      " loss = 0.0028937266343929077\n",
      " loss = 0.0028935892067188706\n",
      " loss = 0.0028934541282457414\n",
      " loss = 0.0028933213588160723\n",
      " loss = 0.0028931908589588744\n",
      " loss = 0.0028930625898778662\n",
      " loss = 0.0028929365134399672\n",
      " loss = 0.0028928125921639336\n",
      " loss = 0.002892690789209243\n",
      " loss = 0.0028925710683651152\n",
      " loss = 0.0028924533940397693\n",
      " loss = 0.002892337731249835\n",
      " loss = 0.0028922240456099417\n",
      " loss = 0.002892112303322513\n",
      " loss = 0.002892002471167705\n",
      " loss = 0.002891894516493544\n",
      " loss = 0.0028917884072062034\n",
      " loss = 0.002891684111760484\n",
      " loss = 0.002891581599150411\n",
      " loss = 0.0028914808389000337\n",
      " loss = 0.002891381801054358\n",
      " loss = 0.0028912844561704448\n",
      " loss = 0.002891188775308656\n",
      " loss = 0.0028910947300240493\n",
      " loss = 0.0028910022923579206\n",
      " loss = 0.002890911434829497\n",
      " loss = 0.0028908221304277666\n",
      " loss = 0.0028907343526034376\n",
      " loss = 0.0028906480752610647\n",
      " loss = 0.0028905632727512726\n",
      " loss = 0.002890479919863144\n",
      " loss = 0.002890397991816715\n",
      " loss = 0.0028903174642556165\n",
      " loss = 0.0028902383132398237\n",
      " loss = 0.0028901605152385533\n",
      " loss = 0.002890084047123252\n",
      " loss = 0.0028900088861607337\n",
      " loss = 0.002889935010006403\n",
      " loss = 0.0028898623966976456\n",
      " loss = 0.002889791024647258\n",
      " loss = 0.002889720872637065\n",
      " loss = 0.0028896519198115837\n",
      " loss = 0.0028895841456718528\n",
      " loss = 0.0028895175300693086\n",
      " loss = 0.002889452053199811\n",
      " loss = 0.0028893876955977593\n",
      " loss = 0.0028893244381302933\n",
      " loss = 0.002889262261991616\n",
      " loss = 0.0028892011486973935\n",
      " loss = 0.002889141080079274\n",
      " loss = 0.0028890820382794663\n",
      " loss = 0.002889024005745447\n",
      " loss = 0.00288896696522474\n",
      " loss = 0.0028889108997597773\n",
      " loss = 0.002888855792682871\n",
      " loss = 0.00288880162761125\n",
      " loss = 0.0028887483884421934\n",
      " loss = 0.0028886960593482386\n",
      " loss = 0.002888644624772482\n",
      " loss = 0.0028885940694239436\n",
      " loss = 0.0028885443782730442\n",
      " loss = 0.0028884955365471063\n",
      " loss = 0.0028884475297259867\n",
      " loss = 0.0028884003435377457\n",
      " loss = 0.002888353963954415\n",
      " loss = 0.002888308377187818\n",
      " loss = 0.002888263569685469\n",
      " loss = 0.002888219528126562\n",
      " loss = 0.0028881762394179877\n",
      " loss = 0.0028881336906904573\n",
      " loss = 0.0028880918692946716\n",
      " loss = 0.0028880507627975518\n",
      " loss = 0.0028880103589785577\n",
      " loss = 0.002887970645826049\n",
      " loss = 0.0028879316115337063\n",
      " loss = 0.0028878932444970375\n",
      " loss = 0.0028878555333099144\n",
      " loss = 0.002887818466761188\n",
      " loss = 0.0028877820338313507\n",
      " loss = 0.0028877462236892625\n",
      " loss = 0.002887711025688934\n",
      " loss = 0.0028876764293663615\n",
      " loss = 0.00288764242443641\n",
      " loss = 0.0028876090007897664\n",
      " loss = 0.002887576148489914\n",
      " loss = 0.002887543857770207\n",
      " loss = 0.0028875121190309397\n",
      " loss = 0.0028874809228365125\n",
      " loss = 0.002887450259912613\n",
      " loss = 0.0028874201211434684\n",
      " loss = 0.0028873904975691292\n",
      " loss = 0.0028873613803828122\n",
      " loss = 0.0028873327609282738\n",
      " loss = 0.002887304630697241\n",
      " loss = 0.0028872769813268863\n",
      " loss = 0.002887249804597337\n",
      " loss = 0.002887223092429219\n",
      " loss = 0.0028871968368812872\n",
      " loss = 0.002887171030148033\n",
      " loss = 0.0028871456645573777\n",
      " loss = 0.0028871207325683866\n",
      " loss = 0.002887096226769043\n",
      " loss = 0.0028870721398740126\n",
      " loss = 0.0028870484647225193\n",
      " loss = 0.002887025194276172\n",
      " loss = 0.002887002321616912\n",
      " loss = 0.002886979839944925\n",
      " loss = 0.0028869577425766455\n",
      " loss = 0.0028869360229427494\n",
      " loss = 0.0028869146745862098\n",
      " loss = 0.002886893691160383\n",
      " loss = 0.0028868730664271054\n",
      " loss = 0.0028868527942548586\n",
      " loss = 0.0028868328686169295\n",
      " loss = 0.002886813283589632\n",
      " loss = 0.002886794033350536\n",
      " loss = 0.0028867751121767456\n",
      " loss = 0.0028867565144431863\n",
      " loss = 0.0028867382346209436\n",
      " loss = 0.0028867202672756094\n",
      " loss = 0.0028867026070656804\n",
      " loss = 0.0028866852487409523\n",
      " loss = 0.002886668187140977\n",
      " loss = 0.00288665141719351\n",
      " loss = 0.0028866349339130193\n",
      " loss = 0.002886618732399195\n",
      " loss = 0.0028866028078354967\n",
      " loss = 0.0028865871554877077\n",
      " loss = 0.0028865717707025475\n",
      " loss = 0.0028865566489062735\n",
      " loss = 0.002886541785603336\n",
      " loss = 0.002886527176375024\n",
      " loss = 0.002886512816878162\n",
      " loss = 0.00288649870284382\n",
      " loss = 0.002886484830076036\n",
      " loss = 0.0028864711944505835\n",
      " loss = 0.002886457791913732\n",
      " loss = 0.0028864446184810343\n",
      " loss = 0.0028864316702361735\n",
      " loss = 0.0028864189433297645\n",
      " loss = 0.002886406433978226\n",
      " loss = 0.0028863941384626576\n",
      " loss = 0.002886382053127732\n",
      " loss = 0.002886370174380596\n",
      " loss = 0.002886358498689823\n",
      " loss = 0.0028863470225843494\n",
      " loss = 0.0028863357426524468\n",
      " loss = 0.0028863246555407033\n",
      " loss = 0.0028863137579530386\n",
      " loss = 0.0028863030466497095\n",
      " loss = 0.0028862925184463526\n",
      " loss = 0.0028862821702130416\n",
      " loss = 0.002886271998873356\n",
      " loss = 0.002886262001403455\n",
      " loss = 0.0028862521748311957\n",
      " loss = 0.0028862425162352436\n",
      " loss = 0.0028862330227441843\n",
      " loss = 0.002886223691535714\n",
      " loss = 0.0028862145198357498\n",
      " loss = 0.0028862055049176448\n",
      " loss = 0.0028861966441013484\n",
      " loss = 0.0028861879347526417\n",
      " loss = 0.0028861793742823156\n",
      " loss = 0.0028861709601454314\n",
      " loss = 0.002886162689840554\n",
      " loss = 0.0028861545609090078\n",
      " loss = 0.0028861465709341394\n",
      " loss = 0.0028861387175406162\n",
      " loss = 0.002886130998393698\n",
      " loss = 0.0028861234111985665\n",
      " loss = 0.002886115953699628\n",
      " loss = 0.00288610862367984\n",
      " loss = 0.0028861014189600605\n",
      " loss = 0.0028860943373984044\n",
      " loss = 0.002886087376889598\n",
      " loss = 0.0028860805353643462\n",
      " loss = 0.002886073810788739\n",
      " loss = 0.0028860672011636257\n",
      " loss = 0.0028860607045240344\n",
      " loss = 0.0028860543189385803\n",
      " loss = 0.0028860480425088896\n",
      " loss = 0.0028860418733690487\n",
      " loss = 0.0028860358096850372\n",
      " loss = 0.002886029849654176\n",
      " loss = 0.0028860239915046155\n",
      " loss = 0.002886018233494787\n",
      " loss = 0.0028860125739128936\n",
      " loss = 0.002886007011076395\n",
      " loss = 0.0028860015433315182\n",
      " loss = 0.002885996169052761\n",
      " loss = 0.002885990886642403\n",
      " loss = 0.0028859856945300426\n",
      " loss = 0.002885980591172112\n",
      " loss = 0.0028859755750514377\n",
      " loss = 0.002885970644676771\n",
      " loss = 0.0028859657985823763\n",
      " loss = 0.002885961035327546\n",
      " loss = 0.0028859563534962196\n",
      " loss = 0.002885951751696535\n",
      " loss = 0.0028859472285604265\n",
      " loss = 0.0028859427827432104\n",
      " loss = 0.0028859384129231898\n",
      " loss = 0.002885934117801258\n",
      " loss = 0.0028859298961005264\n",
      " loss = 0.0028859257465659242\n",
      " loss = 0.0028859216679638353\n",
      " loss = 0.0028859176590817345\n",
      " loss = 0.0028859137187278207\n",
      " loss = 0.0028859098457306716\n",
      " loss = 0.002885906038938876\n",
      " loss = 0.0028859022972207234\n",
      " loss = 0.002885898619463831\n",
      " loss = 0.0028858950045748443\n",
      " loss = 0.0028858914514790913\n",
      " loss = 0.002885887959120275\n",
      " loss = 0.002885884526460151\n",
      " loss = 0.002885881152478226\n",
      " loss = 0.0028858778361714444\n",
      " loss = 0.0028858745765539115\n",
      " loss = 0.0028858713726565713\n",
      " loss = 0.002885868223526935\n",
      " loss = 0.0028858651282288044\n",
      " loss = 0.0028858620858419736\n",
      " loss = 0.002885859095461977\n",
      " loss = 0.002885856156199801\n",
      " loss = 0.0028858532671816347\n",
      " loss = 0.002885850427548601\n",
      " loss = 0.0028858476364565077\n",
      " loss = 0.0028858448930755955\n",
      " loss = 0.0028858421965902784\n",
      " loss = 0.002885839546198923\n",
      " loss = 0.002885836941113591\n",
      " loss = 0.0028858343805598197\n",
      " loss = 0.002885831863776386\n",
      " loss = 0.0028858293900150727\n",
      " loss = 0.002885826958540454\n",
      " loss = 0.002885824568629677\n",
      " loss = 0.002885822219572253\n",
      " loss = 0.002885819910669823\n",
      " loss = 0.002885817641235978\n",
      " loss = 0.002885815410596035\n",
      " loss = 0.002885813218086853\n",
      " loss = 0.0028858110630566184\n",
      " loss = 0.002885808944864661\n",
      " loss = 0.0028858068628812667\n",
      " loss = 0.0028858048164874823\n",
      " loss = 0.0028858028050749336\n",
      " loss = 0.0028858008280456524\n",
      " loss = 0.002885798884811886\n",
      " loss = 0.0028857969747959314\n",
      " loss = 0.0028857950974299582\n",
      " loss = 0.0028857932521558455\n",
      " loss = 0.002885791438425014\n",
      " loss = 0.0028857896556982606\n",
      " loss = 0.002885787903445597\n",
      " loss = 0.002885786181146095\n",
      " loss = 0.002885784488287738\n",
      " loss = 0.002885782824367248\n",
      " loss = 0.0028857811888899645\n",
      " loss = 0.002885779581369674\n",
      " loss = 0.0028857780013284828\n",
      " loss = 0.0028857764482966533\n",
      " loss = 0.0028857749218124907\n",
      " loss = 0.0028857734214221826\n",
      " loss = 0.0028857719466796805\n",
      " loss = 0.002885770497146558\n",
      " loss = 0.0028857690723918866\n",
      " loss = 0.0028857676719920944\n",
      " loss = 0.002885766295530862\n",
      " loss = 0.0028857649425989827\n",
      " loss = 0.0028857636127942385\n",
      " loss = 0.0028857623057212995\n",
      " loss = 0.0028857610209915797\n",
      " loss = 0.0028857597582231404\n",
      " loss = 0.002885758517040583\n",
      " loss = 0.00288575729707491\n",
      " loss = 0.0028857560979634366\n",
      " loss = 0.002885754919349684\n",
      " loss = 0.002885753760883256\n",
      " loss = 0.0028857526222197593\n",
      " loss = 0.002885751503020681\n",
      " loss = 0.002885750402953287\n",
      " loss = 0.002885749321690545\n",
      " loss = 0.002885748258911004\n",
      " loss = 0.002885747214298711\n",
      " loss = 0.002885746187543114\n",
      " loss = 0.002885745178338969\n",
      " loss = 0.0028857441863862497\n",
      " loss = 0.002885743211390058\n",
      " loss = 0.002885742253060539\n",
      " loss = 0.00288574131111279\n",
      " loss = 0.0028857403852667767\n",
      " loss = 0.002885739475247262\n",
      " loss = 0.0028857385807836977\n",
      " loss = 0.0028857377016101794\n",
      " loss = 0.0028857368374653274\n",
      " loss = 0.0028857359880922464\n",
      " loss = 0.002885735153238422\n",
      " loss = 0.002885734332655665\n",
      " loss = 0.0028857335261000205\n",
      " loss = 0.0028857327333317155\n",
      " loss = 0.0028857319541150577\n",
      " loss = 0.0028857311882184013\n",
      " loss = 0.0028857304354140494\n",
      " loss = 0.0028857296954782024\n",
      " loss = 0.0028857289681908853\n",
      " loss = 0.0028857282533358833\n",
      " loss = 0.002885727550700674\n",
      " loss = 0.002885726860076376\n",
      " loss = 0.0028857261812576676\n",
      " loss = 0.0028857255140427515\n",
      " loss = 0.0028857248582332645\n",
      " loss = 0.002885724213634242\n",
      " loss = 0.002885723580054055\n",
      " loss = 0.002885722957304342\n",
      " loss = 0.0028857223451999687\n",
      " loss = 0.002885721743558964\n",
      " loss = 0.0028857211522024624\n",
      " loss = 0.0028857205709546634\n",
      " loss = 0.0028857199996427632\n",
      " loss = 0.0028857194380969226\n",
      " loss = 0.002885718886150196\n",
      " loss = 0.002885718343638495\n",
      " loss = 0.002885717810400538\n",
      " loss = 0.002885717286277795\n",
      " loss = 0.002885716771114456\n",
      " loss = 0.0028857162647573644\n",
      " loss = 0.002885715767055988\n",
      " loss = 0.002885715277862362\n",
      " loss = 0.0028857147970310524\n",
      " loss = 0.002885714324419119\n",
      " loss = 0.0028857138598860567\n",
      " loss = 0.002885713403293765\n",
      " loss = 0.002885712954506497\n",
      " loss = 0.0028857125133908436\n",
      " loss = 0.002885712079815662\n",
      " loss = 0.0028857116536520474\n",
      " loss = 0.002885711234773315\n",
      " loss = 0.0028857108230549333\n",
      " loss = 0.0028857104183745005\n",
      " loss = 0.0028857100206117134\n",
      " loss = 0.002885709629648317\n",
      " loss = 0.0028857092453680845\n",
      " loss = 0.0028857088676567727\n",
      " loss = 0.002885708496402091\n",
      " loss = 0.002885708131493675\n",
      " loss = 0.002885707772823028\n",
      " loss = 0.002885707420283534\n",
      " loss = 0.0028857070737703778\n",
      " loss = 0.002885706733180549\n",
      " loss = 0.0028857063984127967\n",
      " loss = 0.0028857060693675946\n",
      " loss = 0.0028857057459471154\n",
      " loss = 0.002885705428055218\n",
      " loss = 0.002885705115597392\n",
      " loss = 0.0028857048084807496\n",
      " loss = 0.0028857045066139854\n",
      " loss = 0.002885704209907359\n",
      " loss = 0.002885703918272659\n",
      " loss = 0.0028857036316231933\n",
      " loss = 0.0028857033498737353\n",
      " loss = 0.0028857030729405294\n",
      " loss = 0.002885702800741244\n",
      " loss = 0.0028857025331949595\n",
      " loss = 0.002885702270222131\n",
      " loss = 0.002885702011744588\n",
      " loss = 0.0028857017576854804\n",
      " loss = 0.0028857015079692826\n",
      " loss = 0.002885701262521756\n",
      " loss = 0.0028857010212699308\n",
      " loss = 0.002885700784142085\n",
      " loss = 0.0028857005510677268\n",
      " loss = 0.002885700321977557\n",
      " loss = 0.002885700096803479\n",
      " loss = 0.0028856998754785467\n",
      " loss = 0.0028856996579369617\n",
      " loss = 0.0028856994441140513\n",
      " loss = 0.002885699233946249\n",
      " loss = 0.002885699027371078\n",
      " loss = 0.002885698824327115\n",
      " loss = 0.0028856986247540076\n",
      " loss = 0.0028856984285924197\n",
      " loss = 0.002885698235784034\n",
      " loss = 0.002885698046271533\n",
      " loss = 0.0028856978599985763\n",
      " loss = 0.0028856976769097865\n",
      " loss = 0.002885697496950732\n",
      " loss = 0.0028856973200679123\n",
      " loss = 0.002885697146208744\n",
      " loss = 0.0028856969753215398\n",
      " loss = 0.002885696807355499\n",
      " loss = 0.0028856966422606827\n",
      " loss = 0.002885696479988012\n",
      " loss = 0.0028856963204892455\n",
      " loss = 0.0028856961637169646\n",
      " loss = 0.002885696009624563\n",
      " loss = 0.00288569585816623\n",
      " loss = 0.0028856957092969395\n",
      " loss = 0.0028856955629724345\n",
      " loss = 0.002885695419149215\n",
      " loss = 0.002885695277784521\n",
      " loss = 0.0028856951388363285\n",
      " loss = 0.002885695002263326\n",
      " loss = 0.002885694868024916\n",
      " loss = 0.00288569473608119\n",
      " loss = 0.0028856946063929214\n",
      " loss = 0.0028856944789215563\n",
      " loss = 0.002885694353629198\n",
      " loss = 0.0028856942304785957\n",
      " loss = 0.0028856941094331456\n",
      " loss = 0.002885693990456857\n",
      " loss = 0.002885693873514355\n",
      " loss = 0.0028856937585708827\n",
      " loss = 0.002885693645592261\n",
      " loss = 0.0028856935345449087\n",
      " loss = 0.002885693425395808\n",
      " loss = 0.002885693318112513\n",
      " loss = 0.0028856932126631253\n",
      " loss = 0.002885693109016303\n",
      " loss = 0.0028856930071412277\n",
      " loss = 0.0028856929070076123\n",
      " loss = 0.0028856928085856924\n",
      " loss = 0.002885692711846203\n",
      " loss = 0.002885692616760387\n",
      " loss = 0.002885692523299976\n",
      " loss = 0.00288569243143719\n",
      " loss = 0.002885692341144711\n",
      " loss = 0.0028856922523957003\n",
      " loss = 0.0028856921651637737\n",
      " loss = 0.0028856920794229956\n",
      " loss = 0.002885691995147879\n",
      " loss = 0.002885691912313368\n",
      " loss = 0.0028856918308948418\n",
      " loss = 0.002885691750868085\n",
      " loss = 0.0028856916722093157\n",
      " loss = 0.002885691594895148\n",
      " loss = 0.002885691518902593\n",
      " loss = 0.0028856914442090638\n",
      " loss = 0.0028856913707923496\n",
      " loss = 0.00288569129863063\n",
      " loss = 0.0028856912277024473\n",
      " loss = 0.002885691157986718\n",
      " loss = 0.002885691089462715\n",
      " loss = 0.002885691022110069\n",
      " loss = 0.0028856909559087525\n",
      " loss = 0.0028856908908390906\n",
      " loss = 0.002885690826881733\n",
      " loss = 0.002885690764017668\n",
      " loss = 0.002885690702228208\n",
      " loss = 0.0028856906414949815\n",
      " loss = 0.002885690581799936\n",
      " loss = 0.002885690523125323\n",
      " loss = 0.0028856904654536953\n",
      " loss = 0.002885690408767915\n",
      " loss = 0.002885690353051127\n",
      " loss = 0.0028856902982867627\n",
      " loss = 0.0028856902444585495\n",
      " loss = 0.0028856901915504775\n",
      " loss = 0.0028856901395468244\n",
      " loss = 0.002885690088432123\n",
      " loss = 0.0028856900381911826\n",
      " loss = 0.002885689988809065\n",
      " loss = 0.0028856899402710896\n",
      " loss = 0.002885689892562827\n",
      " loss = 0.0028856898456700937\n",
      " loss = 0.0028856897995789485\n",
      " loss = 0.0028856897542756887\n",
      " loss = 0.0028856897097468475\n",
      " loss = 0.0028856896659791866\n",
      " loss = 0.002885689622959693\n",
      " loss = 0.0028856895806755817\n",
      " loss = 0.0028856895391142752\n",
      " loss = 0.0028856894982634248\n",
      " loss = 0.002885689458110879\n",
      " loss = 0.002885689418644705\n",
      " loss = 0.002885689379853168\n",
      " loss = 0.0028856893417247426\n",
      " loss = 0.0028856893042480823\n",
      " loss = 0.002885689267412053\n",
      " loss = 0.0028856892312057038\n",
      " loss = 0.0028856891956182654\n",
      " loss = 0.0028856891606391663\n",
      " loss = 0.0028856891262580018\n",
      " loss = 0.0028856890924645493\n",
      " loss = 0.002885689059248767\n",
      " loss = 0.002885689026600781\n",
      " loss = 0.0028856889945108786\n",
      " loss = 0.0028856889629695244\n",
      " loss = 0.0028856889319673405\n",
      " loss = 0.002885688901495112\n",
      " loss = 0.002885688871543778\n",
      " loss = 0.002885688842104436\n",
      " loss = 0.0028856888131683317\n",
      " loss = 0.0028856887847268646\n",
      " loss = 0.0028856887567715764\n",
      " loss = 0.0028856887292941615\n",
      " loss = 0.0028856887022864442\n",
      " loss = 0.002885688675740399\n",
      " loss = 0.002885688649648139\n",
      " loss = 0.0028856886240018996\n",
      " loss = 0.0028856885987940603\n",
      " loss = 0.0028856885740171233\n",
      " loss = 0.0028856885496637277\n",
      " loss = 0.0028856885257266315\n",
      " loss = 0.0028856885021987183\n",
      " loss = 0.002885688479072993\n",
      " loss = 0.0028856884563425804\n",
      " loss = 0.002885688434000726\n",
      " loss = 0.002885688412040779\n",
      " loss = 0.002885688390456223\n",
      " loss = 0.002885688369240633\n",
      " loss = 0.0028856883483877036\n",
      " loss = 0.0028856883278912376\n",
      " loss = 0.002885688307745141\n",
      " loss = 0.002885688287943421\n",
      " loss = 0.0028856882684801946\n",
      " loss = 0.0028856882493496754\n",
      " loss = 0.002885688230546173\n",
      " loss = 0.0028856882120641006\n",
      " loss = 0.002885688193897962\n",
      " loss = 0.002885688176042357\n",
      " loss = 0.0028856881584919756\n",
      " loss = 0.002885688141241607\n",
      " loss = 0.0028856881242861113\n",
      " loss = 0.00288568810762046\n",
      " loss = 0.00288568809123969\n",
      " loss = 0.002885688075138936\n",
      " loss = 0.002885688059313407\n",
      " loss = 0.002885688043758403\n",
      " loss = 0.0028856880284692946\n",
      " loss = 0.0028856880134415456\n",
      " loss = 0.002885687998670677\n",
      " loss = 0.002885687984152303\n",
      " loss = 0.002885687969882109\n",
      " loss = 0.002885687955855852\n",
      " loss = 0.00288568794206936\n",
      " loss = 0.002885687928518537\n",
      " loss = 0.0028856879151993504\n",
      " loss = 0.0028856879021078425\n",
      " loss = 0.0028856878892401265\n",
      " loss = 0.002885687876592368\n",
      " loss = 0.0028856878641608146\n",
      " loss = 0.002885687851941765\n",
      " loss = 0.0028856878399315896\n",
      " loss = 0.002885687828126717\n",
      " loss = 0.0028856878165236357\n",
      " loss = 0.002885687805118904\n",
      " loss = 0.0028856877939091225\n",
      " loss = 0.0028856877828909626\n",
      " loss = 0.002885687772061148\n",
      " loss = 0.0028856877614164595\n",
      " loss = 0.002885687750953731\n",
      " loss = 0.002885687740669853\n",
      " loss = 0.0028856877305617713\n",
      " loss = 0.0028856877206264757\n",
      " loss = 0.0028856877108610177\n",
      " loss = 0.0028856877012624882\n",
      " loss = 0.0028856876918280363\n",
      " loss = 0.0028856876825548608\n",
      " loss = 0.002885687673440201\n",
      " loss = 0.0028856876644813476\n",
      " loss = 0.0028856876556756362\n",
      " loss = 0.002885687647020451\n",
      " loss = 0.0028856876385132194\n",
      " loss = 0.0028856876301514094\n",
      " loss = 0.0028856876219325407\n",
      " loss = 0.0028856876138541633\n",
      " loss = 0.0028856876059138808\n",
      " loss = 0.002885687598109327\n",
      " loss = 0.002885687590438184\n",
      " loss = 0.0028856875828981742\n",
      " loss = 0.002885687575487053\n",
      " loss = 0.002885687568202619\n",
      " loss = 0.0028856875610427076\n",
      " loss = 0.002885687554005186\n",
      " loss = 0.0028856875470879657\n",
      " loss = 0.0028856875402889885\n",
      " loss = 0.002885687533606233\n",
      " loss = 0.0028856875270377147\n",
      " loss = 0.0028856875205814795\n",
      " loss = 0.002885687514235604\n",
      " loss = 0.0028856875079982065\n",
      " loss = 0.0028856875018674344\n",
      " loss = 0.002885687495841463\n",
      " loss = 0.002885687489918496\n",
      " loss = 0.002885687484096779\n",
      " loss = 0.0028856874783745796\n",
      " loss = 0.0028856874727501963\n",
      " loss = 0.0028856874672219543\n",
      " loss = 0.002885687461788216\n",
      " loss = 0.002885687456447357\n",
      " loss = 0.0028856874511977975\n",
      " loss = 0.002885687446037976\n",
      " loss = 0.002885687440966357\n",
      " loss = 0.002885687435981432\n",
      " loss = 0.002885687431081719\n",
      " loss = 0.002885687426265766\n",
      " loss = 0.0028856874215321317\n",
      " loss = 0.002885687416879418\n",
      " loss = 0.0028856874123062383\n",
      " loss = 0.0028856874078112306\n",
      " loss = 0.0028856874033930608\n",
      " loss = 0.002885687399050418\n",
      " loss = 0.002885687394782008\n",
      " loss = 0.002885687390586562\n",
      " loss = 0.002885687386462833\n",
      " loss = 0.0028856873824095967\n",
      " loss = 0.0028856873784256463\n",
      " loss = 0.0028856873745097987\n",
      " loss = 0.0028856873706608866\n",
      " loss = 0.002885687366877771\n",
      " loss = 0.002885687363159322\n",
      " loss = 0.002885687359504437\n",
      " loss = 0.002885687355912029\n",
      " loss = 0.0028856873523810307\n",
      " loss = 0.002885687348910392\n",
      " loss = 0.002885687345499078\n",
      " loss = 0.0028856873421460785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.002885687338850399\n",
      " loss = 0.0028856873356110516\n",
      " loss = 0.002885687332427081\n",
      " loss = 0.002885687329297537\n",
      " loss = 0.002885687326221487\n",
      " loss = 0.0028856873231980222\n",
      " loss = 0.0028856873202262366\n",
      " loss = 0.0028856873173052555\n",
      " loss = 0.0028856873144342036\n",
      " loss = 0.002885687311612233\n",
      " loss = 0.0028856873088384965\n",
      " loss = 0.002885687306112179\n",
      " loss = 0.002885687303432464\n",
      " loss = 0.0028856873007985545\n",
      " loss = 0.00288568729820967\n",
      " loss = 0.002885687295665039\n",
      " loss = 0.002885687293163908\n",
      " loss = 0.0028856872907055318\n",
      " loss = 0.0028856872882891808\n",
      " loss = 0.0028856872859141327\n",
      " loss = 0.0028856872835796815\n",
      " loss = 0.002885687281285138\n",
      " loss = 0.002885687279029819\n",
      " loss = 0.002885687276813052\n",
      " loss = 0.002885687274634179\n",
      " loss = 0.002885687272492551\n",
      " loss = 0.0028856872703875323\n",
      " loss = 0.002885687268318496\n",
      " loss = 0.0028856872662848276\n",
      " loss = 0.0028856872642859252\n",
      " loss = 0.002885687262321192\n",
      " loss = 0.0028856872603900416\n",
      " loss = 0.0028856872584919063\n",
      " loss = 0.0028856872566262143\n",
      " loss = 0.002885687254792419\n",
      " loss = 0.0028856872529899663\n",
      " loss = 0.0028856872512183266\n",
      " loss = 0.002885687249476971\n",
      " loss = 0.0028856872477653803\n",
      " loss = 0.0028856872460830537\n",
      " loss = 0.0028856872444294824\n",
      " loss = 0.002885687242804173\n",
      " loss = 0.0028856872412066485\n",
      " loss = 0.0028856872396364353\n",
      " loss = 0.00288568723809306\n",
      " loss = 0.0028856872365760713\n",
      " loss = 0.002885687235085011\n",
      " loss = 0.0028856872336194407\n",
      " loss = 0.0028856872321789224\n",
      " loss = 0.0028856872307630272\n",
      " loss = 0.002885687229371338\n",
      " loss = 0.0028856872280034365\n",
      " loss = 0.0028856872266589187\n",
      " loss = 0.0028856872253373873\n",
      " loss = 0.0028856872240384406\n",
      " loss = 0.0028856872227616993\n",
      " loss = 0.002885687221506788\n",
      " loss = 0.0028856872202733213\n",
      " loss = 0.002885687219060944\n",
      " loss = 0.002885687217869289\n",
      " loss = 0.0028856872166980055\n",
      " loss = 0.002885687215546745\n",
      " loss = 0.002885687214415163\n",
      " loss = 0.002885687213302921\n",
      " loss = 0.0028856872122096995\n",
      " loss = 0.0028856872111351576\n",
      " loss = 0.002885687210078988\n",
      " loss = 0.002885687209040872\n",
      " loss = 0.0028856872080205032\n",
      " loss = 0.0028856872070175763\n",
      " loss = 0.0028856872060317915\n",
      " loss = 0.0028856872050628595\n",
      " loss = 0.0028856872041104894\n",
      " loss = 0.002885687203174398\n",
      " loss = 0.0028856872022543097\n",
      " loss = 0.0028856872013499502\n",
      " loss = 0.0028856872004610528\n",
      " loss = 0.002885687199587345\n",
      " loss = 0.0028856871987285745\n",
      " loss = 0.002885687197884482\n",
      " loss = 0.0028856871970548213\n",
      " loss = 0.0028856871962393417\n",
      " loss = 0.0028856871954378023\n",
      " loss = 0.0028856871946499633\n",
      " loss = 0.0028856871938755923\n",
      " loss = 0.002885687193114461\n",
      " loss = 0.0028856871923663373\n",
      " loss = 0.002885687191631005\n",
      " loss = 0.0028856871909082385\n",
      " loss = 0.002885687190197831\n",
      " loss = 0.002885687189499566\n",
      " loss = 0.002885687188813234\n",
      " loss = 0.002885687188138638\n",
      " loss = 0.0028856871874755725\n",
      " loss = 0.0028856871868238407\n",
      " loss = 0.002885687186183252\n",
      " loss = 0.0028856871855536146\n",
      " loss = 0.0028856871849347364\n",
      " loss = 0.0028856871843264366\n",
      " loss = 0.0028856871837285394\n",
      " loss = 0.002885687183140861\n",
      " loss = 0.0028856871825632254\n",
      " loss = 0.002885687181995466\n",
      " loss = 0.002885687181437415\n",
      " loss = 0.002885687180888898\n",
      " loss = 0.0028856871803497595\n",
      " loss = 0.00288568717981984\n",
      " loss = 0.0028856871792989763\n",
      " loss = 0.0028856871787870156\n",
      " loss = 0.002885687178283811\n",
      " loss = 0.002885687177789203\n",
      " loss = 0.002885687177303052\n",
      " loss = 0.0028856871768252095\n",
      " loss = 0.0028856871763555383\n",
      " loss = 0.0028856871758938924\n",
      " loss = 0.0028856871754401403\n",
      " loss = 0.0028856871749941464\n",
      " loss = 0.0028856871745557727\n",
      " loss = 0.002885687174124895\n",
      " loss = 0.00288568717370138\n",
      " loss = 0.0028856871732851064\n",
      " loss = 0.0028856871728759497\n",
      " loss = 0.002885687172473784\n",
      " loss = 0.0028856871720784978\n",
      " loss = 0.0028856871716899627\n",
      " loss = 0.0028856871713080733\n",
      " loss = 0.002885687170932711\n",
      " loss = 0.0028856871705637654\n",
      " loss = 0.002885687170201127\n",
      " loss = 0.0028856871698446874\n",
      " loss = 0.0028856871694943388\n",
      " loss = 0.00288568716914998\n",
      " loss = 0.002885687168811509\n",
      " loss = 0.0028856871684788243\n",
      " loss = 0.002885687168151826\n",
      " loss = 0.0028856871678304163\n",
      " loss = 0.002885687167514501\n",
      " loss = 0.0028856871672039877\n",
      " loss = 0.0028856871668987783\n",
      " loss = 0.002885687166598793\n",
      " loss = 0.0028856871663039303\n",
      " loss = 0.00288568716601411\n",
      " loss = 0.002885687165729243\n",
      " loss = 0.0028856871654492433\n",
      " loss = 0.0028856871651740347\n",
      " loss = 0.0028856871649035284\n",
      " loss = 0.002885687164637646\n",
      " loss = 0.0028856871643763056\n",
      " loss = 0.002885687164119438\n",
      " loss = 0.002885687163866958\n",
      " loss = 0.0028856871636187944\n",
      " loss = 0.002885687163374875\n",
      " loss = 0.0028856871631351214\n",
      " loss = 0.0028856871628994687\n",
      " loss = 0.002885687162667843\n",
      " loss = 0.0028856871624401786\n",
      " loss = 0.0028856871622164075\n",
      " loss = 0.0028856871619964567\n",
      " loss = 0.002885687161780267\n",
      " loss = 0.0028856871615677757\n",
      " loss = 0.002885687161358913\n",
      " loss = 0.002885687161153622\n",
      " loss = 0.0028856871609518426\n",
      " loss = 0.00288568716075351\n",
      " loss = 0.0028856871605585687\n",
      " loss = 0.002885687160366959\n",
      " loss = 0.002885687160178628\n",
      " loss = 0.0028856871599935107\n",
      " loss = 0.0028856871598115607\n",
      " loss = 0.0028856871596327194\n",
      " loss = 0.002885687159456938\n",
      " loss = 0.00288568715928416\n",
      " loss = 0.0028856871591143364\n",
      " loss = 0.0028856871589474148\n",
      " loss = 0.0028856871587833446\n",
      " loss = 0.002885687158622082\n",
      " loss = 0.002885687158463576\n",
      " loss = 0.0028856871583077823\n",
      " loss = 0.0028856871581546453\n",
      " loss = 0.002885687158004126\n",
      " loss = 0.002885687157856185\n",
      " loss = 0.0028856871577107694\n",
      " loss = 0.002885687157567841\n",
      " loss = 0.002885687157427355\n",
      " loss = 0.0028856871572892724\n",
      " loss = 0.0028856871571535476\n",
      " loss = 0.0028856871570201448\n",
      " loss = 0.0028856871568890196\n",
      " loss = 0.0028856871567601384\n",
      " loss = 0.00288568715663346\n",
      " loss = 0.0028856871565089487\n",
      " loss = 0.002885687156386562\n",
      " loss = 0.0028856871562662713\n",
      " loss = 0.002885687156148034\n",
      " loss = 0.0028856871560318195\n",
      " loss = 0.0028856871559175905\n",
      " loss = 0.0028856871558053153\n",
      " loss = 0.002885687155694959\n",
      " loss = 0.0028856871555864873\n",
      " loss = 0.002885687155479871\n",
      " loss = 0.0028856871553750783\n",
      " loss = 0.002885687155272075\n",
      " loss = 0.002885687155170835\n",
      " loss = 0.002885687155071324\n",
      " loss = 0.0028856871549735132\n",
      " loss = 0.0028856871548773753\n",
      " loss = 0.00288568715478288\n",
      " loss = 0.002885687154690003\n",
      " loss = 0.002885687154598713\n",
      " loss = 0.002885687154508979\n",
      " loss = 0.0028856871544207826\n",
      " loss = 0.002885687154334093\n",
      " loss = 0.002885687154248885\n",
      " loss = 0.002885687154165134\n",
      " loss = 0.0028856871540828164\n",
      " loss = 0.002885687154001902\n",
      " loss = 0.002885687153922373\n",
      " loss = 0.0028856871538442052\n",
      " loss = 0.002885687153767371\n",
      " loss = 0.002885687153691851\n",
      " loss = 0.0028856871536176226\n",
      " loss = 0.0028856871535446636\n",
      " loss = 0.0028856871534729484\n",
      " loss = 0.0028856871534024614\n",
      " loss = 0.0028856871533331795\n",
      " loss = 0.0028856871532650812\n",
      " loss = 0.0028856871531981474\n",
      " loss = 0.0028856871531323584\n",
      " loss = 0.0028856871530676914\n",
      " loss = 0.0028856871530041346\n",
      " loss = 0.0028856871529416594\n",
      " loss = 0.0028856871528802567\n",
      " loss = 0.0028856871528198996\n",
      " loss = 0.0028856871527605755\n",
      " loss = 0.0028856871527022663\n",
      " loss = 0.002885687152644955\n",
      " loss = 0.002885687152588621\n",
      " loss = 0.0028856871525332495\n",
      " loss = 0.002885687152478825\n",
      " loss = 0.002885687152425331\n",
      " loss = 0.002885687152372751\n",
      " loss = 0.0028856871523210755\n",
      " loss = 0.0028856871522702767\n",
      " loss = 0.0028856871522203484\n",
      " loss = 0.0028856871521712735\n",
      " loss = 0.002885687152123039\n",
      " loss = 0.002885687152075627\n",
      " loss = 0.002885687152029024\n",
      " loss = 0.002885687151983221\n",
      " loss = 0.002885687151938196\n",
      " loss = 0.002885687151893944\n",
      " loss = 0.002885687151850451\n",
      " loss = 0.002885687151807699\n",
      " loss = 0.00288568715176568\n",
      " loss = 0.0028856871517243766\n",
      " loss = 0.002885687151683779\n",
      " loss = 0.002885687151643874\n",
      " loss = 0.002885687151604653\n",
      " loss = 0.002885687151566104\n",
      " loss = 0.0028856871515282123\n",
      " loss = 0.002885687151490971\n",
      " loss = 0.0028856871514543643\n",
      " loss = 0.00288568715141838\n",
      " loss = 0.0028856871513830143\n",
      " loss = 0.0028856871513482526\n",
      " loss = 0.0028856871513140868\n",
      " loss = 0.0028856871512805047\n",
      " loss = 0.0028856871512474955\n",
      " loss = 0.0028856871512150475\n",
      " loss = 0.0028856871511831585\n",
      " loss = 0.0028856871511518138\n",
      " loss = 0.002885687151121004\n",
      " loss = 0.002885687151090722\n",
      " loss = 0.002885687151060958\n",
      " loss = 0.002885687151031698\n",
      " loss = 0.0028856871510029424\n",
      " loss = 0.0028856871509746786\n",
      " loss = 0.002885687150946898\n",
      " loss = 0.002885687150919591\n",
      " loss = 0.002885687150892753\n",
      " loss = 0.0028856871508663685\n",
      " loss = 0.002885687150840442\n",
      " loss = 0.0028856871508149517\n",
      " loss = 0.0028856871507899036\n",
      " loss = 0.0028856871507652792\n",
      " loss = 0.002885687150741078\n",
      " loss = 0.0028856871507172894\n",
      " loss = 0.002885687150693908\n",
      " loss = 0.002885687150670924\n",
      " loss = 0.0028856871506483363\n",
      " loss = 0.0028856871506261345\n",
      " loss = 0.002885687150604312\n",
      " loss = 0.002885687150582862\n",
      " loss = 0.0028856871505617727\n",
      " loss = 0.0028856871505410528\n",
      " loss = 0.0028856871505206867\n",
      " loss = 0.002885687150500666\n",
      " loss = 0.0028856871504809836\n",
      " loss = 0.0028856871504616454\n",
      " loss = 0.0028856871504426306\n",
      " loss = 0.0028856871504239455\n",
      " loss = 0.0028856871504055782\n",
      " loss = 0.0028856871503875237\n",
      " loss = 0.00288568715036978\n",
      " loss = 0.00288568715035234\n",
      " loss = 0.0028856871503351927\n",
      " loss = 0.002885687150318347\n",
      " loss = 0.002885687150301783\n",
      " loss = 0.0028856871502855055\n",
      " loss = 0.002885687150269504\n",
      " loss = 0.0028856871502537765\n",
      " loss = 0.002885687150238318\n",
      " loss = 0.0028856871502231257\n",
      " loss = 0.00288568715020819\n",
      " loss = 0.0028856871501935113\n",
      " loss = 0.0028856871501790828\n",
      " loss = 0.0028856871501649023\n",
      " loss = 0.002885687150150963\n",
      " loss = 0.0028856871501372625\n",
      " loss = 0.0028856871501237976\n",
      " loss = 0.0028856871501105616\n",
      " loss = 0.0028856871500975495\n",
      " loss = 0.0028856871500847633\n",
      " loss = 0.0028856871500721913\n",
      " loss = 0.0028856871500598383\n",
      " loss = 0.0028856871500476935\n",
      " loss = 0.0028856871500357604\n",
      " loss = 0.0028856871500240284\n",
      " loss = 0.0028856871500124977\n",
      " loss = 0.002885687150001164\n",
      " loss = 0.0028856871499900235\n",
      " loss = 0.002885687149979072\n",
      " loss = 0.0028856871499683104\n",
      " loss = 0.0028856871499577342\n",
      " loss = 0.0028856871499473346\n",
      " loss = 0.0028856871499371144\n",
      " loss = 0.0028856871499270695\n",
      " loss = 0.0028856871499171963\n",
      " loss = 0.0028856871499074897\n",
      " loss = 0.002885687149897954\n",
      " loss = 0.002885687149888577\n",
      " loss = 0.002885687149879362\n",
      " loss = 0.002885687149870303\n",
      " loss = 0.0028856871498614\n",
      " loss = 0.0028856871498526507\n",
      " loss = 0.0028856871498440483\n",
      " loss = 0.002885687149835597\n",
      " loss = 0.002885687149827284\n",
      " loss = 0.0028856871498191155\n",
      " loss = 0.0028856871498110876\n",
      " loss = 0.0028856871498031986\n",
      " loss = 0.0028856871497954417\n",
      " loss = 0.002885687149787821\n",
      " loss = 0.002885687149780324\n",
      " loss = 0.0028856871497729593\n",
      " loss = 0.0028856871497657216\n",
      " loss = 0.002885687149758605\n",
      " loss = 0.0028856871497516126\n",
      " loss = 0.002885687149744738\n",
      " loss = 0.002885687149737979\n",
      " loss = 0.0028856871497313402\n",
      " loss = 0.002885687149724813\n",
      " loss = 0.0028856871497183957\n",
      " loss = 0.0028856871497120883\n",
      " loss = 0.0028856871497058936\n",
      " loss = 0.002885687149699798\n",
      " loss = 0.00288568714969381\n",
      " loss = 0.0028856871496879223\n",
      " loss = 0.002885687149682137\n",
      " loss = 0.00288568714967645\n",
      " loss = 0.0028856871496708617\n",
      " loss = 0.0028856871496653657\n",
      " loss = 0.002885687149659969\n",
      " loss = 0.0028856871496546603\n",
      " loss = 0.002885687149649444\n",
      " loss = 0.0028856871496443174\n",
      " loss = 0.0028856871496392737\n",
      " loss = 0.002885687149634321\n",
      " loss = 0.0028856871496294517\n",
      " loss = 0.002885687149624666\n",
      " loss = 0.0028856871496199614\n",
      " loss = 0.0028856871496153375\n",
      " loss = 0.0028856871496107934\n",
      " loss = 0.0028856871496063265\n",
      " loss = 0.002885687149601934\n",
      " loss = 0.0028856871495976212\n",
      " loss = 0.002885687149593379\n",
      " loss = 0.002885687149589209\n",
      " loss = 0.0028856871495851126\n",
      " loss = 0.002885687149581084\n",
      " loss = 0.0028856871495771233\n",
      " loss = 0.0028856871495732336\n",
      " loss = 0.0028856871495694077\n",
      " loss = 0.002885687149565647\n",
      " loss = 0.002885687149561953\n",
      " loss = 0.002885687149558323\n",
      " loss = 0.002885687149554751\n",
      " loss = 0.002885687149551241\n",
      " loss = 0.002885687149547793\n",
      " loss = 0.0028856871495444004\n",
      " loss = 0.0028856871495410675\n",
      " loss = 0.0028856871495377932\n",
      " loss = 0.0028856871495345766\n",
      " loss = 0.002885687149531412\n",
      " loss = 0.002885687149528299\n",
      " loss = 0.0028856871495252434\n",
      " loss = 0.002885687149522237\n",
      " loss = 0.0028856871495192863\n",
      " loss = 0.0028856871495163833\n",
      " loss = 0.00288568714951353\n",
      " loss = 0.0028856871495107263\n",
      " loss = 0.002885687149507969\n",
      " loss = 0.002885687149505261\n",
      " loss = 0.0028856871495025987\n",
      " loss = 0.002885687149499979\n",
      " loss = 0.002885687149497409\n",
      " loss = 0.0028856871494948788\n",
      " loss = 0.002885687149492393\n",
      " loss = 0.002885687149489948\n",
      " loss = 0.0028856871494875487\n",
      " loss = 0.002885687149485188\n",
      " loss = 0.002885687149482868\n",
      " loss = 0.0028856871494805877\n",
      " loss = 0.002885687149478346\n",
      " loss = 0.0028856871494761425\n",
      " loss = 0.0028856871494739775\n",
      " loss = 0.0028856871494718486\n",
      " loss = 0.0028856871494697582\n",
      " loss = 0.002885687149467702\n",
      " loss = 0.00288568714946568\n",
      " loss = 0.002885687149463691\n",
      " loss = 0.002885687149461742\n",
      " loss = 0.002885687149459822\n",
      " loss = 0.0028856871494579365\n",
      " loss = 0.002885687149456081\n",
      " loss = 0.00288568714945426\n",
      " loss = 0.0028856871494524683\n",
      " loss = 0.002885687149450707\n",
      " loss = 0.002885687149448977\n",
      " loss = 0.0028856871494472745\n",
      " loss = 0.002885687149445605\n",
      " loss = 0.00288568714944396\n",
      " loss = 0.002885687149442346\n",
      " loss = 0.0028856871494407615\n",
      " loss = 0.0028856871494391963\n",
      " loss = 0.002885687149437663\n",
      " loss = 0.002885687149436156\n",
      " loss = 0.0028856871494346743\n",
      " loss = 0.002885687149433221\n",
      " loss = 0.0028856871494317843\n",
      " loss = 0.0028856871494303818\n",
      " loss = 0.002885687149428995\n",
      " loss = 0.0028856871494276374\n",
      " loss = 0.002885687149426303\n",
      " loss = 0.0028856871494249885\n",
      " loss = 0.0028856871494236966\n",
      " loss = 0.002885687149422425\n",
      " loss = 0.00288568714942118\n",
      " loss = 0.0028856871494199543\n",
      " loss = 0.0028856871494187504\n",
      " loss = 0.0028856871494175643\n",
      " loss = 0.0028856871494164034\n",
      " loss = 0.0028856871494152563\n",
      " loss = 0.0028856871494141343\n",
      " loss = 0.0028856871494130276\n",
      " loss = 0.0028856871494119416\n",
      " loss = 0.0028856871494108735\n",
      " loss = 0.0028856871494098244\n",
      " loss = 0.002885687149408794\n",
      " loss = 0.002885687149407777\n",
      " loss = 0.002885687149406783\n",
      " loss = 0.002885687149405801\n",
      " loss = 0.002885687149404839\n",
      " loss = 0.002885687149403894\n",
      " loss = 0.002885687149402963\n",
      " loss = 0.0028856871494020472\n",
      " loss = 0.0028856871494011504\n",
      " loss = 0.002885687149400267\n",
      " loss = 0.002885687149399396\n",
      " loss = 0.0028856871493985444\n",
      " loss = 0.0028856871493977048\n",
      " loss = 0.002885687149396881\n",
      " loss = 0.0028856871493960707\n",
      " loss = 0.002885687149395274\n",
      " loss = 0.002885687149394492\n",
      " loss = 0.002885687149393722\n",
      " loss = 0.0028856871493929638\n",
      " loss = 0.0028856871493922213\n",
      " loss = 0.0028856871493914893\n",
      " loss = 0.002885687149390772\n",
      " loss = 0.0028856871493900646\n",
      " loss = 0.002885687149389371\n",
      " loss = 0.002885687149388692\n",
      " loss = 0.00288568714938802\n",
      " loss = 0.0028856871493873624\n",
      " loss = 0.0028856871493867127\n",
      " loss = 0.002885687149386078\n",
      " loss = 0.0028856871493854507\n",
      " loss = 0.002885687149384838\n",
      " loss = 0.002885687149384231\n",
      " loss = 0.00288568714938364\n",
      " loss = 0.002885687149383052\n",
      " loss = 0.002885687149382478\n",
      " loss = 0.002885687149381917\n",
      " loss = 0.0028856871493813606\n",
      " loss = 0.002885687149380816\n",
      " loss = 0.002885687149380281\n",
      " loss = 0.002885687149379754\n",
      " loss = 0.0028856871493792365\n",
      " loss = 0.0028856871493787286\n",
      " loss = 0.0028856871493782273\n",
      " loss = 0.0028856871493777346\n",
      " loss = 0.002885687149377251\n",
      " loss = 0.0028856871493767784\n",
      " loss = 0.0028856871493763104\n",
      " loss = 0.0028856871493758494\n",
      " loss = 0.0028856871493754023\n",
      " loss = 0.0028856871493749547\n",
      " loss = 0.0028856871493745224\n",
      " loss = 0.0028856871493740943\n",
      " loss = 0.0028856871493736736\n",
      " loss = 0.0028856871493732577\n",
      " loss = 0.002885687149372855\n",
      " loss = 0.002885687149372452\n",
      " loss = 0.0028856871493720612\n",
      " loss = 0.002885687149371673\n",
      " loss = 0.002885687149371294\n",
      " loss = 0.002885687149370921\n",
      " loss = 0.0028856871493705568\n",
      " loss = 0.0028856871493701934\n",
      " loss = 0.00288568714936984\n",
      " loss = 0.0028856871493694912\n",
      " loss = 0.0028856871493691486\n",
      " loss = 0.0028856871493688134\n",
      " loss = 0.0028856871493684834\n",
      " loss = 0.002885687149368158\n",
      " loss = 0.0028856871493678376\n",
      " loss = 0.0028856871493675254\n",
      " loss = 0.002885687149367215\n",
      " loss = 0.002885687149366911\n",
      " loss = 0.002885687149366614\n",
      " loss = 0.0028856871493663206\n",
      " loss = 0.002885687149366034\n",
      " loss = 0.002885687149365753\n",
      " loss = 0.002885687149365471\n",
      " loss = 0.0028856871493652\n",
      " loss = 0.0028856871493649306\n",
      " loss = 0.002885687149364664\n",
      " loss = 0.0028856871493644063\n",
      " loss = 0.002885687149364151\n",
      " loss = 0.0028856871493639\n",
      " loss = 0.002885687149363652\n",
      " loss = 0.0028856871493634097\n",
      " loss = 0.0028856871493631716\n",
      " loss = 0.0028856871493629387\n",
      " loss = 0.002885687149362707\n",
      " loss = 0.0028856871493624808\n",
      " loss = 0.002885687149362259\n",
      " loss = 0.002885687149362039\n",
      " loss = 0.002885687149361827\n",
      " loss = 0.002885687149361614\n",
      " loss = 0.0028856871493614087\n",
      " loss = 0.0028856871493612006\n",
      " loss = 0.0028856871493610045\n",
      " loss = 0.0028856871493608046\n",
      " loss = 0.002885687149360611\n",
      " loss = 0.0028856871493604217\n",
      " loss = 0.0028856871493602347\n",
      " loss = 0.0028856871493600517\n",
      " loss = 0.002885687149359868\n",
      " loss = 0.0028856871493596918\n",
      " loss = 0.0028856871493595174\n",
      " loss = 0.0028856871493593466\n",
      " loss = 0.0028856871493591783\n",
      " loss = 0.0028856871493590126\n",
      " loss = 0.0028856871493588452\n",
      " loss = 0.0028856871493586882\n",
      " loss = 0.002885687149358529\n",
      " loss = 0.0028856871493583743\n",
      " loss = 0.0028856871493582225\n",
      " loss = 0.0028856871493580737\n",
      " loss = 0.0028856871493579263\n",
      " loss = 0.002885687149357782\n",
      " loss = 0.0028856871493576396\n",
      " loss = 0.0028856871493575\n",
      " loss = 0.0028856871493573616\n",
      " loss = 0.0028856871493572267\n",
      " loss = 0.0028856871493570966\n",
      " loss = 0.0028856871493569665\n",
      " loss = 0.002885687149356838\n",
      " loss = 0.002885687149356712\n",
      " loss = 0.0028856871493565884\n",
      " loss = 0.0028856871493564648\n",
      " loss = 0.0028856871493563455\n",
      " loss = 0.002885687149356229\n",
      " loss = 0.0028856871493561143\n",
      " loss = 0.0028856871493560016\n",
      " loss = 0.0028856871493558875\n",
      " loss = 0.002885687149355777\n",
      " loss = 0.0028856871493556716\n",
      " loss = 0.0028856871493555653\n",
      " loss = 0.0028856871493554604\n",
      " loss = 0.0028856871493553584\n",
      " loss = 0.0028856871493552596\n",
      " loss = 0.0028856871493551546\n",
      " loss = 0.0028856871493550627\n",
      " loss = 0.0028856871493549655\n",
      " loss = 0.0028856871493548723\n",
      " loss = 0.0028856871493547777\n",
      " loss = 0.002885687149354687\n",
      " loss = 0.0028856871493545995\n",
      " loss = 0.0028856871493545136\n",
      " loss = 0.002885687149354427\n",
      " loss = 0.0028856871493543428\n",
      " loss = 0.0028856871493542586\n",
      " loss = 0.002885687149354175\n",
      " loss = 0.002885687149354095\n",
      " loss = 0.002885687149354015\n",
      " loss = 0.002885687149353939\n",
      " loss = 0.00288568714935386\n",
      " loss = 0.0028856871493537885\n",
      " loss = 0.002885687149353714\n",
      " loss = 0.0028856871493536398\n",
      " loss = 0.0028856871493535704\n",
      " loss = 0.0028856871493535005\n",
      " loss = 0.0028856871493534325\n",
      " loss = 0.0028856871493533635\n",
      " loss = 0.0028856871493532976\n",
      " loss = 0.002885687149353233\n",
      " loss = 0.002885687149353169\n",
      " loss = 0.0028856871493531046\n",
      " loss = 0.0028856871493530426\n",
      " loss = 0.002885687149352983\n",
      " loss = 0.002885687149352921\n",
      " loss = 0.0028856871493528626\n",
      " loss = 0.0028856871493528023\n",
      " loss = 0.0028856871493527464\n",
      " loss = 0.002885687149352692\n",
      " loss = 0.002885687149352635\n",
      " loss = 0.002885687149352583\n",
      " loss = 0.002885687149352528\n",
      " loss = 0.002885687149352475\n",
      " loss = 0.0028856871493524255\n",
      " loss = 0.002885687149352374\n",
      " loss = 0.0028856871493523253\n",
      " loss = 0.002885687149352278\n",
      " loss = 0.0028856871493522273\n",
      " loss = 0.002885687149352182\n",
      " loss = 0.0028856871493521336\n",
      " loss = 0.00288568714935209\n",
      " loss = 0.0028856871493520464\n",
      " loss = 0.002885687149352002\n",
      " loss = 0.0028856871493519566\n",
      " loss = 0.002885687149351915\n",
      " loss = 0.0028856871493518725\n",
      " loss = 0.0028856871493518335\n",
      " loss = 0.002885687149351793\n",
      " loss = 0.002885687149351752\n",
      " loss = 0.0028856871493517116\n",
      " loss = 0.0028856871493516756\n",
      " loss = 0.002885687149351636\n",
      " loss = 0.0028856871493515997\n",
      " loss = 0.0028856871493515646\n",
      " loss = 0.0028856871493515286\n",
      " loss = 0.002885687149351494\n",
      " loss = 0.0028856871493514605\n",
      " loss = 0.002885687149351426\n",
      " loss = 0.002885687149351393\n",
      " loss = 0.002885687149351358\n",
      " loss = 0.0028856871493513243\n",
      " loss = 0.002885687149351294\n",
      " loss = 0.002885687149351262\n",
      " loss = 0.002885687149351232\n",
      " loss = 0.002885687149351202\n",
      " loss = 0.0028856871493511725\n",
      " loss = 0.0028856871493511452\n",
      " loss = 0.0028856871493511157\n",
      " loss = 0.0028856871493510875\n",
      " loss = 0.002885687149351057\n",
      " loss = 0.002885687149351032\n",
      " loss = 0.002885687149351006\n",
      " loss = 0.0028856871493509787\n",
      " loss = 0.0028856871493509535\n",
      " loss = 0.002885687149350928\n",
      " loss = 0.002885687149350901\n",
      " loss = 0.0028856871493508807\n",
      " loss = 0.002885687149350855\n",
      " loss = 0.002885687149350832\n",
      " loss = 0.0028856871493508083\n",
      " loss = 0.0028856871493507857\n",
      " loss = 0.002885687149350765\n",
      " loss = 0.0028856871493507406\n",
      " loss = 0.0028856871493507185\n",
      " loss = 0.0028856871493506994\n",
      " loss = 0.002885687149350676\n",
      " loss = 0.002885687149350659\n",
      " loss = 0.002885687149350634\n",
      " loss = 0.002885687149350618\n",
      " loss = 0.002885687149350598\n",
      " loss = 0.002885687149350575\n",
      " loss = 0.00288568714935056\n",
      " loss = 0.0028856871493505394\n",
      " loss = 0.0028856871493505225\n",
      " loss = 0.002885687149350503\n",
      " loss = 0.002885687149350486\n",
      " loss = 0.00288568714935047\n",
      " loss = 0.0028856871493504526\n",
      " loss = 0.002885687149350436\n",
      " loss = 0.0028856871493504184\n",
      " loss = 0.002885687149350403\n",
      " loss = 0.0028856871493503854\n",
      " loss = 0.0028856871493503694\n",
      " loss = 0.0028856871493503555\n",
      " loss = 0.0028856871493503416\n",
      " loss = 0.002885687149350326\n",
      " loss = 0.0028856871493503104\n",
      " loss = 0.0028856871493502965\n",
      " loss = 0.0028856871493502826\n",
      " loss = 0.002885687149350268\n",
      " loss = 0.002885687149350255\n",
      " loss = 0.0028856871493502414\n",
      " loss = 0.002885687149350229\n",
      " loss = 0.0028856871493502167\n",
      " loss = 0.0028856871493502033\n",
      " loss = 0.0028856871493501894\n",
      " loss = 0.002885687149350177\n",
      " loss = 0.0028856871493501664\n",
      " loss = 0.0028856871493501577\n",
      " loss = 0.002885687149350143\n",
      " loss = 0.00288568714935013\n",
      " loss = 0.00288568714935012\n",
      " loss = 0.0028856871493501074\n",
      " loss = 0.002885687149350097\n",
      " loss = 0.0028856871493500857\n",
      " loss = 0.002885687149350078\n",
      " loss = 0.0028856871493500675\n",
      " loss = 0.002885687149350059\n",
      " loss = 0.0028856871493500484\n",
      " loss = 0.0028856871493500367\n",
      " loss = 0.0028856871493500255\n",
      " loss = 0.002885687149350018\n",
      " loss = 0.002885687149350007\n",
      " loss = 0.002885687149349998\n",
      " loss = 0.002885687149349991\n",
      " loss = 0.002885687149349982\n",
      " loss = 0.002885687149349972\n",
      " loss = 0.002885687149349964\n",
      " loss = 0.0028856871493499556\n",
      " loss = 0.0028856871493499483\n",
      " loss = 0.0028856871493499396\n",
      " loss = 0.0028856871493499322\n",
      " loss = 0.002885687149349925\n",
      " loss = 0.002885687149349915\n",
      " loss = 0.0028856871493499097\n",
      " loss = 0.002885687149349901\n",
      " loss = 0.0028856871493498928\n",
      " loss = 0.0028856871493498845\n",
      " loss = 0.002885687149349878\n",
      " loss = 0.002885687149349872\n",
      " loss = 0.0028856871493498667\n",
      " loss = 0.002885687149349856\n",
      " loss = 0.002885687149349851\n",
      " loss = 0.0028856871493498438\n",
      " loss = 0.0028856871493498372\n",
      " loss = 0.0028856871493498316\n",
      " loss = 0.0028856871493498273\n",
      " loss = 0.0028856871493498186\n",
      " loss = 0.0028856871493498147\n",
      " loss = 0.002885687149349808\n",
      " loss = 0.002885687149349803\n",
      " loss = 0.0028856871493497973\n",
      " loss = 0.0028856871493497917\n",
      " loss = 0.0028856871493497865\n",
      " loss = 0.0028856871493497813\n",
      " loss = 0.002885687149349776\n",
      " loss = 0.0028856871493497705\n",
      " loss = 0.0028856871493497657\n",
      " loss = 0.0028856871493497622\n",
      " loss = 0.0028856871493497557\n",
      " loss = 0.0028856871493497505\n",
      " loss = 0.002885687149349745\n",
      " loss = 0.0028856871493497397\n",
      " loss = 0.0028856871493497358\n",
      " loss = 0.002885687149349731\n",
      " loss = 0.002885687149349727\n",
      " loss = 0.002885687149349723\n",
      " loss = 0.002885687149349717\n",
      " loss = 0.0028856871493497136\n",
      " loss = 0.0028856871493497106\n",
      " loss = 0.002885687149349709\n",
      " loss = 0.002885687149349704\n",
      " loss = 0.002885687149349697\n",
      " loss = 0.0028856871493496963\n",
      " loss = 0.002885687149349691\n",
      " loss = 0.002885687149349686\n",
      " loss = 0.0028856871493496824\n",
      " loss = 0.0028856871493496794\n",
      " loss = 0.0028856871493496737\n",
      " loss = 0.0028856871493496733\n",
      " loss = 0.00288568714934967\n",
      " loss = 0.0028856871493496655\n",
      " loss = 0.002885687149349661\n",
      " loss = 0.0028856871493496616\n",
      " loss = 0.0028856871493496573\n",
      " loss = 0.0028856871493496534\n",
      " loss = 0.002885687149349649\n",
      " loss = 0.0028856871493496477\n",
      " loss = 0.0028856871493496425\n",
      " loss = 0.002885687149349641\n",
      " loss = 0.0028856871493496404\n",
      " loss = 0.0028856871493496343\n",
      " loss = 0.002885687149349631\n",
      " loss = 0.002885687149349631\n",
      " loss = 0.0028856871493496278\n",
      " loss = 0.0028856871493496243\n",
      " loss = 0.0028856871493496204\n",
      " loss = 0.0028856871493496187\n",
      " loss = 0.0028856871493496195\n",
      " loss = 0.002885687149349613\n",
      " loss = 0.002885687149349609\n",
      " loss = 0.002885687149349608\n",
      " loss = 0.0028856871493496065\n",
      " loss = 0.0028856871493496057\n",
      " loss = 0.0028856871493496044\n",
      " loss = 0.0028856871493496013\n",
      " loss = 0.0028856871493495996\n",
      " loss = 0.0028856871493495966\n",
      " loss = 0.0028856871493495953\n",
      " loss = 0.0028856871493495896\n",
      " loss = 0.002885687149349589\n",
      " loss = 0.0028856871493495883\n",
      " loss = 0.002885687149349586\n",
      " loss = 0.002885687149349584\n",
      " loss = 0.002885687149349581\n",
      " loss = 0.0028856871493495827\n",
      " loss = 0.0028856871493495783\n",
      " loss = 0.002885687149349575\n",
      " loss = 0.002885687149349575\n",
      " loss = 0.0028856871493495723\n",
      " loss = 0.002885687149349571\n",
      " loss = 0.002885687149349569\n",
      " loss = 0.002885687149349568\n",
      " loss = 0.002885687149349569\n",
      " loss = 0.0028856871493495636\n",
      " loss = 0.002885687149349564\n",
      " loss = 0.0028856871493495623\n",
      " loss = 0.0028856871493495593\n",
      " loss = 0.0028856871493495597\n",
      " loss = 0.0028856871493495562\n",
      " loss = 0.002885687149349557\n",
      " loss = 0.002885687149349555\n",
      " loss = 0.0028856871493495528\n",
      " loss = 0.0028856871493495523\n",
      " loss = 0.0028856871493495506\n",
      " loss = 0.002885687149349549\n",
      " loss = 0.0028856871493495484\n",
      " loss = 0.002885687149349546\n",
      " loss = 0.002885687149349547\n",
      " loss = 0.0028856871493495436\n",
      " loss = 0.002885687149349544\n",
      " loss = 0.00288568714934954\n",
      " loss = 0.0028856871493495393\n",
      " loss = 0.00288568714934954\n",
      " loss = 0.002885687149349536\n",
      " loss = 0.002885687149349538\n",
      " loss = 0.0028856871493495384\n",
      " loss = 0.0028856871493495337\n",
      " loss = 0.0028856871493495332\n",
      " loss = 0.0028856871493495324\n",
      " loss = 0.0028856871493495315\n",
      " loss = 0.0028856871493495293\n",
      " loss = 0.0028856871493495298\n",
      " loss = 0.0028856871493495298\n",
      " loss = 0.0028856871493495263\n",
      " loss = 0.0028856871493495267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.0028856871493495233\n",
      " loss = 0.0028856871493495263\n",
      " loss = 0.0028856871493495246\n",
      " loss = 0.0028856871493495237\n",
      " loss = 0.0028856871493495237\n",
      " loss = 0.0028856871493495215\n",
      " loss = 0.002885687149349521\n",
      " loss = 0.002885687149349521\n",
      " loss = 0.002885687149349518\n",
      " loss = 0.0028856871493495194\n",
      " loss = 0.002885687149349515\n",
      " loss = 0.002885687149349514\n",
      " loss = 0.0028856871493495137\n",
      " loss = 0.0028856871493495133\n",
      " loss = 0.0028856871493495176\n",
      " loss = 0.0028856871493495133\n",
      " loss = 0.0028856871493495155\n",
      " loss = 0.002885687149349511\n",
      " loss = 0.0028856871493495124\n",
      " loss = 0.0028856871493495094\n",
      " loss = 0.00288568714934951\n",
      " loss = 0.002885687149349509\n",
      " loss = 0.0028856871493495085\n",
      " loss = 0.002885687149349509\n",
      " loss = 0.002885687149349508\n",
      " loss = 0.0028856871493495076\n",
      " loss = 0.0028856871493495063\n",
      " loss = 0.002885687149349504\n",
      " loss = 0.0028856871493495037\n",
      " loss = 0.0028856871493495055\n",
      " loss = 0.0028856871493495046\n",
      " loss = 0.002885687149349504\n",
      " loss = 0.0028856871493495037\n",
      " loss = 0.0028856871493495037\n",
      " loss = 0.0028856871493495037\n",
      " loss = 0.002885687149349502\n",
      " loss = 0.0028856871493495007\n",
      " loss = 0.002885687149349503\n",
      " loss = 0.002885687149349499\n",
      " loss = 0.0028856871493494972\n",
      " loss = 0.0028856871493495003\n",
      " loss = 0.0028856871493495\n",
      " loss = 0.002885687149349497\n",
      " loss = 0.002885687149349497\n",
      " loss = 0.0028856871493494972\n",
      " loss = 0.0028856871493494955\n",
      " loss = 0.002885687149349496\n",
      " loss = 0.0028856871493494933\n",
      " loss = 0.0028856871493494933\n",
      " loss = 0.002885687149349495\n",
      " loss = 0.0028856871493494933\n",
      " loss = 0.0028856871493494946\n",
      " loss = 0.002885687149349495\n",
      " loss = 0.002885687149349492\n",
      " loss = 0.002885687149349491\n",
      " loss = 0.0028856871493494916\n",
      " loss = 0.0028856871493494907\n",
      " loss = 0.0028856871493494916\n",
      " loss = 0.0028856871493494903\n",
      " loss = 0.0028856871493494933\n",
      " loss = 0.0028856871493494903\n",
      " loss = 0.0028856871493494925\n",
      " loss = 0.0028856871493494886\n",
      " loss = 0.0028856871493494907\n",
      " loss = 0.0028856871493494916\n",
      " loss = 0.002885687149349489\n",
      " loss = 0.0028856871493494886\n",
      " loss = 0.002885687149349488\n",
      " loss = 0.0028856871493494894\n",
      " loss = 0.0028856871493494886\n",
      " loss = 0.002885687149349489\n",
      " loss = 0.002885687149349487\n",
      " loss = 0.002885687149349488\n",
      " loss = 0.0028856871493494864\n",
      " loss = 0.002885687149349487\n",
      " loss = 0.0028856871493494864\n",
      " loss = 0.002885687149349486\n",
      " loss = 0.002885687149349486\n",
      " loss = 0.002885687149349486\n",
      " loss = 0.0028856871493494855\n",
      " loss = 0.0028856871493494864\n",
      " loss = 0.0028856871493494864\n",
      " loss = 0.0028856871493494855\n",
      " loss = 0.0028856871493494847\n",
      " loss = 0.002885687149349484\n",
      " loss = 0.0028856871493494864\n",
      " loss = 0.0028856871493494847\n",
      " loss = 0.0028856871493494855\n",
      " loss = 0.0028856871493494834\n",
      " loss = 0.0028856871493494834\n",
      " loss = 0.002885687149349484\n",
      " loss = 0.002885687149349483\n",
      " loss = 0.002885687149349483\n",
      " loss = 0.0028856871493494847\n",
      " loss = 0.002885687149349485\n",
      " loss = 0.0028856871493494825\n",
      " loss = 0.0028856871493494847\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.002885687149349483\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.002885687149349483\n",
      " loss = 0.0028856871493494786\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.0028856871493494825\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.0028856871493494803\n",
      " loss = 0.0028856871493494808\n",
      " loss = 0.0028856871493494795\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.0028856871493494803\n",
      " loss = 0.0028856871493494795\n",
      " loss = 0.0028856871493494795\n",
      " loss = 0.0028856871493494808\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.0028856871493494803\n",
      " loss = 0.0028856871493494795\n",
      " loss = 0.002885687149349481\n",
      " loss = 0.0028856871493494795\n",
      " loss = 0.0028856871493494786\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494803\n",
      " loss = 0.0028856871493494764\n",
      " loss = 0.00288568714934948\n",
      " loss = 0.0028856871493494773\n",
      " loss = 0.0028856871493494808\n",
      " loss = 0.00288568714934948\n",
      " loss = 0.002885687149349479\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.002885687149349479\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494795\n",
      " loss = 0.0028856871493494786\n",
      " loss = 0.0028856871493494773\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494786\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.002885687149349478\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494773\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494786\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494764\n",
      " loss = 0.0028856871493494773\n",
      " loss = 0.0028856871493494786\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494764\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494764\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494773\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494764\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349477\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.002885687149349477\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494777\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349469\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.002885687149349476\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349469\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349469\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349469\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349469\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349469\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494764\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494686\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494756\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494686\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349469\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349471\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494695\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.00288568714934947\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494712\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494747\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349474\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494704\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349473\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.002885687149349475\n",
      " loss = 0.0028856871493494743\n",
      " loss = 0.0028856871493494734\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.002885687149349472\n",
      " loss = 0.0028856871493494717\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n",
      " loss = 0.0028856871493494725\n"
     ]
    }
   ],
   "source": [
    "rg=reg_NN()\n",
    "rg.batch_gredient_desent(regx_scaled,regy_scaled,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ee4366b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rg.epoch_track,rg.cost_track)\n",
    "plt.title(\"Batch Gredient Descent\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f13e615a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.004087097611736301\n",
      " loss = 0.02575985110430153\n",
      " loss = 0.025459687274376464\n",
      " loss = 0.0251630210713533\n",
      " loss = 0.003836703328301449\n",
      " loss = 0.0038121045119248373\n",
      " loss = 0.003787663409587259\n",
      " loss = 0.02465255926207829\n",
      " loss = 0.0243652980325594\n",
      " loss = 0.003621569963888191\n",
      " loss = 0.003598350463510625\n",
      " loss = 0.003575279833732563\n",
      " loss = 0.003552357120078393\n",
      " loss = 0.003529581374142154\n",
      " loss = 0.0035069516536627675\n",
      " loss = 0.023668851654278806\n",
      " loss = 0.02339305296067769\n",
      " loss = 0.02312046797549347\n",
      " loss = 0.0032855023187480384\n",
      " loss = 0.02278652030263861\n",
      " loss = 0.022521002881260486\n",
      " loss = 0.0031374992362297126\n",
      " loss = 0.0031173833292409267\n",
      " loss = 0.0221343739655442\n",
      " loss = 0.003035986531356387\n",
      " loss = 0.0030165214675955715\n",
      " loss = 0.021755328015423174\n",
      " loss = 0.02150182644994425\n",
      " loss = 0.0028783573443316585\n",
      " loss = 0.02119302262464407\n",
      " loss = 0.020946073271988525\n",
      " loss = 0.020702001455333446\n",
      " loss = 0.0026894488570485034\n",
      " loss = 0.002672205600848124\n",
      " loss = 0.0203505147969961\n",
      " loss = 0.0026005656187441883\n",
      " loss = 0.020059511018136716\n",
      " loss = 0.0025305081811186417\n",
      " loss = 0.002514283964506976\n",
      " loss = 0.019720489185679806\n",
      " loss = 0.01949069835656869\n",
      " loss = 0.019263585137958273\n",
      " loss = 0.0023445641145697213\n",
      " loss = 0.01898935089226764\n",
      " loss = 0.0022802206404183996\n",
      " loss = 0.0187193501613444\n",
      " loss = 0.002217319764673175\n",
      " loss = 0.018453515035830387\n",
      " loss = 0.018238487484066458\n",
      " loss = 0.0021093483699386596\n",
      " loss = 0.002095824396727659\n",
      " loss = 0.0020823871317224656\n",
      " loss = 0.0020690360190094314\n",
      " loss = 0.0020557705062099387\n",
      " loss = 0.01779834997968032\n",
      " loss = 0.0019978949475425146\n",
      " loss = 0.001985085551942765\n",
      " loss = 0.001972358283082928\n",
      " loss = 0.00195971261435556\n",
      " loss = 0.017415493228533942\n",
      " loss = 0.0019039846649100498\n",
      " loss = 0.017169916893419894\n",
      " loss = 0.0018495349232619171\n",
      " loss = 0.0018376767299364681\n",
      " loss = 0.0018258945647652348\n",
      " loss = 0.0018141879403135864\n",
      " loss = 0.016804022092557668\n",
      " loss = 0.01660821507744157\n",
      " loss = 0.01641468967736541\n",
      " loss = 0.0016822816883848002\n",
      " loss = 0.001671495830158844\n",
      " loss = 0.0016607791248869\n",
      " loss = 0.01610718308330124\n",
      " loss = 0.0016119271919304346\n",
      " loss = 0.015881760006660285\n",
      " loss = 0.015696699548335365\n",
      " loss = 0.0015275044576293366\n",
      " loss = 0.01547753185991998\n",
      " loss = 0.015297181620567299\n",
      " loss = 0.015118932900018891\n",
      " loss = 0.014942761197153862\n",
      " loss = 0.014768642318825919\n",
      " loss = 0.0013444296735697983\n",
      " loss = 0.001335809935257077\n",
      " loss = 0.014530694028979593\n",
      " loss = 0.014361376717324102\n",
      " loss = 0.014194032354860173\n",
      " loss = 0.0012314126762939508\n",
      " loss = 0.01399767483882287\n",
      " loss = 0.0011928653160659757\n",
      " loss = 0.001185217324475666\n",
      " loss = 0.0011776183675475396\n",
      " loss = 0.013744168510846292\n",
      " loss = 0.013584016099748231\n",
      " loss = 0.0011112200401361108\n",
      " loss = 0.013396955133047067\n",
      " loss = 0.013240848585289238\n",
      " loss = 0.001047669119320368\n",
      " loss = 0.0010409520453109704\n",
      " loss = 0.0010342780374448328\n",
      " loss = 0.001027646819625807\n",
      " loss = 0.0010210581174918852\n",
      " loss = 0.0010145116584823171\n",
      " loss = 0.0010080071717344095\n",
      " loss = 0.0010015443881429796\n",
      " loss = 0.012869141872628262\n",
      " loss = 0.01271918561364073\n",
      " loss = 0.012570976703954156\n",
      " loss = 0.0009171577456985262\n",
      " loss = 0.012399346036919499\n",
      " loss = 0.0008863943603711705\n",
      " loss = 0.0008807112907602737\n",
      " loss = 0.01220585906411704\n",
      " loss = 0.0008508740874989649\n",
      " loss = 0.012039762780725797\n",
      " loss = 0.0008218055455972209\n",
      " loss = 0.0008165365836801008\n",
      " loss = 0.0008113014034497551\n",
      " loss = 0.011829870188151492\n",
      " loss = 0.0007832465393797647\n",
      " loss = 0.011669478445772902\n",
      " loss = 0.011533501128721469\n",
      " loss = 0.011399108276945267\n",
      " loss = 0.011266281426232077\n",
      " loss = 0.011135002322139825\n",
      " loss = 0.0006711769515010123\n",
      " loss = 0.0006668737366898192\n",
      " loss = 0.010964839443786057\n",
      " loss = 0.01083707285982299\n",
      " loss = 0.0006231391811433331\n",
      " loss = 0.010691547173309694\n",
      " loss = 0.010566965096209292\n",
      " loss = 0.0005814916433605869\n",
      " loss = 0.010425474150309515\n",
      " loss = 0.010303992459501385\n",
      " loss = 0.010183926319600944\n",
      " loss = 0.010065259236979436\n",
      " loss = 0.009947974912866036\n",
      " loss = 0.0004908949445922981\n",
      " loss = 0.009815688668475661\n",
      " loss = 0.00047157472641010144\n",
      " loss = 0.00046855125049880854\n",
      " loss = 0.009669504083246908\n",
      " loss = 0.009556831249384796\n",
      " loss = 0.009445471321582848\n",
      " loss = 0.009335409006422043\n",
      " loss = 0.0004049524935995784\n",
      " loss = 0.00040235616254537373\n",
      " loss = 0.009197882213661147\n",
      " loss = 0.00038561109916344905\n",
      " loss = 0.0003831387744141708\n",
      " loss = 0.0003806823008420179\n",
      " loss = 0.00037824157680572447\n",
      " loss = 0.009035235668012367\n",
      " loss = 0.00892995358017903\n",
      " loss = 0.0003489255666239149\n",
      " loss = 0.0003466884491904633\n",
      " loss = 0.008799798820363141\n",
      " loss = 0.008697260131670655\n",
      " loss = 0.008595916262309027\n",
      " loss = 0.0003068480671785243\n",
      " loss = 0.0003048807273542208\n",
      " loss = 0.008471739402034361\n",
      " loss = 0.008373023392556326\n",
      " loss = 0.00827545766010428\n",
      " loss = 0.00817902879963803\n",
      " loss = 0.008083723565481999\n",
      " loss = 0.0002467899726445993\n",
      " loss = 0.007979065846658789\n",
      " loss = 0.007886090659777325\n",
      " loss = 0.0077941988552744715\n",
      " loss = 0.00021509791794078388\n",
      " loss = 0.007693786052279024\n",
      " loss = 0.00020426770765194597\n",
      " loss = 0.00020295805626816552\n",
      " loss = 0.000201656801646024\n",
      " loss = 0.0002003638899424294\n",
      " loss = 0.007567199974085096\n",
      " loss = 0.00019003575441214857\n",
      " loss = 0.00018881735042761182\n",
      " loss = 0.00018760675817294494\n",
      " loss = 0.00018640392756438326\n",
      " loss = 0.00018520880884315824\n",
      " loss = 0.007434942675013814\n",
      " loss = 0.0073483078251897855\n",
      " loss = 0.0072626824761848245\n",
      " loss = 0.0001589366324632298\n",
      " loss = 0.007170095660000658\n",
      " loss = 0.00015008575703598376\n",
      " loss = 0.0070788619043429\n",
      " loss = 0.006996376245088469\n",
      " loss = 0.00013424273082041852\n",
      " loss = 0.0001333820407974728\n",
      " loss = 0.006900519346151363\n",
      " loss = 0.00012549471331337227\n",
      " loss = 0.006813217769084797\n",
      " loss = 0.00011791458048879056\n",
      " loss = 0.006727187277672943\n",
      " loss = 0.006648799467750091\n",
      " loss = 0.00010433427937823765\n",
      " loss = 0.00010366534577865077\n",
      " loss = 0.00010300070101041593\n",
      " loss = 0.00010234031757670845\n",
      " loss = 0.00010168416815482825\n",
      " loss = 0.00010103222559655973\n",
      " loss = 0.00010038446293485577\n",
      " loss = 9.97408533700482e-05\n",
      " loss = 0.006522592331887944\n",
      " loss = 0.00644658854328953\n",
      " loss = 8.751119382688317e-05\n",
      " loss = 0.006365905807413519\n",
      " loss = 0.0062917277911463355\n",
      " loss = 0.006218414126478342\n",
      " loss = 7.119719007799146e-05\n",
      " loss = 0.006141025114726877\n",
      " loss = 6.591319845570752e-05\n",
      " loss = 6.549059954186857e-05\n",
      " loss = 6.507071009787588e-05\n",
      " loss = 6.465351275132053e-05\n",
      " loss = 6.423899024324693e-05\n",
      " loss = 6.382712542501428e-05\n",
      " loss = 6.34179012545448e-05\n",
      " loss = 0.006036826137650297\n",
      " loss = 5.84980021928792e-05\n",
      " loss = 0.005962079933237659\n",
      " loss = 5.381794835992709e-05\n",
      " loss = 0.0058884106858170925\n",
      " loss = 4.9372138323300535e-05\n",
      " loss = 4.905559152269738e-05\n",
      " loss = 4.8741074245433043e-05\n",
      " loss = 0.005807854743818661\n",
      " loss = 0.005740179355179852\n",
      " loss = 0.00567329254572496\n",
      " loss = 0.005607185129605055\n",
      " loss = 0.005541848021026839\n",
      " loss = 0.005477272246520313\n",
      " loss = 2.7874494491324953e-05\n",
      " loss = 0.005410553874141125\n",
      " loss = 0.005347507992169751\n",
      " loss = 0.005285196742525562\n",
      " loss = 0.005223611570750624\n",
      " loss = 1.7436540247462943e-05\n",
      " loss = 0.00516050787425985\n",
      " loss = 0.005100375625266522\n",
      " loss = 1.3165376087416106e-05\n",
      " loss = 1.3080966989108517e-05\n",
      " loss = 0.005037110544574256\n",
      " loss = 1.1159894923816235e-05\n",
      " loss = 1.108834385996998e-05\n",
      " loss = 1.1017251541654623e-05\n",
      " loss = 0.004973163717654812\n",
      " loss = 9.276563629335865e-06\n",
      " loss = 9.217087442177851e-06\n",
      " loss = 9.157992583511566e-06\n",
      " loss = 0.004910456076751729\n",
      " loss = 7.591905249242415e-06\n",
      " loss = 0.004851806875089502\n",
      " loss = 6.184666401131562e-06\n",
      " loss = 6.145013746342309e-06\n",
      " loss = 6.105615322371927e-06\n",
      " loss = 6.066469499089831e-06\n",
      " loss = 0.0047901632494204765\n",
      " loss = 4.827560967501862e-06\n",
      " loss = 4.796609320887406e-06\n",
      " loss = 0.004732096571686174\n",
      " loss = 3.7122169093588993e-06\n",
      " loss = 0.00467597424993727\n",
      " loss = 2.774480330952386e-06\n",
      " loss = 2.756691900064523e-06\n",
      " loss = 0.004619802781595073\n",
      " loss = 0.004565971038701365\n",
      " loss = 0.004512766564722366\n",
      " loss = 0.004460182048338237\n",
      " loss = 4.2327282106314596e-07\n",
      " loss = 4.205590302155669e-07\n",
      " loss = 4.1786263868188243e-07\n",
      " loss = 0.004407247505538717\n",
      " loss = 0.004355892538356665\n",
      " loss = 2.2788957432504733e-08\n",
      " loss = 2.2642847261393246e-08\n",
      " loss = 2.249767386766114e-08\n",
      " loss = 2.235343124614639e-08\n",
      " loss = 0.004304842085139913\n",
      " loss = 0.004254680387603594\n",
      " loss = 1.1464378624784513e-07\n",
      " loss = 0.004205266852862626\n",
      " loss = 3.3545439967329164e-07\n",
      " loss = 3.333036519013399e-07\n",
      " loss = 3.311666935282429e-07\n",
      " loss = 0.004157097765911446\n",
      " loss = 0.0041086576419420906\n",
      " loss = 1.1083958056435811e-06\n",
      " loss = 0.004061282042230838\n",
      " loss = 1.6561898467991598e-06\n",
      " loss = 0.004014566162428841\n",
      " loss = 2.3071645077006345e-06\n",
      " loss = 2.2923722470153424e-06\n",
      " loss = 0.003969211034272434\n",
      " loss = 0.003922960240920717\n",
      " loss = 0.0038772483783217973\n",
      " loss = 4.881832880086536e-06\n",
      " loss = 4.850533272022934e-06\n",
      " loss = 4.819434339781691e-06\n",
      " loss = 0.0038351184355766947\n",
      " loss = 5.851905994286354e-06\n",
      " loss = 0.00379154033474738\n",
      " loss = 6.9737620423719e-06\n",
      " loss = 0.0037485648804810633\n",
      " loss = 8.182396316566925e-06\n",
      " loss = 8.129935324067805e-06\n",
      " loss = 8.07781068240198e-06\n",
      " loss = 8.026020234994768e-06\n",
      " loss = 0.0037100531298772743\n",
      " loss = 0.00366682214479791\n",
      " loss = 0.0036240949026922495\n",
      " loss = 1.2256786540658495e-05\n",
      " loss = 0.0035834274800642836\n",
      " loss = 1.3785072733986329e-05\n",
      " loss = 0.0035433191398560665\n",
      " loss = 0.003502031003956884\n",
      " loss = 1.71669192896343e-05\n",
      " loss = 1.7056854512984542e-05\n",
      " loss = 0.0034648529321323015\n",
      " loss = 1.8801838459440704e-05\n",
      " loss = 1.8681291486812785e-05\n",
      " loss = 0.0034282567866889976\n",
      " loss = 2.0489396316883187e-05\n",
      " loss = 0.0033902736386684346\n",
      " loss = 2.2363333239928466e-05\n",
      " loss = 0.003352809559151583\n",
      " loss = 2.4300989372183807e-05\n",
      " loss = 0.0033158568255850776\n",
      " loss = 2.630029658422656e-05\n",
      " loss = 2.6131673651571457e-05\n",
      " loss = 0.003281590210431954\n",
      " loss = 0.0032433518414998015\n",
      " loss = 3.048412448350858e-05\n",
      " loss = 3.028867716402699e-05\n",
      " loss = 0.0032102133306807583\n",
      " loss = 0.0031728066732521166\n",
      " loss = 0.0031358358930437666\n",
      " loss = 0.0030992959103893518\n",
      " loss = 3.998171851953178e-05\n",
      " loss = 3.9725377888369044e-05\n",
      " loss = 0.003068392558678092\n",
      " loss = 0.0030326384516014904\n",
      " loss = 4.481297637187079e-05\n",
      " loss = 0.0030000333446105203\n",
      " loss = 0.002965075786581499\n",
      " loss = 5.012389857391304e-05\n",
      " loss = 0.002933382999642118\n",
      " loss = 0.00289920207666603\n",
      " loss = 0.0028654194439316346\n",
      " loss = 0.002832030458827445\n",
      " loss = 0.0027990305365571577\n",
      " loss = 0.0027664151402022647\n",
      " loss = 6.807302210052053e-05\n",
      " loss = 6.763657559212868e-05\n",
      " loss = 6.720292733842584e-05\n",
      " loss = 6.677205939656231e-05\n",
      " loss = 6.63439539411221e-05\n",
      " loss = 0.0027501787228838967\n",
      " loss = 0.002718132568825055\n",
      " loss = 0.002686459827642305\n",
      " loss = 0.002655156150294497\n",
      " loss = 7.910292447176046e-05\n",
      " loss = 7.859576034019685e-05\n",
      " loss = 0.0026310027661009807\n",
      " loss = 0.002600345296967657\n",
      " loss = 0.0025700450600289007\n",
      " loss = 8.849364218324142e-05\n",
      " loss = 0.0025436330372330595\n",
      " loss = 9.148661897868772e-05\n",
      " loss = 9.090005745987768e-05\n",
      " loss = 0.0025211365597811687\n",
      " loss = 9.390906614652474e-05\n",
      " loss = 9.330697323633105e-05\n",
      " loss = 9.270874061415375e-05\n",
      " loss = 0.0025025531673898713\n",
      " loss = 9.572784342786126e-05\n",
      " loss = 9.511408952584744e-05\n",
      " loss = 9.450427067400574e-05\n",
      " loss = 9.389836164240046e-05\n",
      " loss = 9.329633736258306e-05\n",
      " loss = 9.269817292909758e-05\n",
      " loss = 9.210384359554063e-05\n",
      " loss = 9.151332477218128e-05\n",
      " loss = 0.0025021671872518052\n",
      " loss = 9.451666480246892e-05\n",
      " loss = 9.391067630546053e-05\n",
      " loss = 0.0024802119142209563\n",
      " loss = 0.002451311517336488\n",
      " loss = 0.0024227478791419284\n",
      " loss = 0.0001043095265199862\n",
      " loss = 0.002398243692970693\n",
      " loss = 0.00010739015753423087\n",
      " loss = 0.00010670163133538369\n",
      " loss = 0.00237781352132506\n",
      " loss = 0.00235010631142655\n",
      " loss = 0.00011361183001731046\n",
      " loss = 0.002326552534023785\n",
      " loss = 0.00011673557964204606\n",
      " loss = 0.002303306041030713\n",
      " loss = 0.0022764670208584993\n",
      " loss = 0.0022499407397392262\n",
      " loss = 0.0022237235528709412\n",
      " loss = 0.002197811858724663\n",
      " loss = 0.0001358077285191223\n",
      " loss = 0.00013493700459831583\n",
      " loss = 0.0021802934911351814\n",
      " loss = 0.00013813211106495052\n",
      " loss = 0.0001372464844888578\n",
      " loss = 0.00013636653606171448\n",
      " loss = 0.0021670657753927423\n",
      " loss = 0.0021418142798201928\n",
      " loss = 0.0001436662189229532\n",
      " loss = 0.00014274511071124383\n",
      " loss = 0.00014182990813665477\n",
      " loss = 0.0021291669107664116\n",
      " loss = 0.0021043570275686664\n",
      " loss = 0.002079836239144925\n",
      " loss = 0.00205560117583307\n",
      " loss = 0.00015757446519642333\n",
      " loss = 0.0020358680724337505\n",
      " loss = 0.0020121453440043015\n",
      " loss = 0.001988699042233237\n",
      " loss = 0.0019655259454293876\n",
      " loss = 0.0019426228712012279\n",
      " loss = 0.0019199866716396376\n",
      " loss = 0.0001824360656349395\n",
      " loss = 0.0019020024248610433\n",
      " loss = 0.001879839550747731\n",
      " loss = 0.00019009911336110417\n",
      " loss = 0.00018888030315733826\n",
      " loss = 0.00018766930729016267\n",
      " loss = 0.00018646607565170678\n",
      " loss = 0.0018756106512066207\n",
      " loss = 0.00018969050274908095\n",
      " loss = 0.001858177956165955\n",
      " loss = 0.0018365257422839876\n",
      " loss = 0.001815125828607892\n",
      " loss = 0.00020185995148687782\n",
      " loss = 0.0002005657372994313\n",
      " loss = 0.0001992798208990352\n",
      " loss = 0.00019800214908450084\n",
      " loss = 0.0018118753669508626\n",
      " loss = 0.00020120801249350482\n",
      " loss = 0.00019991797817789595\n",
      " loss = 0.0017997078894788625\n",
      " loss = 0.0017787369919924582\n",
      " loss = 0.00020762280940851658\n",
      " loss = 0.0017625165591521306\n",
      " loss = 0.0017419790291615116\n",
      " loss = 0.0017216808106332426\n",
      " loss = 0.0017016191144977083\n",
      " loss = 0.0002244976041944255\n",
      " loss = 0.0016863743170609873\n",
      " loss = 0.0016667240259743133\n",
      " loss = 0.0016473027075649186\n",
      " loss = 0.00023690119733404337\n",
      " loss = 0.00023538231809352176\n",
      " loss = 0.00023387317706447734\n",
      " loss = 0.0002323737118120189\n",
      " loss = 0.0016465873966942854\n",
      " loss = 0.00023550256221352325\n",
      " loss = 0.00023399265024175658\n",
      " loss = 0.00023249241899281635\n",
      " loss = 0.00023100180639844828\n",
      " loss = 0.00022952075078510893\n",
      " loss = 0.0016504060124886712\n",
      " loss = 0.0002326449393176493\n",
      " loss = 0.00023115334884359868\n",
      " loss = 0.0016403563459211276\n",
      " loss = 0.00023426917185662296\n",
      " loss = 0.001625839162505054\n",
      " loss = 0.00023737512184572915\n",
      " loss = 0.0016115010261380774\n",
      " loss = 0.00024047085777890753\n",
      " loss = 0.0015973394517890544\n",
      " loss = 0.000243556049293317\n",
      " loss = 0.00024199450282851097\n",
      " loss = 0.00024044296813684017\n",
      " loss = 0.0002389013810228329\n",
      " loss = 0.0015971792935977735\n",
      " loss = 0.00024198135120985005\n",
      " loss = 0.001583178479656033\n",
      " loss = 0.0015647306666771086\n",
      " loss = 0.001546497814780577\n",
      " loss = 0.00025434111807179875\n",
      " loss = 0.0015331283804060067\n",
      " loss = 0.00025737126711371185\n",
      " loss = 0.0002557211451235261\n",
      " loss = 0.001524572635455925\n",
      " loss = 0.0015068077206657588\n",
      " loss = 0.0002634169431790098\n",
      " loss = 0.00026172805966406365\n",
      " loss = 0.0014985864760609052\n",
      " loss = 0.00026472393902011955\n",
      " loss = 0.00026302667576947876\n",
      " loss = 0.0014904586700219477\n",
      " loss = 0.0014730912641685138\n",
      " loss = 0.00027069940094836306\n",
      " loss = 0.0014606093691138613\n",
      " loss = 0.00027365596361990976\n",
      " loss = 0.000271901433174044\n",
      " loss = 0.001452959668635987\n",
      " loss = 0.00027484826669865877\n",
      " loss = 0.0014407158056337513\n",
      " loss = 0.0014239280235868639\n",
      " loss = 0.0014073358587928654\n",
      " loss = 0.001390937033150179\n",
      " loss = 0.00029193881120314095\n",
      " loss = 0.0013794553847255651\n",
      " loss = 0.0013633814323230464\n",
      " loss = 0.0013474947806314023\n",
      " loss = 0.00030429988309407503\n",
      " loss = 0.0013365425601256412\n",
      " loss = 0.001320968645063145\n",
      " loss = 0.00031187157160050296\n",
      " loss = 0.00030987202385097506\n",
      " loss = 0.0003078852960924424\n",
      " loss = 0.0003059113061299348\n",
      " loss = 0.001324578379674647\n",
      " loss = 0.0013091438760786652\n",
      " loss = 0.0003134544892007385\n",
      " loss = 0.0012986404814453192\n",
      " loss = 0.00031620317487207324\n",
      " loss = 0.00031417585528085464\n",
      " loss = 0.00031216153374160883\n",
      " loss = 0.0012977473282756035\n",
      " loss = 0.0003149070829697203\n",
      " loss = 0.00031288807319859117\n",
      " loss = 0.0003108820082005229\n",
      " loss = 0.00030888880498578517\n",
      " loss = 0.0013015522678798204\n",
      " loss = 0.00031163742640589987\n",
      " loss = 0.0003096393798643956\n",
      " loss = 0.0003076541436945468\n",
      " loss = 0.0013005375233217367\n",
      " loss = 0.00031039940934805333\n",
      " loss = 0.0012900956289993962\n",
      " loss = 0.0012750629317513763\n",
      " loss = 0.0012602054010842686\n",
      " loss = 0.0003225913638747948\n",
      " loss = 0.0003205230867517279\n",
      " loss = 0.00031846807027620367\n",
      " loss = 0.000316426229427006\n",
      " loss = 0.001264400082653372\n",
      " loss = 0.0003191145963412713\n",
      " loss = 0.00031706861032841047\n",
      " loss = 0.001259083383621022\n",
      " loss = 0.0012444120529782098\n",
      " loss = 0.0012299116783443381\n",
      " loss = 0.0012155802678753872\n",
      " loss = 0.001201415852717169\n",
      " loss = 0.001187416486866003\n",
      " loss = 0.0003434054557726201\n",
      " loss = 0.0003412037302184591\n",
      " loss = 0.0011830478571683493\n",
      " loss = 0.0011692625223837705\n",
      " loss = 0.00034849484432744284\n",
      " loss = 0.0011603729085094174\n",
      " loss = 0.00035100131571825854\n",
      " loss = 0.0011515858142398185\n",
      " loss = 0.001138167087115068\n",
      " loss = 0.00112490472032848\n",
      " loss = 0.0011117968922438855\n",
      " loss = 0.0010988418014939469\n",
      " loss = 0.00037248553306812305\n",
      " loss = 0.00037009736217444896\n",
      " loss = 0.0010955246839040663\n",
      " loss = 0.0003724706575491059\n",
      " loss = 0.00037008258203452283\n",
      " loss = 0.0010922317298123919\n",
      " loss = 0.00037244871654037624\n",
      " loss = 0.0010842360834444657\n",
      " loss = 0.0003747972692848137\n",
      " loss = 0.0010763311302817366\n",
      " loss = 0.0003771282198871182\n",
      " loss = 0.00037471028266367594\n",
      " loss = 0.0003723078479052355\n",
      " loss = 0.00036992081622512594\n",
      " loss = 0.001082666123080079\n",
      " loss = 0.00037226609677037215\n",
      " loss = 0.0003698793327800422\n",
      " loss = 0.00036750787140539797\n",
      " loss = 0.0010841646304660427\n",
      " loss = 0.001071531521603387\n",
      " loss = 0.0003745637974912295\n",
      " loss = 0.0010637453836302325\n",
      " loss = 0.00037686693759936474\n",
      " loss = 0.00037445067556133823\n",
      " loss = 0.00037204990526451705\n",
      " loss = 0.0010654273722468628\n",
      " loss = 0.0010530125973258644\n",
      " loss = 0.0010407424840506588\n",
      " loss = 0.0010286153465257398\n",
      " loss = 0.0010166295193945387\n",
      " loss = 0.0010047833557320584\n",
      " loss = 0.000993075228087242\n",
      " loss = 0.000981503528309738\n",
      " loss = 0.0009700666666117757\n",
      " loss = 0.0009587630715247747\n",
      " loss = 0.00041663559288266587\n",
      " loss = 0.000413964356263213\n",
      " loss = 0.00041131024614026753\n",
      " loss = 0.0004086731526904517\n",
      " loss = 0.0004060529668260649\n",
      " loss = 0.00040344958015009816\n",
      " loss = 0.0004008628849399563\n",
      " loss = 0.0009803392070270496\n",
      " loss = 0.0004029640134169465\n",
      " loss = 0.0009735789903910907\n",
      " loss = 0.0004050476384381362\n",
      " loss = 0.00040245069736206734\n",
      " loss = 0.000399870406443327\n",
      " loss = 0.0009762001378733528\n",
      " loss = 0.00040196224067989\n",
      " loss = 0.0003993850814601787\n",
      " loss = 0.000974116144999881\n",
      " loss = 0.00040147222593448867\n",
      " loss = 0.0009674050135660131\n",
      " loss = 0.0004035419558416534\n",
      " loss = 0.0004009546683694617\n",
      " loss = 0.0003983839691491235\n",
      " loss = 0.0009700279174717798\n",
      " loss = 0.0009587247738856762\n",
      " loss = 0.0009475533390787118\n",
      " loss = 0.00040972494136353853\n",
      " loss = 0.0004070980120198537\n",
      " loss = 0.0009457543245345822\n",
      " loss = 0.0009347340263651752\n",
      " loss = 0.00041373356295614183\n",
      " loss = 0.00041108093255429635\n",
      " loss = 0.0004084453093447343\n",
      " loss = 0.000937673877744454\n",
      " loss = 0.0004104376304134464\n",
      " loss = 0.0009313504871890516\n",
      " loss = 0.00041241272256362815\n",
      " loss = 0.0009250962904483254\n",
      " loss = 0.0004143706173776977\n",
      " loss = 0.0004117139025204904\n",
      " loss = 0.0009235008040013768\n",
      " loss = 0.0009127398125566873\n",
      " loss = 0.0004182611837149863\n",
      " loss = 0.0009066885620421452\n",
      " loss = 0.0008961234733931955\n",
      " loss = 0.0008856814933396592\n",
      " loss = 0.0008753611870170391\n",
      " loss = 0.00043391941337941615\n",
      " loss = 0.00043113736247456436\n",
      " loss = 0.0008743044390547318\n",
      " loss = 0.0008641167028852391\n",
      " loss = 0.0008540476781407713\n",
      " loss = 0.0008440959813680829\n",
      " loss = 0.00044665117175433737\n",
      " loss = 0.00044378749187721524\n",
      " loss = 0.0008433703410780589\n",
      " loss = 0.00044549931556019177\n",
      " loss = 0.0008380914089173743\n",
      " loss = 0.00044719457322834656\n",
      " loss = 0.0004443274093540349\n",
      " loss = 0.0008374088994013674\n",
      " loss = 0.0004460223495167932\n",
      " loss = 0.0008321860141113889\n",
      " loss = 0.00044770080376550943\n",
      " loss = 0.0008270183525424709\n",
      " loss = 0.0008173816121440104\n",
      " loss = 0.00045389155698006254\n",
      " loss = 0.0008123770171357151\n",
      " loss = 0.000455504365077149\n",
      " loss = 0.0008074249085558063\n",
      " loss = 0.0007980164786506721\n",
      " loss = 0.0007887176795372616\n",
      " loss = 0.0007795272337361608\n",
      " loss = 0.000470626233098349\n",
      " loss = 0.00046760883841191097\n",
      " loss = 0.0007794321632895184\n",
      " loss = 0.0007703499157094728\n",
      " loss = 0.0007613734982611207\n",
      " loss = 0.00047808504766783127\n",
      " loss = 0.00047501983118324227\n",
      " loss = 0.0007614553157962876\n",
      " loss = 0.0007525825414693721\n",
      " loss = 0.0007438131563386272\n",
      " loss = 0.0007351459556228916\n",
      " loss = 0.0004898582680224393\n",
      " loss = 0.000486717568168511\n",
      " loss = 0.0007354862842365348\n",
      " loss = 0.0004880525502580663\n",
      " loss = 0.0004849234276619749\n",
      " loss = 0.0007358082176233769\n",
      " loss = 0.00048626268750043505\n",
      " loss = 0.00048314504052406374\n",
      " loss = 0.0007361119663607477\n",
      " loss = 0.0007275345026149364\n",
      " loss = 0.0004889238878467525\n",
      " loss = 0.0007234833190068446\n",
      " loss = 0.0007150530093719881\n",
      " loss = 0.0007067209328506218\n",
      " loss = 0.0004990579225346604\n",
      " loss = 0.0004958582395978778\n",
      " loss = 0.000492679071250033\n",
      " loss = 0.0007117079117609438\n",
      " loss = 0.0007034148137628353\n",
      " loss = 0.0006952183499315747\n",
      " loss = 0.000687117394620723\n",
      " loss = 0.0005071203715307211\n",
      " loss = 0.000683492099643652\n",
      " loss = 0.0005082527086561555\n",
      " loss = 0.0005049940738364346\n",
      " loss = 0.0005017563315878028\n",
      " loss = 0.000688651489345283\n",
      " loss = 0.0005029163271223222\n",
      " loss = 0.0006849949517143585\n",
      " loss = 0.0006770131235619248\n",
      " loss = 0.0006691243025883037\n",
      " loss = 0.0005127827513696258\n",
      " loss = 0.0006656751288803072\n",
      " loss = 0.0005138451812800643\n",
      " loss = 0.0006622594417451946\n",
      " loss = 0.0006545425365044899\n",
      " loss = 0.0006469155516407065\n",
      " loss = 0.0006393774393988943\n",
      " loss = 0.0006319271642939441\n",
      " loss = 0.0005321945318055479\n",
      " loss = 0.0005287823952762865\n",
      " loss = 0.0006331740328780656\n",
      " loss = 0.0005297000369035275\n",
      " loss = 0.0006300948717136449\n",
      " loss = 0.0006227527607124946\n",
      " loss = 0.0005348983357527762\n",
      " loss = 0.0005314688639349865\n",
      " loss = 0.0005280613799895087\n",
      " loss = 0.0006283520135560966\n",
      " loss = 0.0005289642550395564\n",
      " loss = 0.0006253096877880126\n",
      " loss = 0.0005298545740473133\n",
      " loss = 0.0005264574400334727\n",
      " loss = 0.0006265697033971177\n",
      " loss = 0.0005273580043941026\n",
      " loss = 0.0005239768770129207\n",
      " loss = 0.0005206174275489672\n",
      " loss = 0.0005172795169981501\n",
      " loss = 0.0006363411932031232\n",
      " loss = 0.0006289262974461836\n",
      " loss = 0.0006215978029786234\n",
      " loss = 0.0006143547028553117\n",
      " loss = 0.0006071960022813942\n",
      " loss = 0.00053524478892488\n",
      " loss = 0.0005318130958463668\n",
      " loss = 0.0006085857007258777\n",
      " loss = 0.0006014942227759281\n",
      " loss = 0.0005944853776275268\n",
      " loss = 0.0005875582022267623\n",
      " loss = 0.0005452961539600408\n",
      " loss = 0.0005418000170888547\n",
      " loss = 0.0005383262955280871\n",
      " loss = 0.0005348748455418384\n",
      " loss = 0.0005975287936560046\n",
      " loss = 0.0005905661549662964\n",
      " loss = 0.0005398546504204936\n",
      " loss = 0.0005878762501292641\n",
      " loss = 0.0005810260867916393\n",
      " loss = 0.0005447726504637326\n",
      " loss = 0.0005412798700165227\n",
      " loss = 0.0005826105918090186\n",
      " loss = 0.000575821786061045\n",
      " loss = 0.000569112086026636\n",
      " loss = 0.000550325449427871\n",
      " loss = 0.0005467970675168117\n",
      " loss = 0.0005432913076313486\n",
      " loss = 0.0005398080247211316\n",
      " loss = 0.0005363470747009762\n",
      " loss = 0.0005832717085030635\n",
      " loss = 0.0005764751990282974\n",
      " loss = 0.0005697578852312663\n",
      " loss = 0.0005631188442081531\n",
      " loss = 0.0005495130655540084\n",
      " loss = 0.0005459898921801474\n",
      " loss = 0.0005424893074518098\n",
      " loss = 0.0005390111665291636\n",
      " loss = 0.0005730872806350726\n",
      " loss = 0.0005396926903581997\n",
      " loss = 0.0005705380427589068\n",
      " loss = 0.0005403632186351657\n",
      " loss = 0.0005368987090277271\n",
      " loss = 0.0005721355853184309\n",
      " loss = 0.0005375822403064555\n",
      " loss = 0.0005695859254568188\n",
      " loss = 0.0005382547826139033\n",
      " loss = 0.0005348037911180177\n",
      " loss = 0.0005711715570941094\n",
      " loss = 0.0005645160434030856\n",
      " loss = 0.0005395952312602557\n",
      " loss = 0.0005620353760693947\n",
      " loss = 0.0005554863207781087\n",
      " loss = 0.0005490135776020378\n",
      " loss = 0.0005426162574055142\n",
      " loss = 0.0005362934811284279\n",
      " loss = 0.0005300443803680152\n",
      " loss = 0.0005606023972993424\n",
      " loss = 0.0005570081252732484\n",
      " loss = 0.0005534368977311241\n",
      " loss = 0.0005360169609390144\n",
      " loss = 0.0005539427167449806\n",
      " loss = 0.0005503911429098952\n",
      " loss = 0.0005468623397973367\n",
      " loss = 0.0005433561614096673\n",
      " loss = 0.0005459668301323932\n",
      " loss = 0.0005396050119245651\n",
      " loss = 0.0005479724214029557\n",
      " loss = 0.0005444591258042771\n",
      " loss = 0.0005413936572729782\n",
      " loss = 0.0005350851271616459\n",
      " loss = 0.0005288501066499968\n",
      " loss = 0.0005226877389746877\n",
      " loss = 0.0005165971775696403\n",
      " loss = 0.0005105775859463397\n",
      " loss = 0.0005046281367739504\n",
      " loss = 0.0005690707466622104\n",
      " loss = 0.0005027269056933275\n",
      " loss = 0.0004968689357716937\n",
      " loss = 0.0004910792251802376\n",
      " loss = 0.0004853569784749073\n",
      " loss = 0.0005812891588945242\n",
      " loss = 0.0005775622548333552\n",
      " loss = 0.0004875929893178884\n",
      " loss = 0.0005778088324398621\n",
      " loss = 0.0005741042423041047\n",
      " loss = 0.0004897972179363976\n",
      " loss = 0.0005743700755878637\n",
      " loss = 0.0005706875328386433\n",
      " loss = 0.0004919698455943834\n",
      " loss = 0.0005709722635179192\n",
      " loss = 0.000567311505662112\n",
      " loss = 0.0004941110561729027\n",
      " loss = 0.0004883534814855593\n",
      " loss = 0.00048266299626950165\n",
      " loss = 0.0005754675457789476\n",
      " loss = 0.0004809521820395272\n",
      " loss = 0.00047534793959331113\n",
      " loss = 0.0005795992218420025\n",
      " loss = 0.0005758831527079439\n",
      " loss = 0.0005721909089553155\n",
      " loss = 0.0004815122161976673\n",
      " loss = 0.0004759014481145415\n",
      " loss = 0.000576325925191101\n",
      " loss = 0.0005726308426243408\n",
      " loss = 0.0004781371346941865\n",
      " loss = 0.0004725656943430609\n",
      " loss = 0.0004670591744667236\n",
      " loss = 0.0004616168189142028\n",
      " loss = 0.0005844788572808861\n",
      " loss = 0.0004600950606653704\n",
      " loss = 0.0005845907812527107\n",
      " loss = 0.0005808427090171225\n",
      " loss = 0.0005771186673251205\n",
      " loss = 0.0005734185021262647\n",
      " loss = 0.00047016096766371306\n",
      " loss = 0.0004646824687539339\n",
      " loss = 0.0005774610451630802\n",
      " loss = 0.00046311439623237963\n",
      " loss = 0.0005776073501998112\n",
      " loss = 0.00046155860090948167\n",
      " loss = 0.0005777467222307016\n",
      " loss = 0.00046001495481651233\n",
      " loss = 0.0004546546811300986\n",
      " loss = 0.000581706159669962\n",
      " loss = 0.0004531758022779064\n",
      " loss = 0.000447895221170551\n",
      " loss = 0.0005856087750570952\n",
      " loss = 0.0005818541759939945\n",
      " loss = 0.000450286591408724\n",
      " loss = 0.0004450396765646742\n",
      " loss = 0.000439853900811364\n",
      " loss = 0.000589521837705615\n",
      " loss = 0.0005857421502485206\n",
      " loss = 0.00044229590257763914\n",
      " loss = 0.0005857745465428154\n",
      " loss = 0.0005820188846410588\n",
      " loss = 0.0004447060766215163\n",
      " loss = 0.0004395241879237102\n",
      " loss = 0.0005858496293953597\n",
      " loss = 0.0005820934861041537\n",
      " loss = 0.0005783614251373209\n",
      " loss = 0.0005746532920707909\n",
      " loss = 0.0004495002548104106\n",
      " loss = 0.0005747512997525564\n",
      " loss = 0.0005710663128006108\n",
      " loss = 0.0004518151824175243\n",
      " loss = 0.0005711852273470148\n",
      " loss = 0.00045032281440007235\n",
      " loss = 0.00044507547733672594\n",
      " loss = 0.00043988928443793995\n",
      " loss = 0.00043476352301140075\n",
      " loss = 0.00042969748909801105\n",
      " loss = 0.0004246904864451278\n",
      " loss = 0.0004197418272607739\n",
      " loss = 0.00041485083184686545\n",
      " loss = 0.0004100168280289053\n",
      " loss = 0.0004052391522548843\n",
      " loss = 0.00040051714761532304\n",
      " loss = 0.0006084967715474294\n",
      " loss = 0.0006045954273378141\n",
      " loss = 0.0004031885523120678\n",
      " loss = 0.00039849044217628814\n",
      " loss = 0.0003938470760723813\n",
      " loss = 0.0003892578164885239\n",
      " loss = 0.0003847220327304744\n",
      " loss = 0.0006189842603931044\n",
      " loss = 0.0003838638211577162\n",
      " loss = 0.00037939089021782823\n",
      " loss = 0.0003749700795195875\n",
      " loss = 0.0006258646933974363\n",
      " loss = 0.0006218519956926897\n",
      " loss = 0.0006178650251902581\n",
      " loss = 0.0003814133274226946\n",
      " loss = 0.0006175157218614164\n",
      " loss = 0.00038057379288423016\n",
      " loss = 0.0006171636562278122\n",
      " loss = 0.0006132067447540005\n",
      " loss = 0.0003833444078259694\n",
      " loss = 0.0006128827969718371\n",
      " loss = 0.0006089533319950593\n",
      " loss = 0.0003860835529906648\n",
      " loss = 0.0006086569800748816\n",
      " loss = 0.0006047546086946855\n",
      " loss = 0.0006008772571557118\n",
      " loss = 0.0005970247650506883\n",
      " loss = 0.0003960183425329218\n",
      " loss = 0.00039140378253536677\n",
      " loss = 0.00038684299313017953\n",
      " loss = 0.0006040207985142309\n",
      " loss = 0.00038592571672190764\n",
      " loss = 0.0006037407155120583\n",
      " loss = 0.0005998698644961235\n",
      " loss = 0.0005960238312254049\n",
      " loss = 0.00039220003139197533\n",
      " loss = 0.00038762996378128624\n",
      " loss = 0.0003831131482458667\n",
      " loss = 0.00037864896457500026\n",
      " loss = 0.0006065315588070045\n",
      " loss = 0.0003777964213413895\n",
      " loss = 0.0006062046520663882\n",
      " loss = 0.00037694885156409474\n",
      " loss = 0.0003725564965675522\n",
      " loss = 0.0006094213526220951\n",
      " loss = 0.00037175468163230064\n",
      " loss = 0.0006090556755541051\n",
      " loss = 0.00037095734462924766\n",
      " loss = 0.0003666348048738802\n",
      " loss = 0.0006122137556750421\n",
      " loss = 0.0003658818723517101\n",
      " loss = 0.0006118100777156816\n",
      " loss = 0.0006078874904253736\n",
      " loss = 0.00036865304427528405\n",
      " loss = 0.0003643573553511681\n",
      " loss = 0.0006110242894700993\n",
      " loss = 0.000607106740224464\n",
      " loss = 0.00036712716030111903\n",
      " loss = 0.00036284925143637855\n",
      " loss = 0.0006102294339984538\n",
      " loss = 0.0006063169809232009\n",
      " loss = 0.0003656175884626931\n",
      " loss = 0.000361357269707553\n",
      " loss = 0.0006094257173507946\n",
      " loss = 0.0006055184172481488\n",
      " loss = 0.0006016361685849242\n",
      " loss = 0.000597778810754685\n",
      " loss = 0.0003711236048330515\n",
      " loss = 0.000366799127910784\n",
      " loss = 0.00036252504148683517\n",
      " loss = 0.000604429353395209\n",
      " loss = 0.00036177789200412625\n",
      " loss = 0.0006040334495460667\n",
      " loss = 0.0003610347316986914\n",
      " loss = 0.0003568278143343152\n",
      " loss = 0.00035266991761609304\n",
      " loss = 0.0006105535154572449\n",
      " loss = 0.0003520075044617859\n",
      " loss = 0.0003479057756635227\n",
      " loss = 0.0006135271396231405\n",
      " loss = 0.0003472839198190991\n",
      " loss = 0.00034323723212915323\n",
      " loss = 0.00033923769802522144\n",
      " loss = 0.0003352847679728464\n",
      " loss = 0.0006232678179437578\n",
      " loss = 0.0003347740149096764\n",
      " loss = 0.0006226702602734901\n",
      " loss = 0.0006186780435061125\n",
      " loss = 0.0006147114226185469\n",
      " loss = 0.0006107702334951649\n",
      " loss = 0.0006068543131112132\n",
      " loss = 0.0006029634994295917\n",
      " loss = 0.0005990976314907333\n",
      " loss = 0.0005952565493567841\n",
      " loss = 0.00035817813180213947\n",
      " loss = 0.00035400450060473886\n",
      " loss = 0.0003498795022091641\n",
      " loss = 0.0006017163568073205\n",
      " loss = 0.0003492109744291881\n",
      " loss = 0.0006012691266503731\n",
      " loss = 0.000597414122098523\n",
      " loss = 0.0005935838337038991\n",
      " loss = 0.0005897781029903498\n",
      " loss = 0.00035879103549489724\n",
      " loss = 0.0005894195297658428\n",
      " loss = 0.00035802616064499996\n",
      " loss = 0.0005890585618759089\n",
      " loss = 0.0005852818446915518\n",
      " loss = 0.000581529341739637\n",
      " loss = 0.0003641038238640269\n",
      " loss = 0.00035986114417538805\n",
      " loss = 0.00035566790192350257\n",
      " loss = 0.0005880425385710173\n",
      " loss = 0.000584272335562433\n",
      " loss = 0.0005805263050205195\n",
      " loss = 0.0005768042919496797\n",
      " loss = 0.00036514333134019764\n",
      " loss = 0.0005765209765507933\n",
      " loss = 0.0003642964689197306\n",
      " loss = 0.0005762346729222452\n",
      " loss = 0.0003634546822555356\n",
      " loss = 0.0005759454124375844\n",
      " loss = 0.00036261792417824324\n",
      " loss = 0.0005756532260334647\n",
      " loss = 0.0003617861483507989\n",
      " loss = 0.00035757047493600576\n",
      " loss = 0.00035340392420427335\n",
      " loss = 0.0003492859238139617\n",
      " loss = 0.0005854856992587841\n",
      " loss = 0.0003485750711570911\n",
      " loss = 0.0003445133386189112\n",
      " loss = 0.0003404989349190671\n",
      " loss = 0.0005917856829936943\n",
      " loss = 0.0003398658930784929\n",
      " loss = 0.0003359056432131087\n",
      " loss = 0.0003319915396177295\n",
      " loss = 0.00032812304476310673\n",
      " loss = 0.0006012776139877109\n",
      " loss = 0.000597422555014814\n",
      " loss = 0.0005935922125423653\n",
      " loss = 0.0003342169513450029\n",
      " loss = 0.00033032252507133697\n",
      " loss = 0.000596404157225094\n",
      " loss = 0.0005925803441634542\n",
      " loss = 0.00033307402696921087\n",
      " loss = 0.000329192918603443\n",
      " loss = 0.0005953818022453451\n",
      " loss = 0.000328645900202042\n",
      " loss = 0.0005948556575437857\n",
      " loss = 0.0005910417725943783\n",
      " loss = 0.0005872523401680811\n",
      " loss = 0.00033468801010551775\n",
      " loss = 0.0003307880948227959\n",
      " loss = 0.0003269336229229539\n",
      " loss = 0.000323124064908085\n",
      " loss = 0.0003193588973255356\n",
      " loss = 0.0005998788949129487\n",
      " loss = 0.00031888933918406087\n",
      " loss = 0.00031517351629280606\n",
      " loss = 0.00031150099159152887\n",
      " loss = 0.00030787126058449434\n",
      " loss = 0.00030428382462655197\n",
      " loss = 0.0003007381908430067\n",
      " loss = 0.0006154026564769133\n",
      " loss = 0.0006114570355515495\n",
      " loss = 0.0006075367117652756\n",
      " loss = 0.0003068433130244022\n",
      " loss = 0.0006068536994263299\n",
      " loss = 0.00030647392792738524\n",
      " loss = 0.0006061713269418384\n",
      " loss = 0.00030610511515262944\n",
      " loss = 0.00030253825901610314\n",
      " loss = 0.0006086840006621589\n",
      " loss = 0.00060478145605072\n",
      " loss = 0.0006009039323729581\n",
      " loss = 0.00030859772179008053\n",
      " loss = 0.0003050018207888343\n",
      " loss = 0.0006034485448836688\n",
      " loss = 0.0003046352797865145\n",
      " loss = 0.0003010855507178101\n",
      " loss = 0.0006059489378170928\n",
      " loss = 0.00030075073949256236\n",
      " loss = 0.0006052398607091617\n",
      " loss = 0.00060135939800864\n",
      " loss = 0.0005975038146743084\n",
      " loss = 0.0003067756083444503\n",
      " loss = 0.0005968581776846059\n",
      " loss = 0.0005930314536780004\n",
      " loss = 0.0005892292645192899\n",
      " loss = 0.0005854514528852723\n",
      " loss = 0.00031595475437574825\n",
      " loss = 0.0005848977309074856\n",
      " loss = 0.0005811476906752148\n",
      " loss = 0.0003186663567840751\n",
      " loss = 0.0005806234652379892\n",
      " loss = 0.0005769008292162897\n",
      " loss = 0.0005732020606922307\n",
      " loss = 0.0005695270066062235\n",
      " loss = 0.0005658755149423472\n",
      " loss = 0.0005622474346250067\n",
      " loss = 0.0005586426155410788\n",
      " loss = 0.000555060908553006\n",
      " loss = 0.0003406727764171896\n",
      " loss = 0.0005547377506073762\n",
      " loss = 0.00033993221221413335\n",
      " loss = 0.00033597118965296663\n",
      " loss = 0.0003320563223404904\n",
      " loss = 0.0005608458311676064\n",
      " loss = 0.0003313927074408543\n",
      " loss = 0.0003275311904971286\n",
      " loss = 0.0003237146693902184\n",
      " loss = 0.0005668442227634692\n",
      " loss = 0.0005632099316303865\n",
      " loss = 0.0003263123442209103\n",
      " loss = 0.0003225100255519704\n",
      " loss = 0.0005659686565962081\n",
      " loss = 0.00032192577678276797\n",
      " loss = 0.0005655158595917599\n",
      " loss = 0.0003213441951592756\n",
      " loss = 0.00031759976731595676\n",
      " loss = 0.0003138989710053937\n",
      " loss = 0.00031024129785383556\n",
      " loss = 0.0005745187470222008\n",
      " loss = 0.0005708352510910433\n",
      " loss = 0.00031290495251174154\n",
      " loss = 0.00030925886198027765\n",
      " loss = 0.0005734544534201696\n",
      " loss = 0.0005697777811457719\n",
      " loss = 0.0003119182268563623\n",
      " loss = 0.000569261227389869\n",
      " loss = 0.00031141406599630324\n",
      " loss = 0.0005687440271230262\n",
      " loss = 0.0005650975554921822\n",
      " loss = 0.00031404399756469715\n",
      " loss = 0.0003103846344774531\n",
      " loss = 0.0005677333876306414\n",
      " loss = 0.00030988645413807615\n",
      " loss = 0.00056721408920798\n",
      " loss = 0.0003093901523074301\n",
      " loss = 0.0005666941923463257\n",
      " loss = 0.000563060863113435\n",
      " loss = 0.0005594508287792537\n",
      " loss = 0.0005558639399920694\n",
      " loss = 0.0005523000483290947\n",
      " loss = 0.0005487590063772117\n",
      " loss = 0.00032453201865559713\n",
      " loss = 0.0005483806102656148\n",
      " loss = 0.0005448646975731766\n",
      " loss = 0.0005413713269713163\n",
      " loss = 0.0005379003539146208\n",
      " loss = 0.0005344516348246069\n",
      " loss = 0.000531025027011906\n",
      " loss = 0.0003396268232443878\n",
      " loss = 0.00033566935900224056\n",
      " loss = 0.0005339312529737789\n",
      " loss = 0.00033490252416471894\n",
      " loss = 0.00033100010934718823\n",
      " loss = 0.0005367917435661889\n",
      " loss = 0.00033027416053721316\n",
      " loss = 0.0005364830918271819\n",
      " loss = 0.0003295523420563125\n",
      " loss = 0.0005361720899749066\n",
      " loss = 0.0005327344515647072\n",
      " loss = 0.0005293188533717957\n",
      " loss = 0.000525925154108536\n",
      " loss = 0.00033823000045062637\n",
      " loss = 0.0005256915305751311\n",
      " loss = 0.00033742076374072377\n",
      " loss = 0.0005254549474814566\n",
      " loss = 0.00033661651071623355\n",
      " loss = 0.00033269412380599277\n",
      " loss = 0.000528335832117239\n",
      " loss = 0.0005249484354438898\n",
      " loss = 0.0003350502412033214\n",
      " loss = 0.0005247033678155059\n",
      " loss = 0.00033426039602661847\n",
      " loss = 0.000524455458954503\n",
      " loss = 0.00033347535343775575\n",
      " loss = 0.0005242047382963683\n",
      " loss = 0.000520843827915525\n",
      " loss = 0.0003358050891516444\n",
      " loss = 0.00033189215725419466\n",
      " loss = 0.0003280248203030331\n",
      " loss = 0.00032420254715701094\n",
      " loss = 0.00032042481263430927\n",
      " loss = 0.0003166910977104443\n",
      " loss = 0.00031300088960570146\n",
      " loss = 0.00030935368115392396\n",
      " loss = 0.0003057489714558411\n",
      " loss = 0.00030218626525075124\n",
      " loss = 0.000548215066014995\n",
      " loss = 0.0005447002147119383\n",
      " loss = 0.0005412078986754945\n",
      " loss = 0.00030775237766695126\n",
      " loss = 0.0005407744698245846\n",
      " loss = 0.00030719684104978643\n",
      " loss = 0.0005403398608322042\n",
      " loss = 0.0005368755009704294\n",
      " loss = 0.00030967561249139596\n",
      " loss = 0.0005364671367746782\n",
      " loss = 0.0003090949358147311\n",
      " loss = 0.0005360573897707354\n",
      " loss = 0.0005326204867384587\n",
      " loss = 0.00031154593771060354\n",
      " loss = 0.0005322364987624258\n",
      " loss = 0.00031094054670813173\n",
      " loss = 0.0005318509321762747\n",
      " loss = 0.0005284409986265285\n",
      " loss = 0.0005250529276739832\n",
      " loss = 0.00031639474672503153\n",
      " loss = 0.0003127079916734206\n",
      " loss = 0.0005277428969333224\n",
      " loss = 0.0003120818310904814\n",
      " loss = 0.00030844533191141943\n",
      " loss = 0.0003048512066934983\n",
      " loss = 0.0005333908630479946\n",
      " loss = 0.0005299710563084825\n",
      " loss = 0.0005265731754811942\n",
      " loss = 0.0005231970799832909\n",
      " loss = 0.0005198426301477983\n",
      " loss = 0.0003163267232990911\n",
      " loss = 0.00031264076099897834\n",
      " loss = 0.0003089977489277863\n",
      " loss = 0.00030539718664158126\n",
      " loss = 0.00030183857950137984\n",
      " loss = 0.000531506374645074\n",
      " loss = 0.000528098650203392\n",
      " loss = 0.00030427744588259223\n",
      " loss = 0.0005276953153512331\n",
      " loss = 0.00030370853093361817\n",
      " loss = 0.0005272906364599339\n",
      " loss = 0.0005239099410009349\n",
      " loss = 0.0003061200807261801\n",
      " loss = 0.0005235306210159301\n",
      " loss = 0.0005201740326898158\n",
      " loss = 0.0005168389649414382\n",
      " loss = 0.00051352527980912\n",
      " loss = 0.0005102328401851081\n",
      " loss = 0.0005069615098584566\n",
      " loss = 0.000503711153501017\n",
      " loss = 0.0005004816366252858\n",
      " loss = 0.00032647523142931805\n",
      " loss = 0.0003226710147332864\n",
      " loss = 0.000503279890871668\n",
      " loss = 0.0003219042866698613\n",
      " loss = 0.0005030481277699593\n",
      " loss = 0.00032114225279634815\n",
      " loss = 0.0003174001780377264\n",
      " loss = 0.00031370170736070386\n",
      " loss = 0.0005087691568336302\n",
      " loss = 0.00031301378700257173\n",
      " loss = 0.00030936642823945956\n",
      " loss = 0.0005114371150241467\n",
      " loss = 0.0003087162325614192\n",
      " loss = 0.00030511895065135234\n",
      " loss = 0.00030156358559353295\n",
      " loss = 0.000517001323389829\n",
      " loss = 0.00030098276755569493\n",
      " loss = 0.0005166216362724708\n",
      " loss = 0.00030040481950349284\n",
      " loss = 0.0005162404848043843\n",
      " loss = 0.0005129306368046408\n",
      " loss = 0.0005096420097030676\n",
      " loss = 0.00030569490894099524\n",
      " loss = 0.0005093113274800842\n",
      " loss = 0.0005060459053948534\n",
      " loss = 0.00030799949079010153\n",
      " loss = 0.0005057389411509911\n",
      " loss = 0.0005024964232283935\n",
      " loss = 0.0003102783979321055\n",
      " loss = 0.0003066629130495607\n",
      " loss = 0.00030308955714645266\n",
      " loss = 0.00029955783946157305\n",
      " loss = 0.0005109749231549955\n",
      " loss = 0.0002989735167415711\n",
      " loss = 0.00029548976077417284\n",
      " loss = 0.00029204659886367514\n",
      " loss = 0.000288643558083952\n",
      " loss = 0.00028528017082337265\n",
      " loss = 0.00028195597497467263\n",
      " loss = 0.0005250153793884607\n",
      " loss = 0.0002815288667518145\n",
      " loss = 0.000524509625731288\n",
      " loss = 0.000281103195496011\n",
      " loss = 0.0002778276715134066\n",
      " loss = 0.0005268514335052312\n",
      " loss = 0.0005234735539618038\n",
      " loss = 0.0005201173315201634\n",
      " loss = 0.0002831336404444172\n",
      " loss = 0.0005196377397052304\n",
      " loss = 0.0002826840131936882\n",
      " loss = 0.0002793900688115926\n",
      " loss = 0.0002761345068123587\n",
      " loss = 0.0002729168799127148\n",
      " loss = 0.0002697367460077537\n",
      " loss = 0.000530474584378632\n",
      " loss = 0.0005270734752124688\n",
      " loss = 0.0005236941720708148\n",
      " loss = 0.0002750417588890823\n",
      " loss = 0.000523160142907472\n",
      " loss = 0.000519805929886884\n",
      " loss = 0.00027747862543189096\n",
      " loss = 0.0002742453362231057\n",
      " loss = 0.000522115496146461\n",
      " loss = 0.00027386100481990736\n",
      " loss = 0.00027066986966885404\n",
      " loss = 0.0005243856590446889\n",
      " loss = 0.000521023588684115\n",
      " loss = 0.000517683074057181\n",
      " loss = 0.0005143639769552785\n",
      " loss = 0.0005110661600736242\n",
      " loss = 0.0002815650359572664\n",
      " loss = 0.0005106118204441849\n",
      " loss = 0.0005073380603135108\n",
      " loss = 0.0002839228461539304\n",
      " loss = 0.0002806144664435549\n",
      " loss = 0.00027734463726203227\n",
      " loss = 0.00027411290940473345\n",
      " loss = 0.0005153282395922969\n",
      " loss = 0.00027371106895283123\n",
      " loss = 0.0002705216808707938\n",
      " loss = 0.0005176038520982609\n",
      " loss = 0.0002701495163877464\n",
      " loss = 0.0005170673146048968\n",
      " loss = 0.0005137521654183859\n",
      " loss = 0.0002725604230350721\n",
      " loss = 0.0005132423234045942\n",
      " loss = 0.0005099516979533016\n",
      " loss = 0.0005066821701707671\n",
      " loss = 0.00027773616542066816\n",
      " loss = 0.000506224624517343\n",
      " loss = 0.0005029789926569446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.0002800760808957877\n",
      " loss = 0.00027681252521823444\n",
      " loss = 0.00027358699767751854\n",
      " loss = 0.000508105879793876\n",
      " loss = 0.00027316894540691493\n",
      " loss = 0.0005076200117324085\n",
      " loss = 0.000272752325841727\n",
      " loss = 0.0005071338186087214\n",
      " loss = 0.0002723371283680551\n",
      " loss = 0.00026916374994675004\n",
      " loss = 0.0005094036026361877\n",
      " loss = 0.0002687783292507281\n",
      " loss = 0.000508890522094153\n",
      " loss = 0.0005056277979649867\n",
      " loss = 0.0002711469192135236\n",
      " loss = 0.0005051407930501113\n",
      " loss = 0.00027073687333320837\n",
      " loss = 0.0002675821417722228\n",
      " loss = 0.0002644641703452316\n",
      " loss = 0.0005101303763705211\n",
      " loss = 0.00026411140099690737\n",
      " loss = 0.0005095905423745924\n",
      " loss = 0.0005063233301025177\n",
      " loss = 0.00026649042294735225\n",
      " loss = 0.0002633851726233467\n",
      " loss = 0.0005085342074083924\n",
      " loss = 0.0005052737677864642\n",
      " loss = 0.0002657595086360103\n",
      " loss = 0.0005047605370150927\n",
      " loss = 0.00026538383001878813\n",
      " loss = 0.0005042472844415988\n",
      " loss = 0.000265009223598765\n",
      " loss = 0.0005037340155063309\n",
      " loss = 0.00026463568230323056\n",
      " loss = 0.000503220735675453\n",
      " loss = 0.00026426319893840415\n",
      " loss = 0.000502707450332327\n",
      " loss = 0.0002638917665004225\n",
      " loss = 0.00026081679677290983\n",
      " loss = 0.0005048953933987421\n",
      " loss = 0.0002604737166635331\n",
      " loss = 0.0005043562941946453\n",
      " loss = 0.00026013142248017544\n",
      " loss = 0.0005038174378024459\n",
      " loss = 0.000259789909801573\n",
      " loss = 0.0005032788272494382\n",
      " loss = 0.0005000520822131158\n",
      " loss = 0.0002621408995495479\n",
      " loss = 0.0004995396721054739\n",
      " loss = 0.00026177479676615283\n",
      " loss = 0.0004990272854836711\n",
      " loss = 0.00026140970510242376\n",
      " loss = 0.0004985149273513506\n",
      " loss = 0.0004953187258010905\n",
      " loss = 0.0004921430165179946\n",
      " loss = 0.00026642494507673564\n",
      " loss = 0.0004916817343005676\n",
      " loss = 0.0004885293433931818\n",
      " loss = 0.0004853971638700626\n",
      " loss = 0.0004822850661536329\n",
      " loss = 0.0002741051308560833\n",
      " loss = 0.0004818981273668245\n",
      " loss = 0.0004788084635236218\n",
      " loss = 0.00047573860889754883\n",
      " loss = 0.0002790246418775234\n",
      " loss = 0.00027577333793742684\n",
      " loss = 0.00047810197358686985\n",
      " loss = 0.00047503664859018446\n",
      " loss = 0.00047199097674847056\n",
      " loss = 0.00046896483207249027\n",
      " loss = 0.00046595808935803\n",
      " loss = 0.0002860912264252229\n",
      " loss = 0.00028275757985628914\n",
      " loss = 0.0004683960017403387\n",
      " loss = 0.0002821660515134282\n",
      " loss = 0.00046809790350202894\n",
      " loss = 0.0004650967190650007\n",
      " loss = 0.00046211477655592185\n",
      " loss = 0.0004591519526035555\n",
      " loss = 0.0004562081246386026\n",
      " loss = 0.000292417854590918\n",
      " loss = 0.00045600093132353996\n",
      " loss = 0.0002917227389137663\n",
      " loss = 0.00045579121384087116\n",
      " loss = 0.00045286893307683025\n",
      " loss = 0.00029374419349482175\n",
      " loss = 0.00045267934239728066\n",
      " loss = 0.00044977701322656324\n",
      " loss = 0.00044689329217609264\n",
      " loss = 0.0004440280599427041\n",
      " loss = 0.00030117766862113705\n",
      " loss = 0.0004439024134583897\n",
      " loss = 0.0004410563570835048\n",
      " loss = 0.00030310305960187036\n",
      " loss = 0.0002995711845173836\n",
      " loss = 0.00029608046428051063\n",
      " loss = 0.00044636816974902104\n",
      " loss = 0.00044350630432467953\n",
      " loss = 0.00044066278759486777\n",
      " loss = 0.00030074163518000347\n",
      " loss = 0.00029723727631180726\n",
      " loss = 0.0004432478214837803\n",
      " loss = 0.00029646961348658765\n",
      " loss = 0.0002930150339422103\n",
      " loss = 0.00044579328450327255\n",
      " loss = 0.0002922850910432921\n",
      " loss = 0.0002888792712778705\n",
      " loss = 0.0002855131373754648\n",
      " loss = 0.0004509701010823162\n",
      " loss = 0.0004480787306159615\n",
      " loss = 0.00028752064380412897\n",
      " loss = 0.0002841703411266168\n",
      " loss = 0.0004505397892701714\n",
      " loss = 0.0002835167991116312\n",
      " loss = 0.000450310541485508\n",
      " loss = 0.000282867144774192\n",
      " loss = 0.00045007903546813866\n",
      " loss = 0.00044719337801546715\n",
      " loss = 0.00044432622180463926\n",
      " loss = 0.00044147744821206936\n",
      " loss = 0.0002901953978088936\n",
      " loss = 0.00028681392790057454\n",
      " loss = 0.00028347186020215656\n",
      " loss = 0.00028016873558921017\n",
      " loss = 0.0004492548901833534\n",
      " loss = 0.00044637451669326205\n",
      " loss = 0.0002821784833832178\n",
      " loss = 0.0002788904297054502\n",
      " loss = 0.000275640689770537\n",
      " loss = 0.0004514119709524113\n",
      " loss = 0.0002750489809660935\n",
      " loss = 0.0004511395884544171\n",
      " loss = 0.0002744605681364757\n",
      " loss = 0.0004508653531961057\n",
      " loss = 0.0004479746543156934\n",
      " loss = 0.00044510248899015556\n",
      " loss = 0.0002791135022953745\n",
      " loss = 0.00044487139288318134\n",
      " loss = 0.0002784785257165743\n",
      " loss = 0.00027523358532495024\n",
      " loss = 0.0004472494607479152\n",
      " loss = 0.0004443819449706122\n",
      " loss = 0.00044153281411787523\n",
      " loss = 0.0004387019503058269\n",
      " loss = 0.0002824744865777858\n",
      " loss = 0.00043850864705569494\n",
      " loss = 0.00028179707966067343\n",
      " loss = 0.00043831286016270045\n",
      " loss = 0.00043550264091277304\n",
      " loss = 0.00028373797125091536\n",
      " loss = 0.00028043174570435714\n",
      " loss = 0.0002771640457040537\n",
      " loss = 0.00044053506447164117\n",
      " loss = 0.00043771059768289597\n",
      " loss = 0.00043490423981022827\n",
      " loss = 0.0004321158747434625\n",
      " loss = 0.000429345387130673\n",
      " loss = 0.0002869492488885011\n",
      " loss = 0.0004292045071863864\n",
      " loss = 0.00042645268564970933\n",
      " loss = 0.00028882211470247315\n",
      " loss = 0.0004263300461165618\n",
      " loss = 0.0004235966540340236\n",
      " loss = 0.000420880786945588\n",
      " loss = 0.00029328538006420375\n",
      " loss = 0.0002898679044823129\n",
      " loss = 0.0002864902506737143\n",
      " loss = 0.00028315195460616195\n",
      " loss = 0.0002798525576421876\n",
      " loss = 0.0004311820542976491\n",
      " loss = 0.00027917169152513494\n",
      " loss = 0.0004309992017641598\n",
      " loss = 0.00027849507817339036\n",
      " loss = 0.00043081384051894085\n",
      " loss = 0.0002778226774987734\n",
      " loss = 0.0004306259961138079\n",
      " loss = 0.0002771544498391264\n",
      " loss = 0.0004304356939027249\n",
      " loss = 0.000276490355990475\n",
      " loss = 0.0004302429590359854\n",
      " loss = 0.0004274844795291234\n",
      " loss = 0.0004247436858646946\n",
      " loss = 0.0004220204646427364\n",
      " loss = 0.00041931470320408866\n",
      " loss = 0.00041662628960448966\n",
      " loss = 0.0002886925124191299\n",
      " loss = 0.00028532855461712756\n",
      " loss = 0.0002820037950523526\n",
      " loss = 0.0004216758965373612\n",
      " loss = 0.00041897234428232914\n",
      " loss = 0.0002838435802055993\n",
      " loss = 0.00041885225277547985\n",
      " loss = 0.000416166804156375\n",
      " loss = 0.00028566122019255266\n",
      " loss = 0.0002823325842373469\n",
      " loss = 0.00027904273482099525\n",
      " loss = 0.00042117431222606647\n",
      " loss = 0.00027833743460634167\n",
      " loss = 0.00042102171202780883\n",
      " loss = 0.00041832235404546503\n",
      " loss = 0.0002801826945562513\n",
      " loss = 0.00027691789649360803\n",
      " loss = 0.000420728180688897\n",
      " loss = 0.0002762263183603218\n",
      " loss = 0.0004205674033535394\n",
      " loss = 0.0002755391533474285\n",
      " loss = 0.00042040401143865784\n",
      " loss = 0.00027485635963133456\n",
      " loss = 0.00027165362609340527\n",
      " loss = 0.0002684882120362747\n",
      " loss = 0.000425275185207137\n",
      " loss = 0.00026786954958777856\n",
      " loss = 0.000425059972946367\n",
      " loss = 0.0004223347238614977\n",
      " loss = 0.00026976462170776624\n",
      " loss = 0.000422138530255293\n",
      " loss = 0.00041943201185650245\n",
      " loss = 0.00027163783173180845\n",
      " loss = 0.0002684726018243094\n",
      " loss = 0.0004217589252454887\n",
      " loss = 0.00041905484065374874\n",
      " loss = 0.00027034663405592205\n",
      " loss = 0.00026719644968502466\n",
      " loss = 0.00026408297251459436\n",
      " loss = 0.00026100577477153325\n",
      " loss = 0.0002579644337468422\n",
      " loss = 0.00025495853155398167\n",
      " loss = 0.00025198765525819326\n",
      " loss = 0.00024905139686927613\n",
      " loss = 0.0004362005645437623\n",
      " loss = 0.00024859781484792257\n",
      " loss = 0.00043585398048311824\n",
      " loss = 0.00043305952620957284\n",
      " loss = 0.00025059577881907856\n",
      " loss = 0.00043273406027248914\n",
      " loss = 0.0002501219594293827\n",
      " loss = 0.0004324074403702474\n",
      " loss = 0.0002496504284059893\n",
      " loss = 0.00043207968109332235\n",
      " loss = 0.0002491811662952958\n",
      " loss = 0.00024627761016845606\n",
      " loss = 0.00043418476414758294\n",
      " loss = 0.0004314010119553742\n",
      " loss = 0.0002482704436051144\n",
      " loss = 0.00024537749956603537\n",
      " loss = 0.0002425182652425406\n",
      " loss = 0.00023969234790370214\n",
      " loss = 0.00043833056235766403\n",
      " loss = 0.0004355202296095744\n",
      " loss = 0.00024171975286664443\n",
      " loss = 0.0004351419462793148\n",
      " loss = 0.0002413124470770253\n",
      " loss = 0.00043476300444136184\n",
      " loss = 0.00024090681078266351\n",
      " loss = 0.00043438341451668166\n",
      " loss = 0.00043159838868970504\n",
      " loss = 0.0002429102827025453\n",
      " loss = 0.00024007979738743302\n",
      " loss = 0.0002372822939864973\n",
      " loss = 0.0002345173881500761\n",
      " loss = 0.00043842303937630486\n",
      " loss = 0.00043561211371737925\n",
      " loss = 0.0002365535425719137\n",
      " loss = 0.00023379712849325697\n",
      " loss = 0.0004375883893013556\n",
      " loss = 0.00043478281495216623\n",
      " loss = 0.00023582982655560945\n",
      " loss = 0.00023308184541707223\n",
      " loss = 0.00043675256404317376\n",
      " loss = 0.00023273624660205883\n",
      " loss = 0.00023002431312990073\n",
      " loss = 0.0002273439801564455\n",
      " loss = 0.0002246948794180103\n",
      " loss = 0.00022207664701082603\n",
      " loss = 0.00021948892328046846\n",
      " loss = 0.00021693135278603122\n",
      " loss = 0.00045039902000988907\n",
      " loss = 0.0004475113109919168\n",
      " loss = 0.00021905363499844568\n",
      " loss = 0.00044697140385598007\n",
      " loss = 0.00021882604651632568\n",
      " loss = 0.0002162762001151591\n",
      " loss = 0.00021375606553983585\n",
      " loss = 0.0002112652964960322\n",
      " loss = 0.000453366839922442\n",
      " loss = 0.00045046010289988904\n",
      " loss = 0.00021340797773635058\n",
      " loss = 0.00021092126475934589\n",
      " loss = 0.00020846352790592453\n",
      " loss = 0.00045446893947776346\n",
      " loss = 0.00020832159296027623\n",
      " loss = 0.0002058941485902289\n",
      " loss = 0.00020349498960822127\n",
      " loss = 0.00045839921314392575\n",
      " loss = 0.00020339338297753698\n",
      " loss = 0.00020102336399390464\n",
      " loss = 0.00045999550007793137\n",
      " loss = 0.00020094070669221157\n",
      " loss = 0.00045930791286166874\n",
      " loss = 0.00020085685513130769\n",
      " loss = 0.00045862257306589926\n",
      " loss = 0.00045568213918904045\n",
      " loss = 0.00045276055773760634\n",
      " loss = 0.0002052988915231914\n",
      " loss = 0.0002029066688102981\n",
      " loss = 0.0004543862033076734\n",
      " loss = 0.0004514729306812783\n",
      " loss = 0.0004485783363521567\n",
      " loss = 0.00020732723200253355\n",
      " loss = 0.00044797100087327674\n",
      " loss = 0.00020717590286403127\n",
      " loss = 0.00020476180845822476\n",
      " loss = 0.00020237584401481225\n",
      " loss = 0.0004518752345525241\n",
      " loss = 0.00020226483691603258\n",
      " loss = 0.00019990796820595346\n",
      " loss = 0.0004534684998272675\n",
      " loss = 0.00019981595774441218\n",
      " loss = 0.0004528003757523341\n",
      " loss = 0.00019972285285109644\n",
      " loss = 0.00019739560429773731\n",
      " loss = 0.00019509547370305538\n",
      " loss = 0.0004565858174519025\n",
      " loss = 0.00019504012763796376\n",
      " loss = 0.0004558783334155038\n",
      " loss = 0.00045295549407979444\n",
      " loss = 0.0004500513943802055\n",
      " loss = 0.0004471659141599696\n",
      " loss = 0.00020166375856942582\n",
      " loss = 0.00019931389385168322\n",
      " loss = 0.00019699141063581348\n",
      " loss = 0.00019469598990751687\n",
      " loss = 0.0004531896055936371\n",
      " loss = 0.000450284004903359\n",
      " loss = 0.0004473970333127857\n",
      " loss = 0.00044452857138683094\n",
      " loss = 0.00020128932124099962\n",
      " loss = 0.0004439037790719045\n",
      " loss = 0.0002011650404389278\n",
      " loss = 0.0004432807426898561\n",
      " loss = 0.0004404386721353058\n",
      " loss = 0.0002032640643598516\n",
      " loss = 0.00020089555221661362\n",
      " loss = 0.00019855463894269783\n",
      " loss = 0.0001962410028250766\n",
      " loss = 0.00019395432608848633\n",
      " loss = 0.0001916942946279333\n",
      " loss = 0.00018946059798410745\n",
      " loss = 0.00018725292923106308\n",
      " loss = 0.0004552132638702982\n",
      " loss = 0.00045229468858836813\n",
      " loss = 0.0004493948256057363\n",
      " loss = 0.0004465135549379507\n",
      " loss = 0.0004436507573838261\n",
      " loss = 0.0004408063144986648\n",
      " loss = 0.00019817206409927047\n",
      " loss = 0.0004401788155428916\n",
      " loss = 0.00019805759559795647\n",
      " loss = 0.00019574975129509637\n",
      " loss = 0.00044174226767592327\n",
      " loss = 0.00019565397268700319\n",
      " loss = 0.0001933741362449601\n",
      " loss = 0.0001911208653886838\n",
      " loss = 0.0004454488396851451\n",
      " loss = 0.00019106217233455974\n",
      " loss = 0.0004447630490258847\n",
      " loss = 0.00044191147474692495\n",
      " loss = 0.0001931738122792886\n",
      " loss = 0.0004412516670323174\n",
      " loss = 0.00019309245552332464\n",
      " loss = 0.0004405940105087682\n",
      " loss = 0.0001930099694738249\n",
      " loss = 0.00043993848965163674\n",
      " loss = 0.00019292636573961554\n",
      " loss = 0.00019067831245443012\n",
      " loss = 0.00018845645440896118\n",
      " loss = 0.00018626048626105794\n",
      " loss = 0.000445742630471104\n",
      " loss = 0.0004428847756427312\n",
      " loss = 0.00018837827361753375\n",
      " loss = 0.00018618321653493292\n",
      " loss = 0.00018401373710760457\n",
      " loss = 0.0001818695373344379\n",
      " loss = 0.00044859561622080755\n",
      " loss = 0.00018187314588316014\n",
      " loss = 0.0004478442138072302\n",
      " loss = 0.00018187494957236822\n",
      " loss = 0.00017975567168983684\n",
      " loss = 0.00017766108850517922\n",
      " loss = 0.0004513196085951985\n",
      " loss = 0.0004484259972744261\n",
      " loss = 0.00017980577331074842\n",
      " loss = 0.00044766315843479686\n",
      " loss = 0.0004447929902533376\n",
      " loss = 0.0004419412239919188\n",
      " loss = 0.0004391077416802082\n",
      " loss = 0.0004362924260949465\n",
      " loss = 0.00043349516075977794\n",
      " loss = 0.00019044422662962702\n",
      " loss = 0.0004328532605609745\n",
      " loss = 0.00019035867922264298\n",
      " loss = 0.00018814054562809454\n",
      " loss = 0.00018594825862411547\n",
      " loss = 0.00018378151702326274\n",
      " loss = 0.00043857603276876544\n",
      " loss = 0.00018374990838120267\n",
      " loss = 0.00018160878275027165\n",
      " loss = 0.00017949260642118842\n",
      " loss = 0.00017740108855047199\n",
      " loss = 0.000175333941927568\n",
      " loss = 0.00017329088242134199\n",
      " loss = 0.0001712716294926854\n",
      " loss = 0.00045039285058968645\n",
      " loss = 0.0001713402697788932\n",
      " loss = 0.00016934374617640985\n",
      " loss = 0.0004516305273242254\n",
      " loss = 0.00016942606192891303\n",
      " loss = 0.0001674518433221691\n",
      " loss = 0.00016550062921790948\n",
      " loss = 0.00016357215132905818\n",
      " loss = 0.00045692105591508745\n",
      " loss = 0.0004539915312196754\n",
      " loss = 0.00016573662348155551\n",
      " loss = 0.0004531211245391107\n",
      " loss = 0.00016584239124831237\n",
      " loss = 0.00016390993103777775\n",
      " loss = 0.00016199998865505145\n",
      " loss = 0.0004563110045721068\n",
      " loss = 0.0001621333736636342\n",
      " loss = 0.00016024413237972177\n",
      " loss = 0.0004574243383894426\n",
      " loss = 0.0004544915869329655\n",
      " loss = 0.00045157763865330173\n",
      " loss = 0.0004486823729896778\n",
      " loss = 0.0001664639330424797\n",
      " loss = 0.0004478385046577514\n",
      " loss = 0.00016655370537778957\n",
      " loss = 0.00016461295667416105\n",
      " loss = 0.00016269482227486353\n",
      " loss = 0.00045103976575703653\n",
      " loss = 0.0004481479486409502\n",
      " loss = 0.00016483228077017112\n",
      " loss = 0.00016291159073847356\n",
      " loss = 0.00044931066261440884\n",
      " loss = 0.0001630243592794015\n",
      " loss = 0.00044844303729497416\n",
      " loss = 0.00016313455822969202\n",
      " loss = 0.00016123365072653957\n",
      " loss = 0.00015935489335811254\n",
      " loss = 0.0001574980279978161\n",
      " loss = 0.0001556627995186041\n",
      " loss = 0.000455554355397867\n",
      " loss = 0.00015582857960847433\n",
      " loss = 0.0004546153321519259\n",
      " loss = 0.0004517005904838672\n",
      " loss = 0.0004488045365306609\n",
      " loss = 0.00044592705046574805\n",
      " loss = 0.00044306801324179164\n",
      " loss = 0.0001639670790987558\n",
      " loss = 0.00016205647073071872\n",
      " loss = 0.00016016812551220206\n",
      " loss = 0.0004462202941891306\n",
      " loss = 0.00016028901842019856\n",
      " loss = 0.00015842126825577643\n",
      " loss = 0.0004473306824636273\n",
      " loss = 0.0004444626459412087\n",
      " loss = 0.0001605390285940881\n",
      " loss = 0.00015866836523317193\n",
      " loss = 0.0004455795882977118\n",
      " loss = 0.00015879601219128723\n",
      " loss = 0.00015694565912730755\n",
      " loss = 0.00015511686709661365\n",
      " loss = 0.0001533093849037301\n",
      " loss = 0.0004505937764977699\n",
      " loss = 0.00015347685400829954\n",
      " loss = 0.0001516884818381564\n",
      " loss = 0.0004516095882923267\n",
      " loss = 0.0001518667115494153\n",
      " loss = 0.00015009710137930325\n",
      " loss = 0.0001483481114666942\n",
      " loss = 0.00014661950147348444\n",
      " loss = 0.00045646240064352403\n",
      " loss = 0.00014683440056532804\n",
      " loss = 0.000455461366774721\n",
      " loss = 0.00014704608133968815\n",
      " loss = 0.00014533264309161116\n",
      " loss = 0.000456383657168002\n",
      " loss = 0.00014555394015885117\n",
      " loss = 0.0004553745399028153\n",
      " loss = 0.00045245493060991435\n",
      " loss = 0.0004495540402357249\n",
      " loss = 0.00044667174877095414\n",
      " loss = 0.0004438079369537863\n",
      " loss = 0.0001534917878953578\n",
      " loss = 0.00015170324171566286\n",
      " loss = 0.00014993553635792763\n",
      " loss = 0.0004467650658445023\n",
      " loss = 0.00044390065574320887\n",
      " loss = 0.00015204277481171413\n",
      " loss = 0.0001502711130988346\n",
      " loss = 0.00044491214479990286\n",
      " loss = 0.00015044231548803027\n",
      " loss = 0.00044398391193606145\n",
      " loss = 0.0001506106003398984\n",
      " loss = 0.00014885562691387922\n",
      " loss = 0.00014712110309307997\n",
      " loss = 0.00014540679061952416\n",
      " loss = 0.0004487882257112058\n",
      " loss = 0.00014561165362095597\n",
      " loss = 0.00014391492986869206\n",
      " loss = 0.00044970641870799245\n",
      " loss = 0.00014412937898302294\n",
      " loss = 0.00044871670725494405\n",
      " loss = 0.00044583978430950776\n",
      " loss = 0.00014623769176056175\n",
      " loss = 0.00014453367312525992\n",
      " loss = 0.00044677256008092403\n",
      " loss = 0.000443908101925115\n",
      " loss = 0.00014663426906410921\n",
      " loss = 0.00014492562938912931\n",
      " loss = 0.00044485019503818655\n",
      " loss = 0.0004419980620157198\n",
      " loss = 0.00014701853760508337\n",
      " loss = 0.00014530542029440803\n",
      " loss = 0.0004429492203704536\n",
      " loss = 0.00044010927535261907\n",
      " loss = 0.00014739067083487553\n",
      " loss = 0.00043918190077167423\n",
      " loss = 0.00014756464565598488\n",
      " loss = 0.0001458451648508435\n",
      " loss = 0.00044014607950006846\n",
      " loss = 0.00014602930881250296\n",
      " loss = 0.00014432771838580487\n",
      " loss = 0.0001426459554928115\n",
      " loss = 0.0004429600969817676\n",
      " loss = 0.00014285263698273482\n",
      " loss = 0.00044199104631230347\n",
      " loss = 0.00043915724457088847\n",
      " loss = 0.00014493056942250718\n",
      " loss = 0.00043821805030159886\n",
      " loss = 0.0004354084389233687\n",
      " loss = 0.00014699500511425426\n",
      " loss = 0.00043449853688138615\n",
      " loss = 0.0004317127729548106\n",
      " loss = 0.0004289448698138968\n",
      " loss = 0.0004261947129263626\n",
      " loss = 0.0004234621885278239\n",
      " loss = 0.0004207471835590428\n",
      " loss = 0.00041804958569499444\n",
      " loss = 0.00015855574789208325\n",
      " loss = 0.00041728434518695814\n",
      " loss = 0.0004146089491269077\n",
      " loss = 0.0004119507062226192\n",
      " loss = 0.0001624598660952573\n",
      " loss = 0.0004112338536492766\n",
      " loss = 0.0004085972499813036\n",
      " loss = 0.00016441413671521607\n",
      " loss = 0.000407905564857789\n",
      " loss = 0.00016442300323800488\n",
      " loss = 0.00040721673577530734\n",
      " loss = 0.00016443018759001608\n",
      " loss = 0.0004065307398393057\n",
      " loss = 0.0004039242899360414\n",
      " loss = 0.0001663622956506818\n",
      " loss = 0.0004032628589866898\n",
      " loss = 0.00016634871589206202\n",
      " loss = 0.0001644103557748904\n",
      " loss = 0.00040452398667235737\n",
      " loss = 0.0004019304029608402\n",
      " loss = 0.00016633289985674144\n",
      " loss = 0.00016439472401573219\n",
      " loss = 0.0004031935455378473\n",
      " loss = 0.000400608491888421\n",
      " loss = 0.0003980400121663618\n",
      " loss = 0.0003954880001169586\n",
      " loss = 0.0003929523501435647\n",
      " loss = 0.0003904329573561655\n",
      " loss = 0.000387929717514184\n",
      " loss = 0.0001759748836826033\n",
      " loss = 0.00017392435575150754\n",
      " loss = 0.0003893233911557288\n",
      " loss = 0.0003868272652512042\n",
      " loss = 0.00017576960741069866\n",
      " loss = 0.0001737214714641418\n",
      " loss = 0.0003882202359192559\n",
      " loss = 0.0001736269945797493\n",
      " loss = 0.00017160382514098865\n",
      " loss = 0.00038958744533043176\n",
      " loss = 0.0001715256426263909\n",
      " loss = 0.00016952695895506475\n",
      " loss = 0.00016755156478992422\n",
      " loss = 0.00039283912587457815\n",
      " loss = 0.00039032045902531677\n",
      " loss = 0.0003878179404707439\n",
      " loss = 0.0001713330725427865\n",
      " loss = 0.00038724904031722503\n",
      " loss = 0.00038476621399967457\n",
      " loss = 0.0001731694191590488\n",
      " loss = 0.0001711515815869252\n",
      " loss = 0.00016915725663126877\n",
      " loss = 0.0003880406663901292\n",
      " loss = 0.00016909007364282518\n",
      " loss = 0.0001671197702040168\n",
      " loss = 0.00016517242548897874\n",
      " loss = 0.0003912498465504429\n",
      " loss = 0.00038874136926709\n",
      " loss = 0.0003862489749549302\n",
      " loss = 0.000168929522181562\n",
      " loss = 0.00016696108955884713\n",
      " loss = 0.00016501559386491435\n",
      " loss = 0.00016309276779301899\n",
      " loss = 0.0001611923473042642\n",
      " loss = 0.00039320892370952703\n",
      " loss = 0.00016118511183761515\n",
      " loss = 0.0001593069200879844\n",
      " loss = 0.00039442681289816335\n",
      " loss = 0.0003918979666767676\n",
      " loss = 0.00016118150559253004\n",
      " loss = 0.00015930335583750986\n",
      " loss = 0.00015744709096066344\n",
      " loss = 0.0001556124560604639\n",
      " loss = 0.00015379919903997527\n",
      " loss = 0.00039866820856425975\n",
      " loss = 0.00039611216886141655\n",
      " loss = 0.00039357251707063736\n",
      " loss = 0.00039104914811861934\n",
      " loss = 0.00015939914798664763\n",
      " loss = 0.0001575417669531992\n",
      " loss = 0.0001557060288977893\n",
      " loss = 0.00015389168155608725\n",
      " loss = 0.0001520984756829572\n",
      " loss = 0.0003977631188757685\n",
      " loss = 0.0003952128821048268\n",
      " loss = 0.0003926789960315265\n",
      " loss = 0.0003901613558395989\n",
      " loss = 0.00015766929454991786\n",
      " loss = 0.0003895048289895333\n",
      " loss = 0.0003870075397913096\n",
      " loss = 0.0003845262618401308\n",
      " loss = 0.0003820608924594188\n",
      " loss = 0.00016322797171376474\n",
      " loss = 0.0003814690149109189\n",
      " loss = 0.0003790232469005297\n",
      " loss = 0.00037659315980866635\n",
      " loss = 0.00016690281657272572\n",
      " loss = 0.0001649579998760935\n",
      " loss = 0.0003779024160984739\n",
      " loss = 0.00016489124103533553\n",
      " loss = 0.0001629698640345989\n",
      " loss = 0.0003791871269988554\n",
      " loss = 0.00037675598919875963\n",
      " loss = 0.00016477013494185544\n",
      " loss = 0.0003761939023316513\n",
      " loss = 0.00016470030300306209\n",
      " loss = 0.00016278115084625104\n",
      " loss = 0.00037747904959317403\n",
      " loss = 0.00016272647362717538\n",
      " loss = 0.00016083032125150523\n",
      " loss = 0.0003787399386276385\n",
      " loss = 0.00016079040029429317\n",
      " loss = 0.00015891680784080187\n",
      " loss = 0.0001570650472418772\n",
      " loss = 0.00015523486407926175\n",
      " loss = 0.00015342600686737705\n",
      " loss = 0.0003854271549765087\n",
      " loss = 0.0003829560095689675\n",
      " loss = 0.0001552577500033852\n",
      " loss = 0.00015344862620681227\n",
      " loss = 0.00038412203884027185\n",
      " loss = 0.00038165926112095506\n",
      " loss = 0.00015527420109238382\n",
      " loss = 0.0003810231267962758\n",
      " loss = 0.00037858021758003797\n",
      " loss = 0.00015708503177184238\n",
      " loss = 0.00015525461577239576\n",
      " loss = 0.00037977477955532734\n",
      " loss = 0.00037733987405601276\n",
      " loss = 0.0001570594783440828\n",
      " loss = 0.000376731503339149\n",
      " loss = 0.0001570371031700867\n",
      " loss = 0.00015520724560093142\n",
      " loss = 0.00037792853296585177\n",
      " loss = 0.000375505464574466\n",
      " loss = 0.00015700326703382522\n",
      " loss = 0.00015517380372074102\n",
      " loss = 0.0003767040965736294\n",
      " loss = 0.00015516248244911492\n",
      " loss = 0.0001533544687583514\n",
      " loss = 0.00015156752267311867\n",
      " loss = 0.00014980139879039732\n",
      " loss = 0.0003814451117406087\n",
      " loss = 0.00014983249988337438\n",
      " loss = 0.0003807778000885063\n",
      " loss = 0.00037833646376600434\n",
      " loss = 0.00037591077995310543\n",
      " loss = 0.00037350064827330046\n",
      " loss = 0.0001552163009231157\n",
      " loss = 0.0003728970515921433\n",
      " loss = 0.0003705062422733462\n",
      " loss = 0.00036813076150340774\n",
      " loss = 0.00015878510203108892\n",
      " loss = 0.00015693487606404155\n",
      " loss = 0.0003693614285087605\n",
      " loss = 0.0001568954238851795\n",
      " loss = 0.0001550672172745393\n",
      " loss = 0.0003705686685303854\n",
      " loss = 0.0003681927875096441\n",
      " loss = 0.00015682779597544556\n",
      " loss = 0.0003676196839728532\n",
      " loss = 0.00015678474859910134\n",
      " loss = 0.0003670486193934415\n",
      " loss = 0.0003646953069793222\n",
      " loss = 0.000158527728176819\n",
      " loss = 0.0003641457552873016\n",
      " loss = 0.00015846596913293628\n",
      " loss = 0.00036359803192914045\n",
      " loss = 0.00015840323596397825\n",
      " loss = 0.00036305212357871507\n",
      " loss = 0.0003607244344875359\n",
      " loss = 0.00035841166925131164\n",
      " loss = 0.0003561137321768847\n",
      " loss = 0.00016371135143363778\n",
      " loss = 0.00016180372294033032\n",
      " loss = 0.0003574170015118366\n",
      " loss = 0.00035512544168982715\n",
      " loss = 0.00016349642701625833\n",
      " loss = 0.0003546411343372212\n",
      " loss = 0.0001633805721750525\n",
      " loss = 0.00016147679799521447\n",
      " loss = 0.0001595952073758745\n",
      " loss = 0.00035772157062048123\n",
      " loss = 0.00015951107697618856\n",
      " loss = 0.0003572050604239392\n",
      " loss = 0.00015942617454322831\n",
      " loss = 0.0001575684785893386\n",
      " loss = 0.0003584593708831184\n",
      " loss = 0.00035616112796864216\n",
      " loss = 0.000353877620114231\n",
      " loss = 0.0001610433108692173\n",
      " loss = 0.0001591667713890151\n",
      " loss = 0.00015731209812008115\n",
      " loss = 0.00015547903619223232\n",
      " loss = 0.0003586767105921033\n",
      " loss = 0.00015542223202191357\n",
      " loss = 0.0001536111915773556\n",
      " loss = 0.00035988386699378565\n",
      " loss = 0.00035757649099486176\n",
      " loss = 0.00035528390861858713\n",
      " loss = 0.00035300602502067266\n",
      " loss = 0.00015883616260452388\n",
      " loss = 0.00015698534170337821\n",
      " loss = 0.0001551560872942474\n",
      " loss = 0.0001533481480113565\n",
      " loss = 0.00015156127563240338\n",
      " loss = 0.00014979522459155416\n",
      " loss = 0.00014804975223078534\n",
      " loss = 0.00036294854928448994\n",
      " loss = 0.0001480473949073033\n",
      " loss = 0.00014632228894986317\n",
      " loss = 0.0003640641769011035\n",
      " loss = 0.00014633264794216728\n",
      " loss = 0.00036344692757884746\n",
      " loss = 0.0003611167072161988\n",
      " loss = 0.00014805999681410102\n",
      " loss = 0.00014633474403526932\n",
      " loss = 0.00036223554801292484\n",
      " loss = 0.0003599130943427403\n",
      " loss = 0.00035760553095523913\n",
      " loss = 0.0001497764055703158\n",
      " loss = 0.00014803115251963648\n",
      " loss = 0.00035874998636890995\n",
      " loss = 0.00035644988019301087\n",
      " loss = 0.000354164521017832\n",
      " loss = 0.00015145735314859107\n",
      " loss = 0.00035361670018508044\n",
      " loss = 0.00015141233461879707\n",
      " loss = 0.0001496480190231837\n",
      " loss = 0.00035478621380996144\n",
      " loss = 0.00014961664223286635\n",
      " loss = 0.0003542253933497868\n",
      " loss = 0.00035195429635569\n",
      " loss = 0.0001512992374115682\n",
      " loss = 0.0001495362397159677\n",
      " loss = 0.00014779378512793338\n",
      " loss = 0.0003548299835327136\n",
      " loss = 0.00035255501024082116\n",
      " loss = 0.00035029462282178765\n",
      " loss = 0.00015119021559267283\n",
      " loss = 0.00014942848820655527\n",
      " loss = 0.00014768728925506226\n",
      " loss = 0.00014596637933631985\n",
      " loss = 0.0003548614104018893\n",
      " loss = 0.0003525862356280307\n",
      " loss = 0.00014765275327559117\n",
      " loss = 0.00014593224582330113\n",
      " loss = 0.00014423178640709389\n",
      " loss = 0.00035539995689546505\n",
      " loss = 0.00014423379567508852\n",
      " loss = 0.0003548055046111981\n",
      " loss = 0.0001442343812525255\n",
      " loss = 0.00035421345964087623\n",
      " loss = 0.00014423355598974227\n",
      " loss = 0.00014255289035204938\n",
      " loss = 0.0003552993134510952\n",
      " loss = 0.0001425644320615438\n",
      " loss = 0.00014090321573390085\n",
      " loss = 0.00013926135648808456\n",
      " loss = 0.00013763862885758676\n",
      " loss = 0.00013603480986737235\n",
      " loss = 0.00013444967922515342\n",
      " loss = 0.00013288301912537016\n",
      " loss = 0.00036461702106374745\n",
      " loss = 0.00013297078771226667\n",
      " loss = 0.00013142136023709257\n",
      " loss = 0.000129889987324442\n",
      " loss = 0.00012837645852692127\n",
      " loss = 0.0003687950740346736\n",
      " loss = 0.00036643056432606195\n",
      " loss = 0.00036408121454175766\n",
      " loss = 0.0001317479711199301\n",
      " loss = 0.00013021279238395366\n",
      " loss = 0.0003649991588243302\n",
      " loss = 0.00013031605536750776\n",
      " loss = 0.00012879756188994757\n",
      " loss = 0.0003658975222838777\n",
      " loss = 0.0003635515900573704\n",
      " loss = 0.00036122069866179453\n",
      " loss = 0.00035890475164462784\n",
      " loss = 0.00035660365320303305\n",
      " loss = 0.00013541399153328684\n",
      " loss = 0.00035595187569170775\n",
      " loss = 0.00035366970944619643\n",
      " loss = 0.00013710435630063958\n",
      " loss = 0.0001355067628818567\n",
      " loss = 0.0003546723346358709\n",
      " loss = 0.00035239837209794894\n",
      " loss = 0.00013719124232519544\n",
      " loss = 0.00013559263649750593\n",
      " loss = 0.00035340431566128854\n",
      " loss = 0.00013563968975655955\n",
      " loss = 0.00013405916321843945\n",
      " loss = 0.00035438987004747003\n",
      " loss = 0.0003521177185202224\n",
      " loss = 0.0003498601347627741\n",
      " loss = 0.00013737104396361444\n",
      " loss = 0.0001357703430166202\n",
      " loss = 0.0003508727348224873\n",
      " loss = 0.00013581052882570929\n",
      " loss = 0.00013422801159381975\n",
      " loss = 0.0003518649250687936\n",
      " loss = 0.00013427924235816067\n",
      " loss = 0.00035122582012195606\n",
      " loss = 0.0001343287111077292\n",
      " loss = 0.00013276346055138565\n",
      " loss = 0.00013121644889997627\n",
      " loss = 0.00012968746368789284\n",
      " loss = 0.000128176294793596\n",
      " loss = 0.00012668273462612608\n",
      " loss = 0.0003585817734305077\n",
      " loss = 0.00012679092382144282\n",
      " loss = 0.00012531350652247479\n",
      " loss = 0.00012385330466159193\n",
      " loss = 0.00012241011767948735\n",
      " loss = 0.00012098374726177933\n",
      " loss = 0.00011957399741769712\n",
      " loss = 0.00036571188098735247\n",
      " loss = 0.0003633671390038659\n",
      " loss = 0.0003610374302062992\n",
      " loss = 0.00035872265820760497\n",
      " loss = 0.00035642272723505447\n",
      " loss = 0.0001260044133371626\n",
      " loss = 0.00012453616079568912\n",
      " loss = 0.0003572843819796078\n",
      " loss = 0.00012465307136550963\n",
      " loss = 0.0003565633700459007\n",
      " loss = 0.00012476776443758666\n",
      " loss = 0.0003558461200105194\n",
      " loss = 0.00012488025681674496\n",
      " loss = 0.00035513259874820914\n",
      " loss = 0.0001249905653524746\n",
      " loss = 0.0003544227735694629\n",
      " loss = 0.0003521504110808275\n",
      " loss = 0.00012666806139642083\n",
      " loss = 0.0003514635682878924\n",
      " loss = 0.0003492101785821628\n",
      " loss = 0.00012833355992298908\n",
      " loss = 0.0003485458850067521\n",
      " loss = 0.0003463112018761053\n",
      " loss = 0.00012998687692130042\n",
      " loss = 0.00034566903288184373\n",
      " loss = 0.0003434527945296894\n",
      " loss = 0.0003412507654795176\n",
      " loss = 0.000133212318058806\n",
      " loss = 0.0003406488217005567\n",
      " loss = 0.00013324334700713577\n",
      " loss = 0.00034004952424835906\n",
      " loss = 0.00033786931507364087\n",
      " loss = 0.0001348591786589157\n",
      " loss = 0.00033729091953536036\n",
      " loss = 0.0001348728511065528\n",
      " loss = 0.00013330126007184262\n",
      " loss = 0.00033829595573064665\n",
      " loss = 0.0003361269894709711\n",
      " loss = 0.0003339719294140161\n",
      " loss = 0.00033183068640901364\n",
      " loss = 0.00013808660439061337\n",
      " loss = 0.0003312955113728511\n",
      " loss = 0.00013806710880217313\n",
      " loss = 0.000136458297019284\n",
      " loss = 0.000332347821634239\n",
      " loss = 0.00033021699150802286\n",
      " loss = 0.00013803770945997106\n",
      " loss = 0.00013642924021871675\n",
      " loss = 0.00033127071607755445\n",
      " loss = 0.00013641945738369424\n",
      " loss = 0.00013482984468539186\n",
      " loss = 0.0003323040121179581\n",
      " loss = 0.0003301734628762006\n",
      " loss = 0.00013640916521166622\n",
      " loss = 0.00013481967242588507\n",
      " loss = 0.00033120845411460697\n",
      " loss = 0.0003290849289863739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.000326975018721634\n",
      " loss = 0.00032487863603819197\n",
      " loss = 0.0003227956941989214\n",
      " loss = 0.00014114150035361494\n",
      " loss = 0.0003223139441790524\n",
      " loss = 0.00014108184927934492\n",
      " loss = 0.00013943790856857925\n",
      " loss = 0.00013781312369733756\n",
      " loss = 0.000324990231322706\n",
      " loss = 0.0003229065739945909\n",
      " loss = 0.00013935669732153367\n",
      " loss = 0.00013773285874245543\n",
      " loss = 0.00032398694042625977\n",
      " loss = 0.0003219097156423323\n",
      " loss = 0.0001392715641187324\n",
      " loss = 0.00013764871751903007\n",
      " loss = 0.00032299065484612914\n",
      " loss = 0.00013761173414842998\n",
      " loss = 0.00032248812269784327\n",
      " loss = 0.00032042050750064207\n",
      " loss = 0.00031836614871078495\n",
      " loss = 0.00031632496132548405\n",
      " loss = 0.0003142968609067722\n",
      " loss = 0.0001438740238632362\n",
      " loss = 0.000313863697613577\n",
      " loss = 0.00031185137745199493\n",
      " loss = 0.0001453592275035465\n",
      " loss = 0.00014366544511328435\n",
      " loss = 0.00014199139932778962\n",
      " loss = 0.0003145878804702586\n",
      " loss = 0.00031257091725571694\n",
      " loss = 0.00014348154206434026\n",
      " loss = 0.0001418096391664334\n",
      " loss = 0.00014015721797408406\n",
      " loss = 0.00013852405144071814\n",
      " loss = 0.00013690991519698718\n",
      " loss = 0.0003183913581847699\n",
      " loss = 0.0003163500091723575\n",
      " loss = 0.00013842151987630312\n",
      " loss = 0.000315878432821864\n",
      " loss = 0.00031385319529848133\n",
      " loss = 0.0003118409424771255\n",
      " loss = 0.00014148140230627065\n",
      " loss = 0.0003114041664309859\n",
      " loss = 0.0001413925295388706\n",
      " loss = 0.0001397449686473175\n",
      " loss = 0.000312524369346325\n",
      " loss = 0.00031052063622157467\n",
      " loss = 0.00014122614495219604\n",
      " loss = 0.00031008760901082773\n",
      " loss = 0.0003080994990376745\n",
      " loss = 0.00030612413572902954\n",
      " loss = 0.00030416143735617743\n",
      " loss = 0.0003022113227172388\n",
      " loss = 0.0001473907229260752\n",
      " loss = 0.00030184383985418516\n",
      " loss = 0.00029990858436285914\n",
      " loss = 0.00029798573666034965\n",
      " loss = 0.000150384687803278\n",
      " loss = 0.0002976501213382043\n",
      " loss = 0.000295741753645143\n",
      " loss = 0.00029384562135398095\n",
      " loss = 0.0002919616460120391\n",
      " loss = 0.0002900897496782198\n",
      " loss = 0.00015652309658593342\n",
      " loss = 0.0002898152210364139\n",
      " loss = 0.0001562815175388991\n",
      " loss = 0.00015446046432155498\n",
      " loss = 0.00015266063073030093\n",
      " loss = 0.00015088176950292057\n",
      " loss = 0.00014912363627843391\n",
      " loss = 0.00014738598955366976\n",
      " loss = 0.00014566859048011305\n",
      " loss = 0.00029893618619308517\n",
      " loss = 0.00014552168461407045\n",
      " loss = 0.0002985712359384293\n",
      " loss = 0.0002966569625765727\n",
      " loss = 0.0002947549624727944\n",
      " loss = 0.0002928651569419153\n",
      " loss = 0.00029098746779541307\n",
      " loss = 0.00028912181735136995\n",
      " loss = 0.0002872681284218451\n",
      " loss = 0.00015473398310928855\n",
      " loss = 0.00028699491717746846\n",
      " loss = 0.00015449651234123542\n",
      " loss = 0.00015269625874323676\n",
      " loss = 0.00015091698244380704\n",
      " loss = 0.00014915843891860481\n",
      " loss = 0.00014742038658831368\n",
      " loss = 0.00014570258674478025\n",
      " loss = 0.00014400480336589764\n",
      " loss = 0.0001423268032378272\n",
      " loss = 0.00014066835582523455\n",
      " loss = 0.0001390292333092941\n",
      " loss = 0.0003005984189944373\n",
      " loss = 0.00029867114845604523\n",
      " loss = 0.0001404507392194114\n",
      " loss = 0.0001388141523980256\n",
      " loss = 0.0001371966357207348\n",
      " loss = 0.0001355979670183373\n",
      " loss = 0.0003028206706017399\n",
      " loss = 0.00013552371485819474\n",
      " loss = 0.00013394453965475577\n",
      " loss = 0.00030388813463718854\n",
      " loss = 0.0001338830139435019\n",
      " loss = 0.00030344027354453455\n",
      " loss = 0.0001338207536600348\n",
      " loss = 0.0001322614220395284\n",
      " loss = 0.00013072026038189212\n",
      " loss = 0.00012919705697130723\n",
      " loss = 0.00030746047326642194\n",
      " loss = 0.0003054892070347147\n",
      " loss = 0.00030353057947010936\n",
      " loss = 0.0003015845095377759\n",
      " loss = 0.00013363847831120152\n",
      " loss = 0.0001320812706364159\n",
      " loss = 0.00013054220818298342\n",
      " loss = 0.00030411609165272344\n",
      " loss = 0.0003021662677402341\n",
      " loss = 0.00013198612285902198\n",
      " loss = 0.00030171454393211974\n",
      " loss = 0.00029978011741427755\n",
      " loss = 0.0002978580933701779\n",
      " loss = 0.0001349076370050301\n",
      " loss = 0.00013333564060399256\n",
      " loss = 0.0002989258712254101\n",
      " loss = 0.00013326551036338196\n",
      " loss = 0.0001317126486439744\n",
      " loss = 0.0001301778815166998\n",
      " loss = 0.00030144861610087085\n",
      " loss = 0.00013013311397177212\n",
      " loss = 0.00012861675219964525\n",
      " loss = 0.00012711805967010502\n",
      " loss = 0.00030392091484365\n",
      " loss = 0.00012709756252002498\n",
      " loss = 0.00012561657213521475\n",
      " loss = 0.00012415283881965863\n",
      " loss = 0.00030634324641186145\n",
      " loss = 0.00012415556426524172\n",
      " loss = 0.00012270885520425953\n",
      " loss = 0.00012127900376249015\n",
      " loss = 0.0001198658135750042\n",
      " loss = 0.00031015161245297694\n",
      " loss = 0.0003081630921284853\n",
      " loss = 0.00012133923302861734\n",
      " loss = 0.00011992534099205567\n",
      " loss = 0.00011852792413276506\n",
      " loss = 0.00011714679056435695\n",
      " loss = 0.0003119104836268718\n",
      " loss = 0.00011720256119862489\n",
      " loss = 0.0001158368712968863\n",
      " loss = 0.00011448709492949149\n",
      " loss = 0.00031416201442787436\n",
      " loss = 0.00011456276146153657\n",
      " loss = 0.00031355891081757335\n",
      " loss = 0.00011463665218354834\n",
      " loss = 0.0003129587754092873\n",
      " loss = 0.00011470878136983675\n",
      " loss = 0.0003123615827352811\n",
      " loss = 0.00011477916303688526\n",
      " loss = 0.00031176730753864663\n",
      " loss = 0.0003097684282731087\n",
      " loss = 0.00011625801511911001\n",
      " loss = 0.0003091939441398607\n",
      " loss = 0.000307211563854051\n",
      " loss = 0.00030524189349012167\n",
      " loss = 0.00030328485156139173\n",
      " loss = 0.00012056412340313535\n",
      " loss = 0.00011915926321791025\n",
      " loss = 0.0001177707730244619\n",
      " loss = 0.00011639846206566709\n",
      " loss = 0.0003070000018906392\n",
      " loss = 0.00030503168794328175\n",
      " loss = 0.0003030759937343847\n",
      " loss = 0.00011926915973895001\n",
      " loss = 0.00011787938897984112\n",
      " loss = 0.00011650581237150326\n",
      " loss = 0.00030536064881044126\n",
      " loss = 0.0003034028454898991\n",
      " loss = 0.0003014575945241651\n",
      " loss = 0.00011936578243921801\n",
      " loss = 0.00030093586354035007\n",
      " loss = 0.0002990064294909405\n",
      " loss = 0.0002970893659019648\n",
      " loss = 0.00012221210340236064\n",
      " loss = 0.00012078804028659417\n",
      " loss = 0.00011938057096276921\n",
      " loss = 0.0001179895019984157\n",
      " loss = 0.00011661464232603616\n",
      " loss = 0.00030222243177626523\n",
      " loss = 0.00011665113698107441\n",
      " loss = 0.0003016814071758416\n",
      " loss = 0.00029974719311756887\n",
      " loss = 0.00011808433206954828\n",
      " loss = 0.0002992248424070136\n",
      " loss = 0.0001181054388601714\n",
      " loss = 0.00029870474732557025\n",
      " loss = 0.00029678961795804476\n",
      " loss = 0.00011952495893202201\n",
      " loss = 0.00011813220747784656\n",
      " loss = 0.00029768392779283174\n",
      " loss = 0.0001181494254553483\n",
      " loss = 0.00029717037123667153\n",
      " loss = 0.00029526507943506856\n",
      " loss = 0.0001195617169082588\n",
      " loss = 0.00029476964756826015\n",
      " loss = 0.00029287974787914567\n",
      " loss = 0.00012096265161536507\n",
      " loss = 0.00011955314758842358\n",
      " loss = 0.00011816006769842145\n",
      " loss = 0.00011678322052048578\n",
      " loss = 0.0001154224169402578\n",
      " loss = 0.0002979540339212048\n",
      " loss = 0.00029604371771222246\n",
      " loss = 0.0002941456493899888\n",
      " loss = 0.0001182238501600572\n",
      " loss = 0.00011684625974047534\n",
      " loss = 0.00011548472157354829\n",
      " loss = 0.00011413904854686645\n",
      " loss = 0.00029777924959080275\n",
      " loss = 0.00011417932839994239\n",
      " loss = 0.00029724163547234386\n",
      " loss = 0.0002953358867689596\n",
      " loss = 0.00011559123144558466\n",
      " loss = 0.0002948167352753233\n",
      " loss = 0.00029292653368748233\n",
      " loss = 0.0002910484510283015\n",
      " loss = 0.0002891824095927368\n",
      " loss = 0.00011975468532925134\n",
      " loss = 0.0002887126395824993\n",
      " loss = 0.000286861574073269\n",
      " loss = 0.00012112656610607291\n",
      " loss = 0.00011971515207945438\n",
      " loss = 0.00011832018444462627\n",
      " loss = 0.00028916796144176095\n",
      " loss = 0.00028731397666216887\n",
      " loss = 0.00011969443325666371\n",
      " loss = 0.00028685136449075834\n",
      " loss = 0.00011967676929648808\n",
      " loss = 0.00028639050683216323\n",
      " loss = 0.0002845543295497452\n",
      " loss = 0.00012103745095406546\n",
      " loss = 0.0002841104675886482\n",
      " loss = 0.0002822889086606762\n",
      " loss = 0.00028047902855876346\n",
      " loss = 0.00027868075240759425\n",
      " loss = 0.00027689400580558076\n",
      " loss = 0.000126551226373381\n",
      " loss = 0.00027651128369994375\n",
      " loss = 0.00012646662196629427\n",
      " loss = 0.00012499298361217707\n",
      " loss = 0.00012353651663296253\n",
      " loss = 0.00012209702097439095\n",
      " loss = 0.0002802750809950341\n",
      " loss = 0.0002784781124358697\n",
      " loss = 0.00012342702190185032\n",
      " loss = 0.0002780718389639374\n",
      " loss = 0.00012336548375353648\n",
      " loss = 0.00027766682109784513\n",
      " loss = 0.00012330331492335357\n",
      " loss = 0.0002772630500467828\n",
      " loss = 0.0002754853929621547\n",
      " loss = 0.00012461776080357004\n",
      " loss = 0.00012316566606050415\n",
      " loss = 0.00012173049169479592\n",
      " loss = 0.0002778403372097407\n",
      " loss = 0.00012167868385735102\n",
      " loss = 0.00027742677086418856\n",
      " loss = 0.0002756480640910222\n",
      " loss = 0.0001229947883872559\n",
      " loss = 0.0002752505104870422\n",
      " loss = 0.00027348575669064186\n",
      " loss = 0.00012429935798530966\n",
      " loss = 0.0002731039160064134\n",
      " loss = 0.00012422006699158627\n",
      " loss = 0.00027272312905573506\n",
      " loss = 0.00027097457943502605\n",
      " loss = 0.000269237240540294\n",
      " loss = 0.0001268850947762483\n",
      " loss = 0.00012540658018507015\n",
      " loss = 0.0002702565338454423\n",
      " loss = 0.000268523798664145\n",
      " loss = 0.00012668428028068617\n",
      " loss = 0.0001252081056557612\n",
      " loss = 0.0002695418593321954\n",
      " loss = 0.00026781370625017823\n",
      " loss = 0.00012648232120583813\n",
      " loss = 0.00012500849987262785\n",
      " loss = 0.00026883051670171826\n",
      " loss = 0.00026710692434989754\n",
      " loss = 0.0001262792479483318\n",
      " loss = 0.00026676067825441417\n",
      " loss = 0.0002650503565593806\n",
      " loss = 0.0001275383103834006\n",
      " loss = 0.0001260521842802638\n",
      " loss = 0.00026608213850233835\n",
      " loss = 0.00012594417387120559\n",
      " loss = 0.00012447662324918175\n",
      " loss = 0.0002670954028279974\n",
      " loss = 0.00026538293506825686\n",
      " loss = 0.0002636814467045886\n",
      " loss = 0.00012709982748121081\n",
      " loss = 0.00026335279415823376\n",
      " loss = 0.000261664321930606\n",
      " loss = 0.0002599866752542772\n",
      " loss = 0.0001297056468101575\n",
      " loss = 0.00025968595949187284\n",
      " loss = 0.0001295578558562533\n",
      " loss = 0.00012804819722275\n",
      " loss = 0.00026074580346143936\n",
      " loss = 0.0001279137716157477\n",
      " loss = 0.0002604327152194044\n",
      " loss = 0.00012777938439359398\n",
      " loss = 0.00012629044919511533\n",
      " loss = 0.00012481886364641188\n",
      " loss = 0.00026282113528503523\n",
      " loss = 0.00012471022288869255\n",
      " loss = 0.0002624829187953598\n",
      " loss = 0.00026080002372999144\n",
      " loss = 0.0002591279184532815\n",
      " loss = 0.0002574665337879504\n",
      " loss = 0.00012865184662621363\n",
      " loss = 0.00012715274514600426\n",
      " loss = 0.00025851944094389736\n",
      " loss = 0.0002568619574976187\n",
      " loss = 0.00012836812451696528\n",
      " loss = 0.00012687232906261566\n",
      " loss = 0.000257912585827711\n",
      " loss = 0.0002562589932058158\n",
      " loss = 0.00012808483546163256\n",
      " loss = 0.0002559638483337816\n",
      " loss = 0.00025432274993296986\n",
      " loss = 0.0001292856855705689\n",
      " loss = 0.00025404121234181415\n",
      " loss = 0.00025241244082164506\n",
      " loss = 0.00013047483808716406\n",
      " loss = 0.00012895449442187375\n",
      " loss = 0.00012745186639658213\n",
      " loss = 0.0001259667475500349\n",
      " loss = 0.00012449893390890525\n",
      " loss = 0.0002575017057061964\n",
      " loss = 0.00025585074741432765\n",
      " loss = 0.00012571180683491935\n",
      " loss = 0.00025554459681071095\n",
      " loss = 0.0002539061864172775\n",
      " loss = 0.00025227828060309424\n",
      " loss = 0.00012825041086619312\n",
      " loss = 0.00012675598708838048\n",
      " loss = 0.00012527897693232138\n",
      " loss = 0.00012381917743873886\n",
      " loss = 0.0002559878814319235\n",
      " loss = 0.00025434662894722614\n",
      " loss = 0.00025271589926353585\n",
      " loss = 0.00012635329645425557\n",
      " loss = 0.0001248809785706567\n",
      " loss = 0.00012342581668383157\n",
      " loss = 0.00012198761091246697\n",
      " loss = 0.00025638750143249775\n",
      " loss = 0.00012188022190529745\n",
      " loss = 0.00012046002604291505\n",
      " loss = 0.00025736952145920586\n",
      " loss = 0.00025571941066080496\n",
      " loss = 0.00025407987946014234\n",
      " loss = 0.0002524508600230414\n",
      " loss = 0.0002508322849607488\n",
      " loss = 0.00024922408730013894\n",
      " loss = 0.0001269489933631305\n",
      " loss = 0.0002489495266745469\n",
      " loss = 0.00024735340022193113\n",
      " loss = 0.00012811398438819524\n",
      " loss = 0.00024709190769256993\n",
      " loss = 0.0002455076912635685\n",
      " loss = 0.00024393363195405996\n",
      " loss = 0.00013059444613519356\n",
      " loss = 0.00024369757890784307\n",
      " loss = 0.00013039805179368983\n",
      " loss = 0.00024346139777141413\n",
      " loss = 0.00024190045815934724\n",
      " loss = 0.00024034952642873987\n",
      " loss = 0.0002388085384099832\n",
      " loss = 0.0001341881015917312\n",
      " loss = 0.00013262448953355364\n",
      " loss = 0.00013107909728365345\n",
      " loss = 0.00024126081793003493\n",
      " loss = 0.0002397139872175229\n",
      " loss = 0.00023817707392399765\n",
      " loss = 0.00013352231097965692\n",
      " loss = 0.00023797683614403767\n",
      " loss = 0.00023645106049823347\n",
      " loss = 0.00023493506728410117\n",
      " loss = 0.00013594604214539084\n",
      " loss = 0.00013436194587132215\n",
      " loss = 0.0002360841606722962\n",
      " loss = 0.00023457051981363628\n",
      " loss = 0.00023306658358433112\n",
      " loss = 0.00013677226987315446\n",
      " loss = 0.00023290071994731929\n",
      " loss = 0.00013650433738091587\n",
      " loss = 0.00013491373560972183\n",
      " loss = 0.00013334166818629133\n",
      " loss = 0.0001317879190940303\n",
      " loss = 0.0001302522748912724\n",
      " loss = 0.00012873452459791145\n",
      " loss = 0.00023930712102359928\n",
      " loss = 0.0001285384175661594\n",
      " loss = 0.00012704063781708875\n",
      " loss = 0.00024037847021267695\n",
      " loss = 0.00023883729662710343\n",
      " loss = 0.0001281593404961157\n",
      " loss = 0.000126665977849115\n",
      " loss = 0.00012519001648844073\n",
      " loss = 0.0001237312535989891\n",
      " loss = 0.0002424881279266044\n",
      " loss = 0.00024093342837939522\n",
      " loss = 0.00023938869670245313\n",
      " loss = 0.00012615792346065292\n",
      " loss = 0.00023914680275064756\n",
      " loss = 0.00023761352593314964\n",
      " loss = 0.00023609007963236984\n",
      " loss = 0.0002345764008286829\n",
      " loss = 0.00012986425865686523\n",
      " loss = 0.0001283510296587143\n",
      " loss = 0.00012685543343056817\n",
      " loss = 0.00023695611391611593\n",
      " loss = 0.00012666530462461325\n",
      " loss = 0.00012518935107089224\n",
      " loss = 0.00012373059593105728\n",
      " loss = 0.0002392915674781641\n",
      " loss = 0.000123567226567976\n",
      " loss = 0.0001221273730286829\n",
      " loss = 0.00012070429723627706\n",
      " loss = 0.00024158306521760556\n",
      " loss = 0.0001205665491294543\n",
      " loss = 0.00024130385942950668\n",
      " loss = 0.00012042894895228532\n",
      " loss = 0.0001190256638747103\n",
      " loss = 0.00011763873041062425\n",
      " loss = 0.00024354915288345066\n",
      " loss = 0.0001175256316641577\n",
      " loss = 0.00024324629034639316\n",
      " loss = 0.00024168672988667613\n",
      " loss = 0.00011867144119769679\n",
      " loss = 0.00024139709795602867\n",
      " loss = 0.00011854619428410329\n",
      " loss = 0.00011716484779247514\n",
      " loss = 0.0001157995973226146\n",
      " loss = 0.00024361264030527515\n",
      " loss = 0.00024205073100651192\n",
      " loss = 0.00011694896978043813\n",
      " loss = 0.00024175051653560676\n",
      " loss = 0.0002402005461485784\n",
      " loss = 0.00011808758575137016\n",
      " loss = 0.00011671158314090361\n",
      " loss = 0.00024116235783783676\n",
      " loss = 0.00011659816539351563\n",
      " loss = 0.0002408636653589258\n",
      " loss = 0.00023931938096338206\n",
      " loss = 0.00023778499766638578\n",
      " loss = 0.00011898296802385828\n",
      " loss = 0.00011759653211395773\n",
      " loss = 0.0002387591620584289\n",
      " loss = 0.0001174712401810931\n",
      " loss = 0.00023847429905834967\n",
      " loss = 0.00011734600204137548\n",
      " loss = 0.0002381898551179816\n",
      " loss = 0.00023666271371385492\n",
      " loss = 0.00023514536349469889\n",
      " loss = 0.00011971291282003596\n",
      " loss = 0.00011831797128816345\n",
      " loss = 0.00011693928418569299\n",
      " loss = 0.00023737043497673726\n",
      " loss = 0.00011681455058470548\n",
      " loss = 0.00011545338187377699\n",
      " loss = 0.00023832217052634544\n",
      " loss = 0.00011534056378432157\n",
      " loss = 0.00023802761475885518\n",
      " loss = 0.0001152276960126752\n",
      " loss = 0.00023773358197755464\n",
      " loss = 0.00011511478024251113\n",
      " loss = 0.00011377341792611015\n",
      " loss = 0.00023866675237987477\n",
      " loss = 0.00023713655337812331\n",
      " loss = 0.00011489915364271571\n",
      " loss = 0.00011356030390621945\n",
      " loss = 0.00011223705495052333\n",
      " loss = 0.00023928813593986032\n",
      " loss = 0.00011214693949415416\n",
      " loss = 0.00011084015962888364\n",
      " loss = 0.0001095486068416608\n",
      " loss = 0.00010827210377045277\n",
      " loss = 0.0001070104750363943\n",
      " loss = 0.0001057635473027243\n",
      " loss = 0.00010453114919753213\n",
      " loss = 0.00010331311149884595\n",
      " loss = 0.00024738977023864564\n",
      " loss = 0.00010329737562131472\n",
      " loss = 0.0002469927978500907\n",
      " loss = 0.00010328077658969313\n",
      " loss = 0.0001020773087454427\n",
      " loss = 0.00024778132814619043\n",
      " loss = 0.00024619269153573265\n",
      " loss = 0.00010325479724937928\n",
      " loss = 0.00010205163206331506\n",
      " loss = 0.0002469822171257098\n",
      " loss = 0.00010204236473463056\n",
      " loss = 0.0002465796303952228\n",
      " loss = 0.0002449986984046313\n",
      " loss = 0.00024342790246982413\n",
      " loss = 0.00024186717761359434\n",
      " loss = 0.00010558674357354555\n",
      " loss = 0.00010435640567542183\n",
      " loss = 0.00024269001295806696\n",
      " loss = 0.00010432305049846676\n",
      " loss = 0.00010310743763298073\n",
      " loss = 0.00024349729143221364\n",
      " loss = 0.0001030835169218338\n",
      " loss = 0.00024311467113667648\n",
      " loss = 0.00024155595454043388\n",
      " loss = 0.00024000723157256595\n",
      " loss = 0.00010542051498146961\n",
      " loss = 0.00010419211402920789\n",
      " loss = 0.00024083100393369113\n",
      " loss = 0.00010415519705812909\n",
      " loss = 0.00010294154007743537\n",
      " loss = 0.00010174202511062643\n",
      " loss = 0.0002428093841167083\n",
      " loss = 0.00024125262485346445\n",
      " loss = 0.00010289558707698778\n",
      " loss = 0.00024087788683908214\n",
      " loss = 0.00010286656571952457\n",
      " loss = 0.00010166792437839135\n",
      " loss = 0.00010048325008797138\n",
      " loss = 9.931238003877073e-05\n",
      " loss = 9.815515349043274e-05\n",
      " loss = 0.0002451481470745991\n",
      " loss = 9.816429427674774e-05\n",
      " loss = 9.702044565031514e-05\n",
      " loss = 9.588992557781035e-05\n",
      " loss = 0.0002470260820256081\n",
      " loss = 0.0002454422876304002\n",
      " loss = 0.0002438686476505351\n",
      " loss = 0.00024230509697600265\n",
      " loss = 9.936694513223124e-05\n",
      " loss = 9.820908275733661e-05\n",
      " loss = 0.000243056063403953\n",
      " loss = 0.00024149772256923437\n",
      " loss = 0.00023994937295088604\n",
      " loss = 0.00023841095049896753\n",
      " loss = 0.00023688239155713746\n",
      " loss = 0.00010283577613319599\n",
      " loss = 0.00023652468391453874\n",
      " loss = 0.00023500821866833752\n",
      " loss = 0.00010395825501127965\n",
      " loss = 0.0002346642329057725\n",
      " loss = 0.00010390755020470094\n",
      " loss = 0.00023432131860690402\n",
      " loss = 0.00023281898012046366\n",
      " loss = 0.00010501858284638178\n",
      " loss = 0.0002324895032848148\n",
      " loss = 0.00023099890938314214\n",
      " loss = 0.00022951787234461602\n",
      " loss = 0.00010728624811168935\n",
      " loss = 0.00022921371349950522\n",
      " loss = 0.00010720133329254105\n",
      " loss = 0.00022891026961615436\n",
      " loss = 0.00010711617463081981\n",
      " loss = 0.00022860753651817806\n",
      " loss = 0.00022714183163391574\n",
      " loss = 0.00022568552404110016\n",
      " loss = 0.00010936400646279813\n",
      " loss = 0.00022540733157677987\n",
      " loss = 0.00022396214463874181\n",
      " loss = 0.00011042531926346246\n",
      " loss = 0.00022369617951663602\n",
      " loss = 0.0002222619635357422\n",
      " loss = 0.00022083694295263787\n",
      " loss = 0.00011264911164442446\n",
      " loss = 0.00011133648024564645\n",
      " loss = 0.00022176416536734823\n",
      " loss = 0.00022034233639078063\n",
      " loss = 0.0002189296233903625\n",
      " loss = 0.00021752596792384528\n",
      " loss = 0.00011472308511264967\n",
      " loss = 0.00021730661093572186\n",
      " loss = 0.00021591336132734934\n",
      " loss = 0.0002145290444634765\n",
      " loss = 0.00021315360307191142\n",
      " loss = 0.00021178698024571218\n",
      " loss = 0.00021042911945372308\n",
      " loss = 0.00012045719833412032\n",
      " loss = 0.00011905358405485769\n",
      " loss = 0.00021144550297614722\n",
      " loss = 0.00011884497221656337\n",
      " loss = 0.0002112692721769586\n",
      " loss = 0.00011863726858908355\n",
      " loss = 0.00021109264824222974\n",
      " loss = 0.00011843046575159887\n",
      " loss = 0.00011705046775770404\n",
      " loss = 0.00011568655006150435\n",
      " loss = 0.00011433852524803765\n",
      " loss = 0.00021442308565410958\n",
      " loss = 0.00011416946384046678\n",
      " loss = 0.00021421239863999062\n",
      " loss = 0.00011400094158134201\n",
      " loss = 0.00011267255816454675\n",
      " loss = 0.00011135965357176369\n",
      " loss = 0.00021631593947803767\n",
      " loss = 0.00021492904150465487\n",
      " loss = 0.00021355103555644096\n",
      " loss = 0.0002121818646131488\n",
      " loss = 0.00021082147204015168\n",
      " loss = 0.00011584992359334942\n",
      " loss = 0.00021063254772425436\n",
      " loss = 0.00011566047241380418\n",
      " loss = 0.00021044336231334864\n",
      " loss = 0.0001154717597309666\n",
      " loss = 0.00011412623773390735\n",
      " loss = 0.0002114101271546565\n",
      " loss = 0.00011395035745623036\n",
      " loss = 0.00021120945013695653\n",
      " loss = 0.00020985529214435586\n",
      " loss = 0.00011492975598619633\n",
      " loss = 0.00020966527600317403\n",
      " loss = 0.00011474375692502171\n",
      " loss = 0.0002094750194150053\n",
      " loss = 0.00011455846974274336\n",
      " loss = 0.00011322358974117054\n",
      " loss = 0.00011190426435752547\n",
      " loss = 0.00021157886056946364\n",
      " loss = 0.00021022233412508348\n",
      " loss = 0.00020887450497519898\n",
      " loss = 0.00011403628444699974\n",
      " loss = 0.00011270748914884589\n",
      " loss = 0.00011139417753602654\n",
      " loss = 0.00021096938657531148\n",
      " loss = 0.00020961676773765658\n",
      " loss = 0.00020827282114233679\n",
      " loss = 0.0001135193823627796\n",
      " loss = 0.00020808149768156313\n",
      " loss = 0.00011333838974098402\n",
      " loss = 0.0001120177266796611\n",
      " loss = 0.00020902897587222785\n",
      " loss = 0.00020768879787590451\n",
      " loss = 0.00020635721235924125\n",
      " loss = 0.0002050341642276909\n",
      " loss = 0.0002037195987507623\n",
      " loss = 0.00020241346154015579\n",
      " loss = 0.00011756435454600588\n",
      " loss = 0.00011619444883719814\n",
      " loss = 0.00011484050582254468\n",
      " loss = 0.00011350233949171691\n",
      " loss = 0.00011217976598753304\n",
      " loss = 0.00011087260359077592\n",
      " loss = 0.00010958067280183565\n",
      " loss = 0.00010830379609454788\n",
      " loss = 0.00021019975690879586\n",
      " loss = 0.00010816278434831161\n",
      " loss = 0.00010690242941991594\n",
      " loss = 0.00021109209489646364\n",
      " loss = 0.00010677285764473531\n",
      " loss = 0.00021085560826300092\n",
      " loss = 0.0002095037189119784\n",
      " loss = 0.00010776053947188532\n",
      " loss = 0.0002092783530478224\n",
      " loss = 0.00010762059042684822\n",
      " loss = 0.00010636655334382435\n",
      " loss = 0.00021016607272027074\n",
      " loss = 0.00020881860428861957\n",
      " loss = 0.00010735107696258463\n",
      " loss = 0.00010610018033493224\n",
      " loss = 0.000209704030093206\n",
      " loss = 0.00020835952402079396\n",
      " loss = 0.00010708258030293525\n",
      " loss = 0.000208134924410429\n",
      " loss = 0.00020680047857582528\n",
      " loss = 0.00010805532944894399\n",
      " loss = 0.00020658673891074198\n",
      " loss = 0.00020526221918563248\n",
      " loss = 0.00010901840037156928\n",
      " loss = 0.0002050591370269086\n",
      " loss = 0.00020374441143765953\n",
      " loss = 0.00020243811513708052\n",
      " loss = 0.0002011401940888359\n",
      " loss = 0.0001998505945923637\n",
      " loss = 0.00011332264890882942\n",
      " loss = 0.00019968895952530578\n",
      " loss = 0.00011311966115647783\n",
      " loss = 0.00011180154674370346\n",
      " loss = 0.00020064172468454346\n",
      " loss = 0.00011161142835454046\n",
      " loss = 0.00011031088847744288\n",
      " loss = 0.00010902550301370062\n",
      " loss = 0.00010775509534573845\n",
      " loss = 0.00010649949097923288\n",
      " loss = 0.00010525851739688189\n",
      " loss = 0.00010403200409131055\n",
      " loss = 0.00020707645208768564\n",
      " loss = 0.00010391028235854684\n",
      " loss = 0.00010269947922320925\n",
      " loss = 0.00020792789417871344\n",
      " loss = 0.00010258852780553939\n",
      " loss = 0.00010139312627240067\n",
      " loss = 0.00010021165402903855\n",
      " loss = 0.0002098438721642657\n",
      " loss = 0.00020849846950166305\n",
      " loss = 0.0002071616928134799\n",
      " loss = 0.00020583348679905112\n",
      " loss = 0.00010336778117198558\n",
      " loss = 0.0001021632994846041\n",
      " loss = 0.00010097285291494487\n",
      " loss = 9.979627783904457e-05\n",
      " loss = 0.00020883351792117753\n",
      " loss = 9.970607500084662e-05\n",
      " loss = 9.854426092328767e-05\n",
      " loss = 0.0002096380544974096\n",
      " loss = 0.00020829397142825746\n",
      " loss = 0.0002069585058730677\n",
      " loss = 0.00010060700176593895\n",
      " loss = 0.00020670509663974317\n",
      " loss = 0.0002053798180679663\n",
      " loss = 0.00010157992703961848\n",
      " loss = 0.00010039627812239819\n",
      " loss = 9.922642155317891e-05\n",
      " loss = 9.807019663292339e-05\n",
      " loss = 9.692744447038426e-05\n",
      " loss = 9.57980081096282e-05\n",
      " loss = 0.00021045794505403708\n",
      " loss = 9.573683705852915e-05\n",
      " loss = 0.0002101645657233565\n",
      " loss = 9.567530532573448e-05\n",
      " loss = 9.45604593820848e-05\n",
      " loss = 9.345860401995168e-05\n",
      " loss = 0.0002119711650516686\n",
      " loss = 0.00021061212336940315\n",
      " loss = 0.00020926179510833033\n",
      " loss = 0.00020792012440000264\n",
      " loss = 9.656813044123269e-05\n",
      " loss = 9.544288095605303e-05\n",
      " loss = 0.00020869182571779045\n",
      " loss = 9.537945544475536e-05\n",
      " loss = 0.0002084033683417768\n",
      " loss = 0.00020706720139324866\n",
      " loss = 9.636573013002331e-05\n",
      " loss = 0.00020679047044160737\n",
      " loss = 9.629177065246505e-05\n",
      " loss = 9.516974139665823e-05\n",
      " loss = 0.00020756069013014322\n",
      " loss = 9.510515140195372e-05\n",
      " loss = 9.399694905558697e-05\n",
      " loss = 0.00020831684987828808\n",
      " loss = 0.00020698123763767954\n",
      " loss = 9.498372432043186e-05\n",
      " loss = 0.00020669726935200074\n",
      " loss = 0.0002053720409643725\n",
      " loss = 9.596164462684421e-05\n",
      " loss = 9.484346211848099e-05\n",
      " loss = 9.373830911695252e-05\n",
      " loss = 9.264603379860165e-05\n",
      " loss = 9.156648609994545e-05\n",
      " loss = 9.049951768196205e-05\n",
      " loss = 0.000210269392929145\n",
      " loss = 9.047011448961873e-05\n",
      " loss = 0.00020994727069896388\n",
      " loss = 9.044010023155114e-05\n",
      " loss = 8.938625689506607e-05\n",
      " loss = 8.834469341895078e-05\n",
      " loss = 8.731526661990294e-05\n",
      " loss = 8.629783507649888e-05\n",
      " loss = 0.0002136913941537595\n",
      " loss = 8.630151727503203e-05\n",
      " loss = 8.529589839029009e-05\n",
      " loss = 8.430199733240086e-05\n",
      " loss = 0.00021534126202982028\n",
      " loss = 0.00021396061314938648\n",
      " loss = 0.00021258881622192305\n",
      " loss = 8.633207061693575e-05\n",
      " loss = 0.00021223356158392147\n",
      " loss = 8.633209423136219e-05\n",
      " loss = 0.0002118797434475412\n",
      " loss = 8.633127625816786e-05\n",
      " loss = 8.532531056605864e-05\n",
      " loss = 8.43310667711377e-05\n",
      " loss = 8.334840825887044e-05\n",
      " loss = 8.23772000992115e-05\n",
      " loss = 8.141730881682286e-05\n",
      " loss = 0.0002165050013548838\n",
      " loss = 0.00021511689122536538\n",
      " loss = 8.244510294619782e-05\n",
      " loss = 8.14844204444936e-05\n",
      " loss = 8.053493220373808e-05\n",
      " loss = 7.959650777526033e-05\n",
      " loss = 7.866901823995028e-05\n",
      " loss = 7.775233618706378e-05\n",
      " loss = 0.00021962842187041448\n",
      " loss = 0.00021822028609514446\n",
      " loss = 0.0002168211785089449\n",
      " loss = 0.00021543104122670942\n",
      " loss = 8.074944667268802e-05\n",
      " loss = 7.980852263282655e-05\n",
      " loss = 7.887856260358008e-05\n",
      " loss = 0.00021698248654928895\n",
      " loss = 0.00021559131504927955\n",
      " loss = 0.0002142090629663885\n",
      " loss = 8.088538550158897e-05\n",
      " loss = 0.00021381478148456605\n",
      " loss = 0.0002124439195516254\n",
      " loss = 0.0002110818468245487\n",
      " loss = 0.0002097285069529671\n",
      " loss = 0.00020838384394967547\n",
      " loss = 8.485750560781932e-05\n",
      " loss = 8.386871285594717e-05\n",
      " loss = 0.0002090227088387395\n",
      " loss = 0.00020768257102407231\n",
      " loss = 0.00020635102542878155\n",
      " loss = 0.0002050280169678727\n",
      " loss = 8.684310648394378e-05\n",
      " loss = 8.583117677065248e-05\n",
      " loss = 0.0002056953108167152\n",
      " loss = 8.581850604446566e-05\n",
      " loss = 8.481851533409557e-05\n",
      " loss = 8.383017690174289e-05\n",
      " loss = 8.28533550171023e-05\n",
      " loss = 0.00020830935161484637\n",
      " loss = 0.0002069737874517958\n",
      " loss = 0.0002056467861856005\n",
      " loss = 8.482494303074842e-05\n",
      " loss = 8.383652973919605e-05\n",
      " loss = 8.285963380640942e-05\n",
      " loss = 0.000207265499052912\n",
      " loss = 8.286810169829352e-05\n",
      " loss = 0.0002069115014284194\n",
      " loss = 8.287568598403539e-05\n",
      " loss = 0.00020655898617900174\n",
      " loss = 0.00020523464438864785\n",
      " loss = 0.0002039187935418736\n",
      " loss = 0.00020261137920349025\n",
      " loss = 8.581496877614613e-05\n",
      " loss = 8.48150192731496e-05\n",
      " loss = 0.00020327075596417382\n",
      " loss = 8.480252423584331e-05\n",
      " loss = 8.381437216945122e-05\n",
      " loss = 0.00020391744795527784\n",
      " loss = 8.380932681356441e-05\n",
      " loss = 8.283274786112278e-05\n",
      " loss = 0.00020455158770400056\n",
      " loss = 8.283495614158766e-05\n",
      " loss = 8.186973092341577e-05\n",
      " loss = 8.091575288636009e-05\n",
      " loss = 0.00020613483074067673\n",
      " loss = 8.093277628406487e-05\n",
      " loss = 0.00020577398968871366\n",
      " loss = 8.094885886408497e-05\n",
      " loss = 0.0002054147173217821\n",
      " loss = 8.09640087970555e-05\n",
      " loss = 8.002058458267782e-05\n",
      " loss = 7.908815352852788e-05\n",
      " loss = 7.816658750698162e-05\n",
      " loss = 0.0002079145870204573\n",
      " loss = 0.00020658155386480922\n",
      " loss = 0.00020525706738217282\n",
      " loss = 8.010652178613899e-05\n",
      " loss = 7.917308936247914e-05\n",
      " loss = 0.00020584535252706648\n",
      " loss = 0.00020452558615679796\n",
      " loss = 8.015088702799592e-05\n",
      " loss = 7.921693764919785e-05\n",
      " loss = 7.829387102588284e-05\n",
      " loss = 0.00020606136673787388\n",
      " loss = 0.0002047402154031819\n",
      " loss = 7.927239332303577e-05\n",
      " loss = 0.00020437517951552576\n",
      " loss = 7.929472144095235e-05\n",
      " loss = 7.837074844039111e-05\n",
      " loss = 7.745754190657212e-05\n",
      " loss = 0.00020589558686788024\n",
      " loss = 0.00020457549842335245\n",
      " loss = 7.843498324689263e-05\n",
      " loss = 0.00020420611539584069\n",
      " loss = 0.0002028968589088209\n",
      " loss = 7.940496404926572e-05\n",
      " loss = 0.00020254016033585662\n",
      " loss = 0.00020124158502880573\n",
      " loss = 8.036739206115925e-05\n",
      " loss = 7.94309198716019e-05\n",
      " loss = 7.850535982377716e-05\n",
      " loss = 0.00020277937601548418\n",
      " loss = 0.00020147926699197683\n",
      " loss = 0.00020018749354546272\n",
      " loss = 8.041164355157936e-05\n",
      " loss = 0.00019984778142250462\n",
      " loss = 0.00019856646815901482\n",
      " loss = 0.0001972933699635403\n",
      " loss = 0.0001960284341676551\n",
      " loss = 8.325808333251361e-05\n",
      " loss = 0.0001957219500229672\n",
      " loss = 0.00019446708930083095\n",
      " loss = 0.0001932202740553888\n",
      " loss = 8.514094977384406e-05\n",
      " loss = 0.00019293559334529904\n",
      " loss = 8.510127501346802e-05\n",
      " loss = 0.0001926518131113866\n",
      " loss = 0.00019141663640989773\n",
      " loss = 0.00019018937897730915\n",
      " loss = 8.697090379101904e-05\n",
      " loss = 0.00018992675882357715\n",
      " loss = 0.0001887090536626047\n",
      " loss = 0.00018749915574963754\n",
      " loss = 8.882904797113364e-05\n",
      " loss = 8.779397728612266e-05\n",
      " loss = 8.677096764042703e-05\n",
      " loss = 8.575987850465371e-05\n",
      " loss = 0.000190118367526639\n",
      " loss = 8.570941365974245e-05\n",
      " loss = 0.00018984905261792121\n",
      " loss = 0.0001886318456623993\n",
      " loss = 0.0001874224427625042\n",
      " loss = 8.756093920479793e-05\n",
      " loss = 0.0001871738067995698\n",
      " loss = 8.74918980076496e-05\n",
      " loss = 8.647240828383698e-05\n",
      " loss = 0.00018787460906978762\n",
      " loss = 8.641190896269522e-05\n",
      " loss = 8.540500367259885e-05\n",
      " loss = 0.00018856264427247\n",
      " loss = 8.535282140642333e-05\n",
      " loss = 8.435825703116615e-05\n",
      " loss = 0.00018923803764045403\n",
      " loss = 8.431417301369248e-05\n",
      " loss = 8.333171135491319e-05\n",
      " loss = 0.00018990091456939651\n",
      " loss = 0.00018868337510407707\n",
      " loss = 8.423257562783219e-05\n",
      " loss = 0.00018841147842913033\n",
      " loss = 0.000187203488404809\n",
      " loss = 8.51255410534553e-05\n",
      " loss = 0.00018694234423142153\n",
      " loss = 0.00018574377348191948\n",
      " loss = 8.601055424949456e-05\n",
      " loss = 8.500832571420367e-05\n",
      " loss = 8.401777555257724e-05\n",
      " loss = 8.303876768939383e-05\n",
      " loss = 0.00018829526755315557\n",
      " loss = 8.300037789531745e-05\n",
      " loss = 8.203322512973618e-05\n",
      " loss = 0.0001889448469238045\n",
      " loss = 0.0001877334372361954\n",
      " loss = 0.00018652979443739592\n",
      " loss = 0.00018533386872779644\n",
      " loss = 0.00018414561063196422\n",
      " loss = 0.00018296497098809476\n",
      " loss = 8.666140056720613e-05\n",
      " loss = 8.565158814772826e-05\n",
      " loss = 8.465354242276732e-05\n",
      " loss = 8.366712633213773e-05\n",
      " loss = 8.269220433815336e-05\n",
      " loss = 0.00018644478530617062\n",
      " loss = 0.00018524940462395287\n",
      " loss = 0.00018406168806180145\n",
      " loss = 8.450326015205809e-05\n",
      " loss = 0.00018380936944616385\n",
      " loss = 8.444467679217991e-05\n",
      " loss = 0.00018355771139290223\n",
      " loss = 8.438582017274961e-05\n",
      " loss = 8.340252366398187e-05\n",
      " loss = 0.0001842294919491476\n",
      " loss = 8.335178564317681e-05\n",
      " loss = 0.00018397016604393217\n",
      " loss = 8.330070931902328e-05\n",
      " loss = 0.0001837115719237842\n",
      " loss = 0.0001825337150929857\n",
      " loss = 8.417066706472517e-05\n",
      " loss = 0.00018228551657687646\n",
      " loss = 0.0001811168028238574\n",
      " loss = 0.0001799555822143015\n",
      " loss = 8.595732847542572e-05\n",
      " loss = 0.00017972706517779192\n",
      " loss = 8.587925538437873e-05\n",
      " loss = 0.00017949900580701124\n",
      " loss = 0.00017834815761661994\n",
      " loss = 8.6725615821838e-05\n",
      " loss = 0.0001781299228967997\n",
      " loss = 8.66385553404156e-05\n",
      " loss = 8.562900909110641e-05\n",
      " loss = 8.463122648175061e-05\n",
      " loss = 8.364507044051638e-05\n",
      " loss = 8.267040548165954e-05\n",
      " loss = 0.00018157862839720496\n",
      " loss = 0.0001804144468181838\n",
      " loss = 0.00017925772932871216\n",
      " loss = 8.444460941178778e-05\n",
      " loss = 0.00017902372075384612\n",
      " loss = 0.00017787591982679703\n",
      " loss = 0.00017673547796895637\n",
      " loss = 8.620742800755158e-05\n",
      " loss = 8.520290544926194e-05\n",
      " loss = 8.421008798029192e-05\n",
      " loss = 8.3228839214623e-05\n",
      " loss = 8.225902434073292e-05\n",
      " loss = 0.00018016377004924413\n",
      " loss = 0.00017900865975804237\n",
      " loss = 8.311179353803847e-05\n",
      " loss = 8.214334250380047e-05\n",
      " loss = 0.0001796727444212372\n",
      " loss = 8.208890923329971e-05\n",
      " loss = 0.00017942424449871866\n",
      " loss = 0.00017827387563861845\n",
      " loss = 8.293805923070562e-05\n",
      " loss = 8.197163264558229e-05\n",
      " loss = 8.101646720785557e-05\n",
      " loss = 8.007243175500957e-05\n",
      " loss = 0.00018073119972627426\n",
      " loss = 8.003333806908414e-05\n",
      " loss = 0.0001804671364228844\n",
      " loss = 7.999382729230742e-05\n",
      " loss = 0.00018020389212277069\n",
      " loss = 0.0001790485245904754\n",
      " loss = 8.084821671992098e-05\n",
      " loss = 0.00017879560787687038\n",
      " loss = 8.079955482709862e-05\n",
      " loss = 7.985804692161368e-05\n",
      " loss = 0.000179434553906378\n",
      " loss = 0.00017828411894746688\n",
      " loss = 8.070867443635472e-05\n",
      " loss = 0.00017803342088018205\n",
      " loss = 8.065895940782014e-05\n",
      " loss = 0.0001777834282792018\n",
      " loss = 8.060892291317489e-05\n",
      " loss = 0.00017753413646646454\n",
      " loss = 8.055856855705164e-05\n",
      " loss = 7.9619868712863e-05\n",
      " loss = 0.00017817221547028236\n",
      " loss = 0.00017702987392828666\n",
      " loss = 0.00017589485644247313\n",
      " loss = 0.00017476711606037015\n",
      " loss = 8.224472818356466e-05\n",
      " loss = 8.128638053033529e-05\n",
      " loss = 8.033919991141998e-05\n",
      " loss = 0.0001763134717473423\n",
      " loss = 0.00017518304744025654\n",
      " loss = 0.0001740598707870795\n",
      " loss = 0.00017294389532114098\n",
      " loss = 8.295264637581642e-05\n",
      " loss = 8.198604975671119e-05\n",
      " loss = 8.103071632994881e-05\n",
      " loss = 8.008651483019461e-05\n",
      " loss = 0.00017538174953038717\n",
      " loss = 8.00339681621721e-05\n",
      " loss = 7.910138117067625e-05\n",
      " loss = 0.0001760170822031353\n",
      " loss = 0.00017488855818123205\n",
      " loss = 7.993535730579679e-05\n",
      " loss = 0.00017464685278398146\n",
      " loss = 0.0001735271139112387\n",
      " loss = 0.00017241455418406191\n",
      " loss = 0.00017130912757236822\n",
      " loss = 8.2527717180844e-05\n",
      " loss = 0.00017109535693792148\n",
      " loss = 0.0001699983882906621\n",
      " loss = 0.0001689084527982773\n",
      " loss = 0.00016782550536964378\n",
      " loss = 0.00016674950120036428\n",
      " loss = 8.599923965250855e-05\n",
      " loss = 8.499714296414332e-05\n",
      " loss = 8.40067231129946e-05\n",
      " loss = 0.00016834464198341154\n",
      " loss = 0.00016726530939734189\n",
      " loss = 8.479678598994055e-05\n",
      " loss = 0.00016707892708133155\n",
      " loss = 0.00016600770955913811\n",
      " loss = 0.00016494336009077883\n",
      " loss = 0.00016388583464117188\n",
      " loss = 8.735661438284806e-05\n",
      " loss = 0.00016372529266788858\n",
      " loss = 0.00016267557679151544\n",
      " loss = 8.811733817414228e-05\n",
      " loss = 8.709056056819583e-05\n",
      " loss = 0.00016341135911302472\n",
      " loss = 8.696202556207574e-05\n",
      " loss = 0.00016325055877520832\n",
      " loss = 0.0001622038866259748\n",
      " loss = 8.77207583474181e-05\n",
      " loss = 0.0001620514012490943\n",
      " loss = 8.75843543235842e-05\n",
      " loss = 8.656378728191925e-05\n",
      " loss = 8.555511227281652e-05\n",
      " loss = 8.455819071460365e-05\n",
      " loss = 0.00016454123892108453\n",
      " loss = 0.00016348629164704548\n",
      " loss = 0.00016243810810905097\n",
      " loss = 0.0001613966449475821\n",
      " loss = 8.708856869314801e-05\n",
      " loss = 8.607377874460155e-05\n",
      " loss = 8.507081352701132e-05\n",
      " loss = 8.407953521797608e-05\n",
      " loss = 0.00016387354719880047\n",
      " loss = 0.00016282288079639642\n",
      " loss = 8.484572992344321e-05\n",
      " loss = 0.00016265340393358156\n",
      " loss = 8.472984872871352e-05\n",
      " loss = 0.0001624839611841865\n",
      " loss = 8.461426761636372e-05\n",
      " loss = 8.362830916972485e-05\n",
      " loss = 8.265383949768205e-05\n",
      " loss = 8.169072474471623e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 8.073883255732992e-05\n",
      " loss = 7.979803218103332e-05\n",
      " loss = 7.886819439027013e-05\n",
      " loss = 0.00016749016681491207\n",
      " loss = 0.00016641631264671672\n",
      " loss = 7.965908822697765e-05\n",
      " loss = 7.873086947041372e-05\n",
      " loss = 0.00016705964150777464\n",
      " loss = 0.00016598854763521734\n",
      " loss = 7.95196732265859e-05\n",
      " loss = 7.859307899492403e-05\n",
      " loss = 7.767728178779619e-05\n",
      " loss = 7.677215582177606e-05\n",
      " loss = 0.00016832627641863955\n",
      " loss = 7.67222938261309e-05\n",
      " loss = 0.00016809246252000456\n",
      " loss = 7.667215092994037e-05\n",
      " loss = 7.577873713236103e-05\n",
      " loss = 7.48957337365131e-05\n",
      " loss = 0.00016953988144363744\n",
      " loss = 0.00016845288564346146\n",
      " loss = 7.569975733470792e-05\n",
      " loss = 0.00016821291572254897\n",
      " loss = 0.00016713442769126233\n",
      " loss = 7.649669159491816e-05\n",
      " loss = 0.00016690401974998976\n",
      " loss = 0.00016583392363398017\n",
      " loss = 7.728649008668035e-05\n",
      " loss = 7.638591777997915e-05\n",
      " loss = 7.54958392881272e-05\n",
      " loss = 7.461613234512406e-05\n",
      " loss = 7.374667608308904e-05\n",
      " loss = 7.288735103425614e-05\n",
      " loss = 7.203803919103384e-05\n",
      " loss = 0.00017060722119740848\n",
      " loss = 0.00016951338220325943\n",
      " loss = 7.284844137903847e-05\n",
      " loss = 0.0001692532073806297\n",
      " loss = 7.282476043176311e-05\n",
      " loss = 7.197617792310369e-05\n",
      " loss = 0.0001698169946229635\n",
      " loss = 0.00016872822212554996\n",
      " loss = 7.278275095137172e-05\n",
      " loss = 7.193465793587087e-05\n",
      " loss = 0.0001692923461141777\n",
      " loss = 0.00016820693737371737\n",
      " loss = 7.273868560508821e-05\n",
      " loss = 0.00016795132964981147\n",
      " loss = 7.271247717351597e-05\n",
      " loss = 0.00016769658775466086\n",
      " loss = 7.26858017663201e-05\n",
      " loss = 0.00016744270533988547\n",
      " loss = 0.0001663691554700365\n",
      " loss = 0.0001653024886102172\n",
      " loss = 0.0001642426606240895\n",
      " loss = 7.512997673941066e-05\n",
      " loss = 7.425453295230352e-05\n",
      " loss = 7.338929017688623e-05\n",
      " loss = 7.25341295444851e-05\n",
      " loss = 0.0001664785319769117\n",
      " loss = 7.250553776257377e-05\n",
      " loss = 0.00016622845797041865\n",
      " loss = 0.00016516269318139808\n",
      " loss = 7.329430790417123e-05\n",
      " loss = 7.244025406382703e-05\n",
      " loss = 7.159615196247675e-05\n",
      " loss = 0.0001665509108514654\n",
      " loss = 0.0001654830786774662\n",
      " loss = 0.00016442209284952975\n",
      " loss = 0.000163367909476293\n",
      " loss = 0.00016232048494028796\n",
      " loss = 0.0001612797759126966\n",
      " loss = 0.00016024573933412926\n",
      " loss = 7.64831046456128e-05\n",
      " loss = 0.00016004192938714361\n",
      " loss = 0.00015901582919332078\n",
      " loss = 0.00015799630778867105\n",
      " loss = 7.806340478910431e-05\n",
      " loss = 7.715377955071556e-05\n",
      " loss = 0.00015863308480570639\n",
      " loss = 7.707675196510491e-05\n",
      " loss = 0.0001584386431773424\n",
      " loss = 7.699970757652804e-05\n",
      " loss = 0.00015824453301520916\n",
      " loss = 7.69226473476881e-05\n",
      " loss = 7.602631464812737e-05\n",
      " loss = 7.51404263805525e-05\n",
      " loss = 7.426486081953073e-05\n",
      " loss = 7.339949769134795e-05\n",
      " loss = 0.00016130706952165858\n",
      " loss = 7.335277041737341e-05\n",
      " loss = 7.24980353285179e-05\n",
      " loss = 0.00016188856591874506\n",
      " loss = 7.24582966853284e-05\n",
      " loss = 7.16139843397499e-05\n",
      " loss = 7.077951028133466e-05\n",
      " loss = 0.00016325957958921675\n",
      " loss = 0.0001622128496062205\n",
      " loss = 0.00016117283067562218\n",
      " loss = 0.0001601394797668416\n",
      " loss = 0.00015911275413458512\n",
      " loss = 7.396807202151949e-05\n",
      " loss = 7.310616719620206e-05\n",
      " loss = 7.225430563272927e-05\n",
      " loss = 7.141237028966898e-05\n",
      " loss = 0.00016130474660216968\n",
      " loss = 0.00016027054992180537\n",
      " loss = 0.0001592429839383241\n",
      " loss = 0.00015822200613772365\n",
      " loss = 7.378172643869204e-05\n",
      " loss = 0.00015801135967757923\n",
      " loss = 7.372429518316982e-05\n",
      " loss = 0.00015780121614923285\n",
      " loss = 7.36666867263572e-05\n",
      " loss = 7.280829375898423e-05\n",
      " loss = 0.00015839100461579792\n",
      " loss = 7.275786923942925e-05\n",
      " loss = 0.00015817409668984983\n",
      " loss = 7.27072087790192e-05\n",
      " loss = 0.00015795775489121735\n",
      " loss = 7.265631519990915e-05\n",
      " loss = 7.18096954830015e-05\n",
      " loss = 0.00015853627788523436\n",
      " loss = 0.0001575198310981454\n",
      " loss = 7.256048692564657e-05\n",
      " loss = 7.171498383563912e-05\n",
      " loss = 7.087933287853733e-05\n",
      " loss = 0.000158887931348304\n",
      " loss = 0.00015786922995143437\n",
      " loss = 7.16324628270076e-05\n",
      " loss = 7.07977734369653e-05\n",
      " loss = 6.997281017430575e-05\n",
      " loss = 6.915745969481031e-05\n",
      " loss = 6.835161002657266e-05\n",
      " loss = 6.755515040332062e-05\n",
      " loss = 0.0001615637309450963\n",
      " loss = 0.0001605278738029692\n",
      " loss = 0.00015949865800297778\n",
      " loss = 0.00015847604096297732\n",
      " loss = 6.98852910523184e-05\n",
      " loss = 0.00015824285408653618\n",
      " loss = 6.985242248648264e-05\n",
      " loss = 6.903847482304213e-05\n",
      " loss = 0.00015878986997392298\n",
      " loss = 0.00015777179729333608\n",
      " loss = 0.0001567602519269711\n",
      " loss = 7.057386679018813e-05\n",
      " loss = 6.975151258234192e-05\n",
      " loss = 6.893874075231217e-05\n",
      " loss = 6.813543965764265e-05\n",
      " loss = 0.00015886923332418404\n",
      " loss = 0.000157850651809614\n",
      " loss = 0.00015683860087546114\n",
      " loss = 0.00015583303865038064\n",
      " loss = 0.00015483392353481077\n",
      " loss = 7.122612387820123e-05\n",
      " loss = 0.00015462244834306624\n",
      " loss = 7.117596967651939e-05\n",
      " loss = 7.034659952697321e-05\n",
      " loss = 6.952689352252033e-05\n",
      " loss = 6.871673905146323e-05\n",
      " loss = 6.791602479577538e-05\n",
      " loss = 0.00015750714614534258\n",
      " loss = 6.789324708291323e-05\n",
      " loss = 0.00015726655967017396\n",
      " loss = 0.00015625825361165912\n",
      " loss = 6.86397885375273e-05\n",
      " loss = 6.783997095212149e-05\n",
      " loss = 0.0001567946330205626\n",
      " loss = 6.781590580111971e-05\n",
      " loss = 6.702568840527329e-05\n",
      " loss = 6.6244678958877e-05\n",
      " loss = 6.547277012493206e-05\n",
      " loss = 0.00015884197564990446\n",
      " loss = 0.0001578235688966464\n",
      " loss = 0.00015681169160459065\n",
      " loss = 0.00015580630190950207\n",
      " loss = 0.00015480735821292853\n",
      " loss = 0.0001538148191924077\n",
      " loss = 0.00015282864377725455\n",
      " loss = 0.00015184879117483493\n",
      " loss = 0.00015087522084597453\n",
      " loss = 7.159853092055085e-05\n",
      " loss = 0.00015068110373141384\n",
      " loss = 0.00014971501996888492\n",
      " loss = 0.0001487551301967088\n",
      " loss = 7.30845916667335e-05\n",
      " loss = 0.00014857709828286147\n",
      " loss = 0.00014762450423406117\n",
      " loss = 7.378309060007771e-05\n",
      " loss = 0.00014745446045992495\n",
      " loss = 7.3698313944612e-05\n",
      " loss = 7.283955244754038e-05\n",
      " loss = 0.00014805766081671585\n",
      " loss = 0.00014710839711430023\n",
      " loss = 7.353559778735548e-05\n",
      " loss = 7.267873232272404e-05\n",
      " loss = 0.00014771028973689892\n",
      " loss = 7.26016866221897e-05\n",
      " loss = 0.00014753367000420824\n",
      " loss = 0.0001465877658397188\n",
      " loss = 0.00014564792628774683\n",
      " loss = 7.406740123261118e-05\n",
      " loss = 7.32043389703037e-05\n",
      " loss = 0.0001462570780052549\n",
      " loss = 7.312011992550822e-05\n",
      " loss = 0.00014608871717482363\n",
      " loss = 7.303599750700252e-05\n",
      " loss = 7.218495357622953e-05\n",
      " loss = 0.0001466865442938511\n",
      " loss = 0.00014574607143128323\n",
      " loss = 7.28745310219007e-05\n",
      " loss = 7.202536856911425e-05\n",
      " loss = 7.118610088763517e-05\n",
      " loss = 0.00014710436662236146\n",
      " loss = 7.1116954340431e-05\n",
      " loss = 0.00014692213963789544\n",
      " loss = 0.00014598015626633468\n",
      " loss = 7.180889723397193e-05\n",
      " loss = 0.00014580591121239893\n",
      " loss = 7.173241674535696e-05\n",
      " loss = 7.089656267692722e-05\n",
      " loss = 0.00014639029129917262\n",
      " loss = 7.082739734671868e-05\n",
      " loss = 7.000208887169291e-05\n",
      " loss = 0.00014696429999821656\n",
      " loss = 0.00014602204631949928\n",
      " loss = 0.00014508583385065667\n",
      " loss = 0.0001441556238549289\n",
      " loss = 7.221072612642994e-05\n",
      " loss = 0.0001439904255841789\n",
      " loss = 7.212690812036522e-05\n",
      " loss = 7.128645725324587e-05\n",
      " loss = 0.0001445811392022269\n",
      " loss = 0.0001436541650281971\n",
      " loss = 7.196598425509632e-05\n",
      " loss = 0.00014348957536067908\n",
      " loss = 0.00014256959969086952\n",
      " loss = 7.263896702054204e-05\n",
      " loss = 7.179254946782521e-05\n",
      " loss = 0.00014316730692521767\n",
      " loss = 0.00014224939746166525\n",
      " loss = 0.0001413373731250442\n",
      " loss = 0.0001404311961865593\n",
      " loss = 0.0001395308291529252\n",
      " loss = 0.00013863623477367747\n",
      " loss = 7.549798517025458e-05\n",
      " loss = 0.00013850854834316083\n",
      " loss = 0.00013762050825922434\n",
      " loss = 0.00013673816179614367\n",
      " loss = 0.00013586147244936585\n",
      " loss = 0.00013499040395078713\n",
      " loss = 7.843031761836712e-05\n",
      " loss = 7.751641698141734e-05\n",
      " loss = 7.661316545907635e-05\n",
      " loss = 0.0001364147043542093\n",
      " loss = 0.0001355400888375588\n",
      " loss = 7.724066391241039e-05\n",
      " loss = 7.634062558275794e-05\n",
      " loss = 7.54510748548428e-05\n",
      " loss = 7.457188949209097e-05\n",
      " loss = 7.370294873295435e-05\n",
      " loss = 0.00013845418302345545\n",
      " loss = 7.359461393443661e-05\n",
      " loss = 7.273706079726053e-05\n",
      " loss = 7.188950021765137e-05\n",
      " loss = 7.105181570588452e-05\n",
      " loss = 7.022389225967921e-05\n",
      " loss = 6.94056160740698e-05\n",
      " loss = 0.00014203693323186544\n",
      " loss = 0.0001411262710980541\n",
      " loss = 0.0001402214476253722\n",
      " loss = 7.081467402415996e-05\n",
      " loss = 0.00014006377596714417\n",
      " loss = 7.072945577636884e-05\n",
      " loss = 0.0001399062522939054\n",
      " loss = 7.06443693067615e-05\n",
      " loss = 6.982119355829016e-05\n",
      " loss = 6.90076097784526e-05\n",
      " loss = 6.820350620293299e-05\n",
      " loss = 0.00014195346013593137\n",
      " loss = 6.813987593524443e-05\n",
      " loss = 6.734588354092582e-05\n",
      " loss = 0.00014250426995203837\n",
      " loss = 6.728905987175672e-05\n",
      " loss = 0.00014231909868677828\n",
      " loss = 0.00014140662746812597\n",
      " loss = 6.796085391231455e-05\n",
      " loss = 0.00014122930443553032\n",
      " loss = 6.789688402695375e-05\n",
      " loss = 6.710572306032494e-05\n",
      " loss = 6.63237810093231e-05\n",
      " loss = 0.00014250214365734885\n",
      " loss = 0.0001415884988551052\n",
      " loss = 0.00014068071183344672\n",
      " loss = 6.772292508445168e-05\n",
      " loss = 0.0001405048949274417\n",
      " loss = 0.00013960405537554203\n",
      " loss = 0.00013870899150700738\n",
      " loss = 6.911281311892203e-05\n",
      " loss = 6.830748365857613e-05\n",
      " loss = 6.751153821145061e-05\n",
      " loss = 6.672486742376019e-05\n",
      " loss = 6.594736326111399e-05\n",
      " loss = 0.00014143815642956393\n",
      " loss = 6.589655168103898e-05\n",
      " loss = 0.0001412495353931211\n",
      " loss = 0.00014034392161903274\n",
      " loss = 0.0001394441141385718\n",
      " loss = 0.00013855007572466404\n",
      " loss = 6.80057066118332e-05\n",
      " loss = 0.0001383839115521684\n",
      " loss = 0.00013749667057006248\n",
      " loss = 0.00013661511808912277\n",
      " loss = 0.00013573921763175464\n",
      " loss = 7.010536295869764e-05\n",
      " loss = 6.928846792005446e-05\n",
      " loss = 6.848109167103284e-05\n",
      " loss = 6.76831232887896e-05\n",
      " loss = 6.68944531349123e-05\n",
      " loss = 0.0001384745122816726\n",
      " loss = 6.683009365177779e-05\n",
      " loss = 0.00013830236041845276\n",
      " loss = 0.00013741564230099272\n",
      " loss = 0.00013653460932865134\n",
      " loss = 6.819891913464804e-05\n",
      " loss = 0.00013637712139309227\n",
      " loss = 0.00013550274684042462\n",
      " loss = 6.883878312150248e-05\n",
      " loss = 0.00013535251197878208\n",
      " loss = 6.875381243734053e-05\n",
      " loss = 0.00013520239848751467\n",
      " loss = 6.866899168834391e-05\n",
      " loss = 6.786883381687178e-05\n",
      " loss = 0.00013576695992672055\n",
      " loss = 0.00013489649739248057\n",
      " loss = 0.00013403161577954032\n",
      " loss = 0.00013317227930985728\n",
      " loss = 0.00013231845242777995\n",
      " loss = 7.065835090583146e-05\n",
      " loss = 0.00013218948755491273\n",
      " loss = 7.055300817789964e-05\n",
      " loss = 6.973089700609834e-05\n",
      " loss = 6.89183653824723e-05\n",
      " loss = 6.811530171913994e-05\n",
      " loss = 0.00013420239306539275\n",
      " loss = 6.803194725900236e-05\n",
      " loss = 6.723921246268218e-05\n",
      " loss = 6.645571495697226e-05\n",
      " loss = 6.568134704732315e-05\n",
      " loss = 6.491600237955148e-05\n",
      " loss = 6.415957580630202e-05\n",
      " loss = 0.0001375728311413917\n",
      " loss = 0.00013669079035942368\n",
      " loss = 6.480972386472945e-05\n",
      " loss = 6.405453568068038e-05\n",
      " loss = 0.0001372125123316401\n",
      " loss = 0.00013633278171615692\n",
      " loss = 0.00013545869144237664\n",
      " loss = 0.00013459020534971686\n",
      " loss = 0.00013372728751264384\n",
      " loss = 0.00013286990222341024\n",
      " loss = 6.75105892449073e-05\n",
      " loss = 0.00013272263535574089\n",
      " loss = 0.00013187169134210781\n",
      " loss = 6.813190002727874e-05\n",
      " loss = 6.733800056937651e-05\n",
      " loss = 0.00013243435890603923\n",
      " loss = 6.725496927894765e-05\n",
      " loss = 0.00013228739539296054\n",
      " loss = 0.00013143924189639754\n",
      " loss = 0.0001305965262922405\n",
      " loss = 0.0001297592137123598\n",
      " loss = 6.92828008483051e-05\n",
      " loss = 0.00012963269779495064\n",
      " loss = 6.917955416010781e-05\n",
      " loss = 0.000129506123241116\n",
      " loss = 0.0001286758017190912\n",
      " loss = 0.00012785080376001492\n",
      " loss = 0.00012703109523283558\n",
      " loss = 7.119405527620996e-05\n",
      " loss = 0.00012692420089800534\n",
      " loss = 0.00012611043323132386\n",
      " loss = 0.00012530188299604263\n",
      " loss = 0.00012449851673601207\n",
      " loss = 7.319649839931936e-05\n",
      " loss = 0.00012441057783797103\n",
      " loss = 0.00012361292613176407\n",
      " loss = 7.376247765285152e-05\n",
      " loss = 0.00012353087301800617\n",
      " loss = 0.0001227388614916365\n",
      " loss = 7.432224140753434e-05\n",
      " loss = 7.345620967457234e-05\n",
      " loss = 7.260026927862201e-05\n",
      " loss = 7.175430261418834e-05\n",
      " loss = 0.00012478187355259785\n",
      " loss = 7.162110663846261e-05\n",
      " loss = 0.0001246852198525243\n",
      " loss = 7.148853890183867e-05\n",
      " loss = 0.00012458826184077974\n",
      " loss = 0.00012378947092300802\n",
      " loss = 7.205885490326588e-05\n",
      " loss = 0.00012369852207149554\n",
      " loss = 0.00012290543567253934\n",
      " loss = 0.00012211743410573542\n",
      " loss = 0.00012133448476841068\n",
      " loss = 7.403141209813294e-05\n",
      " loss = 7.31687692083999e-05\n",
      " loss = 7.231617819599219e-05\n",
      " loss = 7.147352190080001e-05\n",
      " loss = 7.064068456585896e-05\n",
      " loss = 6.981755175249802e-05\n",
      " loss = 0.0001247562943501094\n",
      " loss = 6.969732464868702e-05\n",
      " loss = 0.00012465020948950056\n",
      " loss = 0.00012385102139823924\n",
      " loss = 7.027125336910009e-05\n",
      " loss = 0.00012375106672516152\n",
      " loss = 7.014516812940047e-05\n",
      " loss = 6.932780926480963e-05\n",
      " loss = 6.851997457541096e-05\n",
      " loss = 6.772155309619054e-05\n",
      " loss = 0.00012571771334033522\n",
      " loss = 6.761792206330878e-05\n",
      " loss = 0.00012559764664896606\n",
      " loss = 6.75146472251538e-05\n",
      " loss = 0.00012547749804757126\n",
      " loss = 0.00012467300583960192\n",
      " loss = 0.0001238736715918575\n",
      " loss = 6.878309113221112e-05\n",
      " loss = 0.00012376623507855008\n",
      " loss = 0.00012297271454234215\n",
      " loss = 6.935368188502407e-05\n",
      " loss = 6.854554574374345e-05\n",
      " loss = 6.774682632768598e-05\n",
      " loss = 0.0001242392876631328\n",
      " loss = 6.763897482802407e-05\n",
      " loss = 0.00012412476628424193\n",
      " loss = 0.00012332894704281038\n",
      " loss = 6.821347466710309e-05\n",
      " loss = 6.741862467997284e-05\n",
      " loss = 0.0001239009529042729\n",
      " loss = 6.731202001132187e-05\n",
      " loss = 6.65276741182062e-05\n",
      " loss = 6.575246771475858e-05\n",
      " loss = 0.0001251385702398923\n",
      " loss = 0.00012433625105223866\n",
      " loss = 6.6335413239171e-05\n",
      " loss = 6.556244713761968e-05\n",
      " loss = 0.0001248883185402139\n",
      " loss = 6.547075264232349e-05\n",
      " loss = 0.000124760348416339\n",
      " loss = 6.537931240476056e-05\n",
      " loss = 6.461748716339306e-05\n",
      " loss = 6.386453899481435e-05\n",
      " loss = 6.312036447517245e-05\n",
      " loss = 0.0001266353842154216\n",
      " loss = 0.00012582346828387568\n",
      " loss = 0.00012501675790616842\n",
      " loss = 0.00012421521971198635\n",
      " loss = 6.505003569266877e-05\n",
      " loss = 6.429204729247929e-05\n",
      " loss = 0.00012475424312579012\n",
      " loss = 6.420826944253871e-05\n",
      " loss = 6.346008965290137e-05\n",
      " loss = 0.00012528398675172055\n",
      " loss = 0.00012448073523236598\n",
      " loss = 0.0001236826337167748\n",
      " loss = 6.471203877072944e-05\n",
      " loss = 6.395798886788665e-05\n",
      " loss = 6.321272545621737e-05\n",
      " loss = 6.247614613555242e-05\n",
      " loss = 0.00012553936338212333\n",
      " loss = 6.240615478134802e-05\n",
      " loss = 0.00012539297170893778\n",
      " loss = 0.00012458902143614033\n",
      " loss = 0.00012379022565006656\n",
      " loss = 6.365477435585423e-05\n",
      " loss = 6.291304409203891e-05\n",
      " loss = 0.00012431528042636085\n",
      " loss = 0.00012351823971291679\n",
      " loss = 6.34954041798267e-05\n",
      " loss = 6.275553095676748e-05\n",
      " loss = 6.20242790502276e-05\n",
      " loss = 0.00012469659235039187\n",
      " loss = 0.00012389710687755957\n",
      " loss = 0.0001231027472611816\n",
      " loss = 6.326582118002192e-05\n",
      " loss = 6.252862316106096e-05\n",
      " loss = 6.180001526770889e-05\n",
      " loss = 6.107989737787858e-05\n",
      " loss = 0.00012492714573504157\n",
      " loss = 0.0001241261820831058\n",
      " loss = 6.166761579188812e-05\n",
      " loss = 0.00012398124790445681\n",
      " loss = 0.00012318634882283217\n",
      " loss = 6.224971096613074e-05\n",
      " loss = 6.152435306689636e-05\n",
      " loss = 0.0001236974250006899\n",
      " loss = 0.0001229043456382357\n",
      " loss = 0.00012211635105865816\n",
      " loss = 0.00012133340866449928\n",
      " loss = 0.00012055548606070107\n",
      " loss = 6.406140199024182e-05\n",
      " loss = 0.00012043637578992907\n",
      " loss = 6.396749521481512e-05\n",
      " loss = 0.00012031722674434103\n",
      " loss = 0.0001195458193377861\n",
      " loss = 6.452687644162019e-05\n",
      " loss = 0.00011943280690807693\n",
      " loss = 0.00011866706991368824\n",
      " loss = 6.508055333719856e-05\n",
      " loss = 6.432220933611494e-05\n",
      " loss = 6.357270188273514e-05\n",
      " loss = 0.00011986166017031376\n",
      " loss = 0.00011909317360416303\n",
      " loss = 0.00011832961414804969\n",
      " loss = 6.478114868742858e-05\n",
      " loss = 6.402629347146574e-05\n",
      " loss = 6.328023415689605e-05\n",
      " loss = 6.254286818900558e-05\n",
      " loss = 6.181409429664542e-05\n",
      " loss = 6.10938123713017e-05\n",
      " loss = 0.00012144885402372977\n",
      " loss = 6.102191069216524e-05\n",
      " loss = 0.00012131065259339279\n",
      " loss = 6.0950106140608195e-05\n",
      " loss = 0.00012117259600194362\n",
      " loss = 6.087839845868732e-05\n",
      " loss = 6.016901962773245e-05\n",
      " loss = 5.9467906740934586e-05\n",
      " loss = 5.8774963502394104e-05\n",
      " loss = 5.809009472308971e-05\n",
      " loss = 0.00012356995581838033\n",
      " loss = 5.8042745662456054e-05\n",
      " loss = 0.00012340772874333268\n",
      " loss = 5.799527808359185e-05\n",
      " loss = 0.00012324587077285767\n",
      " loss = 5.794769361672402e-05\n",
      " loss = 0.0001230843798078756\n",
      " loss = 0.00012229523095095237\n",
      " loss = 0.00012151114167992709\n",
      " loss = 5.915918989838312e-05\n",
      " loss = 5.84698439499436e-05\n",
      " loss = 0.00012199154097067015\n",
      " loss = 0.00012120939879038275\n",
      " loss = 5.904494909718211e-05\n",
      " loss = 0.00012106163832800517\n",
      " loss = 0.00012028545816506913\n",
      " loss = 5.961463677622923e-05\n",
      " loss = 0.0001201442426243835\n",
      " loss = 0.00011937394429841299\n",
      " loss = 6.017888409698791e-05\n",
      " loss = 0.00011923915150113045\n",
      " loss = 6.010702567566647e-05\n",
      " loss = 0.00011910449041638636\n",
      " loss = 6.003527348273353e-05\n",
      " loss = 5.93357190610376e-05\n",
      " loss = 5.8644316101943973e-05\n",
      " loss = 5.796096966514045e-05\n",
      " loss = 5.728558585260534e-05\n",
      " loss = 5.661807187730906e-05\n",
      " loss = 0.0001220849866401805\n",
      " loss = 0.00012130224533474869\n",
      " loss = 0.00012052452253654282\n",
      " loss = 5.7815817181890184e-05\n",
      " loss = 0.00012037279978398636\n",
      " loss = 0.0001196010360752081\n",
      " loss = 5.838317272847305e-05\n",
      " loss = 0.00011945588545549124\n",
      " loss = 0.00011869000049174977\n",
      " loss = 5.894517488799889e-05\n",
      " loss = 0.00011855129926284933\n",
      " loss = 5.887942049552714e-05\n",
      " loss = 0.00011841277666509024\n",
      " loss = 0.00011765357954013132\n",
      " loss = 0.00011689924996359391\n",
      " loss = 6.005831952375692e-05\n",
      " loss = 5.935849656893908e-05\n",
      " loss = 5.8666828221758655e-05\n",
      " loss = 5.798321947656259e-05\n",
      " loss = 5.730757638325045e-05\n",
      " loss = 5.6639806170682095e-05\n",
      " loss = 0.00011986005011997782\n",
      " loss = 0.00011909157387759254\n",
      " loss = 5.720561315359561e-05\n",
      " loss = 5.6539031025591e-05\n",
      " loss = 0.00011955410237333476\n",
      " loss = 5.6491113626378236e-05\n",
      " loss = 0.00011939896348773282\n",
      " loss = 5.644309896858444e-05\n",
      " loss = 5.578540196008329e-05\n",
      " loss = 5.513536869509391e-05\n",
      " loss = 0.00012045955241378426\n",
      " loss = 5.5098483717127016e-05\n",
      " loss = 5.445645469000297e-05\n",
      " loss = 5.382190684704904e-05\n",
      " loss = 5.319475300661807e-05\n",
      " loss = 5.25749069847049e-05\n",
      " loss = 5.1962283670189045e-05\n",
      " loss = 5.135679888342917e-05\n",
      " loss = 5.075836945511794e-05\n",
      " loss = 5.0166913126633877e-05\n",
      " loss = 4.9582348690883764e-05\n",
      " loss = 4.90045958152993e-05\n",
      " loss = 4.843357514764864e-05\n",
      " loss = 4.786920824522807e-05\n",
      " loss = 0.00012740665189120063\n",
      " loss = 0.00012658979101720077\n",
      " loss = 0.00012577816740447117\n",
      " loss = 4.905777558738138e-05\n",
      " loss = 0.00012555605503176729\n",
      " loss = 4.906944988823963e-05\n",
      " loss = 4.849767353825676e-05\n",
      " loss = 4.793255972839609e-05\n",
      " loss = 4.737403084751941e-05\n",
      " loss = 4.682201015773077e-05\n",
      " loss = 0.000127649726204101\n",
      " loss = 0.0001268313068749438\n",
      " loss = 0.0001260181347946722\n",
      " loss = 0.00012521017632331047\n",
      " loss = 4.858503047088195e-05\n",
      " loss = 0.00012498756727454755\n",
      " loss = 0.0001241862162315726\n",
      " loss = 4.917886653357663e-05\n",
      " loss = 4.8605815215627235e-05\n",
      " loss = 4.803944129009219e-05\n",
      " loss = 4.747966698327281e-05\n",
      " loss = 4.6926415389442045e-05\n",
      " loss = 0.00012627613622610546\n",
      " loss = 4.695179014006166e-05\n",
      " loss = 0.00012603926646752046\n",
      " loss = 4.6976484757724934e-05\n",
      " loss = 0.00012580352920810146\n",
      " loss = 0.0001249969466713948\n",
      " loss = 0.00012419553549144083\n",
      " loss = 0.00012339926251578814\n",
      " loss = 0.00012260809480237647\n",
      " loss = 4.93022951879111e-05\n",
      " loss = 0.00012240034313470204\n",
      " loss = 0.0001216155799408635\n",
      " loss = 4.9884025630248634e-05\n",
      " loss = 4.9302757494631877e-05\n",
      " loss = 0.00012199262220973269\n",
      " loss = 4.9304645007902105e-05\n",
      " loss = 0.00012178737867364232\n",
      " loss = 4.930603504083009e-05\n",
      " loss = 0.00012158297424807447\n",
      " loss = 0.00012080345156790209\n",
      " loss = 0.00012002892675551311\n",
      " loss = 5.0462306696934646e-05\n",
      " loss = 4.987430021474433e-05\n",
      " loss = 4.929314542401082e-05\n",
      " loss = 0.00012099019224949595\n",
      " loss = 0.00012021447016024464\n",
      " loss = 0.00011944372157507018\n",
      " loss = 0.00011867791459888575\n",
      " loss = 0.0001179170175550927\n",
      " loss = 0.00011716099895849837\n",
      " loss = 5.218445035763977e-05\n",
      " loss = 0.00011699150440743339\n",
      " loss = 0.00011624141969215031\n",
      " loss = 0.00011549614410113934\n",
      " loss = 0.00011475564680498206\n",
      " loss = 0.00011401989717027086\n",
      " loss = 5.4492943986085554e-05\n",
      " loss = 0.0001138752723278484\n",
      " loss = 5.444328613789627e-05\n",
      " loss = 5.3808891718414505e-05\n",
      " loss = 5.3181889534836474e-05\n",
      " loss = 5.256219341192998e-05\n",
      " loss = 5.1949718225583e-05\n",
      " loss = 0.00011605471270343214\n",
      " loss = 5.1921369139011465e-05\n",
      " loss = 5.131636109247601e-05\n",
      " loss = 0.00011646361881684\n",
      " loss = 5.1292886196215094e-05\n",
      " loss = 5.069520150386817e-05\n",
      " loss = 0.00011686489861408983\n",
      " loss = 0.00011611562562340236\n",
      " loss = 5.1249858082344895e-05\n",
      " loss = 0.00011594502046814754\n",
      " loss = 0.00011520164522906752\n",
      " loss = 0.00011446303609940712\n",
      " loss = 0.00011372916251814972\n",
      " loss = 0.00011299999412882637\n",
      " loss = 5.353023115346034e-05\n",
      " loss = 5.290647602811116e-05\n",
      " loss = 0.00011343078584060947\n",
      " loss = 5.286561455867216e-05\n",
      " loss = 5.224960380366062e-05\n",
      " loss = 0.0001138537837751799\n",
      " loss = 5.221389029339177e-05\n",
      " loss = 0.0001136973969528201\n",
      " loss = 5.217800285501393e-05\n",
      " loss = 0.00011354142195284497\n",
      " loss = 5.214194357452065e-05\n",
      " loss = 5.153436531809278e-05\n",
      " loss = 0.00011395634622014776\n",
      " loss = 0.00011322572125695371\n",
      " loss = 5.207409061631826e-05\n",
      " loss = 0.0001130710117565902\n",
      " loss = 0.0001123460630661054\n",
      " loss = 5.260896374928363e-05\n",
      " loss = 0.00011219769148724599\n",
      " loss = 5.256681563096698e-05\n",
      " loss = 5.1954286604363774e-05\n",
      " loss = 0.00011261909623447182\n",
      " loss = 0.00011189704497546571\n",
      " loss = 5.248695529869606e-05\n",
      " loss = 5.187535683461322e-05\n",
      " loss = 5.127088492604022e-05\n",
      " loss = 0.00011288432931368334\n",
      " loss = 0.00011216057753065264\n",
      " loss = 5.1805386199718563e-05\n",
      " loss = 5.120172962264022e-05\n",
      " loss = 5.060510710604633e-05\n",
      " loss = 0.00011313701145546453\n",
      " loss = 5.0577706474410995e-05\n",
      " loss = 0.0001129743729100588\n",
      " loss = 5.055006799380195e-05\n",
      " loss = 4.996103888708444e-05\n",
      " loss = 0.00011337250149703407\n",
      " loss = 0.00011264561982408778\n",
      " loss = 5.049875797462273e-05\n",
      " loss = 0.00011248447099008544\n",
      " loss = 5.047038038752824e-05\n",
      " loss = 0.00011232379661652097\n",
      " loss = 5.044177541579135e-05\n",
      " loss = 0.00011216359349033014\n",
      " loss = 5.041294547189867e-05\n",
      " loss = 4.982551416696428e-05\n",
      " loss = 0.00011256137363747332\n",
      " loss = 4.9801436788505883e-05\n",
      " loss = 4.922113103507767e-05\n",
      " loss = 0.00011295175368964865\n",
      " loss = 4.9201681221049065e-05\n",
      " loss = 4.862836403204976e-05\n",
      " loss = 4.806172738069885e-05\n",
      " loss = 0.00011388559421682482\n",
      " loss = 0.00011315542287757372\n",
      " loss = 4.8602702770775134e-05\n",
      " loss = 4.803636511796726e-05\n",
      " loss = 4.747662665779764e-05\n",
      " loss = 4.6923410489235333e-05\n",
      " loss = 0.0001146252759766269\n",
      " loss = 4.692168918493338e-05\n",
      " loss = 0.0001144358993849717\n",
      " loss = 4.691952619903176e-05\n",
      " loss = 0.00011424727409893695\n",
      " loss = 4.691692558974584e-05\n",
      " loss = 0.00011405939418771625\n",
      " loss = 0.00011332810853814296\n",
      " loss = 0.00011260151148762426\n",
      " loss = 4.800540966756307e-05\n",
      " loss = 4.744603191034561e-05\n",
      " loss = 0.00011297154253536026\n",
      " loss = 0.00011224723158578353\n",
      " loss = 0.00011152756451808868\n",
      " loss = 4.8529538032313766e-05\n",
      " loss = 4.796405293819067e-05\n",
      " loss = 4.7405157087083004e-05\n",
      " loss = 4.685277371758867e-05\n",
      " loss = 4.630682691556765e-05\n",
      " loss = 4.57672417125833e-05\n",
      " loss = 0.00011406816243160684\n",
      " loss = 4.5770941878712194e-05\n",
      " loss = 4.5237601020851205e-05\n",
      " loss = 0.00011440991760659415\n",
      " loss = 0.00011367638459668558\n",
      " loss = 0.00011294755459171266\n",
      " loss = 4.631886550527051e-05\n",
      " loss = 4.577914003176659e-05\n",
      " loss = 4.5245703642594126e-05\n",
      " loss = 4.471848306031858e-05\n",
      " loss = 0.00011436433410140269\n",
      " loss = 4.472892443973526e-05\n",
      " loss = 4.4207725568166e-05\n",
      " loss = 4.369259990446717e-05\n",
      " loss = 0.00011522150858734952\n",
      " loss = 4.371085274381232e-05\n",
      " loss = 4.320151685336823e-05\n",
      " loss = 0.00011553666132767929\n",
      " loss = 0.00011479590425691067\n",
      " loss = 0.00011405989651026423\n",
      " loss = 0.00011332860763855728\n",
      " loss = 0.00011260200738584887\n",
      " loss = 0.00011188006569443213\n",
      " loss = 0.00011116275269190947\n",
      " loss = 4.640482693199503e-05\n",
      " loss = 0.00011098431224649908\n",
      " loss = 4.63974337441229e-05\n",
      " loss = 4.585679276687517e-05\n",
      " loss = 4.532245154674208e-05\n",
      " loss = 4.479433667304849e-05\n",
      " loss = 0.00011239688673751096\n",
      " loss = 0.00011167626016590619\n",
      " loss = 0.00011096025384993297\n",
      " loss = 4.585866886388998e-05\n",
      " loss = 0.00011077947119010717\n",
      " loss = 0.00011006921459014832\n",
      " loss = 0.00010936351176206484\n",
      " loss = 0.00010866233350952258\n",
      " loss = 4.7451197632706604e-05\n",
      " loss = 0.00010849981835129663\n",
      " loss = 0.00010780417762348382\n",
      " loss = 4.7965982221530116e-05\n",
      " loss = 4.740706389894335e-05\n",
      " loss = 0.00010818106904355112\n",
      " loss = 0.00010748747195546032\n",
      " loss = 0.00010679832183058374\n",
      " loss = 0.00010611359015180594\n",
      " loss = 0.0001054332485932374\n",
      " loss = 4.952812372340964e-05\n",
      " loss = 4.8951002715493506e-05\n",
      " loss = 0.00010583066623695643\n",
      " loss = 0.00010515213863196748\n",
      " loss = 4.9451464828527934e-05\n",
      " loss = 4.887523708246213e-05\n",
      " loss = 0.000105549098299311\n",
      " loss = 4.8839422398373865e-05\n",
      " loss = 0.00010540650062916437\n",
      " loss = 0.00010473069253838765\n",
      " loss = 0.00010405921735452991\n",
      " loss = 0.00010339204730049601\n",
      " loss = 0.00010272915477058605\n",
      " loss = 5.094783408204005e-05\n",
      " loss = 0.0001026087316799679\n",
      " loss = 5.089137313920741e-05\n",
      " loss = 5.029836701658787e-05\n",
      " loss = 4.9712270826342744e-05\n",
      " loss = 4.913300405268679e-05\n",
      " loss = 4.856048713374679e-05\n",
      " loss = 0.00010462142903565322\n",
      " loss = 0.00010395065438869062\n",
      " loss = 0.00010328418037868959\n",
      " loss = 0.00010262197942925895\n",
      " loss = 0.0001019640241479755\n",
      " loss = 0.00010131028731211489\n",
      " loss = 5.118986919153583e-05\n",
      " loss = 0.00010119650610288997\n",
      " loss = 5.1128130907975204e-05\n",
      " loss = 5.053236598762139e-05\n",
      " loss = 4.994354315657557e-05\n",
      " loss = 4.9361581508440566e-05\n",
      " loss = 4.8786401109524884e-05\n",
      " loss = 4.821792293229685e-05\n",
      " loss = 0.00010373262152838672\n",
      " loss = 0.00010306754542303011\n",
      " loss = 4.870827665432544e-05\n",
      " loss = 0.00010293383985284077\n",
      " loss = 0.0001022738850935317\n",
      " loss = 0.00010161816159690188\n",
      " loss = 0.00010096664223630957\n",
      " loss = 0.00010031930005759795\n",
      " loss = 9.967610827836974e-05\n",
      " loss = 9.903704029059482e-05\n",
      " loss = 9.840206965139324e-05\n",
      " loss = 5.2380899127207946e-05\n",
      " loss = 5.177053647086642e-05\n",
      " loss = 5.116728598715137e-05\n",
      " loss = 5.0571064812815977e-05\n",
      " loss = 9.989764755582441e-05\n",
      " loss = 5.0509872694290016e-05\n",
      " loss = 9.978562985240552e-05\n",
      " loss = 5.044877807547376e-05\n",
      " loss = 4.986092923586062e-05\n",
      " loss = 0.00010019987392090635\n",
      " loss = 4.9805095505300346e-05\n",
      " loss = 0.00010008300588338538\n",
      " loss = 4.974931205561176e-05\n",
      " loss = 4.916961366119444e-05\n",
      " loss = 4.859667014622467e-05\n",
      " loss = 4.803040280284081e-05\n",
      " loss = 0.00010153094882468092\n",
      " loss = 4.7989616340843574e-05\n",
      " loss = 0.00010139927733291772\n",
      " loss = 4.794874803165538e-05\n",
      " loss = 0.00010126789234671389\n",
      " loss = 0.00010061861872000754\n",
      " loss = 4.842670480114813e-05\n",
      " loss = 0.00010049281313214132\n",
      " loss = 4.838075325755489e-05\n",
      " loss = 4.781700186664476e-05\n",
      " loss = 4.725981952264307e-05\n",
      " loss = 4.6709129668540184e-05\n",
      " loss = 4.616485666314664e-05\n",
      " loss = 0.00010242513677064511\n",
      " loss = 0.00010176844353168189\n",
      " loss = 0.00010111596065039907\n",
      " loss = 0.00010046766112381672\n",
      " loss = 9.982351813437775e-05\n",
      " loss = 9.91835050357406e-05\n",
      " loss = 4.871020262986449e-05\n",
      " loss = 4.814261235800624e-05\n",
      " loss = 4.7581635862814954e-05\n",
      " loss = 4.7027196097531695e-05\n",
      " loss = 4.647921688242985e-05\n",
      " loss = 0.00010111624717206214\n",
      " loss = 4.6447034327148536e-05\n",
      " loss = 4.590581537477435e-05\n",
      " loss = 4.537090290966453e-05\n",
      " loss = 4.48422234407321e-05\n",
      " loss = 0.00010249700917936\n",
      " loss = 0.0001018398551354223\n",
      " loss = 0.00010118691440083792\n",
      " loss = 4.5834729235400766e-05\n",
      " loss = 0.00010104478166229844\n",
      " loss = 0.00010039693849748743\n",
      " loss = 4.631321031865707e-05\n",
      " loss = 4.577355074803121e-05\n",
      " loss = 0.00010076610658284956\n",
      " loss = 0.00010012005012942902\n",
      " loss = 9.947813582987248e-05\n",
      " loss = 9.884033712931007e-05\n",
      " loss = 9.820662764100552e-05\n",
      " loss = 4.7774926643425424e-05\n",
      " loss = 4.721823456768386e-05\n",
      " loss = 9.859448407832923e-05\n",
      " loss = 4.717500326076292e-05\n",
      " loss = 4.662530171848286e-05\n",
      " loss = 4.6082005526930005e-05\n",
      " loss = 4.554504003583234e-05\n",
      " loss = 4.501433148212262e-05\n",
      " loss = 0.00010048247333836754\n",
      " loss = 9.983823538245104e-05\n",
      " loss = 9.919812792505737e-05\n",
      " loss = 4.599259661760586e-05\n",
      " loss = 9.906461326535573e-05\n",
      " loss = 4.595823661881095e-05\n",
      " loss = 9.893142893888133e-05\n",
      " loss = 4.592375206033396e-05\n",
      " loss = 4.538863060049721e-05\n",
      " loss = 4.4859744579079205e-05\n",
      " loss = 4.4337021352047374e-05\n",
      " loss = 0.00010029287286958375\n",
      " loss = 4.431591988572044e-05\n",
      " loss = 4.3799533501199224e-05\n",
      " loss = 4.32891642487163e-05\n",
      " loss = 4.2784742028243045e-05\n",
      " loss = 0.00010162354244114136\n",
      " loss = 0.00010097198858164595\n",
      " loss = 0.00010032461212639192\n",
      " loss = 9.96813862912024e-05\n",
      " loss = 9.9042284462234e-05\n",
      " loss = 4.4748497119090046e-05\n",
      " loss = 4.422707018655937e-05\n",
      " loss = 4.371171912505327e-05\n",
      " loss = 4.320237313285225e-05\n",
      " loss = 4.2698962235391454e-05\n",
      " loss = 4.220141727586753e-05\n",
      " loss = 4.1709669896708014e-05\n",
      " loss = 4.1223652564710766e-05\n",
      " loss = 0.00010232249436592916\n",
      " loss = 4.122598945978871e-05\n",
      " loss = 0.00010214958958796086\n",
      " loss = 4.122790354711124e-05\n",
      " loss = 4.074749993337801e-05\n",
      " loss = 0.00010245844493533907\n",
      " loss = 4.0752917275047455e-05\n",
      " loss = 4.027804838545369e-05\n",
      " loss = 3.980871284431403e-05\n",
      " loss = 0.00010323847270380846\n",
      " loss = 3.9821330473960355e-05\n",
      " loss = 0.00010305350158083546\n",
      " loss = 3.983344794978838e-05\n",
      " loss = 3.936929308375549e-05\n",
      " loss = 0.00010334425647536532\n",
      " loss = 0.0001026816703543608\n",
      " loss = 3.986007858134634e-05\n",
      " loss = 3.939561340383146e-05\n",
      " loss = 3.893656035984577e-05\n",
      " loss = 0.00010344592611036458\n",
      " loss = 0.00010278268813608358\n",
      " loss = 0.00010212370247643619\n",
      " loss = 0.00010146894187054274\n",
      " loss = 4.037774210845748e-05\n",
      " loss = 0.00010129451151480906\n",
      " loss = 0.00010064506722245558\n",
      " loss = 9.999978680570012e-05\n",
      " loss = 4.133698919163653e-05\n",
      " loss = 4.085531447001153e-05\n",
      " loss = 0.00010031351772873148\n",
      " loss = 9.967036302172211e-05\n",
      " loss = 9.903133186796706e-05\n",
      " loss = 9.83963978261046e-05\n",
      " loss = 4.228976438270651e-05\n",
      " loss = 4.179698756265529e-05\n",
      " loss = 4.130995275569237e-05\n",
      " loss = 4.082859308766995e-05\n",
      " loss = 9.967513448720022e-05\n",
      " loss = 4.082694837996117e-05\n",
      " loss = 4.035121687348408e-05\n",
      " loss = 9.998348567041455e-05\n",
      " loss = 4.0353093670497457e-05\n",
      " loss = 3.988288369047307e-05\n",
      " loss = 3.941815276592852e-05\n",
      " loss = 0.00010075497622368296\n",
      " loss = 0.0001001089911313561\n",
      " loss = 9.946714773844054e-05\n",
      " loss = 4.036783938793073e-05\n",
      " loss = 3.9897457587629796e-05\n",
      " loss = 3.943255685747078e-05\n",
      " loss = 3.897307332735057e-05\n",
      " loss = 0.00010070498987033645\n",
      " loss = 3.8984577328398444e-05\n",
      " loss = 3.853031382636293e-05\n",
      " loss = 3.8081343587268524e-05\n",
      " loss = 3.763760492300108e-05\n",
      " loss = 0.00010191371087434386\n",
      " loss = 0.00010126029661828777\n",
      " loss = 3.812108969403344e-05\n",
      " loss = 0.00010107321675283352\n",
      " loss = 3.8138262764365754e-05\n",
      " loss = 3.7693860846638554e-05\n",
      " loss = 0.00010134718800560974\n",
      " loss = 0.00010069740597818751\n",
      " loss = 3.8174790806033854e-05\n",
      " loss = 0.00010051297510516326\n",
      " loss = 3.819037674806469e-05\n",
      " loss = 3.7745367585425814e-05\n",
      " loss = 0.00010078861474328289\n",
      " loss = 0.00010014241397824619\n",
      " loss = 3.82237656077164e-05\n",
      " loss = 3.777836738907264e-05\n",
      " loss = 3.7338159121357245e-05\n",
      " loss = 3.69030803208411e-05\n",
      " loss = 3.647307125222893e-05\n",
      " loss = 3.6048072803330047e-05\n",
      " loss = 0.00010223701082630356\n",
      " loss = 0.00010158152374697719\n",
      " loss = 3.6531958864715885e-05\n",
      " loss = 3.610627423930398e-05\n",
      " loss = 0.0001018348280135227\n",
      " loss = 0.00010118191951175703\n",
      " loss = 0.0001005331970946873\n",
      " loss = 9.988863392774846e-05\n",
      " loss = 3.7496661887722116e-05\n",
      " loss = 3.705973615598623e-05\n",
      " loss = 0.00010015703335193695\n",
      " loss = 9.951488193970933e-05\n",
      " loss = 9.887684764418276e-05\n",
      " loss = 3.799038503413355e-05\n",
      " loss = 9.869879957768166e-05\n",
      " loss = 9.806599754878754e-05\n",
      " loss = 9.7437252695681e-05\n",
      " loss = 9.681253900786294e-05\n",
      " loss = 3.937573179718508e-05\n",
      " loss = 9.665110880410487e-05\n",
      " loss = 9.603143543618437e-05\n",
      " loss = 3.983507153348496e-05\n",
      " loss = 9.587582241820918e-05\n",
      " loss = 9.526111975898899e-05\n",
      " loss = 4.0290634967608565e-05\n",
      " loss = 9.511121480370303e-05\n",
      " loss = 9.450141438347988e-05\n",
      " loss = 9.389552366296319e-05\n",
      " loss = 4.1204712228270095e-05\n",
      " loss = 9.37562304546521e-05\n",
      " loss = 4.1186459191635564e-05\n",
      " loss = 9.361738484501783e-05\n",
      " loss = 4.116797380668403e-05\n",
      " loss = 9.347898364261903e-05\n",
      " loss = 9.287964818538658e-05\n",
      " loss = 9.228415533169733e-05\n",
      " loss = 9.169248044871246e-05\n",
      " loss = 9.110459906054413e-05\n",
      " loss = 9.052048684236995e-05\n",
      " loss = 4.347036974856519e-05\n",
      " loss = 9.040679036199094e-05\n",
      " loss = 4.342963588240728e-05\n",
      " loss = 4.292357683081018e-05\n",
      " loss = 9.075794230673402e-05\n",
      " loss = 4.28871840049345e-05\n",
      " loss = 4.238744580780987e-05\n",
      " loss = 4.18935307564797e-05\n",
      " loss = 4.1405370984179744e-05\n",
      " loss = 9.202337722444588e-05\n",
      " loss = 4.138158924231585e-05\n",
      " loss = 4.0899394831521924e-05\n",
      " loss = 4.0422819144438844e-05\n",
      " loss = 3.9951796682356124e-05\n",
      " loss = 9.326036303320523e-05\n",
      " loss = 9.266242924683683e-05\n",
      " loss = 4.039461661721299e-05\n",
      " loss = 3.992392279296732e-05\n",
      " loss = 9.297702532216925e-05\n",
      " loss = 3.9911480598086465e-05\n",
      " loss = 3.944641646432509e-05\n",
      " loss = 9.328566877521816e-05\n",
      " loss = 3.943757885170999e-05\n",
      " loss = 9.313877197731786e-05\n",
      " loss = 9.25416177654029e-05\n",
      " loss = 3.987996748028958e-05\n",
      " loss = 9.240020720619493e-05\n",
      " loss = 3.98663790041372e-05\n",
      " loss = 3.94018404125569e-05\n",
      " loss = 9.270923385210265e-05\n",
      " loss = 3.939186996198466e-05\n",
      " loss = 9.25643772836563e-05\n",
      " loss = 9.197090577625789e-05\n",
      " loss = 9.138123927751845e-05\n",
      " loss = 4.028243438275132e-05\n",
      " loss = 9.12466928316851e-05\n",
      " loss = 9.066166958651693e-05\n",
      " loss = 9.008039718663522e-05\n",
      " loss = 4.116783334569836e-05\n",
      " loss = 4.0688129707006746e-05\n",
      " loss = 4.0214015756661965e-05\n",
      " loss = 9.085737752293784e-05\n",
      " loss = 9.027485035189492e-05\n",
      " loss = 8.969605801976479e-05\n",
      " loss = 8.912097658349039e-05\n",
      " loss = 4.154848580741646e-05\n",
      " loss = 4.1064346650019276e-05\n",
      " loss = 8.945345878953459e-05\n",
      " loss = 8.887993276817277e-05\n",
      " loss = 8.831008387450989e-05\n",
      " loss = 8.774388853695716e-05\n",
      " loss = 4.2393377311628046e-05\n",
      " loss = 8.763505553561183e-05\n",
      " loss = 4.235227670086381e-05\n",
      " loss = 8.752641905554591e-05\n",
      " loss = 8.69652481422807e-05\n",
      " loss = 4.2764504873464825e-05\n",
      " loss = 8.686136780512641e-05\n",
      " loss = 8.630446083141883e-05\n",
      " loss = 8.575112443648247e-05\n",
      " loss = 4.3627535499573626e-05\n",
      " loss = 4.3119170451257247e-05\n",
      " loss = 8.610997401416439e-05\n",
      " loss = 4.306946036978156e-05\n",
      " loss = 8.601095263348739e-05\n",
      " loss = 4.301980826132813e-05\n",
      " loss = 4.2518524665172746e-05\n",
      " loss = 4.202308223710406e-05\n",
      " loss = 8.681275276026033e-05\n",
      " loss = 4.198219334958848e-05\n",
      " loss = 8.670528198206822e-05\n",
      " loss = 4.194128463698962e-05\n",
      " loss = 8.659800350857319e-05\n",
      " loss = 4.190035668764416e-05\n",
      " loss = 4.1412117402025204e-05\n",
      " loss = 8.693758310183384e-05\n",
      " loss = 8.638018747775486e-05\n",
      " loss = 4.182221117452743e-05\n",
      " loss = 8.627351565494628e-05\n",
      " loss = 4.1781195560468235e-05\n",
      " loss = 8.616703246906059e-05\n",
      " loss = 4.174016341003726e-05\n",
      " loss = 4.125379076619751e-05\n",
      " loss = 4.077308551471652e-05\n",
      " loss = 4.029798162409357e-05\n",
      " loss = 3.982841382944075e-05\n",
      " loss = 3.9364317608560855e-05\n",
      " loss = 3.890562922326683e-05\n",
      " loss = 3.845228565453434e-05\n",
      " loss = 3.800422461353806e-05\n",
      " loss = 8.957715376031295e-05\n",
      " loss = 3.7994987598195724e-05\n",
      " loss = 3.7552255173077976e-05\n",
      " loss = 3.711468165223536e-05\n",
      " loss = 9.030029846744893e-05\n",
      " loss = 8.972134297868938e-05\n",
      " loss = 3.754381043612972e-05\n",
      " loss = 8.957783728498428e-05\n",
      " loss = 8.900351381373654e-05\n",
      " loss = 8.843287258975042e-05\n",
      " loss = 3.84025269247078e-05\n",
      " loss = 3.795504570730456e-05\n",
      " loss = 3.75127787077402e-05\n",
      " loss = 3.7075665187888786e-05\n",
      " loss = 8.959106355355386e-05\n",
      " loss = 8.901665528343754e-05\n",
      " loss = 8.844592979986659e-05\n",
      " loss = 8.787886349491942e-05\n",
      " loss = 3.836346376526866e-05\n",
      " loss = 3.791643772644413e-05\n",
      " loss = 3.747462060969017e-05\n",
      " loss = 8.8606822757363e-05\n",
      " loss = 8.803872489555663e-05\n",
      " loss = 8.747426936307828e-05\n",
      " loss = 3.8325860497395543e-05\n",
      " loss = 8.734415910499182e-05\n",
      " loss = 3.8309224468147e-05\n",
      " loss = 3.786283044677128e-05\n",
      " loss = 3.742163798628417e-05\n",
      " loss = 8.80707124661689e-05\n",
      " loss = 8.750605184437684e-05\n",
      " loss = 8.694501151594681e-05\n",
      " loss = 8.63875682661997e-05\n",
      " loss = 8.583369903631568e-05\n",
      " loss = 3.912920851273136e-05\n",
      " loss = 8.571450815241567e-05\n",
      " loss = 3.910359863130141e-05\n",
      " loss = 8.559564120760826e-05\n",
      " loss = 8.504684937494038e-05\n",
      " loss = 8.450157608999382e-05\n",
      " loss = 3.9940585542299706e-05\n",
      " loss = 3.9475182272227074e-05\n",
      " loss = 8.48227550232855e-05\n",
      " loss = 3.94451735570214e-05\n",
      " loss = 8.470923165688384e-05\n",
      " loss = 3.941506299150693e-05\n",
      " loss = 3.8955783299385114e-05\n",
      " loss = 3.8501855318519355e-05\n",
      " loss = 3.8053216690770704e-05\n",
      " loss = 3.760980577084098e-05\n",
      " loss = 8.630112169173805e-05\n",
      " loss = 3.7594931464884587e-05\n",
      " loss = 8.617153415336737e-05\n",
      " loss = 8.561905001235908e-05\n",
      " loss = 8.507010809220832e-05\n",
      " loss = 3.8428817140981363e-05\n",
      " loss = 3.798102957826284e-05\n",
      " loss = 3.75384597986968e-05\n",
      " loss = 8.579643270311003e-05\n",
      " loss = 3.752277415329228e-05\n",
      " loss = 8.566843554595235e-05\n",
      " loss = 3.750686788665866e-05\n",
      " loss = 3.7069823239423456e-05\n",
      " loss = 8.596110170759716e-05\n",
      " loss = 8.540996674142485e-05\n",
      " loss = 8.486236534824526e-05\n",
      " loss = 8.431827487337489e-05\n",
      " loss = 3.83219621131405e-05\n",
      " loss = 3.787541968253544e-05\n",
      " loss = 8.462200301663495e-05\n",
      " loss = 8.407945360954629e-05\n",
      " loss = 3.8276455000941164e-05\n",
      " loss = 3.783044282094443e-05\n",
      " loss = 3.7389627739856295e-05\n",
      " loss = 8.480221262086661e-05\n",
      " loss = 8.42585078094243e-05\n",
      " loss = 3.77918299732922e-05\n",
      " loss = 8.413807443488051e-05\n",
      " loss = 8.359862771169886e-05\n",
      " loss = 3.8190491607190996e-05\n",
      " loss = 8.348298259702047e-05\n",
      " loss = 3.816505481988474e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 8.336764838221747e-05\n",
      " loss = 3.813948441997894e-05\n",
      " loss = 8.325262306260788e-05\n",
      " loss = 3.811378196792232e-05\n",
      " loss = 8.313790464178574e-05\n",
      " loss = 8.260487045320308e-05\n",
      " loss = 8.20752537834718e-05\n",
      " loss = 3.892736461976554e-05\n",
      " loss = 3.8473767789496236e-05\n",
      " loss = 8.23886564053272e-05\n",
      " loss = 8.186042598141904e-05\n",
      " loss = 3.8863082525960516e-05\n",
      " loss = 3.841023473415035e-05\n",
      " loss = 3.796266369932335e-05\n",
      " loss = 3.752030794153684e-05\n",
      " loss = 8.300570300230082e-05\n",
      " loss = 8.247351641535984e-05\n",
      " loss = 8.194474191475859e-05\n",
      " loss = 3.8330055585422896e-05\n",
      " loss = 3.78834188268453e-05\n",
      " loss = 8.225183731531361e-05\n",
      " loss = 8.172448409974862e-05\n",
      " loss = 3.8272502226333616e-05\n",
      " loss = 3.7826536107049074e-05\n",
      " loss = 3.738576655156768e-05\n",
      " loss = 3.6950133015044444e-05\n",
      " loss = 8.285646020806599e-05\n",
      " loss = 8.232523048430038e-05\n",
      " loss = 8.179740671118668e-05\n",
      " loss = 8.127296705147986e-05\n",
      " loss = 3.816999500931504e-05\n",
      " loss = 8.116624076754571e-05\n",
      " loss = 8.064584779431087e-05\n",
      " loss = 3.855330772284834e-05\n",
      " loss = 3.8104069545168106e-05\n",
      " loss = 3.7660066057622726e-05\n",
      " loss = 8.13691638027609e-05\n",
      " loss = 8.084746980015969e-05\n",
      " loss = 3.804483404438831e-05\n",
      " loss = 3.760152080468556e-05\n",
      " loss = 8.115293195147389e-05\n",
      " loss = 3.757384076788266e-05\n",
      " loss = 8.104341935097563e-05\n",
      " loss = 3.754605487342999e-05\n",
      " loss = 8.093417995054189e-05\n",
      " loss = 3.7518164440703454e-05\n",
      " loss = 8.082521209530359e-05\n",
      " loss = 8.030700561063356e-05\n",
      " loss = 3.7900273956782776e-05\n",
      " loss = 8.02025462735415e-05\n",
      " loss = 7.968833197550047e-05\n",
      " loss = 3.827887464769538e-05\n",
      " loss = 3.783283426206869e-05\n",
      " loss = 3.7391991318861005e-05\n",
      " loss = 8.04060166570707e-05\n",
      " loss = 3.736371751175168e-05\n",
      " loss = 8.02982540533684e-05\n",
      " loss = 3.733534575907126e-05\n",
      " loss = 8.019075444069457e-05\n",
      " loss = 3.730687729532378e-05\n",
      " loss = 3.687216300546337e-05\n",
      " loss = 8.04890663860468e-05\n",
      " loss = 7.99730150810771e-05\n",
      " loss = 7.946027240981452e-05\n",
      " loss = 7.895081716060418e-05\n",
      " loss = 7.844462825634684e-05\n",
      " loss = 7.79416847557712e-05\n",
      " loss = 7.744196585076759e-05\n",
      " loss = 3.929500157747911e-05\n",
      " loss = 3.883712089867388e-05\n",
      " loss = 7.776494544011324e-05\n",
      " loss = 3.8792890856797826e-05\n",
      " loss = 7.767497934213811e-05\n",
      " loss = 3.8748707511796277e-05\n",
      " loss = 7.758512100221031e-05\n",
      " loss = 7.70876881862755e-05\n",
      " loss = 3.91127860147054e-05\n",
      " loss = 3.865702859079003e-05\n",
      " loss = 7.740916459360814e-05\n",
      " loss = 7.691285991267926e-05\n",
      " loss = 7.64197372616095e-05\n",
      " loss = 3.9428374035108044e-05\n",
      " loss = 7.633815974076127e-05\n",
      " loss = 3.937654119628662e-05\n",
      " loss = 7.625661877337986e-05\n",
      " loss = 7.576770357730287e-05\n",
      " loss = 7.52819230342147e-05\n",
      " loss = 4.014144657781422e-05\n",
      " loss = 7.520824687325916e-05\n",
      " loss = 4.008190169820415e-05\n",
      " loss = 3.961485175706313e-05\n",
      " loss = 3.9153244046049106e-05\n",
      " loss = 3.869701517604975e-05\n",
      " loss = 7.635227764797083e-05\n",
      " loss = 7.58627491409322e-05\n",
      " loss = 3.905461907682111e-05\n",
      " loss = 7.578131800711851e-05\n",
      " loss = 7.529545017588304e-05\n",
      " loss = 7.481269746059105e-05\n",
      " loss = 3.981446821789279e-05\n",
      " loss = 7.473908865055245e-05\n",
      " loss = 3.975579850348133e-05\n",
      " loss = 3.929254842637498e-05\n",
      " loss = 7.506972738211858e-05\n",
      " loss = 7.458842187572908e-05\n",
      " loss = 7.411020223318592e-05\n",
      " loss = 7.363504867129224e-05\n",
      " loss = 4.045330241549659e-05\n",
      " loss = 7.356900958843527e-05\n",
      " loss = 7.309732585323526e-05\n",
      " loss = 4.079320881554341e-05\n",
      " loss = 4.0317870435186636e-05\n",
      " loss = 3.984807088684406e-05\n",
      " loss = 3.9383745624658776e-05\n",
      " loss = 7.424627215052608e-05\n",
      " loss = 7.3770246183561e-05\n",
      " loss = 3.972906756358939e-05\n",
      " loss = 7.370005269787599e-05\n",
      " loss = 3.9668128163252384e-05\n",
      " loss = 3.920589965989133e-05\n",
      " loss = 3.874905722466392e-05\n",
      " loss = 7.44305877425285e-05\n",
      " loss = 7.395338004660119e-05\n",
      " loss = 7.34792319415211e-05\n",
      " loss = 3.949682430127958e-05\n",
      " loss = 7.34089318524621e-05\n",
      " loss = 3.943662293316035e-05\n",
      " loss = 3.897709201981622e-05\n",
      " loss = 7.373764262454149e-05\n",
      " loss = 7.326487770795572e-05\n",
      " loss = 3.932025158921351e-05\n",
      " loss = 7.31944708510793e-05\n",
      " loss = 7.272518845160443e-05\n",
      " loss = 3.965992684834174e-05\n",
      " loss = 3.919779390034441e-05\n",
      " loss = 7.305681734981463e-05\n",
      " loss = 3.91386042689449e-05\n",
      " loss = 7.298625442949122e-05\n",
      " loss = 3.907961242768453e-05\n",
      " loss = 3.8624241544730935e-05\n",
      " loss = 7.331175092724892e-05\n",
      " loss = 7.284171659219325e-05\n",
      " loss = 7.237469585674666e-05\n",
      " loss = 3.9362442155785584e-05\n",
      " loss = 7.230777949478632e-05\n",
      " loss = 3.9300113163993516e-05\n",
      " loss = 3.8842172915663984e-05\n",
      " loss = 3.838956877472078e-05\n",
      " loss = 7.303030640079818e-05\n",
      " loss = 3.833561581715487e-05\n",
      " loss = 7.295573429107912e-05\n",
      " loss = 7.248798253754972e-05\n",
      " loss = 3.867546999439769e-05\n",
      " loss = 7.241716209156247e-05\n",
      " loss = 7.195286336493164e-05\n",
      " loss = 7.149154146512404e-05\n",
      " loss = 3.940652303605062e-05\n",
      " loss = 7.142808167828216e-05\n",
      " loss = 3.934147595038131e-05\n",
      " loss = 3.888305372624878e-05\n",
      " loss = 7.175770897656817e-05\n",
      " loss = 3.882239100406905e-05\n",
      " loss = 7.169032878926444e-05\n",
      " loss = 7.123069011549185e-05\n",
      " loss = 7.07739983896768e-05\n",
      " loss = 3.9547955978650915e-05\n",
      " loss = 7.071386052727614e-05\n",
      " loss = 3.947998180982425e-05\n",
      " loss = 7.065360244901777e-05\n",
      " loss = 7.02006106887864e-05\n",
      " loss = 6.975052326181145e-05\n",
      " loss = 4.019905960041328e-05\n",
      " loss = 6.969730301709595e-05\n",
      " loss = 4.0123846971600305e-05\n",
      " loss = 6.964390474921282e-05\n",
      " loss = 6.919738661211527e-05\n",
      " loss = 6.87537313027886e-05\n",
      " loss = 6.831292046548522e-05\n",
      " loss = 6.787493586345994e-05\n",
      " loss = 6.743975937563884e-05\n",
      " loss = 4.2022094770904955e-05\n",
      " loss = 4.153243692604537e-05\n",
      " loss = 6.779843492461929e-05\n",
      " loss = 6.736374891745363e-05\n",
      " loss = 6.693184987717425e-05\n",
      " loss = 4.223277584714237e-05\n",
      " loss = 6.689832684412179e-05\n",
      " loss = 6.646941183156054e-05\n",
      " loss = 6.604324678474683e-05\n",
      " loss = 4.292681752520427e-05\n",
      " loss = 6.601601073855299e-05\n",
      " loss = 4.282200876925397e-05\n",
      " loss = 4.232303000937229e-05\n",
      " loss = 6.638288101490318e-05\n",
      " loss = 4.2223564718643964e-05\n",
      " loss = 4.1731559266902596e-05\n",
      " loss = 4.1245286858692876e-05\n",
      " loss = 4.076468068671692e-05\n",
      " loss = 4.0289674732020696e-05\n",
      " loss = 6.791551351098934e-05\n",
      " loss = 6.748007686039855e-05\n",
      " loss = 6.704743198907195e-05\n",
      " loss = 6.661756099700527e-05\n",
      " loss = 4.137819813394307e-05\n",
      " loss = 6.658110502083848e-05\n",
      " loss = 6.61542238601111e-05\n",
      " loss = 4.1676376760236127e-05\n",
      " loss = 4.119074737248932e-05\n",
      " loss = 6.651034872422803e-05\n",
      " loss = 6.608392121207212e-05\n",
      " loss = 4.148893332643894e-05\n",
      " loss = 6.604984217247355e-05\n",
      " loss = 4.1394316233476515e-05\n",
      " loss = 6.60154362421235e-05\n",
      " loss = 6.559218183554146e-05\n",
      " loss = 6.517164110122726e-05\n",
      " loss = 6.475379664168645e-05\n",
      " loss = 6.433863116947115e-05\n",
      " loss = 4.2859042297729024e-05\n",
      " loss = 6.431687615229324e-05\n",
      " loss = 4.2749582567248734e-05\n",
      " loss = 4.2251447764649095e-05\n",
      " loss = 4.175911742148633e-05\n",
      " loss = 4.127252390432282e-05\n",
      " loss = 6.545859722090308e-05\n",
      " loss = 4.117767172488668e-05\n",
      " loss = 6.542522291430768e-05\n",
      " loss = 6.500575262921313e-05\n",
      " loss = 4.146948420384605e-05\n",
      " loss = 6.497530882874688e-05\n",
      " loss = 6.455872314257925e-05\n",
      " loss = 4.1757933351492096e-05\n",
      " loss = 6.453115545254677e-05\n",
      " loss = 6.411741743116603e-05\n",
      " loss = 6.370633206970865e-05\n",
      " loss = 6.329788236056191e-05\n",
      " loss = 6.289205140369984e-05\n",
      " loss = 4.3204494730577226e-05\n",
      " loss = 6.287671630314946e-05\n",
      " loss = 4.3088156354398414e-05\n",
      " loss = 4.258607635622888e-05\n",
      " loss = 6.324715553462839e-05\n",
      " loss = 4.247530295398751e-05\n",
      " loss = 4.198036414436604e-05\n",
      " loss = 6.361193403354196e-05\n",
      " loss = 4.1875008562369836e-05\n",
      " loss = 4.13870646364686e-05\n",
      " loss = 6.397109043037734e-05\n",
      " loss = 4.128698366110166e-05\n",
      " loss = 6.394335250511969e-05\n",
      " loss = 4.118752463353824e-05\n",
      " loss = 6.391524815044372e-05\n",
      " loss = 4.10886816997495e-05\n",
      " loss = 4.060990036427713e-05\n",
      " loss = 6.426700650664714e-05\n",
      " loss = 6.385496206258921e-05\n",
      " loss = 4.089617037051335e-05\n",
      " loss = 6.382580667933015e-05\n",
      " loss = 4.079910886953337e-05\n",
      " loss = 4.0323701736843465e-05\n",
      " loss = 3.9853834240296065e-05\n",
      " loss = 6.455242393521662e-05\n",
      " loss = 3.976619409441206e-05\n",
      " loss = 6.451553818895717e-05\n",
      " loss = 3.967905387296369e-05\n",
      " loss = 3.9216698067305083e-05\n",
      " loss = 3.875972980922566e-05\n",
      " loss = 3.830808631445115e-05\n",
      " loss = 6.560110152178752e-05\n",
      " loss = 6.518050360030394e-05\n",
      " loss = 3.8607097436562296e-05\n",
      " loss = 3.815723248563851e-05\n",
      " loss = 3.771260954388789e-05\n",
      " loss = 3.727316751177875e-05\n",
      " loss = 6.624885529584799e-05\n",
      " loss = 3.72079944654103e-05\n",
      " loss = 3.6774432397764516e-05\n",
      " loss = 6.656176472467608e-05\n",
      " loss = 3.6713466052188025e-05\n",
      " loss = 6.65028025980032e-05\n",
      " loss = 3.665274297948971e-05\n",
      " loss = 3.6225650924639255e-05\n",
      " loss = 3.5803535517349624e-05\n",
      " loss = 3.538633876089021e-05\n",
      " loss = 3.4974003339350654e-05\n",
      " loss = 3.456647261231104e-05\n",
      " loss = 6.826323336432879e-05\n",
      " loss = 6.782556732730102e-05\n",
      " loss = 6.739070736185236e-05\n",
      " loss = 6.695863547876406e-05\n",
      " loss = 3.56116240205859e-05\n",
      " loss = 6.689263687640232e-05\n",
      " loss = 6.646375834577214e-05\n",
      " loss = 3.592255061131039e-05\n",
      " loss = 6.640116828576463e-05\n",
      " loss = 6.597544077813113e-05\n",
      " loss = 3.6230303347882163e-05\n",
      " loss = 3.580813372042533e-05\n",
      " loss = 3.539088337156268e-05\n",
      " loss = 3.497849500019644e-05\n",
      " loss = 3.457091193841375e-05\n",
      " loss = 6.735987958387567e-05\n",
      " loss = 3.4526604189053634e-05\n",
      " loss = 6.728679231697209e-05\n",
      " loss = 6.68553866793373e-05\n",
      " loss = 6.642674697525773e-05\n",
      " loss = 6.600085547269283e-05\n",
      " loss = 3.556089947143012e-05\n",
      " loss = 3.5146529996637274e-05\n",
      " loss = 3.4736988930948884e-05\n",
      " loss = 3.4332219981253424e-05\n",
      " loss = 3.393216756824132e-05\n",
      " loss = 6.736858557702228e-05\n",
      " loss = 3.3892006826078744e-05\n",
      " loss = 6.72921485078514e-05\n",
      " loss = 6.686070852933342e-05\n",
      " loss = 3.42074418032274e-05\n",
      " loss = 3.3808843357107334e-05\n",
      " loss = 6.714249496527008e-05\n",
      " loss = 6.671201448212743e-05\n",
      " loss = 6.628429400107455e-05\n",
      " loss = 6.585931582778718e-05\n",
      " loss = 6.543706237880446e-05\n",
      " loss = 6.501751618442312e-05\n",
      " loss = 3.5549332590339114e-05\n",
      " loss = 3.513509790448645e-05\n",
      " loss = 6.53149323758477e-05\n",
      " loss = 3.508157946065741e-05\n",
      " loss = 6.525230746247511e-05\n",
      " loss = 6.483394581438542e-05\n",
      " loss = 6.441826647028313e-05\n",
      " loss = 6.400525223050915e-05\n",
      " loss = 6.359488600966605e-05\n",
      " loss = 3.645652517081726e-05\n",
      " loss = 6.354540496510377e-05\n",
      " loss = 3.638926630297471e-05\n",
      " loss = 6.349577099980049e-05\n",
      " loss = 6.308867129084671e-05\n",
      " loss = 6.268418167932654e-05\n",
      " loss = 6.22822854315138e-05\n",
      " loss = 3.73971557070766e-05\n",
      " loss = 6.224206014523752e-05\n",
      " loss = 6.184299853591236e-05\n",
      " loss = 3.767871318234163e-05\n",
      " loss = 3.723966611748518e-05\n",
      " loss = 3.6805735009018504e-05\n",
      " loss = 3.637686022519943e-05\n",
      " loss = 6.287680034968458e-05\n",
      " loss = 3.6308251212980694e-05\n",
      " loss = 3.5885173305891555e-05\n",
      " loss = 3.546702526789222e-05\n",
      " loss = 6.353693862098964e-05\n",
      " loss = 6.31295749672175e-05\n",
      " loss = 6.272482310406295e-05\n",
      " loss = 6.232266628570558e-05\n",
      " loss = 3.646804056383107e-05\n",
      " loss = 3.604310073181189e-05\n",
      " loss = 3.562311247672632e-05\n",
      " loss = 6.298401820799196e-05\n",
      " loss = 3.5559895939686064e-05\n",
      " loss = 6.293231352541086e-05\n",
      " loss = 3.549695976562006e-05\n",
      " loss = 6.288048395374177e-05\n",
      " loss = 6.247732912507532e-05\n",
      " loss = 6.207675910162911e-05\n",
      " loss = 3.613805540346155e-05\n",
      " loss = 3.571696068532694e-05\n",
      " loss = 3.530077273784403e-05\n",
      " loss = 6.273277964855003e-05\n",
      " loss = 6.233057181759223e-05\n",
      " loss = 6.193094272049917e-05\n",
      " loss = 3.594001212466935e-05\n",
      " loss = 6.188490175894224e-05\n",
      " loss = 6.148813005066343e-05\n",
      " loss = 6.109390222268978e-05\n",
      " loss = 3.6573962031790754e-05\n",
      " loss = 6.105391694077411e-05\n",
      " loss = 6.0662473047468645e-05\n",
      " loss = 3.6850374491468314e-05\n",
      " loss = 6.0625335389068605e-05\n",
      " loss = 6.023663932297152e-05\n",
      " loss = 3.712371183206517e-05\n",
      " loss = 6.0202296387525e-05\n",
      " loss = 5.98163126136365e-05\n",
      " loss = 3.739397630686378e-05\n",
      " loss = 5.9784712487485794e-05\n",
      " loss = 5.940140603012253e-05\n",
      " loss = 3.7661170999425046e-05\n",
      " loss = 5.9372497795194124e-05\n",
      " loss = 5.8991834229528344e-05\n",
      " loss = 5.8613611268223846e-05\n",
      " loss = 5.823781326252016e-05\n",
      " loss = 3.863027709942418e-05\n",
      " loss = 5.8217368313951896e-05\n",
      " loss = 3.8532365399087333e-05\n",
      " loss = 5.819654442339781e-05\n",
      " loss = 3.8435085898465594e-05\n",
      " loss = 5.8175345340043045e-05\n",
      " loss = 3.833843258913723e-05\n"
     ]
    }
   ],
   "source": [
    "rg=reg_NN()\n",
    "rg.stocastic_batch_gredient_descent(regx_scaled,regy_scaled,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "422e53b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rg.epoch_track,rg.cost_track)\n",
    "plt.title(\"Stocastic Batch Gredient Descent\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7fb697a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.29923486577658676\n",
      " loss = 0.2896887336366957\n",
      " loss = 0.38379897013047304\n",
      " loss = 0.2689851620246979\n",
      " loss = 0.35786356004056824\n",
      " loss = 0.2497990522484343\n",
      " loss = 0.15006130158362546\n",
      " loss = 0.1462443479168906\n",
      " loss = 0.1425360271850253\n",
      " loss = 0.31353753942233076\n",
      " loss = 0.21700019124810613\n",
      " loss = 0.1278687720752625\n",
      " loss = 0.2866382915361352\n",
      " loss = 0.19727690206929932\n",
      " loss = 0.19114422388400704\n",
      " loss = 0.259730857938475\n",
      " loss = 0.17768547537238372\n",
      " loss = 0.24251199232451778\n",
      " loss = 0.23321809179131409\n",
      " loss = 0.15851992506198292\n",
      " loss = 0.02533641412835543\n",
      " loss = 0.15209863615042557\n",
      " loss = 0.023158774977390384\n",
      " loss = 0.08428325837958456\n",
      " loss = 0.14306144360933498\n",
      " loss = 0.13874187776692665\n",
      " loss = 0.19241388335941967\n",
      " loss = 0.1291556198352867\n",
      " loss = 0.12529905989831844\n",
      " loss = 0.06827793937995537\n",
      " loss = 0.17171786208855544\n",
      " loss = 0.0637074796545659\n",
      " loss = 0.062308150875478044\n",
      " loss = 0.11019736321039351\n",
      " loss = 0.05890142761136044\n",
      " loss = 0.10499444730087694\n",
      " loss = 0.05571562248818503\n",
      " loss = 0.19118476638695353\n",
      " loss = 0.13871318451986714\n",
      " loss = 0.13353640041480377\n",
      " loss = 0.006128668976049687\n",
      " loss = 0.046583408240157984\n",
      " loss = 0.08568804785857967\n",
      " loss = 0.12236451869246093\n",
      " loss = 0.08004302651804127\n",
      " loss = 0.040920566092904155\n",
      " loss = 0.11292223478047726\n",
      " loss = 0.03840801145271497\n",
      " loss = 0.10709516842011847\n",
      " loss = 0.06962954231820137\n",
      " loss = 0.034999546229515774\n",
      " loss = 0.06670005189317765\n",
      " loss = 0.12802830224579043\n",
      " loss = 0.0315688773778251\n",
      " loss = 0.09061758687583987\n",
      " loss = 0.0873445382538666\n",
      " loss = 0.02857772246852535\n",
      " loss = 0.05559291932203857\n",
      " loss = 0.027366271579717338\n",
      " loss = 0.05343233722092479\n",
      " loss = 0.07794480208484685\n",
      " loss = 0.07517247485397574\n",
      " loss = 0.07250952587093028\n",
      " loss = 0.09324342881778484\n",
      " loss = 0.022246986727712116\n",
      " loss = 0.06590598403857965\n",
      " loss = 0.04240568724773149\n",
      " loss = 0.04142396799000612\n",
      " loss = 0.020247686632881453\n",
      " loss = 0.02002698450758274\n",
      " loss = 0.019811892398839282\n",
      " loss = 0.039146781426777834\n",
      " loss = 0.01918190939392333\n",
      " loss = 0.03786469256150183\n",
      " loss = 0.055466930962075\n",
      " loss = 0.035800964484000226\n",
      " loss = 0.06976312713314234\n",
      " loss = 0.050019346439305196\n",
      " loss = 0.04834740649391308\n",
      " loss = 0.04674125627528777\n",
      " loss = 0.0008792509859589854\n",
      " loss = 0.015689608210459012\n",
      " loss = 0.03027032355632885\n",
      " loss = 0.015337726453394323\n",
      " loss = 0.04365114538629052\n",
      " loss = 0.014879685651558337\n",
      " loss = 0.04188678232806058\n",
      " loss = 0.027498155940979006\n",
      " loss = 0.05245307546914141\n",
      " loss = 0.013873474046645202\n",
      " loss = 0.013808023028436719\n",
      " loss = 0.02559396036043475\n",
      " loss = 0.01358423458528591\n",
      " loss = 0.047948190968843694\n",
      " loss = 0.02404465099888959\n",
      " loss = 0.023652917374620316\n",
      " loss = 0.03360540336074248\n",
      " loss = 0.042488928211808254\n",
      " loss = 0.031187858832772496\n",
      " loss = 0.02130588165259295\n",
      " loss = 0.012270745107338613\n",
      " loss = 0.012237767795998732\n",
      " loss = 0.020832067208686734\n",
      " loss = 0.012123806390452463\n",
      " loss = 0.0204617704759215\n",
      " loss = 0.028344913844150874\n",
      " loss = 0.019711904944927906\n",
      " loss = 0.027068927350672956\n",
      " loss = 0.019019254803997042\n",
      " loss = 0.032967926402837876\n",
      " loss = 0.011590067184819707\n",
      " loss = 0.01816311093546135\n",
      " loss = 0.02438247565052299\n",
      " loss = 0.017588099891977713\n",
      " loss = 0.023360694794266078\n",
      " loss = 0.011385314934136564\n",
      " loss = 0.01702587667834356\n",
      " loss = 0.016848706302282097\n",
      " loss = 0.016676585938584062\n",
      " loss = 0.011277500677622468\n",
      " loss = 0.011254133276562706\n",
      " loss = 0.021685879214780445\n",
      " loss = 0.016161384511406994\n",
      " loss = 0.02083093053148012\n",
      " loss = 0.01573259979042255\n",
      " loss = 0.020029689375433396\n",
      " loss = 0.015336416044559981\n",
      " loss = 0.011135515392790382\n",
      " loss = 0.01110886515692501\n",
      " loss = 0.015180838595560587\n",
      " loss = 0.019038647377843162\n",
      " loss = 0.018569319992185432\n",
      " loss = 0.011084759811051153\n",
      " loss = 0.011055332077010977\n",
      " loss = 0.01814230054674291\n",
      " loss = 0.014373120100772747\n",
      " loss = 0.011033023464354974\n",
      " loss = 0.011002023273499724\n",
      " loss = 0.007687936501583492\n",
      " loss = 0.014346094321996489\n",
      " loss = 0.00758365952925649\n",
      " loss = 0.014330517216975114\n",
      " loss = 0.020961796289999664\n",
      " loss = 0.010893671442066965\n",
      " loss = 0.010861932806920653\n",
      " loss = 0.007745547613974741\n",
      " loss = 0.014003487365086989\n",
      " loss = 0.01390182510755467\n",
      " loss = 0.016842298940899753\n",
      " loss = 0.01928177809073808\n",
      " loss = 0.013358615556480446\n",
      " loss = 0.01083958736943325\n",
      " loss = 0.01327240140936402\n",
      " loss = 0.008411059219342865\n",
      " loss = 0.00819639159996373\n",
      " loss = 0.013346159358959346\n",
      " loss = 0.010663024664968589\n",
      " loss = 0.015881844380880077\n",
      " loss = 0.01065728408046622\n",
      " loss = 0.015551476521444528\n",
      " loss = 0.01520360544581079\n",
      " loss = 0.014869125206059559\n",
      " loss = 0.012635574533665987\n",
      " loss = 0.016254901273442857\n",
      " loss = 0.012371952960299616\n",
      " loss = 0.01231017728905067\n",
      " loss = 0.01369528777197256\n",
      " loss = 0.012133832871799657\n",
      " loss = 0.010848646783526976\n",
      " loss = 0.01079961730840619\n",
      " loss = 0.0120754666334032\n",
      " loss = 0.012018773476463879\n",
      " loss = 0.00953552081764588\n",
      " loss = 0.010654672977440782\n",
      " loss = 0.01060840328468969\n",
      " loss = 0.013467520849579168\n",
      " loss = 0.010607181533241035\n",
      " loss = 0.010560361505237937\n",
      " loss = 0.01189839094852369\n",
      " loss = 0.011841155806679342\n",
      " loss = 0.010512426727996642\n",
      " loss = 0.014420298163388561\n",
      " loss = 0.011623756207140411\n",
      " loss = 0.010557273641498624\n",
      " loss = 0.009443258551829304\n",
      " loss = 0.011621392094288049\n",
      " loss = 0.01272509459719786\n",
      " loss = 0.012474369673993272\n",
      " loss = 0.011369239747208179\n",
      " loss = 0.011321991203691647\n",
      " loss = 0.010501634988890665\n",
      " loss = 0.011273663608787255\n",
      " loss = 0.012788045415472885\n",
      " loss = 0.01164814465628564\n",
      " loss = 0.011436893171269207\n",
      " loss = 0.01094427635483734\n",
      " loss = 0.011416856600361538\n",
      " loss = 0.010764373546162966\n",
      " loss = 0.010698794619274754\n",
      " loss = 0.010634607175140441\n",
      " loss = 0.011009845178894837\n",
      " loss = 0.010820336204925975\n",
      " loss = 0.010658956692960896\n",
      " loss = 0.010625158513941297\n",
      " loss = 0.010667413028830397\n",
      " loss = 0.010555551385280951\n",
      " loss = 0.010717006139924861\n",
      " loss = 0.01064730520561211\n",
      " loss = 0.010486421774689874\n",
      " loss = 0.010335311608299229\n",
      " loss = 0.010167954199635365\n",
      " loss = 0.010344557153071091\n",
      " loss = 0.01067350860477013\n",
      " loss = 0.010306177906715707\n",
      " loss = 0.010276119197914336\n",
      " loss = 0.009907984047197463\n",
      " loss = 0.01063960631283314\n",
      " loss = 0.010566269795865803\n",
      " loss = 0.009863603988341567\n",
      " loss = 0.01054900459165465\n",
      " loss = 0.010476653803724938\n",
      " loss = 0.01011211935306212\n",
      " loss = 0.010397723283755756\n",
      " loss = 0.009821031277097004\n",
      " loss = 0.010381770294222875\n",
      " loss = 0.010015698032792647\n",
      " loss = 0.010303424716681856\n",
      " loss = 0.010234464162311368\n",
      " loss = 0.009971112163031502\n",
      " loss = 0.009722643640704031\n",
      " loss = 0.010212459807566063\n",
      " loss = 0.010143964903510515\n",
      " loss = 0.010076983144053404\n",
      " loss = 0.009868154991116155\n",
      " loss = 0.01017142011582687\n",
      " loss = 0.009800188188090817\n",
      " loss = 0.009777637834175958\n",
      " loss = 0.009274704187437937\n",
      " loss = 0.010097611880901894\n",
      " loss = 0.009315255672425958\n",
      " loss = 0.009172216187170937\n",
      " loss = 0.010132274954977939\n",
      " loss = 0.010060008924681792\n",
      " loss = 0.010414982332175297\n",
      " loss = 0.009574028366823351\n",
      " loss = 0.009546219959462927\n",
      " loss = 0.009845736204614396\n",
      " loss = 0.009779396377668406\n",
      " loss = 0.009714524721059038\n",
      " loss = 0.009805476541785246\n",
      " loss = 0.00949360255001528\n",
      " loss = 0.009583818088841919\n",
      " loss = 0.009454391806120264\n",
      " loss = 0.00933298412876613\n",
      " loss = 0.009373706998303873\n",
      " loss = 0.009132191201732132\n",
      " loss = 0.009608727153171629\n",
      " loss = 0.00929063903513435\n",
      " loss = 0.008990091169176997\n",
      " loss = 0.009218049121749464\n",
      " loss = 0.0095777940642554\n",
      " loss = 0.0095120115426854\n",
      " loss = 0.009176057456311466\n",
      " loss = 0.009440214769808952\n",
      " loss = 0.008907039898760735\n",
      " loss = 0.009096319855542212\n",
      " loss = 0.009070374338319564\n",
      " loss = 0.009409498860663484\n",
      " loss = 0.00965360622794749\n",
      " loss = 0.009048946722959935\n",
      " loss = 0.009021833221841535\n",
      " loss = 0.008775209362734935\n",
      " loss = 0.009262556597009688\n",
      " loss = 0.00945783605724549\n",
      " loss = 0.008825341847207104\n",
      " loss = 0.008908233485168861\n",
      " loss = 0.008881983242310789\n",
      " loss = 0.00885598791986508\n",
      " loss = 0.008548571327471326\n",
      " loss = 0.009159172287302918\n",
      " loss = 0.009096213893365776\n",
      " loss = 0.008772206237746896\n",
      " loss = 0.008746717824733845\n",
      " loss = 0.00842279062315555\n",
      " loss = 0.008292729670212717\n",
      " loss = 0.008640716755196563\n",
      " loss = 0.009104658967239011\n",
      " loss = 0.008608256555362934\n",
      " loss = 0.009031048849307242\n",
      " loss = 0.008967460989246494\n",
      " loss = 0.009242597733411214\n",
      " loss = 0.008578423239453868\n",
      " loss = 0.008553123325071205\n",
      " loss = 0.008528069666913442\n",
      " loss = 0.008503255372071632\n",
      " loss = 0.008765122252351971\n",
      " loss = 0.008237278127162006\n",
      " loss = 0.008429798830714335\n",
      " loss = 0.008405888677530577\n",
      " loss = 0.007674523885959869\n",
      " loss = 0.00782511586958903\n",
      " loss = 0.008296085645482815\n",
      " loss = 0.008274488964702375\n",
      " loss = 0.008253027303140937\n",
      " loss = 0.00761386963620584\n",
      " loss = 0.0082007862608714\n",
      " loss = 0.008883186110448506\n",
      " loss = 0.007522034500241002\n",
      " loss = 0.007417224608174016\n",
      " loss = 0.008110844078003323\n",
      " loss = 0.008892439385699098\n",
      " loss = 0.007334045909348117\n",
      " loss = 0.00723511195010995\n",
      " loss = 0.0089116992002319\n",
      " loss = 0.00718409957951722\n",
      " loss = 0.008884125247409794\n",
      " loss = 0.007134030646812158\n",
      " loss = 0.008856247143697657\n",
      " loss = 0.009633870307571884\n",
      " loss = 0.006468424084568789\n",
      " loss = 0.007032630392215793\n",
      " loss = 0.007872158695955008\n",
      " loss = 0.00785344814904147\n",
      " loss = 0.00877263857765913\n",
      " loss = 0.008700406740141138\n",
      " loss = 0.008629886460023727\n",
      " loss = 0.008561029312066485\n",
      " loss = 0.007781567740728128\n",
      " loss = 0.007762223554330625\n",
      " loss = 0.007015789702571662\n",
      " loss = 0.007717278287251888\n",
      " loss = 0.008500096669321435\n",
      " loss = 0.007685932522475587\n",
      " loss = 0.007667031053010033\n",
      " loss = 0.00764821490640904\n",
      " loss = 0.008395628462392547\n",
      " loss = 0.00832939383378515\n",
      " loss = 0.006947407594118835\n",
      " loss = 0.008306727147670324\n",
      " loss = 0.008241854091410695\n",
      " loss = 0.006935830311906523\n",
      " loss = 0.008220201631046625\n",
      " loss = 0.006881397133414393\n",
      " loss = 0.006786838758501158\n",
      " loss = 0.006695766703797385\n",
      " loss = 0.007444466621506184\n",
      " loss = 0.007426624050455194\n",
      " loss = 0.009099213021890684\n",
      " loss = 0.006668425056413792\n",
      " loss = 0.0073775625352553095\n",
      " loss = 0.007359762365489943\n",
      " loss = 0.006534718643952253\n",
      " loss = 0.007320265943297112\n",
      " loss = 0.007302882190987539\n",
      " loss = 0.007285557482428791\n",
      " loss = 0.006388406328997715\n",
      " loss = 0.0072484540786649995\n",
      " loss = 0.006289607858328917\n",
      " loss = 0.008213061074375822\n",
      " loss = 0.007197626277213915\n",
      " loss = 0.007180785671779405\n",
      " loss = 0.007163994070406132\n",
      " loss = 0.00619699040402679\n",
      " loss = 0.005114975110363466\n",
      " loss = 0.0059962560525435955\n",
      " loss = 0.009440234466869386\n",
      " loss = 0.007079969445019343\n",
      " loss = 0.0070636361181431895\n",
      " loss = 0.00598881495408341\n",
      " loss = 0.00703219188388445\n",
      " loss = 0.007016020843003444\n",
      " loss = 0.006999887530631613\n",
      " loss = 0.005876755953742554\n",
      " loss = 0.006969858530522\n",
      " loss = 0.008109848353544342\n",
      " loss = 0.00693569363047831\n",
      " loss = 0.005820925282761107\n",
      " loss = 0.006905976614306067\n",
      " loss = 0.006890112803846073\n",
      " loss = 0.006874285434355636\n",
      " loss = 0.00685849442212574\n",
      " loss = 0.005703371383754514\n",
      " loss = 0.00920738022478261\n",
      " loss = 0.006809055148320036\n",
      " loss = 0.005713395769410033\n",
      " loss = 0.007910025445241772\n",
      " loss = 0.006762149759589877\n",
      " loss = 0.008895161472064398\n",
      " loss = 0.005760059033140911\n",
      " loss = 0.007735478846077644\n",
      " loss = 0.004760367429672359\n",
      " loss = 0.006684426416703403\n",
      " loss = 0.005598884429819758\n",
      " loss = 0.008894290516719376\n",
      " loss = 0.0056217483509143655\n",
      " loss = 0.0066230045661218855\n",
      " loss = 0.004481353731421674\n",
      " loss = 0.0054361719074690045\n",
      " loss = 0.005379019082240804\n",
      " loss = 0.005323899566520195\n",
      " loss = 0.006567128974559969\n",
      " loss = 0.005261604318273013\n",
      " loss = 0.003877605078982601\n",
      " loss = 0.006542951331230944\n",
      " loss = 0.006527298949549327\n",
      " loss = 0.00510639240138301\n",
      " loss = 0.006504774717820124\n",
      " loss = 0.00505353390889846\n",
      " loss = 0.0035349899949829715\n",
      " loss = 0.006487479020175936\n",
      " loss = 0.006471254221862977\n",
      " loss = 0.004919298850442498\n",
      " loss = 0.0064501188024818495\n",
      " loss = 0.007993645193556661\n",
      " loss = 0.006406899191195111\n",
      " loss = 0.007883219032608354\n",
      " loss = 0.0063656390182074505\n",
      " loss = 0.006350193630719698\n",
      " loss = 0.00491728705155133\n",
      " loss = 0.0048742568325236\n",
      " loss = 0.006323224884307848\n",
      " loss = 0.007787744019979226\n",
      " loss = 0.0048577363144054085\n",
      " loss = 0.0062765404835303665\n",
      " loss = 0.007711942947708703\n",
      " loss = 0.006236428824640367\n",
      " loss = 0.004834352009849451\n",
      " loss = 0.0062153360020431175\n",
      " loss = 0.007614186451410383\n",
      " loss = 0.007536073462153427\n",
      " loss = 0.007459920035534143\n",
      " loss = 0.004878148717599222\n",
      " loss = 0.00870921984105196\n",
      " loss = 0.006096973109929884\n",
      " loss = 0.00846157589599632\n",
      " loss = 0.0049659836934520555\n",
      " loss = 0.0060494374519686304\n",
      " loss = 0.00716570031612127\n",
      " loss = 0.006017326792238507\n",
      " loss = 0.006003467795285178\n",
      " loss = 0.007062696306310939\n",
      " loss = 0.00494833248814794\n",
      " loss = 0.007028636893217992\n",
      " loss = 0.0049270883446989894\n",
      " loss = 0.004874417031187395\n",
      " loss = 0.004823624381836603\n",
      " loss = 0.005915862553384786\n",
      " loss = 0.0070382623298347\n",
      " loss = 0.005883803391678811\n",
      " loss = 0.004787343562632063\n",
      " loss = 0.004738478321761627\n",
      " loss = 0.0035299003765814495\n",
      " loss = 0.005851722791463797\n",
      " loss = 0.005837831102180826\n",
      " loss = 0.007052352283921654\n",
      " loss = 0.00580371213676653\n",
      " loss = 0.004617523369316319\n",
      " loss = 0.004573461624100959\n",
      " loss = 0.0045309427707089026\n",
      " loss = 0.0044899059760401625\n",
      " loss = 0.005764282783446399\n",
      " loss = 0.005750233190524302\n",
      " loss = 0.007033125563194516\n",
      " loss = 0.005714377212335845\n",
      " loss = 0.005700688719099515\n",
      " loss = 0.005687050567605428\n",
      " loss = 0.006898039357067159\n",
      " loss = 0.006828911250022287\n",
      " loss = 0.005633782644082574\n",
      " loss = 0.005620609967054246\n",
      " loss = 0.00560747532588901\n",
      " loss = 0.006705543213397669\n",
      " loss = 0.005576327233256413\n",
      " loss = 0.00556339905101093\n",
      " loss = 0.005550504559117358\n",
      " loss = 0.0034364215797554245\n",
      " loss = 0.006663704895554011\n",
      " loss = 0.005516564712716819\n",
      " loss = 0.006580540246172686\n",
      " loss = 0.004455438454207762\n",
      " loss = 0.0033429132441476737\n",
      " loss = 0.004332478567611513\n",
      " loss = 0.00429216237690966\n",
      " loss = 0.005464258836353007\n",
      " loss = 0.0030441576170357637\n",
      " loss = 0.005454023822589384\n",
      " loss = 0.006707096668902058\n",
      " loss = 0.0042003419770445475\n",
      " loss = 0.006664062539928682\n",
      " loss = 0.004190042094322055\n",
      " loss = 0.004153257635732832\n",
      " loss = 0.005382714422091554\n",
      " loss = 0.005369405111761422\n",
      " loss = 0.005356158142017967\n",
      " loss = 0.005342972301296654\n",
      " loss = 0.005329846416745576\n",
      " loss = 0.004094247488239435\n",
      " loss = 0.006564902566575813\n",
      " loss = 0.00408485322395729\n",
      " loss = 0.004049742788362457\n",
      " loss = 0.007813090047043223\n",
      " loss = 0.0052518558093750545\n",
      " loss = 0.005239129528804091\n",
      " loss = 0.0028946329622702533\n",
      " loss = 0.005229639548696814\n",
      " loss = 0.003990889853662459\n",
      " loss = 0.005212455838071118\n",
      " loss = 0.005199401953084044\n",
      " loss = 0.003949462792888362\n",
      " loss = 0.005182439658437841\n",
      " loss = 0.007681534503496634\n",
      " loss = 0.0039665591725221334\n",
      " loss = 0.006337350098993657\n",
      " loss = 0.005114412678625662\n",
      " loss = 0.005101987247912686\n",
      " loss = 0.003947315068118484\n",
      " loss = 0.006256726727682173\n",
      " loss = 0.00393757960375566\n",
      " loss = 0.00505999492454337\n",
      " loss = 0.006197066621715308\n",
      " loss = 0.003922904006158971\n",
      " loss = 0.002752844403001873\n",
      " loss = 0.006227161521565514\n",
      " loss = 0.0026941707202707724\n",
      " loss = 0.005010287661613186\n",
      " loss = 0.0037862639809897024\n",
      " loss = 0.0037557807994387632\n",
      " loss = 0.0037263307956953416\n",
      " loss = 0.006277755376222816\n",
      " loss = 0.006209542138691764\n",
      " loss = 0.0049431413884930605\n",
      " loss = 0.00612191450228708\n",
      " loss = 0.006057480667205424\n",
      " loss = 0.0048905804256265\n",
      " loss = 0.005975688417019681\n",
      " loss = 0.0048602476271742525\n",
      " loss = 0.004848628180021366\n",
      " loss = 0.0037950478384502365\n",
      " loss = 0.005903099627833215\n",
      " loss = 0.004813930060133844\n",
      " loss = 0.003779096831427282\n",
      " loss = 0.0026918595065846063\n",
      " loss = 0.005915589288413246\n",
      " loss = 0.0037067378580424564\n",
      " loss = 0.004776051574118442\n",
      " loss = 0.006952871978749134\n",
      " loss = 0.004739483012672066\n",
      " loss = 0.005740206729096386\n",
      " loss = 0.004711416212500871\n",
      " loss = 0.005666603864718082\n",
      " loss = 0.004684486984684489\n",
      " loss = 0.004673560714761648\n",
      " loss = 0.004662665108655554\n",
      " loss = 0.005565077934041672\n",
      " loss = 0.006385770469217978\n",
      " loss = 0.003818974924263276\n",
      " loss = 0.004612256447122044\n",
      " loss = 0.003770780470591065\n",
      " loss = 0.004594227679539367\n",
      " loss = 0.005442555163416858\n",
      " loss = 0.00539096656043861\n",
      " loss = 0.004556772341884109\n",
      " loss = 0.005327977806401627\n",
      " loss = 0.003788908290456136\n",
      " loss = 0.005303336196009325\n",
      " loss = 0.004513118257710726\n",
      " loss = 0.004502750340611411\n",
      " loss = 0.004492406265798635\n",
      " loss = 0.005218938372987545\n",
      " loss = 0.005171711740044577\n",
      " loss = 0.0044595958384511135\n",
      " loss = 0.004449305967540227\n",
      " loss = 0.004439041269675216\n",
      " loss = 0.004428801635372667\n",
      " loss = 0.005083211697813947\n",
      " loss = 0.004408260692116358\n",
      " loss = 0.00439804983772856\n",
      " loss = 0.005018477845748666\n",
      " loss = 0.005571850882932493\n",
      " loss = 0.004370406448505648\n",
      " loss = 0.004891590867929024\n",
      " loss = 0.003852547556660425\n",
      " loss = 0.003803598827144398\n",
      " loss = 0.005470377609737113\n",
      " loss = 0.004320778091945498\n",
      " loss = 0.004310490134586103\n",
      " loss = 0.004300238005631034\n",
      " loss = 0.003778552555809544\n",
      " loss = 0.0037311385854041606\n",
      " loss = 0.0036854537628541574\n",
      " loss = 0.0030261099930318316\n",
      " loss = 0.004247930705597741\n",
      " loss = 0.004917834436855932\n",
      " loss = 0.002935225719827774\n",
      " loss = 0.004930294608398729\n",
      " loss = 0.005561750623282373\n",
      " loss = 0.004197955283393323\n",
      " loss = 0.004188247995150292\n",
      " loss = 0.004178565161684472\n",
      " loss = 0.003558097052331139\n",
      " loss = 0.003516889019930363\n",
      " loss = 0.005498802295399599\n",
      " loss = 0.004749238707954395\n",
      " loss = 0.0041305653143447925\n",
      " loss = 0.0029657256660788564\n",
      " loss = 0.0034702379528449004\n",
      " loss = 0.0041033741722096406\n",
      " loss = 0.004093947204544295\n",
      " loss = 0.0027457315018669967\n",
      " loss = 0.0033489132503017986\n",
      " loss = 0.003314057232508248\n",
      " loss = 0.004851780811197035\n",
      " loss = 0.004053429539256758\n",
      " loss = 0.004792952678145824\n",
      " loss = 0.004032089085699163\n",
      " loss = 0.004022809640486513\n",
      " loss = 0.004724516253782923\n",
      " loss = 0.004002276015481536\n",
      " loss = 0.0039930810683485255\n",
      " loss = 0.003983907285620957\n",
      " loss = 0.004647902042574147\n",
      " loss = 0.003964155294010418\n",
      " loss = 0.003955046054623144\n",
      " loss = 0.003945957845309291\n",
      " loss = 0.003936890614225223\n",
      " loss = 0.0032913055864169636\n",
      " loss = 0.00392026128421972\n",
      " loss = 0.003911254592103617\n",
      " loss = 0.003240477004491996\n",
      " loss = 0.004584875575701149\n",
      " loss = 0.005200293921636252\n",
      " loss = 0.003275744538273186\n",
      " loss = 0.004491260132782856\n",
      " loss = 0.0038551825333661797\n",
      " loss = 0.004441301784325596\n",
      " loss = 0.003272173327582159\n",
      " loss = 0.0032343584898624042\n",
      " loss = 0.0038207014853365332\n",
      " loss = 0.0038119232580626217\n",
      " loss = 0.0031828117078886347\n",
      " loss = 0.0037958954789366187\n",
      " loss = 0.0037871734875414382\n",
      " loss = 0.003778471611910414\n",
      " loss = 0.004412636358285995\n",
      " loss = 0.0031471101361295814\n",
      " loss = 0.0037524577708976346\n",
      " loss = 0.0037438357901641603\n",
      " loss = 0.004371762496881598\n",
      " loss = 0.003725201643077489\n",
      " loss = 0.0031113063651061635\n",
      " loss = 0.0024446830975819065\n",
      " loss = 0.0030185232997900677\n",
      " loss = 0.005123309236246722\n",
      " loss = 0.00303233307255723\n",
      " loss = 0.0036796080477383203\n",
      " loss = 0.0029946967670922454\n",
      " loss = 0.002964105733686618\n",
      " loss = 0.0036601865232823664\n",
      " loss = 0.0029295582369767304\n",
      " loss = 0.004392483195920014\n",
      " loss = 0.0029197384088321945\n",
      " loss = 0.0028912473910621375\n",
      " loss = 0.004386577211668926\n",
      " loss = 0.0036126152167373043\n",
      " loss = 0.003604149596986546\n",
      " loss = 0.004318817032328886\n",
      " loss = 0.00358392560155999\n",
      " loss = 0.004265323384168311\n",
      " loss = 0.004224450301497264\n",
      " loss = 0.002292580472652748\n",
      " loss = 0.003550744959636222\n",
      " loss = 0.0035425049402529173\n",
      " loss = 0.0035342866591621604\n",
      " loss = 0.0041992243560340205\n",
      " loss = 0.004159143255522094\n",
      " loss = 0.0035049796137146053\n",
      " loss = 0.004110079271155956\n",
      " loss = 0.0029023703541137796\n",
      " loss = 0.004090689132077625\n",
      " loss = 0.002889502185585798\n",
      " loss = 0.003464817243949774\n",
      " loss = 0.004666302137554238\n",
      " loss = 0.004547208460402495\n",
      " loss = 0.002940304794476735\n",
      " loss = 0.0034294958525203424\n",
      " loss = 0.003421594888596078\n",
      " loss = 0.004458778413505872\n",
      " loss = 0.0038753687072291265\n",
      " loss = 0.003398493537117941\n",
      " loss = 0.0038351377070481116\n",
      " loss = 0.004221873762205624\n",
      " loss = 0.003746625562940407\n",
      " loss = 0.003373394034865908\n",
      " loss = 0.0033651666996039227\n",
      " loss = 0.0037053473527972614\n",
      " loss = 0.0033515091650317677\n",
      " loss = 0.003997919160188596\n",
      " loss = 0.003341563239911122\n",
      " loss = 0.0033331073378958164\n",
      " loss = 0.0030400838329111145\n",
      " loss = 0.0033130335450879864\n",
      " loss = 0.0033048527391349907\n",
      " loss = 0.003617311861439463\n",
      " loss = 0.0029942882582696877\n",
      " loss = 0.0036071732524975975\n",
      " loss = 0.0029718070734171013\n",
      " loss = 0.003596878370690281\n",
      " loss = 0.0026404694578926638\n",
      " loss = 0.0032460962072745746\n",
      " loss = 0.002872550928527676\n",
      " loss = 0.003228920480400235\n",
      " loss = 0.002826856263429942\n",
      " loss = 0.003212583170295771\n",
      " loss = 0.004048489766554549\n",
      " loss = 0.0035725553499692474\n",
      " loss = 0.0028449829970919843\n",
      " loss = 0.0035610067002736934\n",
      " loss = 0.003178819012090494\n",
      " loss = 0.0035261226359329465\n",
      " loss = 0.0038295005764688223\n",
      " loss = 0.002594959183239878\n",
      " loss = 0.003150096802050901\n",
      " loss = 0.0031424846178940685\n",
      " loss = 0.003476709462151255\n",
      " loss = 0.003129570534512253\n",
      " loss = 0.002800309769082368\n",
      " loss = 0.0027635885839789867\n",
      " loss = 0.00385295167281993\n",
      " loss = 0.003426946199315126\n",
      " loss = 0.002483268179329675\n",
      " loss = 0.003796014493648049\n",
      " loss = 0.003699132356306033\n",
      " loss = 0.0028133247205780914\n",
      " loss = 0.0027747558599027244\n",
      " loss = 0.0033748783563463756\n",
      " loss = 0.002754472553085058\n",
      " loss = 0.0030413517193753925\n",
      " loss = 0.0023826089927226463\n",
      " loss = 0.003023394361859515\n",
      " loss = 0.002639674835632758\n",
      " loss = 0.0030082688574825153\n",
      " loss = 0.0025993974698832506\n",
      " loss = 0.0025681245407272995\n",
      " loss = 0.0034359029509010495\n",
      " loss = 0.0029799693600989488\n",
      " loss = 0.0025471978575735505\n",
      " loss = 0.0038640363524089067\n",
      " loss = 0.002959544783096511\n",
      " loss = 0.0029526523027125938\n",
      " loss = 0.0029457788187887066\n",
      " loss = 0.002938924181292545\n",
      " loss = 0.0037415851119698995\n",
      " loss = 0.0022074454428834245\n",
      " loss = 0.0029183147956825238\n",
      " loss = 0.00291153626571369\n",
      " loss = 0.003718867299676634\n",
      " loss = 0.0028993000162730147\n",
      " loss = 0.002529072637246616\n",
      " loss = 0.003271789199161934\n",
      " loss = 0.003609127656704311\n",
      " loss = 0.0031958703922949907\n",
      " loss = 0.0028697272818653374\n",
      " loss = 0.002560363545802072\n",
      " loss = 0.0028540082207343864\n",
      " loss = 0.002847190314001157\n",
      " loss = 0.0028403968775037036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.0028336275587887774\n",
      " loss = 0.002160747207364918\n",
      " loss = 0.00206092104390624\n",
      " loss = 0.002388479768867608\n",
      " loss = 0.003249288716454992\n",
      " loss = 0.002376320862382343\n",
      " loss = 0.0027923016949242376\n",
      " loss = 0.0032283457004254248\n",
      " loss = 0.0031994648429662467\n",
      " loss = 0.0027724354729267327\n",
      " loss = 0.0031649416269365007\n",
      " loss = 0.002382197239298761\n",
      " loss = 0.0031525926927999477\n",
      " loss = 0.002746998976063771\n",
      " loss = 0.0034977469194883717\n",
      " loss = 0.0027356293565852633\n",
      " loss = 0.0030666991809135897\n",
      " loss = 0.003358511866933274\n",
      " loss = 0.002720951947135904\n",
      " loss = 0.002714312256069275\n",
      " loss = 0.002707700911384621\n",
      " loss = 0.002701117407600118\n",
      " loss = 0.0026945612552049117\n",
      " loss = 0.002688031980124281\n",
      " loss = 0.0026815291232029316\n",
      " loss = 0.002675052239705604\n",
      " loss = 0.0029603010838631432\n",
      " loss = 0.002936477966580542\n",
      " loss = 0.0026597696556461686\n",
      " loss = 0.002141497577313575\n",
      " loss = 0.0026427855577095746\n",
      " loss = 0.002636462844895652\n",
      " loss = 0.002327055153701827\n",
      " loss = 0.0022975303896800993\n",
      " loss = 0.002615663722083884\n",
      " loss = 0.0026095511798833342\n",
      " loss = 0.0026034561786925656\n",
      " loss = 0.0022490548353834277\n",
      " loss = 0.0018530459814394375\n",
      " loss = 0.002176421577249418\n",
      " loss = 0.003008340591579695\n",
      " loss = 0.0021659921044174324\n",
      " loss = 0.0017152836259363882\n",
      " loss = 0.002565052486352357\n",
      " loss = 0.0030219902059349033\n",
      " loss = 0.001667883031964561\n",
      " loss = 0.0020699711697437094\n",
      " loss = 0.0025453271814200864\n",
      " loss = 0.0020454704493530294\n",
      " loss = 0.0020253468616037527\n",
      " loss = 0.002532661908086752\n",
      " loss = 0.0020028238299173886\n",
      " loss = 0.0025236882036080623\n",
      " loss = 0.001444699019999177\n",
      " loss = 0.002518425267957429\n",
      " loss = 0.002512304820003938\n",
      " loss = 0.0019433103567248107\n",
      " loss = 0.0025038448056667758\n",
      " loss = 0.0030713260888666247\n",
      " loss = 0.001936252838624372\n",
      " loss = 0.0019191635987553537\n",
      " loss = 0.00190266435488834\n",
      " loss = 0.0024812595882783587\n",
      " loss = 0.002475061666422412\n",
      " loss = 0.002468894736208849\n",
      " loss = 0.003044773189766491\n",
      " loss = 0.0024527940485935284\n",
      " loss = 0.003003374371194893\n",
      " loss = 0.0029725982636479202\n",
      " loss = 0.001914342196870107\n",
      " loss = 0.0029547561338662365\n",
      " loss = 0.002416924476133825\n",
      " loss = 0.003421717320099085\n",
      " loss = 0.002867471716409203\n",
      " loss = 0.0019461096295501899\n",
      " loss = 0.0014634117682697531\n",
      " loss = 0.0023885991368496054\n",
      " loss = 0.0013955647781557538\n",
      " loss = 0.001857151055468009\n",
      " loss = 0.0034611390964168036\n",
      " loss = 0.0023686841707261782\n",
      " loss = 0.001863857997829542\n",
      " loss = 0.003387833857125301\n",
      " loss = 0.0018731445911064893\n",
      " loss = 0.001855280113922906\n",
      " loss = 0.00284906346673502\n",
      " loss = 0.0018497886924506114\n",
      " loss = 0.00283230048093291\n",
      " loss = 0.002803999680219463\n",
      " loss = 0.0018560728365165347\n",
      " loss = 0.002313188817341493\n",
      " loss = 0.002780327342689\n",
      " loss = 0.001846965908530001\n",
      " loss = 0.0027648807352417867\n",
      " loss = 0.0022892708757797356\n",
      " loss = 0.002283940624629977\n",
      " loss = 0.0022786250234871305\n",
      " loss = 0.002273323957789581\n",
      " loss = 0.00314865563475692\n",
      " loss = 0.0026638303210649006\n",
      " loss = 0.0022529382656483517\n",
      " loss = 0.0018627590513757724\n",
      " loss = 0.002243789872321814\n",
      " loss = 0.002638211891576214\n",
      " loss = 0.0026136459951154535\n",
      " loss = 0.002226264774084282\n",
      " loss = 0.0025838472894859675\n",
      " loss = 0.0022154673552995047\n",
      " loss = 0.0018657340996386701\n",
      " loss = 0.002205853555996326\n",
      " loss = 0.0022007858510260615\n",
      " loss = 0.002555364233555239\n",
      " loss = 0.0015057401889634757\n",
      " loss = 0.0018113335253431293\n",
      " loss = 0.002573287591137792\n",
      " loss = 0.001803562961052162\n",
      " loss = 0.001784288138341477\n",
      " loss = 0.0025723560645799287\n",
      " loss = 0.0013916304489521587\n",
      " loss = 0.0021607010318925057\n",
      " loss = 0.002570509466094375\n",
      " loss = 0.0021489947325455316\n",
      " loss = 0.0025394087674311034\n",
      " loss = 0.0021377148233093276\n",
      " loss = 0.0017562423780326394\n",
      " loss = 0.00252063624100621\n",
      " loss = 0.002122971243691908\n",
      " loss = 0.00174532784083758\n",
      " loss = 0.0017269719261719726\n",
      " loss = 0.002513156572755736\n",
      " loss = 0.0021047469544638823\n",
      " loss = 0.0024829187966310387\n",
      " loss = 0.002459617134159763\n",
      " loss = 0.002087996296708479\n",
      " loss = 0.0020831999070271426\n",
      " loss = 0.0020784145360604914\n",
      " loss = 0.0020736401584682137\n",
      " loss = 0.0020688767489692155\n",
      " loss = 0.001719315191970694\n",
      " loss = 0.0017006740442928419\n",
      " loss = 0.0016826991982615922\n",
      " loss = 0.0012771901531141274\n",
      " loss = 0.002052518632926981\n",
      " loss = 0.002047703162721705\n",
      " loss = 0.0024557968468336454\n",
      " loss = 0.0016404967447812978\n",
      " loss = 0.002442346432351693\n",
      " loss = 0.002026680957531859\n",
      " loss = 0.0016318540790067196\n",
      " loss = 0.002019129365764373\n",
      " loss = 0.0024158456280342576\n",
      " loss = 0.0016233642319715112\n",
      " loss = 0.0020050139773529737\n",
      " loss = 0.0020003344707001415\n",
      " loss = 0.0019956681940750333\n",
      " loss = 0.0015989194342325844\n",
      " loss = 0.001988339869165543\n",
      " loss = 0.0015807629369215584\n",
      " loss = 0.0019811948811274023\n",
      " loss = 0.0023896833039952193\n",
      " loss = 0.0015733644419733104\n",
      " loss = 0.001558275504964398\n",
      " loss = 0.0015437153884353002\n",
      " loss = 0.0015296632413095536\n",
      " loss = 0.001516099038482533\n",
      " loss = 0.0019589899658096826\n",
      " loss = 0.0028599462792601536\n",
      " loss = 0.0015222292386573894\n",
      " loss = 0.0015085167685846444\n",
      " loss = 0.0014952795319856064\n",
      " loss = 0.0019381809823367255\n",
      " loss = 0.0023859227554468036\n",
      " loss = 0.0019256667476263405\n",
      " loss = 0.0019209892400023731\n",
      " loss = 0.00191633102040897\n",
      " loss = 0.0019116917572247524\n",
      " loss = 0.0023315399700814805\n",
      " loss = 0.0018999506930674754\n",
      " loss = 0.0014898880339495007\n",
      " loss = 0.001893357826901797\n",
      " loss = 0.002717781826622425\n",
      " loss = 0.001879727638434295\n",
      " loss = 0.0014929758228318483\n",
      " loss = 0.0014788048933585983\n",
      " loss = 0.001870854344871394\n",
      " loss = 0.0018663823873449129\n",
      " loss = 0.001861926567348065\n",
      " loss = 0.0010603671996445023\n",
      " loss = 0.0018581211978111502\n",
      " loss = 0.0018535932127068436\n",
      " loss = 0.002266948123189537\n",
      " loss = 0.001440296341434373\n",
      " loss = 0.0022528904061978987\n",
      " loss = 0.001039706089059773\n",
      " loss = 0.0009916718397770712\n",
      " loss = 0.001835419973373155\n",
      " loss = 0.002272367694688477\n",
      " loss = 0.002248469067531616\n",
      " loss = 0.002225173285406941\n",
      " loss = 0.0018090504386823582\n",
      " loss = 0.002195774873816031\n",
      " loss = 0.0017982165546572993\n",
      " loss = 0.0010470618364223818\n",
      " loss = 0.0013964504253676422\n",
      " loss = 0.0026091054464253386\n",
      " loss = 0.0017832312590351754\n",
      " loss = 0.0021564579527719218\n",
      " loss = 0.002134999620103656\n",
      " loss = 0.0017668263546371317\n",
      " loss = 0.0017627102209823655\n",
      " loss = 0.0014146087715457242\n",
      " loss = 0.0021116634796139555\n",
      " loss = 0.001750404378916908\n",
      " loss = 0.0024244993983036987\n",
      " loss = 0.0017396542634519267\n",
      " loss = 0.002046071595267758\n",
      " loss = 0.00143442719873522\n",
      " loss = 0.0017276561261829596\n",
      " loss = 0.0020312049421347044\n",
      " loss = 0.0017187948879126033\n",
      " loss = 0.0014221356873591736\n",
      " loss = 0.0014069046492756884\n",
      " loss = 0.0017089747310128915\n",
      " loss = 0.002020548745951196\n",
      " loss = 0.0016999818326977447\n",
      " loss = 0.0019965895138370758\n",
      " loss = 0.0016913031297980461\n",
      " loss = 0.0014014132909096178\n",
      " loss = 0.0016843833451166013\n",
      " loss = 0.0019775854706617167\n",
      " loss = 0.0011089234104549657\n",
      " loss = 0.0016738139659429841\n",
      " loss = 0.0016699506195980362\n",
      " loss = 0.0016660967668038157\n",
      " loss = 0.001662252364935049\n",
      " loss = 0.001354976229953903\n",
      " loss = 0.0019705627877594106\n",
      " loss = 0.0016507556506338936\n",
      " loss = 0.0019468727848133778\n",
      " loss = 0.0016421678797011318\n",
      " loss = 0.0013528108984725688\n",
      " loss = 0.002229749040261779\n",
      " loss = 0.0013587199287284507\n",
      " loss = 0.001910191362160243\n",
      " loss = 0.0016225990955191037\n",
      " loss = 0.0016188718007360955\n",
      " loss = 0.001346419805873601\n",
      " loss = 0.0013317891592356764\n",
      " loss = 0.0019010889220461432\n",
      " loss = 0.0013261902931710513\n",
      " loss = 0.0013121260960485838\n",
      " loss = 0.0015994019561023387\n",
      " loss = 0.0012960986345944565\n",
      " loss = 0.001903623708489463\n",
      " loss = 0.0009942917319664894\n",
      " loss = 0.0012678824132397043\n",
      " loss = 0.001255726380151532\n",
      " loss = 0.002262555781283124\n",
      " loss = 0.002204810680385054\n",
      " loss = 0.0015698782047540727\n",
      " loss = 0.0012780295579334197\n",
      " loss = 0.0018626878674204948\n",
      " loss = 0.0018449013875130665\n",
      " loss = 0.0012813477166085767\n",
      " loss = 0.0012678576488957486\n",
      " loss = 0.0012548476163625015\n",
      " loss = 0.0015471409990389007\n",
      " loss = 0.0021503269871827944\n",
      " loss = 0.0018164686717852198\n",
      " loss = 0.0017994539892050604\n",
      " loss = 0.0012748139912782998\n",
      " loss = 0.0012609508622353548\n",
      " loss = 0.0015233638459225542\n",
      " loss = 0.0015198530434005863\n",
      " loss = 0.0017901734700695475\n",
      " loss = 0.0012505511198746795\n",
      " loss = 0.0012372587090489378\n",
      " loss = 0.0020719093800207387\n",
      " loss = 0.0012428043630836935\n",
      " loss = 0.0014989203768985533\n",
      " loss = 0.0012270459895190864\n",
      " loss = 0.0014930361098184383\n",
      " loss = 0.001211962624545499\n",
      " loss = 0.001487332558077833\n",
      " loss = 0.0014838772386902871\n",
      " loss = 0.0009102613781174817\n",
      " loss = 0.0014798724116938916\n",
      " loss = 0.0011721947288989179\n",
      " loss = 0.0014746065784348493\n",
      " loss = 0.0011594532947974408\n",
      " loss = 0.001469456476176731\n",
      " loss = 0.0017846646114561752\n",
      " loss = 0.001766725237215691\n",
      " loss = 0.001749233806389059\n",
      " loss = 0.0011694154641297707\n",
      " loss = 0.0017396724020213722\n",
      " loss = 0.0014440410947787457\n",
      " loss = 0.0017181429653506436\n",
      " loss = 0.0011707368088863408\n",
      " loss = 0.0014340053394466235\n",
      " loss = 0.0019786674481897725\n",
      " loss = 0.0019281677644318546\n",
      " loss = 0.001191782278961236\n",
      " loss = 0.0014180757055866585\n",
      " loss = 0.0018925450619095604\n",
      " loss = 0.0014107300748346326\n",
      " loss = 0.0014074813297862434\n",
      " loss = 0.0018368979913973929\n",
      " loss = 0.0014009190348518944\n",
      " loss = 0.0012029509185100566\n",
      " loss = 0.0011887099389002757\n",
      " loss = 0.0011749843785037342\n",
      " loss = 0.0011617538877083564\n",
      " loss = 0.0009122053650621062\n",
      " loss = 0.0011271492530013736\n",
      " loss = 0.001648562518886087\n",
      " loss = 0.0011228940368246385\n",
      " loss = 0.0013757179161573002\n",
      " loss = 0.0011094258685708253\n",
      " loss = 0.0016427398663000944\n",
      " loss = 0.0018874949290672086\n",
      " loss = 0.001361094538196793\n",
      " loss = 0.0011195965494181406\n",
      " loss = 0.0011078029518629927\n",
      " loss = 0.001096429057169026\n",
      " loss = 0.0016176772590236522\n",
      " loss = 0.0010924547292563036\n",
      " loss = 0.0016090637943623766\n",
      " loss = 0.001593547502865201\n",
      " loss = 0.0013369521329647093\n",
      " loss = 0.0013338715277500456\n",
      " loss = 0.0008512680361663399\n",
      " loss = 0.0013297348663199914\n",
      " loss = 0.001326642215988494\n",
      " loss = 0.0013235579511060116\n",
      " loss = 0.0015758589176550707\n",
      " loss = 0.0010719757858168937\n",
      " loss = 0.001567626911686067\n",
      " loss = 0.0013102684169038598\n",
      " loss = 0.0013072426305833036\n",
      " loss = 0.000823275625873634\n",
      " loss = 0.001303370689709479\n",
      " loss = 0.0013003276378466002\n",
      " loss = 0.0012972932261920303\n",
      " loss = 0.0012942673794087466\n",
      " loss = 0.0007830180245251708\n",
      " loss = 0.0012909449484322158\n",
      " loss = 0.0012878871847912176\n",
      " loss = 0.0015538565724633289\n",
      " loss = 0.0015384782284954203\n",
      " loss = 0.0010289190104385774\n",
      " loss = 0.0015300772383561303\n",
      " loss = 0.0015151910509818782\n",
      " loss = 0.001266308010917911\n",
      " loss = 0.0010299276602097342\n",
      " loss = 0.0012614405226834895\n",
      " loss = 0.0014994662552770164\n",
      " loss = 0.0012546328102377895\n",
      " loss = 0.0014813722169490266\n",
      " loss = 0.0008093339410632776\n",
      " loss = 0.001484354974390424\n",
      " loss = 0.0014701996000236906\n",
      " loss = 0.0012394408550923772\n",
      " loss = 0.0010203035755848666\n",
      " loss = 0.0010095325961854557\n",
      " loss = 0.0012325323464763536\n",
      " loss = 0.0014620843247142184\n",
      " loss = 0.0007814729242251184\n",
      " loss = 0.0012250125043758212\n",
      " loss = 0.0012221606593472232\n",
      " loss = 0.0014569168302902575\n",
      " loss = 0.0012154743559892789\n",
      " loss = 0.0009861546989733709\n",
      " loss = 0.0009761726598883026\n",
      " loss = 0.0012091522867783353\n",
      " loss = 0.0012063236761575983\n",
      " loss = 0.0014437078482394698\n",
      " loss = 0.0014296899048434823\n",
      " loss = 0.0016361493457397096\n",
      " loss = 0.0009904554149998092\n",
      " loss = 0.0011896125094130218\n",
      " loss = 0.0007685537445691953\n",
      " loss = 0.0011857655212220203\n",
      " loss = 0.0014083989549311476\n",
      " loss = 0.0011793901693816346\n",
      " loss = 0.0009618922428344505\n",
      " loss = 0.0009520057215967851\n",
      " loss = 0.001634368274903671\n",
      " loss = 0.0009564330933725441\n",
      " loss = 0.0013867265282880789\n",
      " loss = 0.0011631131222306704\n",
      " loss = 0.0011604326984781782\n",
      " loss = 0.0013667049927858761\n",
      " loss = 0.0013539281934636274\n",
      " loss = 0.0011512826574487482\n",
      " loss = 0.0009588687651147863\n",
      " loss = 0.0011464855429267383\n",
      " loss = 0.000946341981582054\n",
      " loss = 0.0013474392832149148\n",
      " loss = 0.0011385869085451094\n",
      " loss = 0.001135970054639949\n",
      " loss = 0.0015236729739785528\n",
      " loss = 0.001307366316259636\n",
      " loss = 0.0009586451256669926\n",
      " loss = 0.001301837930532883\n",
      " loss = 0.0011219787311863181\n",
      " loss = 0.0009512382235811531\n",
      " loss = 0.0011169845179910469\n",
      " loss = 0.0011144159400614006\n",
      " loss = 0.0011118533545259807\n",
      " loss = 0.000933440570853527\n",
      " loss = 0.0011070838879542876\n",
      " loss = 0.0011045407883531842\n",
      " loss = 0.0011020035306247222\n",
      " loss = 0.0010994721013465947\n",
      " loss = 0.0012793297275203932\n",
      " loss = 0.001094082202127828\n",
      " loss = 0.0010915666348691897\n",
      " loss = 0.0010890569247320283\n",
      " loss = 0.001086553055619236\n",
      " loss = 0.0010840550115595482\n",
      " loss = 0.0009092739482466932\n",
      " loss = 0.0007189006585606582\n",
      " loss = 0.0010780611750467305\n",
      " loss = 0.001075575534884448\n",
      " loss = 0.0012678607396222823\n",
      " loss = 0.0010699932128492519\n",
      " loss = 0.001067533284969767\n",
      " loss = 0.0014348631977471385\n",
      " loss = 0.0010618181758603414\n",
      " loss = 0.0010593766283093946\n",
      " loss = 0.0008892321862093704\n",
      " loss = 0.0010548351478857718\n",
      " loss = 0.0010524120716006561\n",
      " loss = 0.0008752828199731335\n",
      " loss = 0.0008657720367369132\n",
      " loss = 0.0010462453605556191\n",
      " loss = 0.001043833893353322\n",
      " loss = 0.00104142823874889\n",
      " loss = 0.0012266517277075924\n",
      " loss = 0.0006777630686478973\n",
      " loss = 0.0008407018816374738\n",
      " loss = 0.0008322200610194036\n",
      " loss = 0.0012399337372852935\n",
      " loss = 0.0012278491308905619\n",
      " loss = 0.0012160640868893549\n",
      " loss = 0.0010223254931107167\n",
      " loss = 0.0012016081434443153\n",
      " loss = 0.0006704084090049834\n",
      " loss = 0.0010159309743967215\n",
      " loss = 0.001013584435123326\n",
      " loss = 0.0013848174972809987\n",
      " loss = 0.001007734633797543\n",
      " loss = 0.001175848022190125\n",
      " loss = 0.000840374849619937\n",
      " loss = 0.0011704868960380193\n",
      " loss = 0.0009981247118583173\n",
      " loss = 0.0006731139871808643\n",
      " loss = 0.000994401308138452\n",
      " loss = 0.0008164929607456384\n",
      " loss = 0.0011729800229416342\n",
      " loss = 0.001336319023414454\n",
      " loss = 0.0011433120366325343\n",
      " loss = 0.0011330291778579435\n",
      " loss = 0.0009795723404961382\n",
      " loss = 0.0008339033923611479\n",
      " loss = 0.0012769244708432693\n",
      " loss = 0.0009728131909833581\n",
      " loss = 0.001242279826840405\n",
      " loss = 0.0009687292912529024\n",
      " loss = 0.0008451641710985248\n",
      " loss = 0.0009638974225844835\n",
      " loss = 0.0009616481403915322\n",
      " loss = 0.0009594052055079033\n",
      " loss = 0.0010868870111398654\n",
      " loss = 0.001077627162214702\n",
      " loss = 0.001068588917583956\n",
      " loss = 0.0009514850392588212\n",
      " loss = 0.0009492094833049734\n",
      " loss = 0.0009469421775105632\n",
      " loss = 0.0008348201112081118\n",
      " loss = 0.0008242590050768445\n",
      " loss = 0.0008140834485182769\n",
      " loss = 0.000937191058938867\n",
      " loss = 0.0009350184538506115\n",
      " loss = 0.0009328515043942932\n",
      " loss = 0.0009306901752169383\n",
      " loss = 0.000928534431798813\n",
      " loss = 0.0009263842404262043\n",
      " loss = 0.0010574129235013567\n",
      " loss = 0.0006700504062214816\n",
      " loss = 0.0009199962011977901\n",
      " loss = 0.0011985355448744953\n",
      " loss = 0.0010418448410903936\n",
      " loss = 0.0007946587834545822\n",
      " loss = 0.0010379485831127828\n",
      " loss = 0.0010290446297424058\n",
      " loss = 0.0009076704191186612\n",
      " loss = 0.0007924976861470188\n",
      " loss = 0.0009031288954549762\n",
      " loss = 0.0009010200974498355\n",
      " loss = 0.0008989172940475376\n",
      " loss = 0.0010178019952153386\n",
      " loss = 0.0008949503254903105\n",
      " loss = 0.0010073274428244305\n",
      " loss = 0.0008910786140985019\n",
      " loss = 0.0009971616191928876\n",
      " loss = 0.0007856727429294112\n",
      " loss = 0.0007756848257663047\n",
      " loss = 0.000766061755140804\n",
      " loss = 0.0007567891209347029\n",
      " loss = 0.0007478530838923562\n",
      " loss = 0.0006022990728318533\n",
      " loss = 0.0008747426502671926\n",
      " loss = 0.0007230133490229985\n",
      " loss = 0.0008711946421291152\n",
      " loss = 0.0007138158700996725\n",
      " loss = 0.0007063806251304038\n",
      " loss = 0.00103368413068469\n",
      " loss = 0.0010237763944094661\n",
      " loss = 0.0005553396138733697\n",
      " loss = 0.0006950531976569175\n",
      " loss = 0.0010302504999704742\n",
      " loss = 0.000856422968397694\n",
      " loss = 0.0008544367421725127\n",
      " loss = 0.0006900373906540855\n",
      " loss = 0.0010193007701197467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.0010094450840343616\n",
      " loss = 0.0008459106574438373\n",
      " loss = 0.0008439602960343803\n",
      " loss = 0.0008420146572624995\n",
      " loss = 0.0006878164401731474\n",
      " loss = 0.0009967502218787788\n",
      " loss = 0.0008361961455852676\n",
      " loss = 0.0006837163735343978\n",
      " loss = 0.0006766372428109685\n",
      " loss = 0.0006698093639536196\n",
      " loss = 0.000663222825049829\n",
      " loss = 0.0006568681068344079\n",
      " loss = 0.0010062719438654407\n",
      " loss = 0.0006548981548319217\n",
      " loss = 0.0008245686024631518\n",
      " loss = 0.0006478032863685482\n",
      " loss = 0.0010015271577333798\n",
      " loss = 0.0006459555551303798\n",
      " loss = 0.00046222349238659606\n",
      " loss = 0.0010067438085104203\n",
      " loss = 0.0006334684296916378\n",
      " loss = 0.0006278988057040644\n",
      " loss = 0.0010042856548360991\n",
      " loss = 0.0006264349180569836\n",
      " loss = 0.0008094025099716206\n",
      " loss = 0.00118161002490333\n",
      " loss = 0.0008031292220923799\n",
      " loss = 0.0006280864381122438\n",
      " loss = 0.0006224096960701571\n",
      " loss = 0.000799580386762069\n",
      " loss = 0.0006161808387982101\n",
      " loss = 0.0007969074656726113\n",
      " loss = 0.0007949435463981169\n",
      " loss = 0.0004259669364401282\n",
      " loss = 0.000599981291493923\n",
      " loss = 0.0007931194664429302\n",
      " loss = 0.0009875258513131321\n",
      " loss = 0.0009770000038638676\n",
      " loss = 0.0007844016982049933\n",
      " loss = 0.0011446780973017217\n",
      " loss = 0.0009468978807562581\n",
      " loss = 0.0007755284114119567\n",
      " loss = 0.0009346744768512002\n",
      " loss = 0.0009254476895607284\n",
      " loss = 0.0009164503210753068\n",
      " loss = 0.0007661511857132682\n",
      " loss = 0.0007643821599252402\n",
      " loss = 0.0007626175034826336\n",
      " loss = 0.000760857196067949\n",
      " loss = 0.0008984747249877173\n",
      " loss = 0.0007568759868089494\n",
      " loss = 0.0007551349765983732\n",
      " loss = 0.0007533980457377172\n",
      " loss = 0.0008835655098517524\n",
      " loss = 0.0008753880111550382\n",
      " loss = 0.0009872231288547064\n",
      " loss = 0.0007456666761119959\n",
      " loss = 0.0007439419171342359\n",
      " loss = 0.0009585878420753593\n",
      " loss = 0.0008374011310581399\n",
      " loss = 0.0009214987454581083\n",
      " loss = 0.0007382068908761705\n",
      " loss = 0.000736426125665399\n",
      " loss = 0.0008155170091788238\n",
      " loss = 0.0008844939291873227\n",
      " loss = 0.0006683927005967953\n",
      " loss = 0.0006592819348300469\n",
      " loss = 0.0006505067680124821\n",
      " loss = 0.0008932625045192779\n",
      " loss = 0.0007250181729019001\n",
      " loss = 0.0007232455050796582\n",
      " loss = 0.0007953698234006356\n",
      " loss = 0.0005828244478336333\n",
      " loss = 0.0007982434380463834\n",
      " loss = 0.000716205215247426\n",
      " loss = 0.0007905533890205346\n",
      " loss = 0.0007132799533128986\n",
      " loss = 0.0006399902552320916\n",
      " loss = 0.0007092776696590227\n",
      " loss = 0.0006293770675942991\n",
      " loss = 0.0005370942390362572\n",
      " loss = 0.0007988803229211274\n",
      " loss = 0.0007018701588235296\n",
      " loss = 0.0008810499898298631\n",
      " loss = 0.0007788630908213696\n",
      " loss = 0.0007725298775595156\n",
      " loss = 0.0006967577599443135\n",
      " loss = 0.0006950528688768327\n",
      " loss = 0.0006933554038056561\n",
      " loss = 0.0006204017067651088\n",
      " loss = 0.0006122664086808815\n",
      " loss = 0.0006044294138228622\n",
      " loss = 0.0005968789385019371\n",
      " loss = 0.0007781246640115601\n",
      " loss = 0.0006824064120369035\n",
      " loss = 0.0006808084511478168\n",
      " loss = 0.0006792151831920144\n",
      " loss = 0.0007672104071907924\n",
      " loss = 0.0005917638826957002\n",
      " loss = 0.00076444429557664\n",
      " loss = 0.0006730596901559428\n",
      " loss = 0.0005863412620867707\n",
      " loss = 0.0007603059401525245\n",
      " loss = 0.0006683225768184639\n",
      " loss = 0.0006667532729025746\n",
      " loss = 0.0005792661837968187\n",
      " loss = 0.0007547682708543799\n",
      " loss = 0.0005758355809115345\n",
      " loss = 0.0005688335877374418\n",
      " loss = 0.0008522991512924121\n",
      " loss = 0.000657430514762474\n",
      " loss = 0.0005691719163752891\n",
      " loss = 0.0006542526620345362\n",
      " loss = 0.0005607156312363938\n",
      " loss = 0.0005541108319818632\n",
      " loss = 0.0006498020457441164\n",
      " loss = 0.0008521465524270128\n",
      " loss = 0.0006467022646934618\n",
      " loss = 0.0006452032967652202\n",
      " loss = 0.0005517870364381344\n",
      " loss = 0.0006422330650220317\n",
      " loss = 0.000543906892017342\n",
      " loss = 0.0005376977881978711\n",
      " loss = 0.0005317122849503398\n",
      " loss = 0.0004149447211676258\n",
      " loss = 0.00039577434370727135\n",
      " loss = 0.000635982542665995\n",
      " loss = 0.0005059097576688888\n",
      " loss = 0.000766302339798883\n",
      " loss = 0.0005042993472192482\n",
      " loss = 0.0007619427144950867\n",
      " loss = 0.0005026731386097501\n",
      " loss = 0.0007576348238854349\n",
      " loss = 0.0007501721067720342\n",
      " loss = 0.0005042592916385212\n",
      " loss = 0.0006226843254740057\n",
      " loss = 0.000498382229610942\n",
      " loss = 0.0007472701885507425\n",
      " loss = 0.0008615609286558915\n",
      " loss = 0.0007277381025845495\n",
      " loss = 0.0006141223738886442\n",
      " loss = 0.0006127104736165992\n",
      " loss = 0.0005051366639691425\n",
      " loss = 0.0007207129192288512\n",
      " loss = 0.00039752895762259485\n",
      " loss = 0.000493510584652464\n",
      " loss = 0.0007253730896651105\n",
      " loss = 0.0007183918198378546\n",
      " loss = 0.0007115830811541114\n",
      " loss = 0.0006015006142086458\n",
      " loss = 0.0006001182624865568\n",
      " loss = 0.000598739107595005\n",
      " loss = 0.0008025180389751136\n",
      " loss = 0.0007820361195826723\n",
      " loss = 0.0005101331324594128\n",
      " loss = 0.00041552595180112736\n",
      " loss = 0.0004939722774078791\n",
      " loss = 0.0004885806896279704\n",
      " loss = 0.0004833820078795711\n",
      " loss = 0.0006986754969463401\n",
      " loss = 0.0003761576413609691\n",
      " loss = 0.0005862733281031961\n",
      " loss = 0.0005849106057786165\n",
      " loss = 0.000583551551402268\n",
      " loss = 0.0006944122252755595\n",
      " loss = 0.0005803860162743942\n",
      " loss = 0.000686003360842172\n",
      " loss = 0.00047513638261994953\n",
      " loss = 0.0005763730185632241\n",
      " loss = 0.00036342243560317204\n",
      " loss = 0.0006886718977717792\n",
      " loss = 0.0005728070563558368\n",
      " loss = 0.00046275475341628195\n",
      " loss = 0.0004581295697409622\n",
      " loss = 0.000569886586803466\n",
      " loss = 0.0004529333771030481\n",
      " loss = 0.00044862540818102036\n",
      " loss = 0.0006899088876448653\n",
      " loss = 0.00044730772191224134\n",
      " loss = 0.00044313891281698003\n",
      " loss = 0.0008134089983048353\n",
      " loss = 0.00044536836052969174\n",
      " loss = 0.0005604544553785026\n",
      " loss = 0.0005591230135772441\n",
      " loss = 0.0004398816736003279\n",
      " loss = 0.0005571674905559413\n",
      " loss = 0.0004352253855313937\n",
      " loss = 0.000431306513792344\n",
      " loss = 0.00042752344755934524\n",
      " loss = 0.00042387083464277993\n",
      " loss = 0.0006872181043249002\n",
      " loss = 0.00042296637025257766\n",
      " loss = 0.000682627992890356\n",
      " loss = 0.0006754803622508257\n",
      " loss = 0.000546606306855888\n",
      " loss = 0.00042414759644117227\n",
      " loss = 0.00042041038809219555\n",
      " loss = 0.0005442658885703869\n",
      " loss = 0.0005429224635370622\n",
      " loss = 0.0006673118447446064\n",
      " loss = 0.00041848013922974193\n",
      " loss = 0.0006630439817550191\n",
      " loss = 0.0005368292466750485\n",
      " loss = 0.0006541698985342429\n",
      " loss = 0.0004195519086690688\n",
      " loss = 0.0005329630272535877\n",
      " loss = 0.0004151610752800705\n",
      " loss = 0.000770511782399466\n",
      " loss = 0.000750846728841062\n",
      " loss = 0.0006288974922116963\n",
      " loss = 0.0005244482326272041\n",
      " loss = 0.0005232351421695837\n",
      " loss = 0.0006196207460369878\n",
      " loss = 0.0005204612120181411\n",
      " loss = 0.0005192626451367298\n",
      " loss = 0.0005180669326776638\n",
      " loss = 0.0005168740646813346\n",
      " loss = 0.00042365321795107355\n",
      " loss = 0.0005148365397584677\n",
      " loss = 0.0005136471209185224\n",
      " loss = 0.00051246066235695\n",
      " loss = 0.0005112771496042527\n",
      " loss = 0.00041597656968906294\n",
      " loss = 0.0004117313102699145\n",
      " loss = 0.000609528870103708\n",
      " loss = 0.0006036233267934064\n",
      " loss = 0.0005978639660501329\n",
      " loss = 0.0004155766928817671\n",
      " loss = 0.0005030563596589661\n",
      " loss = 0.0005934180030101615\n",
      " loss = 0.0004130241998425178\n",
      " loss = 0.0004995820487696534\n",
      " loss = 0.0005890205986240523\n",
      " loss = 0.0004104733185577899\n",
      " loss = 0.00040612768758001945\n",
      " loss = 0.0005887469378600369\n",
      " loss = 0.0004938424255083528\n",
      " loss = 0.0004037104871800345\n",
      " loss = 0.000491912581600815\n",
      " loss = 0.0004907746100028699\n",
      " loss = 0.0004896395212528096\n",
      " loss = 0.0004885072996885741\n",
      " loss = 0.0005782698684739893\n",
      " loss = 0.0005727984643694444\n",
      " loss = 0.0005674617102732014\n",
      " loss = 0.0005622557842707769\n",
      " loss = 0.000557176974127252\n",
      " loss = 0.0004808242039035267\n",
      " loss = 0.0006224547294676119\n",
      " loss = 0.0004786676922863708\n",
      " loss = 0.0005416024281624055\n",
      " loss = 0.00041611862342363784\n",
      " loss = 0.00047531641907118193\n",
      " loss = 0.0003454196072230521\n",
      " loss = 0.0004012663293545772\n",
      " loss = 0.0005474421010252077\n",
      " loss = 0.0006141816194094816\n",
      " loss = 0.0004698082479767412\n",
      " loss = 0.0005975556480299772\n",
      " loss = 0.0004106587164486376\n",
      " loss = 0.00046660910111394327\n",
      " loss = 0.0005266984356738231\n",
      " loss = 0.0004645713493593624\n",
      " loss = 0.0004634756573187152\n",
      " loss = 0.0005204125761287167\n",
      " loss = 0.0004068990651503133\n",
      " loss = 0.00046019988162846555\n",
      " loss = 0.0004591180557418893\n",
      " loss = 0.00045803954542572654\n",
      " loss = 0.0004569643151337841\n",
      " loss = 0.0005148921204749389\n",
      " loss = 0.0004549804917404602\n",
      " loss = 0.00045390476863762304\n",
      " loss = 0.0005087899178939062\n",
      " loss = 0.0005045652188958335\n",
      " loss = 0.000451150862033697\n",
      " loss = 0.0004500643592236388\n",
      " loss = 0.0003991110570624691\n",
      " loss = 0.0003939891924270159\n",
      " loss = 0.00044642916470840363\n",
      " loss = 0.000387871075405332\n",
      " loss = 0.0005053406619243987\n",
      " loss = 0.0005010168400567565\n",
      " loss = 0.00033361579608489467\n",
      " loss = 0.0005025879093373602\n",
      " loss = 0.0003820794624402764\n",
      " loss = 0.00043907253526946437\n",
      " loss = 0.0004997091052996183\n",
      " loss = 0.0004954042807066666\n",
      " loss = 0.0004912028015204707\n",
      " loss = 0.0005388556877130554\n",
      " loss = 0.00047996906700548364\n",
      " loss = 0.0004341271256469455\n",
      " loss = 0.0004330588607435396\n",
      " loss = 0.0003892162329446327\n",
      " loss = 0.00043061134837685884\n",
      " loss = 0.0004295724097739778\n",
      " loss = 0.0004285375317095982\n",
      " loss = 0.0004275066485593989\n",
      " loss = 0.0003788137401720152\n",
      " loss = 0.00047650242911668843\n",
      " loss = 0.0003763045599451798\n",
      " loss = 0.0003715059775871478\n",
      " loss = 0.0004220659500382847\n",
      " loss = 0.00031048837910288617\n",
      " loss = 0.0003580704193274994\n",
      " loss = 0.000549345437251347\n",
      " loss = 0.00041806066088782964\n",
      " loss = 0.00041709035981965026\n",
      " loss = 0.00029871023835642823\n",
      " loss = 0.00035005840088932005\n",
      " loss = 0.0004825978136240946\n",
      " loss = 0.0003483638147432996\n",
      " loss = 0.0004124608437587944\n",
      " loss = 0.000343659673101534\n",
      " loss = 0.00041073982081514743\n",
      " loss = 0.0004804275570221144\n",
      " loss = 0.0004760090963877128\n",
      " loss = 0.0004076245588465556\n",
      " loss = 0.0004066869613204026\n",
      " loss = 0.00040575155918805164\n",
      " loss = 0.00046862804783213714\n",
      " loss = 0.00046444604485829707\n",
      " loss = 0.00034539640617818786\n",
      " loss = 0.0004019567397934372\n",
      " loss = 0.00040102993825336233\n",
      " loss = 0.0004606325835530418\n",
      " loss = 0.0004565757042933081\n",
      " loss = 0.000398275147560565\n",
      " loss = 0.0003429419609714278\n",
      " loss = 0.000511468582949406\n",
      " loss = 0.0003955761635059794\n",
      " loss = 0.0003946493563471232\n",
      " loss = 0.00039372528768600977\n",
      " loss = 0.00034106785171765785\n",
      " loss = 0.0002820586619225255\n",
      " loss = 0.00026902759841170254\n",
      " loss = 0.0003902932915298934\n",
      " loss = 0.0003227320334243682\n",
      " loss = 0.0003887078937169439\n",
      " loss = 0.0003186203908666785\n",
      " loss = 0.0004590529906997268\n",
      " loss = 0.00038602518045157514\n",
      " loss = 0.0003166724868620349\n",
      " loss = 0.0004556357678530778\n",
      " loss = 0.0003153859197933759\n",
      " loss = 0.00038272415788829844\n",
      " loss = 0.0003818405315261452\n",
      " loss = 0.00031085949949775287\n",
      " loss = 0.00030768125182576686\n",
      " loss = 0.0003798222472613488\n",
      " loss = 0.0003040911892165537\n",
      " loss = 0.00045572757678141425\n",
      " loss = 0.00037716573400433463\n",
      " loss = 0.000523782427206296\n",
      " loss = 0.00037482192950695514\n",
      " loss = 0.00044151359243128674\n",
      " loss = 0.0004373846038978473\n",
      " loss = 0.00043335693161560007\n",
      " loss = 0.00025384141366804083\n",
      " loss = 0.0003703100132353192\n",
      " loss = 0.0003694587996348364\n",
      " loss = 0.00043233714394342356\n",
      " loss = 0.00042835671421611996\n",
      " loss = 0.0002510015822482625\n",
      " loss = 0.00023940535067962367\n",
      " loss = 0.00043435143503890955\n",
      " loss = 0.0004302311734399074\n",
      " loss = 0.00030086141339950547\n",
      " loss = 0.0002976579327720782\n",
      " loss = 0.0003623133824690778\n",
      " loss = 0.00036147566823961733\n",
      " loss = 0.00036064006126301524\n",
      " loss = 0.0003598065505466954\n",
      " loss = 0.0004923148377828386\n",
      " loss = 0.0003577159373956203\n",
      " loss = 0.00035689401381590904\n",
      " loss = 0.00035607398533525104\n",
      " loss = 0.000234196072555918\n",
      " loss = 0.00035485096052723656\n",
      " loss = 0.00022306882559642856\n",
      " loss = 0.0003538066270506264\n",
      " loss = 0.00028280371837549064\n",
      " loss = 0.0003525160916121112\n",
      " loss = 0.00049581889691803\n",
      " loss = 0.0002837131924940906\n",
      " loss = 0.00028087329286093\n",
      " loss = 0.0003492165898087381\n",
      " loss = 0.00027768165702089467\n",
      " loss = 0.0004208855392090609\n",
      " loss = 0.00034675963235194834\n",
      " loss = 0.00034594746642913597\n",
      " loss = 0.000414393330545027\n",
      " loss = 0.0002776582866932779\n",
      " loss = 0.00034352564366772287\n",
      " loss = 0.0004110005393689514\n",
      " loss = 0.0003416127795206626\n",
      " loss = 0.00034082041820958326\n",
      " loss = 0.0004696969848480658\n",
      " loss = 0.00045770934679470097\n",
      " loss = 0.0003918704802960101\n",
      " loss = 0.00028537962305724625\n",
      " loss = 0.0002821391885669921\n",
      " loss = 0.0003355018705375498\n",
      " loss = 0.0003347311437277288\n",
      " loss = 0.0002777544123777041\n",
      " loss = 0.0002747556088812476\n",
      " loss = 0.00021093615938721922\n",
      " loss = 0.0002668750091525753\n",
      " loss = 0.00033211522740502424\n",
      " loss = 0.00026385277150416895\n",
      " loss = 0.00033092403904862676\n",
      " loss = 0.000191762217662239\n",
      " loss = 0.00018290283493560173\n",
      " loss = 0.00017445275422504862\n",
      " loss = 0.0002485632320365825\n",
      " loss = 0.0002466188618357374\n",
      " loss = 0.0002447399845981043\n",
      " loss = 0.0003301466744447708\n",
      " loss = 0.0003292667536992918\n",
      " loss = 0.0004142064479640213\n",
      " loss = 0.0004925022726501876\n",
      " loss = 0.0004023836196550069\n",
      " loss = 0.00032350209461981343\n",
      " loss = 0.00032270914403684237\n",
      " loss = 0.00024824385637961597\n",
      " loss = 0.00039714903079826814\n",
      " loss = 0.00039302236959412563\n",
      " loss = 0.0002492352656375282\n",
      " loss = 0.00024700969463904054\n",
      " loss = 0.00024486112956363773\n",
      " loss = 0.00031822041599718415\n",
      " loss = 0.0003174300822392835\n",
      " loss = 0.0003166435597857769\n",
      " loss = 0.0003897333372456656\n",
      " loss = 0.00017242090272926719\n",
      " loss = 0.00031482064987129284\n",
      " loss = 0.00038868619180246395\n",
      " loss = 0.0003846250351664218\n",
      " loss = 0.00024240694492610432\n",
      " loss = 0.00031123125998046037\n",
      " loss = 0.0003809697769489545\n",
      " loss = 0.0003092822973700766\n",
      " loss = 0.00037591383489287734\n",
      " loss = 0.0003074167906013652\n",
      " loss = 0.000306688875251159\n",
      " loss = 0.0003699549974261096\n",
      " loss = 0.0003049096673759715\n",
      " loss = 0.0003652727256671631\n",
      " loss = 0.0003617177379741849\n",
      " loss = 0.00035825084411419234\n",
      " loss = 0.00035486954219661834\n",
      " loss = 0.0003005121882268384\n",
      " loss = 0.00019797021523404028\n",
      " loss = 0.0002994744497603189\n",
      " loss = 0.00018855922498697172\n",
      " loss = 0.0003579583174261243\n",
      " loss = 0.00029762341337586317\n",
      " loss = 0.00024031498238435696\n",
      " loss = 0.0002965050164483941\n",
      " loss = 0.00023750554662670416\n",
      " loss = 0.00035564208210021127\n",
      " loss = 0.00017897639297477104\n",
      " loss = 0.00023253151581280573\n",
      " loss = 0.0002303775034383073\n",
      " loss = 0.00029370756893308867\n",
      " loss = 0.00022800052045125584\n",
      " loss = 0.00022598886924259616\n",
      " loss = 0.000292447951545205\n",
      " loss = 0.00029172655515511493\n",
      " loss = 0.0002235374411727938\n",
      " loss = 0.0002907613924875779\n",
      " loss = 0.0003586648241641631\n",
      " loss = 0.00022280050833888395\n",
      " loss = 0.00022089198794890164\n",
      " loss = 0.00021904897850117988\n",
      " loss = 0.00021726889921137356\n",
      " loss = 0.00021554927152419245\n",
      " loss = 0.00043557587022877256\n",
      " loss = 0.00035520701448445434\n",
      " loss = 0.0003514642814594509\n",
      " loss = 0.00034781599782637574\n",
      " loss = 0.0002825374217066505\n",
      " loss = 0.00022051189952720923\n",
      " loss = 0.00021853186449651905\n",
      " loss = 0.0002812992535121165\n",
      " loss = 0.00028061097041463416\n",
      " loss = 0.00040757380251890153\n",
      " loss = 0.00021913982241788453\n",
      " loss = 0.00027817673542517745\n",
      " loss = 0.000277509019539008\n",
      " loss = 0.0002768438030858496\n",
      " loss = 0.00027618104785010714\n",
      " loss = 0.00033510105368944636\n",
      " loss = 0.00021732003995868118\n",
      " loss = 0.00015637861571304553\n",
      " loss = 0.0003368804533083777\n",
      " loss = 0.00021306946254634444\n",
      " loss = 0.0002111767477308912\n",
      " loss = 0.0002727216252317195\n",
      " loss = 0.0002720510224460538\n",
      " loss = 0.00020886387379266948\n",
      " loss = 0.0003352078929973239\n",
      " loss = 0.0002700512912499359\n",
      " loss = 0.0002081341471374516\n",
      " loss = 0.0002691483335459319\n",
      " loss = 0.00020610639233662706\n",
      " loss = 0.00039603848013833646\n",
      " loss = 0.0003263479983572506\n",
      " loss = 0.00026576462460389187\n",
      " loss = 0.0002651307400689821\n",
      " loss = 0.00026449909836082926\n",
      " loss = 0.000376404287620646\n",
      " loss = 0.0001585346322941115\n",
      " loss = 0.00031831953615358357\n",
      " loss = 0.00026169561053616253\n",
      " loss = 0.0002610809018463544\n",
      " loss = 0.0003133705428389969\n",
      " loss = 0.00031030679371062126\n",
      " loss = 0.0002587834291765605\n",
      " loss = 0.00025818486615718136\n",
      " loss = 0.0003538729696880982\n",
      " loss = 0.00025667298728613105\n",
      " loss = 0.0003000447923813276\n",
      " loss = 0.00021348982558175146\n",
      " loss = 0.00029865927736694533\n",
      " loss = 0.00021251413335484926\n",
      " loss = 0.0002537335989073548\n",
      " loss = 0.0002965767066186052\n",
      " loss = 0.00025246539384327267\n",
      " loss = 0.000210582013013302\n",
      " loss = 0.0002945402158575168\n",
      " loss = 0.00020961893820711872\n",
      " loss = 0.00029318096502104054\n",
      " loss = 0.00033140351848490483\n",
      " loss = 0.0002488972195594731\n",
      " loss = 0.0002853315601680399\n",
      " loss = 0.0002828303261085466\n",
      " loss = 0.00021402069824370457\n",
      " loss = 0.0002114484649515264\n",
      " loss = 0.0002089695162281675\n",
      " loss = 0.0002455035768896354\n",
      " loss = 0.0002060742347680554\n",
      " loss = 0.0003257982659320713\n",
      " loss = 0.0002437662498066042\n",
      " loss = 0.0002800370098187854\n",
      " loss = 0.0002775697994838839\n",
      " loss = 0.000209018686181664\n",
      " loss = 0.0002065241541292704\n",
      " loss = 0.00024096238165352668\n",
      " loss = 0.00024040730717966185\n",
      " loss = 0.0001663019698738659\n",
      " loss = 0.00019902633705571644\n",
      " loss = 0.0002811196386624842\n",
      " loss = 0.00023833280307535687\n",
      " loss = 0.00019770437160437175\n",
      " loss = 0.0002373538280224446\n",
      " loss = 0.0001951573615886466\n",
      " loss = 0.00023640826270279573\n",
      " loss = 0.00023586286018604006\n",
      " loss = 0.00023531878941658298\n",
      " loss = 0.00023477604468194019\n",
      " loss = 0.0002769007525528603\n",
      " loss = 0.00027430340572564724\n",
      " loss = 0.00019404983578146897\n",
      " loss = 0.00015140880056646806\n",
      " loss = 0.00027616452953686913\n",
      " loss = 0.0002315421677310735\n",
      " loss = 0.0002728534397152926\n",
      " loss = 0.0002303421001540397\n",
      " loss = 0.0002696525903519639\n",
      " loss = 0.00019119840627163632\n",
      " loss = 0.0002683950507426274\n",
      " loss = 0.00022812931653287536\n",
      " loss = 0.0002276052719918698\n",
      " loss = 0.0001518319140507285\n",
      " loss = 0.00022678595568795015\n",
      " loss = 0.000226263369873906\n",
      " loss = 0.00018504657733267653\n",
      " loss = 0.00018312936089338964\n",
      " loss = 0.00022504115766093302\n",
      " loss = 0.00018095679210129996\n",
      " loss = 0.0001791732634129622\n",
      " loss = 0.00017745253215179158\n",
      " loss = 0.00022365325112860753\n",
      " loss = 0.00012795416224118457\n",
      " loss = 0.000223187935300734\n",
      " loss = 0.00017240073681844872\n",
      " loss = 0.00032550653210210097\n",
      " loss = 0.00026922914146767845\n",
      " loss = 0.00026652608746580283\n",
      " loss = 0.00026389050968631195\n",
      " loss = 0.0003036581732903407\n",
      " loss = 0.00021815211833720038\n",
      " loss = 0.00029514669043773605\n",
      " loss = 0.00021694832605537358\n",
      " loss = 0.00021644987013699107\n",
      " loss = 0.0001807572095542726\n",
      " loss = 0.00021553923191355184\n",
      " loss = 0.00021504398672355236\n",
      " loss = 0.00021454988344438332\n",
      " loss = 0.00021405691930912347\n",
      " loss = 0.0002499429349149594\n",
      " loss = 0.00021299179533517271\n",
      " loss = 0.0002470973057303667\n",
      " loss = 0.0002448686273172248\n",
      " loss = 0.00021144790341970783\n",
      " loss = 0.00021095960443104925\n",
      " loss = 0.00021047251386054327\n",
      " loss = 0.00020998662601520507\n",
      " loss = 0.00024070460419951502\n",
      " loss = 0.00017943999603029518\n",
      " loss = 0.00023973676471145458\n",
      " loss = 0.00020804863594731617\n",
      " loss = 0.00017797062233643483\n",
      " loss = 0.000269500835856045\n",
      " loss = 0.00020662442949636667\n",
      " loss = 0.00017810703904489378\n",
      " loss = 0.00017597758447328684\n",
      " loss = 0.00023642982674539537\n",
      " loss = 0.00014538843953030764\n",
      " loss = 0.00020426976227222237\n",
      " loss = 0.00023654320372049634\n",
      " loss = 0.0001721575114389323\n",
      " loss = 0.00023552039579478418\n",
      " loss = 0.00020235167079010795\n",
      " loss = 0.00017086293539051177\n",
      " loss = 0.0001689278734545602\n",
      " loss = 0.00013305106046145507\n",
      " loss = 0.00016386999377545453\n",
      " loss = 0.00023885428498286214\n",
      " loss = 0.00019990745337095429\n",
      " loss = 0.00012638966289931747\n",
      " loss = 0.00023868563961300517\n",
      " loss = 0.00023637721214213057\n",
      " loss = 0.0002341259015040992\n",
      " loss = 0.00012860171310000466\n",
      " loss = 0.000234604881680006\n",
      " loss = 0.00023237342340218787\n",
      " loss = 0.0001961222249221257\n",
      " loss = 0.00019567134574134502\n",
      " loss = 0.00019522151452993237\n",
      " loss = 0.0001609981859751395\n",
      " loss = 0.00015928978556139584\n",
      " loss = 0.00019412375605714334\n",
      " loss = 0.00019367463802063458\n",
      " loss = 0.00012085855821256653\n",
      " loss = 0.00019311913954278388\n",
      " loss = 0.00019266692672786353\n",
      " loss = 0.00015368413704441213\n",
      " loss = 0.00023173049029602365\n",
      " loss = 0.0001531834023247634\n",
      " loss = 0.00019106522416545606\n",
      " loss = 0.0001906154719121834\n",
      " loss = 0.00022911212689011458\n",
      " loss = 0.00015219422837164264\n",
      " loss = 0.00015071085412296902\n",
      " loss = 0.00018904039872386156\n",
      " loss = 0.00026767008843915874\n",
      " loss = 0.0002242989213225919\n",
      " loss = 0.00022214226838740577\n",
      " loss = 0.00018660816662052478\n",
      " loss = 0.00021949511652916322\n",
      " loss = 0.00021744941077676345\n",
      " loss = 0.0001851474933943569\n",
      " loss = 0.00018472213702323313\n",
      " loss = 0.0002446649312456882\n",
      " loss = 0.00021110959870766077\n",
      " loss = 0.00020926071334079047\n",
      " loss = 0.00020745641765062837\n",
      " loss = 0.00018259560956581007\n",
      " loss = 0.00018216615379506397\n",
      " loss = 0.00018173802127456102\n",
      " loss = 0.00013475146871937523\n",
      " loss = 0.00020697553538880057\n",
      " loss = 0.00022993537868198853\n",
      " loss = 0.00020208254662140333\n",
      " loss = 0.00015910577673695396\n",
      " loss = 0.00017924397143627234\n",
      " loss = 0.00020105024518380054\n",
      " loss = 0.00022027918332944585\n",
      " loss = 0.0001600873070921122\n",
      " loss = 0.00017771794850623168\n",
      " loss = 0.00019713683082821286\n",
      " loss = 0.00019554109743144966\n",
      " loss = 0.0001594001447696163\n",
      " loss = 0.0001572814118342046\n",
      " loss = 0.00015524049398442217\n",
      " loss = 0.00015327431714011076\n",
      " loss = 0.0001513799290029859\n",
      " loss = 0.00012491856163726985\n",
      " loss = 0.00017380939375386684\n",
      " loss = 0.00017340961268065883\n",
      " loss = 0.00011849898052443812\n",
      " loss = 0.0002025894408675026\n",
      " loss = 0.0001438012559443821\n",
      " loss = 0.00011252516522089999\n",
      " loss = 0.0002039745669829738\n",
      " loss = 0.00014044342328962733\n",
      " loss = 0.00013898617036323368\n",
      " loss = 0.00017070794288091845\n",
      " loss = 0.00020328804011316906\n",
      " loss = 0.0001697786458338087\n",
      " loss = 0.00020082046034462062\n",
      " loss = 0.00013884301180640276\n",
      " loss = 0.0001686041900174606\n",
      " loss = 0.00016821479784090378\n",
      " loss = 0.00013685588006199655\n",
      " loss = 0.00016756757945874951\n",
      " loss = 0.00019914691193157944\n",
      " loss = 0.00010550257794357187\n",
      " loss = 0.00016654993269391957\n",
      " loss = 0.00019896388407534315\n",
      " loss = 0.00010280748468560356\n",
      " loss = 0.0001655505197243078\n",
      " loss = 0.00013159063489183418\n",
      " loss = 0.00019957324374846372\n",
      " loss = 0.00023080712633919762\n",
      " loss = 0.0001637073011249526\n",
      " loss = 0.00016332879679061807\n",
      " loss = 0.00013259175104687724\n",
      " loss = 0.00019416209594520263\n",
      " loss = 0.00013209396411815804\n",
      " loss = 0.00016194962668036043\n",
      " loss = 0.00019263361944473094\n",
      " loss = 0.00013135572320333144\n",
      " loss = 0.00019163375622344947\n",
      " loss = 0.0001603281229123381\n",
      " loss = 0.00013059561937810545\n",
      " loss = 0.00015970887764728414\n",
      " loss = 0.00018965837646617523\n",
      " loss = 0.00012985163569328634\n",
      " loss = 0.0001285171222868033\n",
      " loss = 0.00015836953197030822\n",
      " loss = 0.00018899329192708413\n",
      " loss = 0.00015749858177525484\n",
      " loss = 0.0001866834480110954\n",
      " loss = 0.00015665999433129343\n",
      " loss = 0.00012814655887231205\n",
      " loss = 0.00018527496901290125\n",
      " loss = 0.0001835191149283472\n",
      " loss = 0.00015513376294620275\n",
      " loss = 0.0001547772412184081\n",
      " loss = 0.00015442154390631272\n",
      " loss = 0.00015406666893302896\n",
      " loss = 0.00015371261423259108\n",
      " loss = 0.000127055461725838\n",
      " loss = 0.00015308905792265923\n",
      " loss = 0.00018003415950799083\n",
      " loss = 0.0001523029254095681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 0.00015195295613098985\n",
      " loss = 0.00015160379454513551\n",
      " loss = 0.0001770981064015274\n",
      " loss = 0.00017547430633013493\n",
      " loss = 0.00015046215946709182\n",
      " loss = 0.00015011591766802025\n",
      " loss = 0.00012639923307637138\n",
      " loss = 0.00014946487886414035\n",
      " loss = 0.00017355789051247015\n",
      " loss = 0.00017198905477906537\n",
      " loss = 0.00012629359266130402\n",
      " loss = 0.000101629614802781\n",
      " loss = 0.00014781258381840891\n",
      " loss = 0.00017284048735446118\n",
      " loss = 0.00014707249276074775\n",
      " loss = 0.000170863453247646\n",
      " loss = 0.00010043440173803357\n",
      " loss = 0.00017128133473122873\n",
      " loss = 0.00014572179293516457\n",
      " loss = 0.00016932110497678722\n",
      " loss = 0.00014501165408611392\n",
      " loss = 0.0001446780940117883\n",
      " loss = 0.00014434531535972766\n",
      " loss = 0.00012132986257403931\n",
      " loss = 0.00014372333619559478\n",
      " loss = 0.00011969412162487916\n",
      " loss = 9.365271941568506e-05\n",
      " loss = 0.00011614988245287232\n",
      " loss = 0.00014276050938045662\n",
      " loss = 0.0001424285076923304\n",
      " loss = 0.00014209740534533284\n",
      " loss = 0.00014176719567642764\n",
      " loss = 0.0001960028499984923\n",
      " loss = 0.00014090371507083534\n",
      " loss = 0.00019051092723057026\n",
      " loss = 0.00016288859821058404\n",
      " loss = 0.00011812372079966814\n",
      " loss = 0.00016217671366242694\n",
      " loss = 0.00016071429048788104\n",
      " loss = 0.00011829709290676015\n",
      " loss = 0.00016004246806601536\n",
      " loss = 0.00011768246616805989\n",
      " loss = 0.00011632646222782912\n",
      " loss = 0.0001601163498819476\n",
      " loss = 0.00011575990396722113\n",
      " loss = 0.00013693519736514075\n",
      " loss = 0.00011419201861271655\n",
      " loss = 0.0001597820836194644\n",
      " loss = 0.0001359924905682907\n",
      " loss = 0.00011340437468272351\n",
      " loss = 0.00013542331280875218\n",
      " loss = 0.0001119164915976867\n",
      " loss = 0.00013487431464983022\n",
      " loss = 0.00013456373467939344\n",
      " loss = 0.00013425389365151783\n",
      " loss = 0.00015785246346764338\n",
      " loss = 0.00015638263330775823\n",
      " loss = 0.00017669231359923707\n",
      " loss = 0.0001328471606273512\n",
      " loss = 0.0001522017567038445\n",
      " loss = 0.00013223525833095832\n",
      " loss = 0.00013192850323568748\n",
      " loss = 0.00011296809178648582\n",
      " loss = 0.0001313181753655706\n",
      " loss = 0.00017034938869112264\n",
      " loss = 0.00016600172013007941\n",
      " loss = 0.00016176501305860622\n",
      " loss = 0.0001303423604967482\n",
      " loss = 0.00010254035836706648\n",
      " loss = 0.00012956338923187472\n",
      " loss = 0.00011332362097030794\n",
      " loss = 0.00011191773004005068\n",
      " loss = 0.0001285869698436178\n",
      " loss = 0.00012828850667042507\n",
      " loss = 0.0001279908328289375\n",
      " loss = 0.00012769394301754514\n",
      " loss = 0.00012739783206413126\n",
      " loss = 0.00014517693204696801\n",
      " loss = 0.00016102221647675889\n",
      " loss = 0.00012660630022303364\n",
      " loss = 0.00012630599893121824\n",
      " loss = 9.546899776171551e-05\n",
      " loss = 0.0001429224797888982\n",
      " loss = 0.00012536708525690267\n",
      " loss = 0.0001414399867575853\n",
      " loss = 0.00010939408892692312\n",
      " loss = 0.00015738287694119218\n",
      " loss = 0.00012428534010004353\n",
      " loss = 0.00012398945970110007\n",
      " loss = 0.0001236946081552964\n",
      " loss = 0.00012340077135605094\n",
      " loss = 0.00010832393391985494\n",
      " loss = 9.11664655434441e-05\n",
      " loss = 0.00012244215748113052\n",
      " loss = 0.00010441415159819393\n",
      " loss = 0.00010320019438250072\n",
      " loss = 0.00014122959487490242\n",
      " loss = 0.00012132324479446507\n",
      " loss = 8.380636077299503e-05\n",
      " loss = 0.0001617338642257828\n",
      " loss = 0.00012048328377509086\n",
      " loss = 0.0001387483073746333\n",
      " loss = 0.00011991715412198295\n",
      " loss = 0.00010204157677715056\n",
      " loss = 0.0001378896900505491\n",
      " loss = 8.393091047965608e-05\n",
      " loss = 0.00011885407951871186\n",
      " loss = 9.921905089430063e-05\n",
      " loss = 0.00013857963413306805\n",
      " loss = 0.0001180358080260568\n",
      " loss = 0.00011776462335180764\n",
      " loss = 9.829749836681991e-05\n",
      " loss = 0.0001373213867862618\n",
      " loss = 0.000136061964607126\n",
      " loss = 0.00013483329205519652\n",
      " loss = 0.00011637113048826187\n",
      " loss = 9.884540549929416e-05\n",
      " loss = 0.00011584942868835408\n",
      " loss = 0.00011558291143863808\n",
      " loss = 0.00013341095338952616\n",
      " loss = 0.00011503482012120667\n",
      " loss = 9.759048155342106e-05\n",
      " loss = 0.00013257176840852193\n",
      " loss = 0.0001142398846624678\n",
      " loss = 0.00011397639391164559\n",
      " loss = 0.00011371354437313384\n",
      " loss = 0.00011345133336517271\n",
      " loss = 9.608325577957949e-05\n",
      " loss = 9.498635173756079e-05\n",
      " loss = 0.00015031446352634613\n",
      " loss = 9.537128961015074e-05\n",
      " loss = 0.00013005225626515278\n",
      " loss = 7.789144609737108e-05\n",
      " loss = 0.00014908150080110452\n",
      " loss = 0.00011137020120085989\n",
      " loss = 9.4174195113341e-05\n",
      " loss = 0.00012865526420529152\n",
      " loss = 0.0001275007650862809\n",
      " loss = 7.826725147935268e-05\n",
      " loss = 0.00011011319874633103\n",
      " loss = 0.0001275598769973975\n",
      " loss = 0.00010958328208498705\n",
      " loss = 0.00010933091820081902\n",
      " loss = 0.00010907915550401814\n",
      " loss = 9.204794235013596e-05\n",
      " loss = 9.100721151709425e-05\n",
      " loss = 0.00010839241489194045\n",
      " loss = 0.00012648427110807818\n",
      " loss = 9.038156229416175e-05\n",
      " loss = 0.00010764620676439026\n",
      " loss = 0.00012561269027966458\n",
      " loss = 0.0001244639104524632\n",
      " loss = 0.0001233431582375375\n",
      " loss = 0.0001065834606426252\n",
      " loss = 7.501113443402423e-05\n",
      " loss = 0.00010612767460074509\n",
      " loss = 0.00012314113506440284\n",
      " loss = 8.919699790792087e-05\n",
      " loss = 0.00010539682580403161\n",
      " loss = 0.00012232491171764\n",
      " loss = 0.00012122050561499308\n",
      " loss = 8.911922442560572e-05\n",
      " loss = 7.178298487936808e-05\n",
      " loss = 8.634857897541085e-05\n",
      " loss = 0.00010404689136855796\n",
      " loss = 0.00010380730928076577\n",
      " loss = 0.000103568296864067\n",
      " loss = 0.00010332985215998885\n",
      " loss = 0.00010309197323641288\n",
      " loss = 8.454544057002531e-05\n",
      " loss = 8.366249747003569e-05\n",
      " loss = 8.281093400086312e-05\n",
      " loss = 8.198951216382073e-05\n",
      " loss = 0.0001443513572707138\n",
      " loss = 0.00010181149654195587\n",
      " loss = 8.223133320556255e-05\n",
      " loss = 0.00010142857279650259\n",
      " loss = 0.0001211152248352848\n",
      " loss = 0.0001199454620331802\n",
      " loss = 0.00011880463282045521\n",
      " loss = 8.285232457830426e-05\n",
      " loss = 0.00011822430336169788\n",
      " loss = 9.981059780937212e-05\n",
      " loss = 9.958115336703578e-05\n",
      " loss = 9.93522416410427e-05\n",
      " loss = 8.196766049495607e-05\n",
      " loss = 9.895182477644553e-05\n",
      " loss = 9.872383650407321e-05\n",
      " loss = 0.0001162262639147306\n",
      " loss = 8.128803682110233e-05\n",
      " loss = 6.280196413699646e-05\n",
      " loss = 7.8931671782732e-05\n",
      " loss = 5.8481758651939235e-05\n",
      " loss = 7.679890322251819e-05\n",
      " loss = 9.77125243486801e-05\n",
      " loss = 0.00011895445273108527\n",
      " loss = 9.711816692971358e-05\n",
      " loss = 0.00011740353582599799\n",
      " loss = 9.654856732356821e-05\n",
      " loss = 0.00011590728792790268\n",
      " loss = 0.0001147735862906948\n",
      " loss = 7.772800707989728e-05\n",
      " loss = 7.6944060250636e-05\n",
      " loss = 9.542389330815231e-05\n",
      " loss = 9.520043615187854e-05\n",
      " loss = 9.497763548957518e-05\n",
      " loss = 9.475548499772305e-05\n",
      " loss = 9.453397852928374e-05\n",
      " loss = 7.555084174486575e-05\n",
      " loss = 9.41893112375732e-05\n",
      " loss = 7.470101743918931e-05\n",
      " loss = 9.385303686503045e-05\n",
      " loss = 7.388505201589345e-05\n",
      " loss = 5.288169889663304e-05\n",
      " loss = 7.20014178522149e-05\n",
      " loss = 0.00013767063274253578\n",
      " loss = 9.296971938573131e-05\n",
      " loss = 5.1814654039353176e-05\n",
      " loss = 9.27952968448396e-05\n",
      " loss = 7.102757013515587e-05\n",
      " loss = 0.00011454794909006491\n",
      " loss = 9.210994888792624e-05\n",
      " loss = 9.188427757408095e-05\n",
      " loss = 0.00013357418753112924\n",
      " loss = 7.169506620732825e-05\n",
      " loss = 9.10853797899143e-05\n",
      " loss = 7.094506548843719e-05\n",
      " loss = 0.00011123609958221235\n",
      " loss = 9.042950396517853e-05\n",
      " loss = 9.021311840501542e-05\n",
      " loss = 7.056090109382694e-05\n",
      " loss = 8.990195616390134e-05\n",
      " loss = 8.96851284882431e-05\n",
      " loss = 8.94691457119305e-05\n",
      " loss = 5.003589444406032e-05\n",
      " loss = 6.851159986719493e-05\n",
      " loss = 8.922418821484526e-05\n",
      " loss = 0.00011014026404721083\n",
      " loss = 6.828863524930769e-05\n",
      " loss = 8.856144397036055e-05\n",
      " loss = 6.763116130254225e-05\n",
      " loss = 6.706641733831347e-05\n",
      " loss = 0.00010988763223781421\n",
      " loss = 4.6039072690671175e-05\n",
      " loss = 0.00010992510284739435\n",
      " loss = 6.632233150892508e-05\n",
      " loss = 6.578824027337143e-05\n",
      " loss = 0.00010955833022846663\n",
      " loss = 6.567224790103545e-05\n",
      " loss = 0.0001087817444125456\n",
      " loss = 8.658423981024985e-05\n",
      " loss = 0.00010724597133465683\n",
      " loss = 0.0001262278589277943\n",
      " loss = 8.554233372753004e-05\n",
      " loss = 6.67191230384058e-05\n",
      " loss = 8.524916597958581e-05\n",
      " loss = 6.603678520068277e-05\n",
      " loss = 4.595518105673157e-05\n",
      " loss = 0.00010562895577552025\n",
      " loss = 8.467409391773476e-05\n",
      " loss = 4.5054190842741796e-05\n",
      " loss = 8.454298237663801e-05\n",
      " loss = 8.432864951290965e-05\n",
      " loss = 0.00010459542597512874\n",
      " loss = 6.40313032650554e-05\n",
      " loss = 8.369374142772168e-05\n",
      " loss = 0.00012358227773258756\n",
      " loss = 6.430411475177473e-05\n",
      " loss = 0.00010212406211620377\n",
      " loss = 6.414739990187894e-05\n",
      " loss = 6.358536299887759e-05\n",
      " loss = 0.0001018710216619749\n",
      " loss = 8.212493656032985e-05\n",
      " loss = 0.00010048908761702539\n",
      " loss = 4.591298051028617e-05\n",
      " loss = 8.165027294558006e-05\n",
      " loss = 8.144972198680737e-05\n",
      " loss = 4.389898068251562e-05\n",
      " loss = 0.00010103939385447088\n",
      " loss = 9.997403209576966e-05\n",
      " loss = 6.23668901957566e-05\n",
      " loss = 6.18280005987098e-05\n",
      " loss = 9.971197994594318e-05\n",
      " loss = 8.017996817734123e-05\n",
      " loss = 7.998352482101278e-05\n",
      " loss = 7.978794505755134e-05\n",
      " loss = 9.771606877373123e-05\n",
      " loss = 7.928693578136793e-05\n",
      " loss = 7.909650463892437e-05\n",
      " loss = 7.890679007420633e-05\n",
      " loss = 7.871778105366785e-05\n",
      " loss = 7.85294668848137e-05\n",
      " loss = 9.524940717922725e-05\n",
      " loss = 7.806090274795588e-05\n",
      " loss = 7.787669562208692e-05\n",
      " loss = 7.769307617457819e-05\n",
      " loss = 4.5565809414970936e-05\n",
      " loss = 6.048799923176838e-05\n",
      " loss = 9.492458689682476e-05\n",
      " loss = 7.714225620535216e-05\n",
      " loss = 6.0246186626160474e-05\n",
      " loss = 5.970408436917945e-05\n",
      " loss = 7.680329979526262e-05\n",
      " loss = 7.661555563304258e-05\n",
      " loss = 7.642862338036577e-05\n",
      " loss = 9.351933112246351e-05\n",
      " loss = 7.595097484251596e-05\n",
      " loss = 5.9258056313888754e-05\n",
      " loss = 7.569048395455073e-05\n",
      " loss = 7.550731602101537e-05\n",
      " loss = 9.20746044531743e-05\n",
      " loss = 9.114024775314248e-05\n",
      " loss = 9.022927274056676e-05\n",
      " loss = 7.452342568570667e-05\n",
      " loss = 8.909492229793449e-05\n",
      " loss = 7.410996286496657e-05\n",
      " loss = 7.393818412908878e-05\n",
      " loss = 7.37668517712902e-05\n",
      " loss = 0.00010148029430557822\n",
      " loss = 6.054621659907891e-05\n",
      " loss = 5.990572664898451e-05\n",
      " loss = 5.928804491662853e-05\n",
      " loss = 7.297783032697244e-05\n",
      " loss = 7.280793992510416e-05\n",
      " loss = 7.263851551871648e-05\n",
      " loss = 7.246955349025747e-05\n",
      " loss = 5.827710582798324e-05\n",
      " loss = 7.220054787193222e-05\n",
      " loss = 8.645714950593225e-05\n",
      " loss = 5.797702496667764e-05\n",
      " loss = 7.169530815362734e-05\n",
      " loss = 8.575077387092138e-05\n",
      " loss = 4.4051343190296645e-05\n",
      " loss = 7.126619859320192e-05\n",
      " loss = 8.564644849507177e-05\n",
      " loss = 7.086047938511762e-05\n",
      " loss = 5.6815155690046796e-05\n",
      " loss = 7.059971325720516e-05\n",
      " loss = 7.043410295005339e-05\n",
      " loss = 8.446204475457741e-05\n",
      " loss = 7.003744832984885e-05\n",
      " loss = 6.98746301468164e-05\n",
      " loss = 6.971225102484147e-05\n",
      " loss = 8.296740869860313e-05\n",
      " loss = 6.933383855026856e-05\n",
      " loss = 5.638513801882108e-05\n",
      " loss = 4.2553468787896845e-05\n",
      " loss = 8.326610451826427e-05\n",
      " loss = 8.244733082652284e-05\n",
      " loss = 5.5521324718364786e-05\n",
      " loss = 5.4966853545752844e-05\n",
      " loss = 8.235694346777466e-05\n",
      " loss = 5.478195195970218e-05\n",
      " loss = 8.19009357953922e-05\n",
      " loss = 6.784792745106444e-05\n",
      " loss = 8.088097837484818e-05\n",
      " loss = 6.74767252720447e-05\n",
      " loss = 6.73206964942413e-05\n",
      " loss = 7.968979852459736e-05\n",
      " loss = 7.893582128964529e-05\n",
      " loss = 7.820039912719099e-05\n",
      " loss = 8.837191719296909e-05\n",
      " loss = 6.641436258997481e-05\n",
      " loss = 7.61085310757612e-05\n",
      " loss = 5.6774407632767055e-05\n",
      " loss = 6.595460651407902e-05\n",
      " loss = 6.580242372683165e-05\n",
      " loss = 6.565061330826471e-05\n",
      " loss = 5.566577798408278e-05\n",
      " loss = 4.469830787048821e-05\n",
      " loss = 7.656599250664231e-05\n",
      " loss = 8.664451759843799e-05\n",
      " loss = 8.443317038995102e-05\n",
      " loss = 6.475006157158019e-05\n",
      " loss = 7.33749735104889e-05\n",
      " loss = 7.274941162474968e-05\n",
      " loss = 5.653201398157384e-05\n",
      " loss = 5.582674754692282e-05\n",
      " loss = 7.28461692574919e-05\n",
      " loss = 8.058399147580282e-05\n",
      " loss = 5.63751203682787e-05\n",
      " loss = 7.149531348974589e-05\n",
      " loss = 6.345570150079492e-05\n",
      " loss = 7.0781605414703e-05\n",
      " loss = 7.02008306382111e-05\n",
      " loss = 7.618799989170925e-05\n",
      " loss = 6.863959529048545e-05\n",
      " loss = 5.7778802718674356e-05\n",
      " loss = 5.6979481523706634e-05\n",
      " loss = 6.250793847491917e-05\n",
      " loss = 6.870393134886761e-05\n",
      " loss = 5.0445729443161244e-05\n",
      " loss = 6.200691670303985e-05\n",
      " loss = 5.487495182533701e-05\n",
      " loss = 6.918326667399707e-05\n",
      " loss = 4.746539273180598e-05\n",
      " loss = 6.136476846240842e-05\n",
      " loss = 6.122116507029188e-05\n",
      " loss = 6.107798038880247e-05\n",
      " loss = 5.28436471523808e-05\n",
      " loss = 6.93612284637354e-05\n",
      " loss = 5.253828908904282e-05\n",
      " loss = 6.0500964546397085e-05\n",
      " loss = 6.895934853308336e-05\n",
      " loss = 6.022759200262371e-05\n",
      " loss = 4.379369842546512e-05\n",
      " loss = 5.994261683014866e-05\n",
      " loss = 5.072511259364742e-05\n",
      " loss = 5.967770565793804e-05\n",
      " loss = 6.905547433492153e-05\n",
      " loss = 4.130258940937798e-05\n",
      " loss = 3.9394416612674964e-05\n",
      " loss = 3.757440108344754e-05\n",
      " loss = 3.5838469970528644e-05\n",
      " loss = 4.666996522547347e-05\n",
      " loss = 8.479182825246728e-05\n",
      " loss = 7.071930729209479e-05\n",
      " loss = 5.86164542562421e-05\n",
      " loss = 5.84801267248756e-05\n",
      " loss = 3.57276805375986e-05\n",
      " loss = 7.04483544822056e-05\n",
      " loss = 6.975317772117958e-05\n",
      " loss = 5.793606644971919e-05\n",
      " loss = 6.88916537365849e-05\n",
      " loss = 7.884278090884281e-05\n",
      " loss = 6.712736677371419e-05\n",
      " loss = 4.8028668665090564e-05\n",
      " loss = 6.682227669401006e-05\n",
      " loss = 7.541560947147478e-05\n",
      " loss = 4.8542195800724454e-05\n",
      " loss = 4.79795650273942e-05\n",
      " loss = 5.661428056605765e-05\n",
      " loss = 7.480399217063778e-05\n",
      " loss = 5.6334447886743176e-05\n",
      " loss = 7.2761375035296e-05\n",
      " loss = 5.608455502388357e-05\n",
      " loss = 5.5953441284452364e-05\n",
      " loss = 6.325887251758792e-05\n",
      " loss = 6.272258635003572e-05\n",
      " loss = 5.559931950183586e-05\n",
      " loss = 4.884066812525211e-05\n",
      " loss = 5.5314042061539635e-05\n",
      " loss = 5.5184180226434504e-05\n",
      " loss = 5.5054710837790816e-05\n",
      " loss = 6.206128574877832e-05\n",
      " loss = 5.4815351236447976e-05\n",
      " loss = 4.793982031608902e-05\n",
      " loss = 6.17331554255901e-05\n",
      " loss = 6.121126488891482e-05\n",
      " loss = 6.0701836510076973e-05\n",
      " loss = 5.422419937304803e-05\n",
      " loss = 5.409382410289423e-05\n",
      " loss = 6.00120786664309e-05\n",
      " loss = 5.9526158837128494e-05\n",
      " loss = 4.851076993108736e-05\n",
      " loss = 4.786619697295297e-05\n",
      " loss = 5.964560635965754e-05\n",
      " loss = 4.173080038293482e-05\n",
      " loss = 5.984774162700701e-05\n",
      " loss = 5.306279845504411e-05\n",
      " loss = 4.6625182040113596e-05\n",
      " loss = 5.279022735442625e-05\n",
      " loss = 4.589946031960421e-05\n",
      " loss = 4.5338467823818305e-05\n",
      " loss = 5.240413207219966e-05\n",
      " loss = 5.2282924303128975e-05\n",
      " loss = 4.4555677956709506e-05\n",
      " loss = 5.204552825003991e-05\n",
      " loss = 5.192568262771628e-05\n",
      " loss = 4.381529693309048e-05\n",
      " loss = 4.331999198506714e-05\n",
      " loss = 5.159887662500979e-05\n",
      " loss = 6.0213986884591775e-05\n",
      " loss = 5.1342774678303694e-05\n",
      " loss = 5.1224798863069035e-05\n",
      " loss = 4.281767866427715e-05\n",
      " loss = 5.100855719761671e-05\n",
      " loss = 5.089136485225084e-05\n",
      " loss = 4.2156860775704045e-05\n",
      " loss = 4.1703878222994446e-05\n",
      " loss = 5.0598942802894314e-05\n",
      " loss = 5.048213029598687e-05\n",
      " loss = 5.9626302714404326e-05\n",
      " loss = 5.021770766466621e-05\n",
      " loss = 4.128281079180394e-05\n",
      " loss = 4.0848690926755736e-05\n",
      " loss = 4.993963231382685e-05\n",
      " loss = 4.035498254532017e-05\n",
      " loss = 5.955171203934135e-05\n",
      " loss = 4.959263762989914e-05\n",
      " loss = 4.947779976325523e-05\n",
      " loss = 4.0057741285168285e-05\n",
      " loss = 4.929033819823679e-05\n",
      " loss = 6.835729353550621e-05\n",
      " loss = 4.017254538880112e-05\n",
      " loss = 4.8906616737180364e-05\n",
      " loss = 4.879352907065728e-05\n",
      " loss = 3.960341206008658e-05\n",
      " loss = 5.8012322996792445e-05\n",
      " loss = 4.8455353902098364e-05\n",
      " loss = 4.834340456343368e-05\n",
      " loss = 5.716168238517711e-05\n",
      " loss = 3.955555844384821e-05\n",
      " loss = 3.9141653529920586e-05\n",
      " loss = 4.793516278239344e-05\n",
      " loss = 5.69764019446677e-05\n",
      " loss = 4.767654988867524e-05\n",
      " loss = 5.628901819695618e-05\n",
      " loss = 5.5759730523429935e-05\n",
      " loss = 3.9347221612169074e-05\n",
      " loss = 4.720909500133276e-05\n",
      " loss = 5.5361791254921705e-05\n",
      " loss = 4.696970972903153e-05\n",
      " loss = 3.900106240844938e-05\n",
      " loss = 3.0382268638551167e-05\n",
      " loss = 4.6730740414036656e-05\n",
      " loss = 4.662247313048994e-05\n",
      " loss = 5.531557349144388e-05\n",
      " loss = 3.795683429914932e-05\n",
      " loss = 4.629924376670864e-05\n",
      " loss = 4.6192075423995535e-05\n",
      " loss = 3.742332637570754e-05\n",
      " loss = 4.6016688191628915e-05\n",
      " loss = 6.376822227676292e-05\n",
      " loss = 3.752984752202315e-05\n",
      " loss = 3.713978336618041e-05\n",
      " loss = 5.441671695784276e-05\n",
      " loss = 5.389452924482029e-05\n",
      " loss = 5.3385237301243825e-05\n",
      " loss = 3.7480049011339075e-05\n",
      " loss = 5.312925349978548e-05\n",
      " loss = 2.9659107719687057e-05\n",
      " loss = 4.492501311540131e-05\n",
      " loss = 4.482125643831312e-05\n",
      " loss = 3.6464050140727536e-05\n",
      " loss = 3.609199458491121e-05\n",
      " loss = 4.458512128345182e-05\n",
      " loss = 3.5671935366624444e-05\n",
      " loss = 3.53256427170428e-05\n",
      " loss = 3.4991511834197724e-05\n",
      " loss = 3.466906314512909e-05\n",
      " loss = 4.427164926397121e-05\n",
      " loss = 6.386631729509531e-05\n",
      " loss = 5.309110302586475e-05\n",
      " loss = 3.502405603690429e-05\n",
      " loss = 3.468695317430309e-05\n",
      " loss = 4.368680276738222e-05\n",
      " loss = 4.358292103864675e-05\n",
      " loss = 3.426119860376264e-05\n",
      " loss = 4.343078422912438e-05\n",
      " loss = 4.332671719826502e-05\n",
      " loss = 3.385258248305878e-05\n",
      " loss = 6.243786626963659e-05\n",
      " loss = 4.296388690001213e-05\n",
      " loss = 3.397102101709252e-05\n",
      " loss = 4.281171239203789e-05\n",
      " loss = 4.270983978590442e-05\n",
      " loss = 2.450206904404405e-05\n",
      " loss = 5.224500132691863e-05\n",
      " loss = 6.0964798945959596e-05\n",
      " loss = 5.083255182063512e-05\n",
      " loss = 3.3896619913421135e-05\n",
      " loss = 4.20584171496076e-05\n",
      " loss = 4.195988583388959e-05\n",
      " loss = 4.186164537150503e-05\n",
      " loss = 3.3396894825170175e-05\n",
      " loss = 3.307552064695026e-05\n",
      " loss = 2.387073728246457e-05\n",
      " loss = 4.1672915685952624e-05\n",
      " loss = 5.096264537501477e-05\n",
      " loss = 4.1413268642759545e-05\n",
      " loss = 5.02883703917503e-05\n",
      " loss = 4.1164688313665716e-05\n",
      " loss = 4.963808751246763e-05\n",
      " loss = 3.270517908374103e-05\n",
      " loss = 4.935652606858933e-05\n",
      " loss = 3.25990851885647e-05\n",
      " loss = 4.907827867411514e-05\n",
      " loss = 2.4440375844145726e-05\n",
      " loss = 3.192388077150606e-05\n",
      " loss = 4.0491468571235905e-05\n",
      " loss = 4.03943743927843e-05\n",
      " loss = 4.029764048641351e-05\n",
      " loss = 3.150014103224433e-05\n",
      " loss = 3.1215863041436234e-05\n",
      " loss = 4.0119913717927275e-05\n",
      " loss = 4.9139898842774e-05\n",
      " loss = 5.7404171566536634e-05\n",
      " loss = 4.780726810434245e-05\n",
      " loss = 4.73381742531901e-05\n",
      " loss = 4.6880727443543836e-05\n",
      " loss = 3.9295906200458506e-05\n",
      " loss = 3.920531694509986e-05\n",
      " loss = 3.911494661619118e-05\n",
      " loss = 3.902479434652446e-05\n",
      " loss = 3.893485928313719e-05\n",
      " loss = 3.183323645263519e-05\n",
      " loss = 3.878263941953194e-05\n",
      " loss = 4.594217809999781e-05\n",
      " loss = 3.164668158763222e-05\n",
      " loss = 3.131806881744197e-05\n",
      " loss = 4.591116486714644e-05\n",
      " loss = 3.8335732269086945e-05\n",
      " loss = 3.824714339543712e-05\n",
      " loss = 3.8158775755685e-05\n",
      " loss = 2.3969229689394583e-05\n",
      " loss = 3.804677454019867e-05\n",
      " loss = 5.306818852710931e-05\n",
      " loss = 4.4759716078441005e-05\n",
      " loss = 4.433836110423992e-05\n",
      " loss = 2.4913188634771594e-05\n",
      " loss = 3.754411874091799e-05\n",
      " loss = 3.745748635865089e-05\n",
      " loss = 3.737106607278399e-05\n",
      " loss = 2.3657096514723863e-05\n",
      " loss = 2.2564142570094876e-05\n",
      " loss = 3.725006127145477e-05\n",
      " loss = 5.28015344623515e-05\n",
      " loss = 4.4225158519880833e-05\n",
      " loss = 4.379927385589058e-05\n",
      " loss = 3.676844473179536e-05\n",
      " loss = 4.327623005993433e-05\n",
      " loss = 3.6578919440154215e-05\n",
      " loss = 3.6494853706447596e-05\n",
      " loss = 3.6410982420178234e-05\n",
      " loss = 4.256797598272551e-05\n",
      " loss = 3.0280721994394488e-05\n",
      " loss = 3.616026969507369e-05\n",
      " loss = 2.988343982764643e-05\n",
      " loss = 4.2462897723131714e-05\n",
      " loss = 3.591119597900396e-05\n",
      " loss = 3.582867320189875e-05\n",
      " loss = 4.799049561906491e-05\n",
      " loss = 3.0077037595076287e-05\n",
      " loss = 3.556721869600706e-05\n",
      " loss = 2.385293555191237e-05\n",
      " loss = 2.909393045215317e-05\n",
      " loss = 3.537900642514049e-05\n",
      " loss = 3.529724519677094e-05\n",
      " loss = 2.8679845301003535e-05\n",
      " loss = 4.193570349142191e-05\n",
      " loss = 4.153405042685407e-05\n",
      " loss = 3.49491197806316e-05\n",
      " loss = 3.4868695443578876e-05\n",
      " loss = 2.8635383160572538e-05\n",
      " loss = 2.8335141388095427e-05\n",
      " loss = 3.4676564183474066e-05\n",
      " loss = 4.119836378623168e-05\n",
      " loss = 2.817458914954926e-05\n",
      " loss = 4.098616919659016e-05\n",
      " loss = 3.433053312306481e-05\n",
      " loss = 3.4251358953674016e-05\n",
      " loss = 4.039142698048311e-05\n",
      " loss = 3.407325356048561e-05\n",
      " loss = 2.8073334784063746e-05\n",
      " loss = 3.393656158926899e-05\n",
      " loss = 2.772021508651821e-05\n",
      " loss = 4.0174551417348514e-05\n",
      " loss = 2.1520234622200863e-05\n",
      " loss = 4.025064952088436e-05\n",
      " loss = 3.356939558894457e-05\n",
      " loss = 4.60281081133518e-05\n",
      " loss = 3.911292984469792e-05\n",
      " loss = 3.328188118256649e-05\n",
      " loss = 2.2285187098770143e-05\n",
      " loss = 3.911307641729997e-05\n",
      " loss = 3.874813423643072e-05\n",
      " loss = 2.7560434581990596e-05\n",
      " loss = 2.7258810377666012e-05\n",
      " loss = 3.2856071534139606e-05\n",
      " loss = 3.864837974590581e-05\n",
      " loss = 2.7086202370032676e-05\n",
      " loss = 3.262945588088407e-05\n",
      " loss = 3.836731346783634e-05\n",
      " loss = 3.2462002122274485e-05\n",
      " loss = 3.7920413038303134e-05\n",
      " loss = 3.230017469767736e-05\n",
      " loss = 4.275019529188116e-05\n",
      " loss = 3.213924731156835e-05\n",
      " loss = 3.206504143342559e-05\n",
      " loss = 2.2477861697133686e-05\n",
      " loss = 2.6684500000384246e-05\n",
      " loss = 3.1869241439875406e-05\n",
      " loss = 2.6334529599922465e-05\n",
      " loss = 4.311324947178531e-05\n",
      " loss = 3.6824685719645696e-05\n",
      " loss = 3.649173163687385e-05\n",
      " loss = 2.6789442828586185e-05\n",
      " loss = 3.140974015108013e-05\n",
      " loss = 2.6415821742573344e-05\n",
      " loss = 3.642837153758857e-05\n",
      " loss = 2.628809456760505e-05\n",
      " loss = 3.113031532711816e-05\n",
      " loss = 2.5933316178602306e-05\n",
      " loss = 3.1000498449829136e-05\n",
      " loss = 3.092924617932627e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 3.0858158949245145e-05\n",
      " loss = 2.5482518402991694e-05\n",
      " loss = 3.6255684245520945e-05\n",
      " loss = 2.537387950853343e-05\n",
      " loss = 3.059183113150667e-05\n",
      " loss = 3.052137683946673e-05\n",
      " loss = 2.500014266540147e-05\n",
      " loss = 4.172404653385383e-05\n",
      " loss = 1.9929081322238726e-05\n",
      " loss = 3.0260329764045374e-05\n",
      " loss = 3.0190410187903504e-05\n",
      " loss = 2.4538867675223064e-05\n",
      " loss = 3.0074602537228855e-05\n",
      " loss = 1.8485051744737943e-05\n",
      " loss = 2.9992861522297133e-05\n",
      " loss = 1.762632935278532e-05\n",
      " loss = 2.3367853177934343e-05\n",
      " loss = 2.989323427954752e-05\n",
      " loss = 2.982074237548912e-05\n",
      " loss = 2.9748545588610572e-05\n",
      " loss = 2.9676638916277183e-05\n",
      " loss = 2.9605017512780707e-05\n",
      " loss = 2.9533676684102503e-05\n",
      " loss = 2.2979264542100185e-05\n",
      " loss = 2.9432997440098834e-05\n",
      " loss = 3.597645776993197e-05\n",
      " loss = 2.925009465100838e-05\n",
      " loss = 3.5501221794446325e-05\n",
      " loss = 1.693507796490091e-05\n",
      " loss = 2.9079496444980526e-05\n",
      " loss = 3.5432306509376964e-05\n",
      " loss = 2.273018075890726e-05\n",
      " loss = 3.521762798052278e-05\n",
      " loss = 2.8764040291296217e-05\n",
      " loss = 2.8695787767818648e-05\n",
      " loss = 3.465677762309058e-05\n",
      " loss = 2.852829787009757e-05\n",
      " loss = 2.8461403476176088e-05\n",
      " loss = 3.4120483614853315e-05\n",
      " loss = 2.830133962995518e-05\n",
      " loss = 2.2773891792033015e-05\n",
      " loss = 3.384322083963217e-05\n",
      " loss = 2.810415013396071e-05\n",
      " loss = 2.803890850123725e-05\n",
      " loss = 3.8698535154804214e-05\n",
      " loss = 2.786946182086279e-05\n",
      " loss = 2.290036979400848e-05\n",
      " loss = 1.756106541923083e-05\n",
      " loss = 1.6749747102551595e-05\n",
      " loss = 3.36137624560177e-05\n",
      " loss = 3.327940609033664e-05\n",
      " loss = 3.29533781904525e-05\n",
      " loss = 2.745738613065341e-05\n",
      " loss = 3.255041931665129e-05\n",
      " loss = 3.224136567361669e-05\n",
      " loss = 1.781801515530196e-05\n",
      " loss = 2.2099385509012008e-05\n",
      " loss = 3.245036820120713e-05\n",
      " loss = 2.7077902375006042e-05\n",
      " loss = 2.7015298603268317e-05\n",
      " loss = 2.6952852184624532e-05\n",
      " loss = 3.689060692978667e-05\n",
      " loss = 2.2219489236171457e-05\n",
      " loss = 3.628214622719095e-05\n",
      " loss = 3.535615084974249e-05\n",
      " loss = 3.052216139362224e-05\n",
      " loss = 2.6529524928360544e-05\n",
      " loss = 3.019605617335071e-05\n",
      " loss = 2.641026156976237e-05\n",
      " loss = 2.28173279331465e-05\n",
      " loss = 3.002441060414522e-05\n",
      " loss = 2.6225744843805774e-05\n",
      " loss = 2.6164601318834978e-05\n",
      " loss = 2.6103628515577932e-05\n",
      " loss = 2.2489605245753704e-05\n",
      " loss = 2.5979893449242215e-05\n",
      " loss = 2.2160640947839425e-05\n",
      " loss = 2.5861503759764523e-05\n",
      " loss = 2.184685066052558e-05\n",
      " loss = 2.5747959474348712e-05\n",
      " loss = 2.983026728197998e-05\n",
      " loss = 1.7747831581651797e-05\n",
      " loss = 3.423111023061751e-05\n",
      " loss = 3.335746153188857e-05\n",
      " loss = 3.2506110154036456e-05\n",
      " loss = 2.8537413784982486e-05\n",
      " loss = 2.830044432266365e-05\n",
      " loss = 2.253890125320635e-05\n",
      " loss = 1.9267866841375573e-05\n",
      " loss = 2.5151117358072083e-05\n",
      " loss = 2.5092463202280734e-05\n",
      " loss = 2.8430179934339737e-05\n",
      " loss = 2.1775047245182522e-05\n",
      " loss = 3.1733518813094905e-05\n",
      " loss = 2.487289865371907e-05\n",
      " loss = 3.088611150580253e-05\n",
      " loss = 2.2124103925029312e-05\n",
      " loss = 2.4707095144107422e-05\n",
      " loss = 2.464820682810063e-05\n",
      " loss = 2.4589525529923352e-05\n",
      " loss = 3.034673327847028e-05\n",
      " loss = 2.4502435915948287e-05\n",
      " loss = 2.4442858182187085e-05\n",
      " loss = 2.1811990887477432e-05\n",
      " loss = 2.4308863375548228e-05\n",
      " loss = 2.7045438176319894e-05\n",
      " loss = 2.4207389754428026e-05\n",
      " loss = 2.1515159308093105e-05\n",
      " loss = 2.407693056087251e-05\n",
      " loss = 2.687101589899052e-05\n",
      " loss = 2.6650245987503706e-05\n",
      " loss = 2.1433028392248597e-05\n",
      " loss = 2.3860069299484935e-05\n",
      " loss = 2.6523750857834066e-05\n",
      " loss = 2.1213490279815263e-05\n",
      " loss = 2.6439315109195975e-05\n",
      " loss = 2.3646173560940295e-05\n",
      " loss = 2.6181908424141475e-05\n",
      " loss = 2.597092690595751e-05\n",
      " loss = 2.3510747910637126e-05\n",
      " loss = 2.345279338219379e-05\n",
      " loss = 2.56908122439468e-05\n",
      " loss = 2.3358803016982437e-05\n",
      " loss = 2.3300697953227877e-05\n",
      " loss = 1.8891750982646728e-05\n",
      " loss = 2.3148944939146833e-05\n",
      " loss = 2.5672791717358533e-05\n",
      " loss = 2.064127510942701e-05\n",
      " loss = 2.559259337098062e-05\n",
      " loss = 2.0498517968212944e-05\n",
      " loss = 2.815122315865618e-05\n",
      " loss = 2.0554889444622358e-05\n",
      " loss = 2.526650856469778e-05\n",
      " loss = 2.7390149613201436e-05\n",
      " loss = 2.669109637168075e-05\n",
      " loss = 2.436357662804374e-05\n",
      " loss = 2.1195286820600693e-05\n",
      " loss = 2.089037840288803e-05\n",
      " loss = 2.443231753679931e-05\n",
      " loss = 2.2483377841716138e-05\n",
      " loss = 2.2425911141888015e-05\n",
      " loss = 2.236877217372262e-05\n",
      " loss = 2.2311953602077196e-05\n",
      " loss = 2.2255448330023242e-05\n",
      " loss = 2.2199249490855434e-05\n",
      " loss = 2.4060058437778227e-05\n",
      " loss = 2.2112314593310076e-05\n",
      " loss = 2.3846026683768424e-05\n",
      " loss = 2.5305491332606473e-05\n",
      " loss = 2.33453847963004e-05\n",
      " loss = 2.434859693577176e-05\n",
      " loss = 2.2025438177146148e-05\n",
      " loss = 2.2856426216185662e-05\n",
      " loss = 2.1943569275628458e-05\n",
      " loss = 2.2681040731849986e-05\n",
      " loss = 2.1862120076763652e-05\n",
      " loss = 2.2509363451362326e-05\n",
      " loss = 2.2935704627124487e-05\n",
      " loss = 2.1815151987626884e-05\n",
      " loss = 2.174822851633564e-05\n",
      " loss = 2.1682024158815072e-05\n",
      " loss = 2.1616518249049125e-05\n",
      " loss = 2.1080769534669302e-05\n",
      " loss = 2.074664884214945e-05\n",
      " loss = 2.225157820726008e-05\n",
      " loss = 2.053942446156948e-05\n",
      " loss = 2.2213038391686e-05\n",
      " loss = 2.119829764312909e-05\n",
      " loss = 2.0238127632637523e-05\n",
      " loss = 2.2153283370237156e-05\n",
      " loss = 2.10209854319901e-05\n",
      " loss = 2.197635701864096e-05\n",
      " loss = 2.0942527765373078e-05\n",
      " loss = 2.0883785423036545e-05\n",
      " loss = 1.9867672171143918e-05\n",
      " loss = 1.956863020788872e-05\n",
      " loss = 2.2009367439789192e-05\n",
      " loss = 2.18490227559403e-05\n",
      " loss = 1.841185189409241e-05\n",
      " loss = 2.1940755500622332e-05\n",
      " loss = 1.913309114798019e-05\n",
      " loss = 2.037408352666912e-05\n",
      " loss = 2.0321536604240016e-05\n",
      " loss = 2.3406562770936395e-05\n",
      " loss = 2.154045739816658e-05\n",
      " loss = 2.0249095197051812e-05\n",
      " loss = 2.1362868843421454e-05\n",
      " loss = 2.121028674693779e-05\n",
      " loss = 2.0152835995866062e-05\n",
      " loss = 2.1986519165244577e-05\n",
      " loss = 2.1425377743628917e-05\n",
      " loss = 2.0511856225419972e-05\n",
      " loss = 2.0131427823092973e-05\n",
      " loss = 2.0662253957607446e-05\n",
      " loss = 2.012113580022973e-05\n",
      " loss = 1.9997025761332898e-05\n",
      " loss = 1.987556369234412e-05\n",
      " loss = 2.071800569368627e-05\n",
      " loss = 1.9969557232809057e-05\n",
      " loss = 1.984544148253412e-05\n",
      " loss = 1.987842431955607e-05\n",
      " loss = 1.971393328520423e-05\n",
      " loss = 1.9594213392841543e-05\n",
      " loss = 1.9794282878540617e-05\n",
      " loss = 1.920866139989557e-05\n",
      " loss = 1.977865320168362e-05\n",
      " loss = 2.017813739809176e-05\n",
      " loss = 1.9338536056918662e-05\n",
      " loss = 1.9926038414030104e-05\n",
      " loss = 1.958455586283898e-05\n",
      " loss = 1.925594857974633e-05\n",
      " loss = 1.9520684719920218e-05\n",
      " loss = 1.9039641763302272e-05\n",
      " loss = 1.9878634315401713e-05\n",
      " loss = 1.903356892176818e-05\n",
      " loss = 1.9358117765298666e-05\n",
      " loss = 1.90273171937822e-05\n",
      " loss = 1.947359823141932e-05\n",
      " loss = 1.897659174697182e-05\n",
      " loss = 1.8770275687856233e-05\n",
      " loss = 1.8659275327775612e-05\n",
      " loss = 1.9032373729568248e-05\n",
      " loss = 1.9389295717299603e-05\n",
      " loss = 1.8637291026186566e-05\n",
      " loss = 1.9148341743671848e-05\n",
      " loss = 1.8821059813768903e-05\n",
      " loss = 1.8716020335233983e-05\n",
      " loss = 1.8600283604311393e-05\n",
      " loss = 1.85409114358234e-05\n",
      " loss = 1.829120742747996e-05\n",
      " loss = 1.8782799340859627e-05\n",
      " loss = 1.8659463507815593e-05\n",
      " loss = 1.808373906730136e-05\n",
      " loss = 1.8213137020193934e-05\n",
      " loss = 1.769729081288784e-05\n",
      " loss = 1.7418877038964916e-05\n",
      " loss = 1.8814588948290994e-05\n",
      " loss = 1.7965776021665752e-05\n",
      " loss = 1.791508616409672e-05\n",
      " loss = 1.786482956114773e-05\n",
      " loss = 1.8633658365591796e-05\n",
      " loss = 1.7798251129353543e-05\n",
      " loss = 1.9228314476577855e-05\n",
      " loss = 1.7768410424337226e-05\n",
      " loss = 1.8761407866320625e-05\n",
      " loss = 1.7742688370166723e-05\n",
      " loss = 1.7688761495692123e-05\n",
      " loss = 1.7635401408464224e-05\n",
      " loss = 1.7975119605812118e-05\n",
      " loss = 1.699458275948518e-05\n",
      " loss = 1.6209435847955254e-05\n",
      " loss = 1.8261425806752488e-05\n",
      " loss = 1.813225333261216e-05\n",
      " loss = 1.7293552596705362e-05\n",
      " loss = 1.7244928876199956e-05\n",
      " loss = 1.7973583305429497e-05\n",
      " loss = 1.8517601276671613e-05\n",
      " loss = 1.678018458067578e-05\n",
      " loss = 1.651568980488361e-05\n",
      " loss = 1.7806644524138398e-05\n",
      " loss = 1.6352614398730922e-05\n",
      " loss = 1.693886282369516e-05\n",
      " loss = 1.602677200122394e-05\n",
      " loss = 1.5788347155701963e-05\n",
      " loss = 1.5558789547498693e-05\n",
      " loss = 1.5337748702757055e-05\n",
      " loss = 1.662541176707693e-05\n",
      " loss = 1.6583977546167183e-05\n",
      " loss = 1.654274759397856e-05\n",
      " loss = 1.8050725801069428e-05\n",
      " loss = 1.6477040072440834e-05\n",
      " loss = 1.4984932667770127e-05\n",
      " loss = 1.637904874566403e-05\n",
      " loss = 1.795119972208592e-05\n",
      " loss = 1.6313328150934686e-05\n",
      " loss = 1.6272793103260745e-05\n",
      " loss = 1.470441415048561e-05\n",
      " loss = 1.9521856215179027e-05\n",
      " loss = 1.6167695558373024e-05\n",
      " loss = 1.468260605062352e-05\n",
      " loss = 1.7661019523994613e-05\n",
      " loss = 1.7522177723569127e-05\n",
      " loss = 1.602344948371093e-05\n",
      " loss = 1.598308582820422e-05\n",
      " loss = 1.7340581261689585e-05\n",
      " loss = 1.5920365931209376e-05\n",
      " loss = 1.587989575354355e-05\n",
      " loss = 1.451562701703078e-05\n",
      " loss = 1.725112102989661e-05\n",
      " loss = 1.304516858481934e-05\n",
      " loss = 1.5691455326915443e-05\n",
      " loss = 1.4016949803798243e-05\n",
      " loss = 1.560505781244105e-05\n",
      " loss = 1.5567720354160997e-05\n",
      " loss = 1.9108319447629472e-05\n",
      " loss = 1.3960823305501304e-05\n",
      " loss = 1.7153181513414864e-05\n",
      " loss = 1.859193170691591e-05\n",
      " loss = 1.4084094909453048e-05\n",
      " loss = 1.3891692152372519e-05\n",
      " loss = 1.3706378434889015e-05\n",
      " loss = 1.7028015446183063e-05\n",
      " loss = 1.5250762037449423e-05\n",
      " loss = 1.6863006960478388e-05\n",
      " loss = 1.5188186425800237e-05\n",
      " loss = 1.670259794336221e-05\n",
      " loss = 1.3683238096340449e-05\n",
      " loss = 1.6653901019593084e-05\n",
      " loss = 1.652128103058576e-05\n",
      " loss = 1.5029094759978525e-05\n",
      " loss = 1.4991670053303335e-05\n",
      " loss = 1.6346466582085534e-05\n",
      " loss = 1.4932218070452828e-05\n",
      " loss = 1.2287926497906049e-05\n",
      " loss = 1.483082495609882e-05\n",
      " loss = 1.3228691733006925e-05\n",
      " loss = 1.4749675403045673e-05\n",
      " loss = 1.4714451406087516e-05\n",
      " loss = 1.6388572954637632e-05\n",
      " loss = 1.6254594062061764e-05\n",
      " loss = 1.3131927927369742e-05\n",
      " loss = 1.6204694717838513e-05\n",
      " loss = 1.455677420536972e-05\n",
      " loss = 1.2993649892235688e-05\n",
      " loss = 1.1171614152710201e-05\n",
      " loss = 1.4430170536010358e-05\n",
      " loss = 1.2505247035775465e-05\n",
      " loss = 1.235367744694368e-05\n",
      " loss = 1.2207610810797058e-05\n",
      " loss = 1.652305575016304e-05\n",
      " loss = 1.8492065180802055e-05\n",
      " loss = 1.6124704845915012e-05\n",
      " loss = 1.2412005109624511e-05\n",
      " loss = 1.2259178123337903e-05\n",
      " loss = 1.6143849423904496e-05\n",
      " loss = 1.0281579734980831e-05\n",
      " loss = 1.1934588427392745e-05\n",
      " loss = 1.6266915266643525e-05\n",
      " loss = 1.399776888377878e-05\n",
      " loss = 1.3965507526209457e-05\n",
      " loss = 1.3933323871637727e-05\n",
      " loss = 1.601973590241828e-05\n",
      " loss = 1.5878317676819308e-05\n",
      " loss = 1.5740317451179833e-05\n",
      " loss = 1.3807683197817266e-05\n",
      " loss = 1.5577077454044907e-05\n",
      " loss = 1.5445702382100563e-05\n",
      " loss = 1.6913698718693214e-05\n",
      " loss = 1.5094115366344158e-05\n",
      " loss = 1.3684359876997744e-05\n",
      " loss = 1.4953610583484527e-05\n",
      " loss = 1.3629827211481376e-05\n",
      " loss = 1.2374616310121012e-05\n",
      " loss = 1.4892016713047108e-05\n",
      " loss = 1.1034719982032064e-05\n",
      " loss = 1.3472701898706616e-05\n",
      " loss = 1.1957609334137918e-05\n",
      " loss = 1.3400522030103522e-05\n",
      " loss = 1.3368714167435013e-05\n",
      " loss = 1.1727825247544164e-05\n",
      " loss = 1.673900157445833e-05\n",
      " loss = 1.1764543918235284e-05\n",
      " loss = 1.1614824203041948e-05\n",
      " loss = 1.3206472452150588e-05\n",
      " loss = 1.4914799122812876e-05\n",
      " loss = 1.150871438216498e-05\n",
      " loss = 1.4861096933315133e-05\n",
      " loss = 1.3086807079987788e-05\n",
      " loss = 1.305600768332479e-05\n",
      " loss = 1.1367986437820221e-05\n",
      " loss = 1.12285445667923e-05\n",
      " loss = 1.2959831210737548e-05\n",
      " loss = 1.1063846297584394e-05\n",
      " loss = 1.0934841231779481e-05\n",
      " loss = 1.2873375010935086e-05\n",
      " loss = 1.284378571881651e-05\n",
      " loss = 1.2814264991634497e-05\n",
      " loss = 1.2784812651876962e-05\n",
      " loss = 1.6853279824323404e-05\n",
      " loss = 1.0871886713546472e-05\n",
      " loss = 1.0745558920846925e-05\n",
      " loss = 1.2667294940127611e-05\n",
      " loss = 1.4678030468666551e-05\n",
      " loss = 1.0666520287123252e-05\n",
      " loss = 1.258003775599335e-05\n",
      " loss = 1.2551129809106304e-05\n",
      " loss = 8.46870614710445e-06\n",
      " loss = 1.2504227986440406e-05\n",
      " loss = 1.2475455307190084e-05\n",
      " loss = 1.0247628029586417e-05\n",
      " loss = 1.2425918562942052e-05\n",
      " loss = 1.2397239629641291e-05\n",
      " loss = 1.4637169181971532e-05\n",
      " loss = 1.0165312990837612e-05\n",
      " loss = 1.4564849263879739e-05\n",
      " loss = 1.0123254983717694e-05\n",
      " loss = 1.6731294921727793e-05\n",
      " loss = 1.4258743954240268e-05\n",
      " loss = 1.4128899427239566e-05\n",
      " loss = 1.4002219273994648e-05\n",
      " loss = 1.2121812243371064e-05\n",
      " loss = 1.3850666756044798e-05\n",
      " loss = 1.2066538992363389e-05\n",
      " loss = 1.3703777952094597e-05\n",
      " loss = 1.358632773287327e-05\n",
      " loss = 1.1988403563868935e-05\n",
      " loss = 1.3448093596504473e-05\n",
      " loss = 1.3336224763033842e-05\n",
      " loss = 1.0603792137086419e-05\n",
      " loss = 1.4705645691729016e-05\n",
      " loss = 1.0633995149175627e-05\n",
      " loss = 1.182934789967634e-05\n",
      " loss = 1.1801015357545359e-05\n",
      " loss = 1.0424562309051227e-05\n",
      " loss = 1.3186035524452758e-05\n",
      " loss = 1.0356680458160566e-05\n",
      " loss = 1.4599177501506576e-05\n",
      " loss = 1.1667426996342952e-05\n",
      " loss = 1.1639346932397983e-05\n",
      " loss = 1.2905799525896584e-05\n",
      " loss = 1.1591224419958855e-05\n",
      " loss = 1.034428749911363e-05\n",
      " loss = 1.1527664381170244e-05\n",
      " loss = 1.1500117117598817e-05\n",
      " loss = 1.147266901406251e-05\n",
      " loss = 1.2782318247044903e-05\n",
      " loss = 8.918272257740961e-06\n",
      " loss = 1.1385722837369826e-05\n",
      " loss = 9.915312513720423e-06\n",
      " loss = 1.286507375195229e-05\n",
      " loss = 1.2755461623680432e-05\n",
      " loss = 1.2648472750441158e-05\n",
      " loss = 1.1262069111924345e-05\n",
      " loss = 9.946750834777245e-06\n",
      " loss = 1.1202963182632113e-05\n",
      " loss = 1.2563573574609488e-05\n",
      " loss = 1.2459132271994153e-05\n",
      " loss = 1.2357172757368671e-05\n",
      " loss = 1.111578139782173e-05\n",
      " loss = 1.3389547550401165e-05\n",
      " loss = 1.009766560609022e-05\n",
      " loss = 1.2125673528156753e-05\n",
      " loss = 1.0021181993450364e-05\n",
      " loss = 1.2091478236479789e-05\n",
      " loss = 1.1996097116075478e-05\n",
      " loss = 1.0954841813859059e-05\n",
      " loss = 1.0927331643052996e-05\n",
      " loss = 1.0899963551972093e-05\n",
      " loss = 9.890519976562867e-06\n",
      " loss = 9.756491269871449e-06\n",
      " loss = 1.0801192978100253e-05\n",
      " loss = 9.59419365685351e-06\n",
      " loss = 1.2015683698100406e-05\n",
      " loss = 9.529795966775489e-06\n",
      " loss = 1.1976282233583282e-05\n",
      " loss = 9.466495091206503e-06\n",
      " loss = 9.345633370499797e-06\n",
      " loss = 1.1995206537423672e-05\n",
      " loss = 1.3197461687304463e-05\n",
      " loss = 1.0576903479065003e-05\n",
      " loss = 1.2849417850846829e-05\n",
      " loss = 1.0542353021520458e-05\n",
      " loss = 9.516887834383614e-06\n",
      " loss = 1.1573803902213709e-05\n",
      " loss = 1.0464507189305576e-05\n",
      " loss = 1.146509959883277e-05\n",
      " loss = 1.04225519327996e-05\n",
      " loss = 1.1359332631841248e-05\n",
      " loss = 1.2161323411276966e-05\n",
      " loss = 1.1115414160698881e-05\n",
      " loss = 1.0367315248733335e-05\n",
      " loss = 1.0339911234230952e-05\n",
      " loss = 9.616435599632291e-06\n",
      " loss = 1.027210174422071e-05\n",
      " loss = 9.439661867556913e-06\n",
      " loss = 1.2008589741071005e-05\n",
      " loss = 9.458045603486944e-06\n",
      " loss = 1.0167312358457384e-05\n",
      " loss = 1.014158173039687e-05\n",
      " loss = 1.0981622573293988e-05\n",
      " loss = 1.089787087023217e-05\n",
      " loss = 1.0816056704822928e-05\n",
      " loss = 1.0076385631446643e-05\n",
      " loss = 1.0049831036235832e-05\n",
      " loss = 1.0711970936827689e-05\n",
      " loss = 9.389683199501456e-06\n",
      " loss = 8.536005064766873e-06\n",
      " loss = 9.921704313432177e-06\n",
      " loss = 8.996933595938049e-06\n",
      " loss = 8.87520007170462e-06\n",
      " loss = 1.1980384606926992e-05\n",
      " loss = 9.823572276664258e-06\n",
      " loss = 1.073388982999349e-05\n",
      " loss = 9.784431921381886e-06\n",
      " loss = 8.884158225693271e-06\n",
      " loss = 8.763582771419627e-06\n",
      " loss = 1.1791540255793801e-05\n",
      " loss = 9.687433079542279e-06\n",
      " loss = 8.752681731778136e-06\n",
      " loss = 1.0627606850944526e-05\n",
      " loss = 8.68839285658145e-06\n",
      " loss = 9.584431096726267e-06\n",
      " loss = 1.159889671013178e-05\n",
      " loss = 9.553744650175294e-06\n",
      " loss = 8.646135488714823e-06\n",
      " loss = 8.52968581011956e-06\n",
      " loss = 8.41751964282694e-06\n",
      " loss = 9.440443186502726e-06\n",
      " loss = 8.282715632127477e-06\n",
      " loss = 9.392250360901789e-06\n",
      " loss = 1.058605950995628e-05\n",
      " loss = 9.351435144752136e-06\n",
      " loss = 9.3293346377774e-06\n",
      " loss = 9.307305722241045e-06\n",
      " loss = 8.128589002081675e-06\n",
      " loss = 6.795557361725125e-06\n",
      " loss = 9.237534070241814e-06\n",
      " loss = 7.83888968384543e-06\n",
      " loss = 9.196272346866606e-06\n",
      " loss = 7.729774767897233e-06\n",
      " loss = 6.129966421216689e-06\n",
      " loss = 9.144558727876512e-06\n",
      " loss = 1.0766606082852424e-05\n",
      " loss = 1.0666029415415893e-05\n",
      " loss = 9.07258437828473e-06\n",
      " loss = 7.55960081476225e-06\n",
      " loss = 5.919348427106672e-06\n",
      " loss = 1.0714663301579995e-05\n",
      " loss = 1.0613139290581244e-05\n",
      " loss = 7.43050054767278e-06\n",
      " loss = 1.0561855332658815e-05\n",
      " loss = 8.931028898688455e-06\n",
      " loss = 8.910505188791725e-06\n",
      " loss = 1.1937800294523963e-05\n",
      " loss = 7.478708462595206e-06\n",
      " loss = 1.1746969826708618e-05\n",
      " loss = 1.14471628723336e-05\n",
      " loss = 9.978587092706344e-06\n",
      " loss = 7.6740555572052e-06\n",
      " loss = 7.579685933119694e-06\n",
      " loss = 7.48874900981889e-06\n",
      " loss = 8.719548655933507e-06\n",
      " loss = 8.699447744387142e-06\n",
      " loss = 6.04627774770798e-06\n",
      " loss = 1.0112063005871602e-05\n",
      " loss = 8.640925315740417e-06\n",
      " loss = 5.867290635789451e-06\n",
      " loss = 8.607965407891107e-06\n",
      " loss = 7.0869048539263936e-06\n",
      " loss = 1.0134976142476705e-05\n",
      " loss = 5.566060008299023e-06\n",
      " loss = 6.924506104659116e-06\n",
      " loss = 1.020013675068035e-05\n",
      " loss = 8.500491291239326e-06\n",
      " loss = 1.0075479468698371e-05\n",
      " loss = 6.930613521609601e-06\n",
      " loss = 8.441603217060296e-06\n",
      " loss = 9.998428835840934e-06\n",
      " loss = 6.889925855010466e-06\n",
      " loss = 9.947972237345212e-06\n",
      " loss = 8.358087086207122e-06\n",
      " loss = 5.357543240771729e-06\n",
      " loss = 8.331773038387892e-06\n",
      " loss = 6.708776069137642e-06\n",
      " loss = 9.959070062896786e-06\n",
      " loss = 1.1450920298888251e-05\n",
      " loss = 8.242778200538333e-06\n",
      " loss = 6.770565896587719e-06\n",
      " loss = 9.720567278317065e-06\n",
      " loss = 9.629053149869756e-06\n",
      " loss = 9.539788350248098e-06\n",
      " loss = 5.5187563450391015e-06\n",
      " loss = 8.129420000241986e-06\n",
      " loss = 9.538990288901736e-06\n",
      " loss = 6.725581956452089e-06\n",
      " loss = 8.073398529375888e-06\n",
      " loss = 9.470754945185125e-06\n",
      " loss = 5.331105763390571e-06\n",
      " loss = 8.022613080463735e-06\n",
      " loss = 6.540680032666698e-06\n",
      " loss = 7.991537364663375e-06\n",
      " loss = 7.973022154493175e-06\n",
      " loss = 7.954554780863685e-06\n",
      " loss = 7.936134955478721e-06\n",
      " loss = 7.917762396704366e-06\n",
      " loss = 6.4129902728107415e-06\n",
      " loss = 7.887724499066428e-06\n",
      " loss = 6.337155542007639e-06\n",
      " loss = 9.442193675181738e-06\n",
      " loss = 6.315244127267788e-06\n",
      " loss = 6.252933711836371e-06\n",
      " loss = 9.430616820459089e-06\n",
      " loss = 7.785127319801287e-06\n",
      " loss = 7.766938690848099e-06\n",
      " loss = 6.211397810960654e-06\n",
      " loss = 9.325952008459146e-06\n",
      " loss = 9.23441411982972e-06\n",
      " loss = 6.230617999466405e-06\n",
      " loss = 9.185129253037697e-06\n",
      " loss = 9.096483678859013e-06\n",
      " loss = 6.248019308929886e-06\n",
      " loss = 7.616815097717865e-06\n",
      " loss = 9.026648950543301e-06\n",
      " loss = 8.941011717979903e-06\n",
      " loss = 1.0160383427099542e-05\n",
      " loss = 7.531763705136982e-06\n",
      " loss = 7.514440001434857e-06\n",
      " loss = 9.859929349607455e-06\n",
      " loss = 6.413605145099789e-06\n",
      " loss = 6.338382248133263e-06\n",
      " loss = 7.445302003939752e-06\n",
      " loss = 8.60584782833932e-06\n",
      " loss = 6.2906849018822e-06\n",
      " loss = 6.218846722182797e-06\n",
      " loss = 6.149595687913161e-06\n",
      " loss = 7.365645215125566e-06\n",
      " loss = 6.069732290948397e-06\n",
      " loss = 7.336078149454968e-06\n",
      " loss = 5.9933354973970875e-06\n",
      " loss = 7.307470006997516e-06\n",
      " loss = 4.549835728062529e-06\n",
      " loss = 8.760197081618932e-06\n",
      " loss = 7.262630305780384e-06\n",
      " loss = 8.651364631712701e-06\n",
      " loss = 4.532544077522005e-06\n",
      " loss = 7.218767017767342e-06\n",
      " loss = 8.642485411325313e-06\n",
      " loss = 7.178437444391567e-06\n",
      " loss = 8.535746622387012e-06\n",
      " loss = 7.139636797726345e-06\n",
      " loss = 8.432636654182759e-06\n",
      " loss = 8.353271419840148e-06\n",
      " loss = 8.275856760249854e-06\n",
      " loss = 7.063644692936265e-06\n",
      " loss = 5.91270687873512e-06\n",
      " loss = 7.03367154281694e-06\n",
      " loss = 7.017513237748262e-06\n",
      " loss = 8.181834749453415e-06\n",
      " loss = 6.982817070176017e-06\n",
      " loss = 5.84440518135667e-06\n",
      " loss = 6.953198844513784e-06\n",
      " loss = 6.937225309668453e-06\n",
      " loss = 4.586204647160216e-06\n",
      " loss = 6.912986862136359e-06\n",
      " loss = 6.897034651962244e-06\n",
      " loss = 8.140930104659593e-06\n",
      " loss = 6.861018647122473e-06\n",
      " loss = 8.044917503080468e-06\n",
      " loss = 6.826246438806352e-06\n",
      " loss = 5.669067343959746e-06\n",
      " loss = 7.988469373385173e-06\n",
      " loss = 9.049930872600947e-06\n",
      " loss = 6.759994046506942e-06\n",
      " loss = 5.715783678465348e-06\n",
      " loss = 7.809609022985833e-06\n",
      " loss = 7.739519627779317e-06\n",
      " loss = 6.697372261567226e-06\n",
      " loss = 6.681884051256161e-06\n",
      " loss = 5.6927249053284825e-06\n",
      " loss = 6.651577321115355e-06\n",
      " loss = 7.660087643239003e-06\n",
      " loss = 7.592201739050828e-06\n",
      " loss = 6.605246370120623e-06\n",
      " loss = 5.668480754042607e-06\n",
      " loss = 4.628535052075788e-06\n",
      " loss = 6.5616336686639905e-06\n",
      " loss = 5.475255650152482e-06\n",
      " loss = 5.415216818273039e-06\n",
      " loss = 5.357327592758728e-06\n",
      " loss = 7.722214715707669e-06\n",
      " loss = 7.649240079244378e-06\n",
      " loss = 7.57806077713389e-06\n",
      " loss = 7.508625851798206e-06\n",
      " loss = 7.440885808014402e-06\n",
      " loss = 7.3747925709158095e-06\n",
      " loss = 6.409910425846412e-06\n",
      " loss = 5.494079977724941e-06\n",
      " loss = 5.429346160600799e-06\n",
      " loss = 4.367624181371365e-06\n",
      " loss = 6.3559839429609565e-06\n",
      " loss = 4.157425413273754e-06\n",
      " loss = 5.1499528470849095e-06\n",
      " loss = 6.325040645229493e-06\n",
      " loss = 6.310338825755308e-06\n",
      " loss = 3.863472453762087e-06\n",
      " loss = 6.2934261539125044e-06\n",
      " loss = 6.278589026132011e-06\n",
      " loss = 6.263798774478265e-06\n",
      " loss = 8.815760260901979e-06\n",
      " loss = 6.2224732999882e-06\n",
      " loss = 6.208053029000979e-06\n",
      " loss = 6.193670138787862e-06\n",
      " loss = 5.010195580354558e-06\n",
      " loss = 7.3806047823791725e-06\n",
      " loss = 6.150662076233945e-06\n",
      " loss = 6.1364276165733545e-06\n",
      " loss = 8.420695873669745e-06\n",
      " loss = 6.100299349394079e-06\n",
      " loss = 8.185755404739248e-06\n",
      " loss = 5.113417997300406e-06\n",
      " loss = 5.056175889081533e-06\n",
      " loss = 5.000989433607681e-06\n",
      " loss = 6.033744912873124e-06\n",
      " loss = 4.937657251627774e-06\n",
      " loss = 6.010085140545369e-06\n",
      " loss = 8.234495543954669e-06\n",
      " loss = 3.92556644632891e-06\n",
      " loss = 8.19254304487605e-06\n",
      " loss = 4.929230013010972e-06\n",
      " loss = 6.997046602341934e-06\n",
      " loss = 5.919946007308507e-06\n",
      " loss = 4.897147369028525e-06\n",
      " loss = 4.844730141155655e-06\n",
      " loss = 5.886157703306849e-06\n",
      " loss = 6.960259494465005e-06\n",
      " loss = 5.85516401297459e-06\n",
      " loss = 5.841688782537819e-06\n",
      " loss = 7.8934860275481e-06\n",
      " loss = 5.8096402964641155e-06\n",
      " loss = 4.856846356722887e-06\n",
      " loss = 5.785102522262032e-06\n",
      " loss = 4.792570676974703e-06\n",
      " loss = 4.741062621893621e-06\n",
      " loss = 5.751848858067322e-06\n",
      " loss = 7.851364366387368e-06\n",
      " loss = 4.752694518788626e-06\n",
      " loss = 6.715412332426692e-06\n",
      " loss = 5.69249203471193e-06\n",
      " loss = 5.679414714072833e-06\n",
      " loss = 7.578053911967952e-06\n",
      " loss = 6.517335454903704e-06\n",
      " loss = 4.813382938354723e-06\n",
      " loss = 4.757554547004899e-06\n",
      " loss = 6.520813898645944e-06\n",
      " loss = 5.598058107156488e-06\n",
      " loss = 5.585169846093639e-06\n",
      " loss = 5.572312162330092e-06\n",
      " loss = 4.6982159882013645e-06\n",
      " loss = 5.548024286458847e-06\n",
      " loss = 5.535277064052578e-06\n",
      " loss = 4.6232420962467156e-06\n",
      " loss = 3.6328488452909704e-06\n",
      " loss = 6.5260565476650734e-06\n",
      " loss = 6.464452378230282e-06\n",
      " loss = 4.543466475520239e-06\n",
      " loss = 4.4946883705566805e-06\n",
      " loss = 4.447651192576241e-06\n",
      " loss = 5.446642430805585e-06\n",
      " loss = 6.473792206247992e-06\n",
      " loss = 4.422576083046991e-06\n",
      " loss = 5.408824808855894e-06\n",
      " loss = 3.342102682103428e-06\n",
      " loss = 3.187698091181586e-06\n",
      " loss = 4.2171824491228064e-06\n",
      " loss = 5.3883755244466656e-06\n",
      " loss = 6.576608607684786e-06\n",
      " loss = 6.509727924415895e-06\n",
      " loss = 5.335973952803465e-06\n",
      " loss = 5.323385731395248e-06\n",
      " loss = 5.310837554392881e-06\n",
      " loss = 4.207622469021644e-06\n",
      " loss = 5.2919287601327125e-06\n",
      " loss = 6.396883005032296e-06\n",
      " loss = 6.333291081361959e-06\n",
      " loss = 5.243365030477147e-06\n",
      " loss = 5.231155358869773e-06\n",
      " loss = 5.218979285595069e-06\n",
      " loss = 4.1931768702767495e-06\n",
      " loss = 3.104243272139159e-06\n",
      " loss = 5.199235366074642e-06\n",
      " loss = 5.186838509157497e-06\n",
      " loss = 5.174485384856299e-06\n",
      " loss = 5.162175379657056e-06\n",
      " loss = 6.243324188683962e-06\n",
      " loss = 7.2305368024049105e-06\n",
      " loss = 4.142261404501394e-06\n",
      " loss = 6.104666745638626e-06\n",
      " loss = 6.045767020687747e-06\n",
      " loss = 5.071066514284091e-06\n",
      " loss = 5.059380345979501e-06\n",
      " loss = 5.047722278367904e-06\n",
      " loss = 5.943658329708918e-06\n",
      " loss = 5.8881225914503715e-06\n",
      " loss = 5.833949275151277e-06\n",
      " loss = 6.5671861993234726e-06\n",
      " loss = 4.9826174728126055e-06\n",
      " loss = 5.679835523782983e-06\n",
      " loss = 5.630716249134025e-06\n",
      " loss = 5.582777450663634e-06\n",
      " loss = 5.5359856884662186e-06\n",
      " loss = 5.490308482142323e-06\n",
      " loss = 4.398317747474654e-06\n",
      " loss = 4.34115708173816e-06\n",
      " loss = 4.2860901007825335e-06\n",
      " loss = 4.233034102644662e-06\n",
      " loss = 4.86784115198602e-06\n",
      " loss = 4.8565488363884355e-06\n",
      " loss = 4.845286171081212e-06\n",
      " loss = 6.208045826355053e-06\n",
      " loss = 5.4371083965296204e-06\n",
      " loss = 4.815144769254315e-06\n",
      " loss = 4.803724131934627e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 4.792341826164504e-06\n",
      " loss = 4.198024625483326e-06\n",
      " loss = 4.768036136067336e-06\n",
      " loss = 4.1333017682330005e-06\n",
      " loss = 4.7448672045211185e-06\n",
      " loss = 4.071638172894874e-06\n",
      " loss = 4.722730581428532e-06\n",
      " loss = 4.711826023056142e-06\n",
      " loss = 5.399674189187808e-06\n",
      " loss = 3.365546066038751e-06\n",
      " loss = 4.679803598494867e-06\n",
      " loss = 4.669038864300809e-06\n",
      " loss = 5.391185369782304e-06\n",
      " loss = 4.646865809290283e-06\n",
      " loss = 5.332009038442248e-06\n",
      " loss = 3.965508533048944e-06\n",
      " loss = 5.310412556408957e-06\n",
      " loss = 5.263693797061672e-06\n",
      " loss = 3.969284776204477e-06\n",
      " loss = 5.243276592803497e-06\n",
      " loss = 4.572309799562351e-06\n",
      " loss = 4.561667420789479e-06\n",
      " loss = 5.177898774319689e-06\n",
      " loss = 5.7257936662523125e-06\n",
      " loss = 4.011600025926977e-06\n",
      " loss = 5.082013031034746e-06\n",
      " loss = 5.039775614721309e-06\n",
      " loss = 4.0104824657669276e-06\n",
      " loss = 4.491130754820665e-06\n",
      " loss = 4.480461469846508e-06\n",
      " loss = 4.46982855320154e-06\n",
      " loss = 4.459231522493162e-06\n",
      " loss = 4.448669909850192e-06\n",
      " loss = 4.43814326143922e-06\n",
      " loss = 4.97205344238975e-06\n",
      " loss = 4.419228204591501e-06\n",
      " loss = 4.40868932514238e-06\n",
      " loss = 4.398187683557258e-06\n",
      " loss = 4.387722756129001e-06\n",
      " loss = 4.897932450211084e-06\n",
      " loss = 4.369226817791736e-06\n",
      " loss = 3.867649390602714e-06\n",
      " loss = 3.818230241999366e-06\n",
      " loss = 3.7706174594100777e-06\n",
      " loss = 4.9217063971604476e-06\n",
      " loss = 4.313966228873901e-06\n",
      " loss = 4.303870621867991e-06\n",
      " loss = 3.726077110523346e-06\n",
      " loss = 4.283066989163341e-06\n",
      " loss = 4.27312858319655e-06\n",
      " loss = 3.660467707880829e-06\n",
      " loss = 2.9814780049603257e-06\n",
      " loss = 4.245293878029718e-06\n",
      " loss = 4.235541651183417e-06\n",
      " loss = 3.5280579523922822e-06\n",
      " loss = 4.94621270361252e-06\n",
      " loss = 4.206383586346212e-06\n",
      " loss = 4.19672073890571e-06\n",
      " loss = 4.878393446433183e-06\n",
      " loss = 4.834184547179308e-06\n",
      " loss = 4.79105166870314e-06\n",
      " loss = 3.5635503680230436e-06\n",
      " loss = 4.146717003340579e-06\n",
      " loss = 3.5126213081788957e-06\n",
      " loss = 2.816677220724493e-06\n",
      " loss = 3.4042347104289335e-06\n",
      " loss = 4.8614848585188465e-06\n",
      " loss = 3.3899488698842114e-06\n",
      " loss = 4.837730688064892e-06\n",
      " loss = 5.500828378849355e-06\n",
      " loss = 3.427153298716598e-06\n",
      " loss = 2.7143773549463353e-06\n",
      " loss = 5.5273849270206454e-06\n",
      " loss = 4.044651726538845e-06\n",
      " loss = 4.704692423845997e-06\n",
      " loss = 3.387713414369996e-06\n",
      " loss = 4.016806636361325e-06\n",
      " loss = 4.007579544381072e-06\n",
      " loss = 3.998373649159375e-06\n",
      " loss = 3.326790603316927e-06\n",
      " loss = 3.2906003090914123e-06\n",
      " loss = 2.5365112126673554e-06\n",
      " loss = 3.1955753557737053e-06\n",
      " loss = 3.966396767498114e-06\n",
      " loss = 3.95710179787927e-06\n",
      " loss = 3.947834358023459e-06\n",
      " loss = 4.728648455797652e-06\n",
      " loss = 3.925728053179571e-06\n",
      " loss = 3.916612459118759e-06\n",
      " loss = 4.657734935804871e-06\n",
      " loss = 4.613181287974785e-06\n",
      " loss = 4.569727060910366e-06\n",
      " loss = 4.527341041590786e-06\n",
      " loss = 3.862794609305404e-06\n",
      " loss = 3.2318356270699402e-06\n",
      " loss = 5.147024288202677e-06\n",
      " loss = 2.6549113241970294e-06\n",
      " loss = 3.828652619178007e-06\n",
      " loss = 3.173316052351595e-06\n",
      " loss = 2.4653567715172743e-06\n",
      " loss = 3.8094703575166965e-06\n",
      " loss = 4.526470785236828e-06\n",
      " loss = 3.0946419693255326e-06\n",
      " loss = 3.7830272336405467e-06\n",
      " loss = 3.0572274949215262e-06\n",
      " loss = 3.7687740187658777e-06\n",
      " loss = 3.7599908467105895e-06\n",
      " loss = 5.221520478779844e-06\n",
      " loss = 3.060812795955957e-06\n",
      " loss = 4.432108208339572e-06\n",
      " loss = 5.0607058904509515e-06\n",
      " loss = 4.931546214178142e-06\n",
      " loss = 3.696859312251789e-06\n",
      " loss = 3.134228492227125e-06\n",
      " loss = 4.262462861062894e-06\n",
      " loss = 4.224383687645963e-06\n",
      " loss = 4.711730511389625e-06\n",
      " loss = 3.1874167392559048e-06\n",
      " loss = 3.6459860170118677e-06\n",
      " loss = 3.637497323993025e-06\n",
      " loss = 4.127748056583094e-06\n",
      " loss = 4.563557549903598e-06\n",
      " loss = 4.031401396959755e-06\n",
      " loss = 3.609261872354059e-06\n",
      " loss = 3.2088139351287443e-06\n",
      " loss = 3.167380036821187e-06\n",
      " loss = 3.1274625892122663e-06\n",
      " loss = 3.0890016933601577e-06\n",
      " loss = 3.5616123392116074e-06\n",
      " loss = 4.063181151673362e-06\n",
      " loss = 4.027976238335536e-06\n",
      " loss = 3.538006632285545e-06\n",
      " loss = 3.073034318056018e-06\n",
      " loss = 4.490887389522171e-06\n",
      " loss = 3.514320223650256e-06\n",
      " loss = 3.07359662605853e-06\n",
      " loss = 3.4966132409126465e-06\n",
      " loss = 3.0264442841022577e-06\n",
      " loss = 3.969579820134818e-06\n",
      " loss = 3.935381507097406e-06\n",
      " loss = 3.0279716426919653e-06\n",
      " loss = 2.9907109203133597e-06\n",
      " loss = 3.447417034656177e-06\n",
      " loss = 2.94666629985262e-06\n",
      " loss = 4.470346223352049e-06\n",
      " loss = 3.890020566925353e-06\n",
      " loss = 3.416579186157894e-06\n",
      " loss = 3.849838130089353e-06\n",
      " loss = 3.817462031790058e-06\n",
      " loss = 4.176404289138336e-06\n",
      " loss = 3.3917383219478337e-06\n",
      " loss = 3.3834403791709005e-06\n",
      " loss = 3.375178539500897e-06\n",
      " loss = 3.7141287588496978e-06\n",
      " loss = 3.6846494211041705e-06\n",
      " loss = 3.3563742945626703e-06\n",
      " loss = 3.0450986697473817e-06\n",
      " loss = 3.669392899866599e-06\n",
      " loss = 3.6404890901220017e-06\n",
      " loss = 3.0406113914293306e-06\n",
      " loss = 2.9989469979288554e-06\n",
      " loss = 3.994042783624696e-06\n",
      " loss = 3.0062492660243635e-06\n",
      " loss = 2.9654180885981586e-06\n",
      " loss = 3.2796794035633617e-06\n",
      " loss = 3.2717627055039167e-06\n",
      " loss = 3.2638770702293327e-06\n",
      " loss = 3.2560219933171354e-06\n",
      " loss = 3.6103321354715896e-06\n",
      " loss = 3.2425597700688405e-06\n",
      " loss = 2.8937101496788217e-06\n",
      " loss = 2.8560042413993814e-06\n",
      " loss = 3.611367741131238e-06\n",
      " loss = 3.953423310609159e-06\n",
      " loss = 2.8826329039736413e-06\n",
      " loss = 3.195787451301976e-06\n",
      " loss = 2.834875624222388e-06\n",
      " loss = 3.558942409900735e-06\n",
      " loss = 2.8159856844045548e-06\n",
      " loss = 2.3963885086778155e-06\n",
      " loss = 3.1542429203077356e-06\n",
      " loss = 2.2774639035032848e-06\n",
      " loss = 2.6559412837698994e-06\n",
      " loss = 3.1331147603021535e-06\n",
      " loss = 2.619637312256492e-06\n",
      " loss = 3.1198750047216657e-06\n",
      " loss = 2.5849525625141603e-06\n",
      " loss = 3.65706636445735e-06\n",
      " loss = 3.098392233936137e-06\n",
      " loss = 3.091273986925855e-06\n",
      " loss = 2.5621324926815855e-06\n",
      " loss = 3.078614158717071e-06\n",
      " loss = 3.6138391816442395e-06\n",
      " loss = 2.545549507287657e-06\n",
      " loss = 3.0573962381138885e-06\n",
      " loss = 2.5128048159914467e-06\n",
      " loss = 2.486399079200713e-06\n",
      " loss = 2.4609327030468275e-06\n",
      " loss = 3.0360974932442446e-06\n",
      " loss = 2.43215426940968e-06\n",
      " loss = 1.7919555410274358e-06\n",
      " loss = 3.682821262605959e-06\n",
      " loss = 3.013979930198697e-06\n",
      " loss = 3.6351647847858387e-06\n",
      " loss = 3.5992171090900183e-06\n",
      " loss = 3.564163619585079e-06\n",
      " loss = 2.977364892705245e-06\n",
      " loss = 4.0713795273864965e-06\n",
      " loss = 3.4637913462262174e-06\n",
      " loss = 3.4320771616063377e-06\n",
      " loss = 2.9446620748077114e-06\n",
      " loss = 2.481923904184005e-06\n",
      " loss = 2.9318432942181035e-06\n",
      " loss = 2.9251072535833805e-06\n",
      " loss = 3.3944055106671138e-06\n",
      " loss = 2.91092969478169e-06\n",
      " loss = 2.4519276953833955e-06\n",
      " loss = 2.424341949439887e-06\n",
      " loss = 2.8927693836662804e-06\n",
      " loss = 3.873469402906631e-06\n",
      " loss = 2.8775519952772875e-06\n",
      " loss = 2.422948568951273e-06\n",
      " loss = 3.8037856315069666e-06\n",
      " loss = 2.4326092904653902e-06\n",
      " loss = 2.4046206396102663e-06\n",
      " loss = 3.7805918281959334e-06\n",
      " loss = 2.4142375631311856e-06\n",
      " loss = 2.3865069194299846e-06\n",
      " loss = 2.359775767471905e-06\n",
      " loss = 3.3066695954026015e-06\n",
      " loss = 2.812658224038338e-06\n",
      " loss = 2.8061969506432547e-06\n",
      " loss = 3.2613659589616757e-06\n",
      " loss = 3.2318246974064143e-06\n",
      " loss = 2.3683086752686095e-06\n",
      " loss = 3.2181329252097402e-06\n",
      " loss = 2.772803998604642e-06\n",
      " loss = 3.5991251162604326e-06\n",
      " loss = 2.7602079692887805e-06\n",
      " loss = 2.379744186566136e-06\n",
      " loss = 2.3512768794105856e-06\n",
      " loss = 2.3238413223245647e-06\n",
      " loss = 3.1727392570603034e-06\n",
      " loss = 3.1442856894613295e-06\n",
      " loss = 2.721755779816957e-06\n",
      " loss = 2.7154600922486043e-06\n",
      " loss = 2.3143990517901715e-06\n",
      " loss = 2.7031245662704665e-06\n",
      " loss = 3.5272705572254767e-06\n",
      " loss = 3.06388918357386e-06\n",
      " loss = 2.6847558341504345e-06\n",
      " loss = 2.324949097036865e-06\n",
      " loss = 2.2968210630668013e-06\n",
      " loss = 2.665513441381225e-06\n",
      " loss = 2.6593603660058343e-06\n",
      " loss = 3.0487064753169945e-06\n",
      " loss = 2.2721839710373347e-06\n",
      " loss = 2.6409554540428516e-06\n",
      " loss = 3.0301365012575905e-06\n",
      " loss = 2.2539263302670286e-06\n",
      " loss = 2.2275055779754644e-06\n",
      " loss = 2.202039782606426e-06\n",
      " loss = 2.6118548226089893e-06\n",
      " loss = 2.605855092640035e-06\n",
      " loss = 3.032255650992027e-06\n",
      " loss = 2.5930783596398772e-06\n",
      " loss = 2.5871162921185486e-06\n",
      " loss = 2.1707972413925406e-06\n",
      " loss = 2.576040723487776e-06\n",
      " loss = 2.1417050335273662e-06\n",
      " loss = 2.118456547601132e-06\n",
      " loss = 3.0259061232160235e-06\n",
      " loss = 2.1095740148165263e-06\n",
      " loss = 2.549168749028975e-06\n",
      " loss = 3.0035842515091325e-06\n",
      " loss = 1.6569412253425364e-06\n",
      " loss = 2.5333346995663408e-06\n",
      " loss = 3.001987204762573e-06\n",
      " loss = 2.973512601417217e-06\n",
      " loss = 2.0795542069900816e-06\n",
      " loss = 2.5082547597386374e-06\n",
      " loss = 2.9517631994248373e-06\n",
      " loss = 2.924220207147232e-06\n",
      " loss = 2.4885660842908664e-06\n",
      " loss = 2.890784606720782e-06\n",
      " loss = 2.0882745446293908e-06\n",
      " loss = 2.8780070230071566e-06\n",
      " loss = 2.0781528784016904e-06\n",
      " loss = 2.0548632599233377e-06\n",
      " loss = 2.8784593169033563e-06\n",
      " loss = 2.448756382910538e-06\n",
      " loss = 2.4431310222477174e-06\n",
      " loss = 2.8390426649092425e-06\n",
      " loss = 2.431220593519842e-06\n",
      " loss = 2.4256283917458043e-06\n",
      " loss = 2.0389793372883997e-06\n",
      " loss = 3.2131907996062644e-06\n",
      " loss = 2.047172891314552e-06\n",
      " loss = 2.7829266885879166e-06\n",
      " loss = 2.3973992157475196e-06\n",
      " loss = 2.3918705836744682e-06\n",
      " loss = 2.0261308768918026e-06\n",
      " loss = 2.0029871554560017e-06\n",
      " loss = 2.37652275228475e-06\n",
      " loss = 1.976129440420037e-06\n",
      " loss = 1.954669163304776e-06\n",
      " loss = 2.362611296474132e-06\n",
      " loss = 2.3571653579711136e-06\n",
      " loss = 3.2028645772627174e-06\n",
      " loss = 1.955287245758197e-06\n",
      " loss = 2.745062424834327e-06\n",
      " loss = 2.3331222504969942e-06\n",
      " loss = 2.713547310966233e-06\n",
      " loss = 2.321706736554617e-06\n",
      " loss = 1.5830068491243638e-06\n",
      " loss = 2.7141609766575975e-06\n",
      " loss = 1.540884058029004e-06\n",
      " loss = 2.303396708353446e-06\n",
      " loss = 2.2980883599831544e-06\n",
      " loss = 2.2927927834390524e-06\n",
      " loss = 1.875072502589096e-06\n",
      " loss = 1.8556471458668392e-06\n",
      " loss = 2.280409594518042e-06\n",
      " loss = 1.833635021663755e-06\n",
      " loss = 1.8155641422692838e-06\n",
      " loss = 1.7981295227941564e-06\n",
      " loss = 2.751389582039243e-06\n",
      " loss = 2.723913633375338e-06\n",
      " loss = 1.8042204939464023e-06\n",
      " loss = 1.3257567400906593e-06\n",
      " loss = 2.7394150837462705e-06\n",
      " loss = 3.184042614407481e-06\n",
      " loss = 1.792967660539585e-06\n",
      " loss = 2.226537325600815e-06\n",
      " loss = 2.221317383017819e-06\n",
      " loss = 2.21611297367869e-06\n",
      " loss = 2.6552114779789317e-06\n",
      " loss = 2.6293612562853885e-06\n",
      " loss = 1.7894795145167013e-06\n",
      " loss = 2.6156434015344352e-06\n",
      " loss = 1.782704395734035e-06\n",
      " loss = 2.6020489882433226e-06\n",
      " loss = 2.1765396642559985e-06\n",
      " loss = 1.3733065854678105e-06\n",
      " loss = 1.3098600484491668e-06\n",
      " loss = 2.1696386700305985e-06\n",
      " loss = 1.7069618069687707e-06\n",
      " loss = 2.1620500577102143e-06\n",
      " loss = 1.6888917779609565e-06\n",
      " loss = 3.1164765303704976e-06\n",
      " loss = 2.590435389335701e-06\n",
      " loss = 1.7083256713438694e-06\n",
      " loss = 2.133834408738653e-06\n",
      " loss = 2.128804568254274e-06\n",
      " loss = 1.686587109447318e-06\n",
      " loss = 1.6707024112046973e-06\n",
      " loss = 2.1188649397725103e-06\n",
      " loss = 1.6531055345078728e-06\n",
      " loss = 1.638279448338974e-06\n",
      " loss = 1.6239667705825314e-06\n",
      " loss = 2.605367394839629e-06\n",
      " loss = 2.5782291005279504e-06\n",
      " loss = 3.0124070988286153e-06\n",
      " loss = 2.0810194393812592e-06\n",
      " loss = 2.0761251235583507e-06\n",
      " loss = 2.07124588369005e-06\n",
      " loss = 2.066381556234505e-06\n",
      " loss = 2.4799227790696662e-06\n",
      " loss = 2.4556844606310523e-06\n",
      " loss = 2.4320473881844513e-06\n",
      " loss = 2.408994484735429e-06\n",
      " loss = 2.0362230182253734e-06\n",
      " loss = 2.0315433841497425e-06\n",
      " loss = 1.678547540134644e-06\n",
      " loss = 2.385986222200591e-06\n",
      " loss = 2.0175495496427623e-06\n",
      " loss = 2.358141853769558e-06\n",
      " loss = 2.336491574206492e-06\n",
      " loss = 2.3153700456884323e-06\n",
      " loss = 1.9974285119529353e-06\n",
      " loss = 1.992818554242819e-06\n",
      " loss = 1.3940779569725296e-06\n",
      " loss = 1.9844567860902234e-06\n",
      " loss = 2.3065863229307327e-06\n",
      " loss = 1.3529422754642528e-06\n",
      " loss = 2.3121991438146623e-06\n",
      " loss = 1.6415475243420926e-06\n",
      " loss = 1.284725912301916e-06\n",
      " loss = 2.3280146660126755e-06\n",
      " loss = 1.954573890195711e-06\n",
      " loss = 2.6503795833553975e-06\n",
      " loss = 2.2632062745321445e-06\n",
      " loss = 1.634604571567741e-06\n",
      " loss = 1.9347380253e-06\n",
      " loss = 1.930293466502131e-06\n",
      " loss = 2.2429718160314997e-06\n",
      " loss = 2.2226641249100283e-06\n",
      " loss = 1.6295056798815658e-06\n",
      " loss = 2.2132601648478905e-06\n",
      " loss = 1.907337061702344e-06\n",
      " loss = 1.6169236034347419e-06\n",
      " loss = 1.8988502047301663e-06\n",
      " loss = 1.8944837661798298e-06\n",
      " loss = 2.189674382654103e-06\n",
      " loss = 2.170099399722092e-06\n",
      " loss = 2.1509991439718714e-06\n",
      " loss = 1.365814711734465e-06\n",
      " loss = 1.8723685234801372e-06\n",
      " loss = 1.2988578706650155e-06\n",
      " loss = 1.8647185918649523e-06\n",
      " loss = 1.2360824178651611e-06\n",
      " loss = 1.51856029543951e-06\n",
      " loss = 2.2074850131494863e-06\n",
      " loss = 2.523353749458497e-06\n",
      " loss = 1.5355021649174917e-06\n",
      " loss = 2.1609955387120805e-06\n",
      " loss = 1.8348438064312286e-06\n",
      " loss = 1.8306289534123193e-06\n",
      " loss = 2.435952406838621e-06\n",
      " loss = 1.8212756421574403e-06\n",
      " loss = 1.8170780161335138e-06\n",
      " loss = 2.3645489500901847e-06\n",
      " loss = 1.8087231856547424e-06\n",
      " loss = 1.3084874595293723e-06\n",
      " loss = 2.3525601717910718e-06\n",
      " loss = 1.2996463555591747e-06\n",
      " loss = 2.3442708373780737e-06\n",
      " loss = 1.787694699983313e-06\n",
      " loss = 1.7835412064877984e-06\n",
      " loss = 1.5306254142699056e-06\n",
      " loss = 2.3005872027104103e-06\n",
      " loss = 1.7713935654418202e-06\n",
      " loss = 1.5316139065554217e-06\n",
      " loss = 2.262312224230144e-06\n",
      " loss = 1.9820170595312713e-06\n",
      " loss = 1.965455168229978e-06\n",
      " loss = 1.5562634257823362e-06\n",
      " loss = 1.7476604634590216e-06\n",
      " loss = 1.9556068968411838e-06\n",
      " loss = 1.939436636700817e-06\n",
      " loss = 1.9236500171814876e-06\n",
      " loss = 1.7342308109456348e-06\n",
      " loss = 1.9054082583231915e-06\n",
      " loss = 1.564117854750518e-06\n",
      " loss = 1.7215189246997057e-06\n",
      " loss = 1.7173342046424466e-06\n",
      " loss = 1.351285224968892e-06\n",
      " loss = 1.7070651690473088e-06\n",
      " loss = 1.912841230503358e-06\n",
      " loss = 1.3054125949345117e-06\n",
      " loss = 1.6944230768024755e-06\n",
      " loss = 1.690463719092189e-06\n",
      " loss = 1.686515712276461e-06\n",
      " loss = 1.6825789544172602e-06\n",
      " loss = 1.4525313914443807e-06\n",
      " loss = 1.9139801727026836e-06\n",
      " loss = 1.4442479679097571e-06\n",
      " loss = 1.666765898678636e-06\n",
      " loss = 1.6629075545095471e-06\n",
      " loss = 2.1388269216662976e-06\n",
      " loss = 1.6556788093848666e-06\n",
      " loss = 1.8665549517524562e-06\n",
      " loss = 1.6484783580884572e-06\n",
      " loss = 1.644583717117021e-06\n",
      " loss = 1.6407016512940735e-06\n",
      " loss = 1.6368320096972785e-06\n",
      " loss = 1.632974645855247e-06\n",
      " loss = 1.4236194435980573e-06\n",
      " loss = 1.1873500140985614e-06\n",
      " loss = 1.6208867218422769e-06\n",
      " loss = 1.3731084703136987e-06\n",
      " loss = 1.6136940831175365e-06\n",
      " loss = 1.354104309388495e-06\n",
      " loss = 1.3390255385474686e-06\n",
      " loss = 1.324487857567885e-06\n",
      " loss = 1.8916514479822255e-06\n",
      " loss = 1.596431418408329e-06\n",
      " loss = 1.5927612017575553e-06\n",
      " loss = 1.313238994121161e-06\n",
      " loss = 1.8733985238692824e-06\n",
      " loss = 1.5817856192832896e-06\n",
      " loss = 1.5781495095402004e-06\n",
      " loss = 1.5745218387507187e-06\n",
      " loss = 1.8426036720786226e-06\n",
      " loss = 1.3075842910370692e-06\n",
      " loss = 1.5636784957899404e-06\n",
      " loss = 1.8296575614898296e-06\n",
      " loss = 1.8128154702256829e-06\n",
      " loss = 1.7963849798709744e-06\n",
      " loss = 1.54797757405483e-06\n",
      " loss = 1.544407218426336e-06\n",
      " loss = 2.0050523129319047e-06\n",
      " loss = 1.7456319985024334e-06\n",
      " loss = 1.7307620442826676e-06\n",
      " loss = 1.5311268083903703e-06\n",
      " loss = 1.8990973976140484e-06\n",
      " loss = 1.20050069298718e-06\n",
      " loss = 1.707761042185104e-06\n",
      " loss = 1.6935864015866977e-06\n",
      " loss = 1.51454922958826e-06\n",
      " loss = 1.8432867627877845e-06\n",
      " loss = 1.2228682349969545e-06\n",
      " loss = 1.8407023257579732e-06\n",
      " loss = 1.3562814133238335e-06\n",
      " loss = 1.1792163434249303e-06\n",
      " loss = 1.30832797978361e-06\n",
      " loss = 1.487909362538509e-06\n",
      " loss = 1.2882368761860279e-06\n",
      " loss = 1.48071546846243e-06\n",
      " loss = 1.685465257673685e-06\n",
      " loss = 1.6709401353400007e-06\n",
      " loss = 1.656763752309636e-06\n",
      " loss = 1.4681426952026492e-06\n",
      " loss = 1.6401394433820078e-06\n",
      " loss = 1.4619393585493089e-06\n",
      " loss = 1.2928799958408355e-06\n",
      " loss = 1.2763984099415712e-06\n",
      " loss = 1.45029280066335e-06\n",
      " loss = 1.6370521459253552e-06\n",
      " loss = 1.4439592528920223e-06\n",
      " loss = 1.4405536521312946e-06\n",
      " loss = 1.7978714846216357e-06\n",
      " loss = 1.5935703324938463e-06\n",
      " loss = 1.4326863288012962e-06\n",
      " loss = 1.5783201969731553e-06\n",
      " loss = 1.4268642145114748e-06\n",
      " loss = 1.4233566061654528e-06\n",
      " loss = 1.5612055254051825e-06\n",
      " loss = 1.417634681092356e-06\n",
      " loss = 1.5467489755995331e-06\n",
      " loss = 1.4120047658990836e-06\n",
      " loss = 1.532677388508591e-06\n",
      " loss = 1.5209175502931844e-06\n",
      " loss = 1.2997253110733095e-06\n",
      " loss = 1.1635412098400594e-06\n",
      " loss = 1.393103255008346e-06\n",
      " loss = 1.5324644725207705e-06\n",
      " loss = 1.3874629425906571e-06\n",
      " loss = 1.1158548895753663e-06\n",
      " loss = 1.378631372990999e-06\n",
      " loss = 1.3753352234720783e-06\n",
      " loss = 1.054640460047896e-06\n",
      " loss = 1.1868106601815521e-06\n",
      " loss = 1.364286001787516e-06\n",
      " loss = 1.5530600383540016e-06\n",
      " loss = 1.358149693581214e-06\n",
      " loss = 1.5367905614087444e-06\n",
      " loss = 1.523735174461085e-06\n",
      " loss = 1.5109919705214029e-06\n",
      " loss = 1.3470157629648779e-06\n",
      " loss = 1.343787990191036e-06\n",
      " loss = 1.1874577237245843e-06\n",
      " loss = 1.336720184137965e-06\n",
      " loss = 1.4984753710370472e-06\n",
      " loss = 1.175993387987838e-06\n",
      " loss = 9.94995429003596e-07\n",
      " loss = 1.698039672164636e-06\n",
      " loss = 1.1541150068303336e-06\n",
      " loss = 1.1399209279579122e-06\n",
      " loss = 1.3142889688197181e-06\n",
      " loss = 1.123144914583122e-06\n",
      " loss = 1.110014311126969e-06\n",
      " loss = 1.5135954315002357e-06\n",
      " loss = 1.5000381286511569e-06\n",
      " loss = 1.4868097841798054e-06\n",
      " loss = 1.2962416419527102e-06\n",
      " loss = 1.2932252340457455e-06\n",
      " loss = 1.4682542272361372e-06\n",
      " loss = 1.4556794544018253e-06\n",
      " loss = 1.2848639447615542e-06\n",
      " loss = 1.4408833135565978e-06\n",
      " loss = 1.129835531314949e-06\n",
      " loss = 1.2757668735756238e-06\n",
      " loss = 1.272763065755709e-06\n",
      " loss = 1.2697686206795726e-06\n",
      " loss = 1.105260613843647e-06\n",
      " loss = 9.199328666906462e-07\n",
      " loss = 1.2604722930859055e-06\n",
      " loss = 1.2575675277773893e-06\n",
      " loss = 1.0634548648632858e-06\n",
      " loss = 1.252024363049617e-06\n",
      " loss = 1.4494704895000722e-06\n",
      " loss = 1.2460148508244713e-06\n",
      " loss = 1.2431445035156283e-06\n",
      " loss = 1.4303863432685387e-06\n",
      " loss = 1.237322708225494e-06\n",
      " loss = 1.4148653958782382e-06\n",
      " loss = 1.2316647516104358e-06\n",
      " loss = 1.2288026567582104e-06\n",
      " loss = 1.3971060260070988e-06\n",
      " loss = 1.3850993481756084e-06\n",
      " loss = 1.373380718469438e-06\n",
      " loss = 1.2184401235618838e-06\n",
      " loss = 1.2155425860270728e-06\n",
      " loss = 1.0679561459399538e-06\n",
      " loss = 1.364043869840639e-06\n",
      " loss = 1.3526096202346092e-06\n",
      " loss = 1.0678596602598595e-06\n",
      " loss = 1.2011753390490966e-06\n",
      " loss = 1.3457637080872969e-06\n",
      " loss = 1.0575075062763068e-06\n",
      " loss = 1.3412066878582004e-06\n",
      " loss = 1.3300464017261311e-06\n",
      " loss = 1.3191513874397121e-06\n",
      " loss = 1.1861553529920996e-06\n",
      " loss = 1.3065338069365003e-06\n",
      " loss = 1.2961391043301842e-06\n",
      " loss = 1.285988149966683e-06\n",
      " loss = 9.812816567343612e-07\n",
      " loss = 1.1725634853449072e-06\n",
      " loss = 1.2889508514466087e-06\n",
      " loss = 1.2787470048693488e-06\n",
      " loss = 1.0633398755615356e-06\n",
      " loss = 1.2752255822151482e-06\n",
      " loss = 1.1602450210695838e-06\n",
      " loss = 9.450756047075866e-07\n",
      " loss = 9.014132681439576e-07\n",
      " loss = 1.1486360603615722e-06\n",
      " loss = 1.1459321269044651e-06\n",
      " loss = 1.288471010707711e-06\n",
      " loss = 1.1409915000266341e-06\n",
      " loss = 1.27551303375529e-06\n",
      " loss = 1.0073302450249998e-06\n",
      " loss = 1.2712678736329706e-06\n",
      " loss = 1.2607443338720397e-06\n",
      " loss = 1.2504705490201856e-06\n",
      " loss = 1.3540646868604242e-06\n",
      " loss = 1.2228221983901425e-06\n",
      " loss = 1.213490194391637e-06\n",
      " loss = 1.0418217648107106e-06\n",
      " loss = 1.1188086821694796e-06\n",
      " loss = 1.208997817560695e-06\n",
      " loss = 1.2851965558880764e-06\n",
      " loss = 1.1146122141974137e-06\n",
      " loss = 1.1116476998980595e-06\n",
      " loss = 1.253146639642734e-06\n",
      " loss = 1.0532759083411635e-06\n",
      " loss = 1.1712310747256321e-06\n",
      " loss = 1.1031969763878925e-06\n",
      " loss = 1.100202924715869e-06\n",
      " loss = 1.0340136759223978e-06\n",
      " loss = 1.018851981582238e-06\n",
      " loss = 1.1724402268700977e-06\n",
      " loss = 1.1636696140306821e-06\n",
      " loss = 1.155100602099742e-06\n",
      " loss = 1.0844034787512865e-06\n",
      " loss = 1.145534331009017e-06\n",
      " loss = 1.080319255948525e-06\n",
      " loss = 1.1361922508967354e-06\n",
      " loss = 1.0243945170497037e-06\n",
      " loss = 1.0715167742887054e-06\n",
      " loss = 1.0686410719869757e-06\n",
      " loss = 1.0657859088622653e-06\n",
      " loss = 1.0629507691471398e-06\n",
      " loss = 9.911469666610394e-07\n",
      " loss = 1.13493694506575e-06\n",
      " loss = 9.826478870335564e-07\n",
      " loss = 1.050438271537953e-06\n",
      " loss = 1.0477504541427342e-06\n",
      " loss = 9.606978828193626e-07\n",
      " loss = 1.1352238053581778e-06\n",
      " loss = 1.0397858391795455e-06\n",
      " loss = 9.493041120187834e-07\n",
      " loss = 8.390160049029451e-07\n",
      " loss = 1.0293406181377892e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 9.116915675960707e-07\n",
      " loss = 1.023873956981709e-06\n",
      " loss = 8.9714999930749e-07\n",
      " loss = 1.018675088453049e-06\n",
      " loss = 8.833061956849877e-07\n",
      " loss = 8.725841381527691e-07\n",
      " loss = 8.62251436601351e-07\n",
      " loss = 1.0090978735367673e-06\n",
      " loss = 1.1633975257534104e-06\n",
      " loss = 1.0043348641252596e-06\n",
      " loss = 1.002015942197901e-06\n",
      " loss = 8.510822806857222e-07\n",
      " loss = 8.412909363212619e-07\n",
      " loss = 1.159146383139181e-06\n",
      " loss = 9.929333321668475e-07\n",
      " loss = 1.146167224951148e-06\n",
      " loss = 9.882235589946278e-07\n",
      " loss = 8.382885310020773e-07\n",
      " loss = 9.838156529849272e-07\n",
      " loss = 1.1364719645684832e-06\n",
      " loss = 8.319448988051474e-07\n",
      " loss = 1.131642115052472e-06\n",
      " loss = 9.746191965505735e-07\n",
      " loss = 9.72371945532213e-07\n",
      " loss = 1.116847607976784e-06\n",
      " loss = 9.67849607129256e-07\n",
      " loss = 1.1047991469250772e-06\n",
      " loss = 1.0952131854188612e-06\n",
      " loss = 9.614152007551819e-07\n",
      " loss = 8.344419080217203e-07\n",
      " loss = 1.0891520301881594e-06\n",
      " loss = 1.0798154875573203e-06\n",
      " loss = 1.0707027754939144e-06\n",
      " loss = 9.509133514070233e-07\n",
      " loss = 1.0600368214283842e-06\n",
      " loss = 8.424900883098324e-07\n",
      " loss = 1.0565862228907644e-06\n",
      " loss = 7.313392996098273e-07\n",
      " loss = 9.392572201817164e-07\n",
      " loss = 8.159171420747368e-07\n",
      " loss = 1.0633412466493026e-06\n",
      " loss = 8.110883790081787e-07\n",
      " loss = 8.0122865376617e-07\n",
      " loss = 9.280911491774193e-07\n",
      " loss = 1.0622845838678548e-06\n",
      " loss = 7.946562439877429e-07\n",
      " loss = 9.216611465790935e-07\n",
      " loss = 9.195330035294325e-07\n",
      " loss = 7.81104888605629e-07\n",
      " loss = 9.15409532720579e-07\n",
      " loss = 9.133035511032659e-07\n",
      " loss = 7.68281429907181e-07\n",
      " loss = 7.596684563562411e-07\n",
      " loss = 7.513648523986685e-07\n",
      " loss = 9.060534031811737e-07\n",
      " loss = 9.039665934624152e-07\n",
      " loss = 7.403063534424246e-07\n",
      " loss = 7.326060032794692e-07\n",
      " loss = 7.251791504787763e-07\n",
      " loss = 8.977938460365585e-07\n",
      " loss = 8.956944990568052e-07\n",
      " loss = 8.936012192762361e-07\n",
      " loss = 8.915139508958634e-07\n",
      " loss = 8.894326396523894e-07\n",
      " loss = 7.119311046710463e-07\n",
      " loss = 1.0673401543217966e-06\n",
      " loss = 7.095435425107244e-07\n",
      " loss = 5.232171971400629e-07\n",
      " loss = 1.0734827175349454e-06\n",
      " loss = 8.788161073823641e-07\n",
      " loss = 6.938715591902086e-07\n",
      " loss = 8.757148544107377e-07\n",
      " loss = 6.864230055603197e-07\n",
      " loss = 8.726791249514963e-07\n",
      " loss = 6.792620638701179e-07\n",
      " loss = 1.0661873339439271e-06\n",
      " loss = 4.885811366550387e-07\n",
      " loss = 8.667808260625993e-07\n",
      " loss = 1.0636948228538267e-06\n",
      " loss = 8.61278377451813e-07\n",
      " loss = 6.68939933205682e-07\n",
      " loss = 6.63027909535205e-07\n",
      " loss = 1.2580912437674116e-06\n",
      " loss = 1.0394744781499535e-06\n",
      " loss = 8.498555100915893e-07\n",
      " loss = 8.478423614331009e-07\n",
      " loss = 1.0229821116640327e-06\n",
      " loss = 8.429178620445683e-07\n",
      " loss = 8.409439259773484e-07\n",
      " loss = 8.389757907324171e-07\n",
      " loss = 8.370134003929476e-07\n",
      " loss = 1.0016259900808958e-06\n",
      " loss = 6.727930383928539e-07\n",
      " loss = 9.962175532110591e-07\n",
      " loss = 8.284796246603198e-07\n",
      " loss = 8.26558926118718e-07\n",
      " loss = 9.813720809170137e-07\n",
      " loss = 9.720206618111986e-07\n",
      " loss = 8.197329302605404e-07\n",
      " loss = 8.178479812296242e-07\n",
      " loss = 6.736663591167339e-07\n",
      " loss = 8.145698038895792e-07\n",
      " loss = 9.601836871192467e-07\n",
      " loss = 8.103423274256811e-07\n",
      " loss = 9.48909051318978e-07\n",
      " loss = 6.723605730473023e-07\n",
      " loss = 6.650469673342585e-07\n",
      " loss = 8.033716724706955e-07\n",
      " loss = 8.015202544557096e-07\n",
      " loss = 9.440198647456376e-07\n",
      " loss = 7.973761376944804e-07\n",
      " loss = 7.955433407881304e-07\n",
      " loss = 5.196598095949984e-07\n",
      " loss = 6.442623290525334e-07\n",
      " loss = 6.377562842696259e-07\n",
      " loss = 1.1088195214341942e-06\n",
      " loss = 7.873557039868084e-07\n",
      " loss = 6.395352009556252e-07\n",
      " loss = 9.356438190403177e-07\n",
      " loss = 7.819008595771343e-07\n",
      " loss = 6.358810510333535e-07\n",
      " loss = 9.283928361967036e-07\n",
      " loss = 9.195133047510573e-07\n",
      " loss = 9.108528813741113e-07\n",
      " loss = 6.416669516698244e-07\n",
      " loss = 7.706394362358132e-07\n",
      " loss = 7.688665474026362e-07\n",
      " loss = 9.021247746618819e-07\n",
      " loss = 7.649585956085838e-07\n",
      " loss = 7.63201303437596e-07\n",
      " loss = 7.614480511824565e-07\n",
      " loss = 7.596988294542007e-07\n",
      " loss = 6.304135839367777e-07\n",
      " loss = 7.565744423731999e-07\n",
      " loss = 7.548342091549141e-07\n",
      " loss = 8.852371731410745e-07\n",
      " loss = 7.51005714758389e-07\n",
      " loss = 7.492805231592754e-07\n",
      " loss = 6.221299910501425e-07\n",
      " loss = 8.769839177905988e-07\n",
      " loss = 6.19373410584616e-07\n",
      " loss = 7.427597867349052e-07\n",
      " loss = 7.410516169709363e-07\n",
      " loss = 6.100566664196826e-07\n",
      " loss = 6.03615752054957e-07\n",
      " loss = 8.764363530509707e-07\n",
      " loss = 7.346786352838034e-07\n",
      " loss = 8.659217362920425e-07\n",
      " loss = 8.578121359460521e-07\n",
      " loss = 4.867793938147463e-07\n",
      " loss = 5.961046654733409e-07\n",
      " loss = 7.267548601949054e-07\n",
      " loss = 7.250731058055773e-07\n",
      " loss = 7.233956287956755e-07\n",
      " loss = 5.865879964340931e-07\n",
      " loss = 8.606226078060897e-07\n",
      " loss = 7.183793997705892e-07\n",
      " loss = 7.167189231472611e-07\n",
      " loss = 8.479729667024226e-07\n",
      " loss = 7.129353457739602e-07\n",
      " loss = 7.112942013553743e-07\n",
      " loss = 5.834756501382589e-07\n",
      " loss = 9.706926671526725e-07\n",
      " loss = 5.860636946913987e-07\n",
      " loss = 4.5478930918758735e-07\n",
      " loss = 8.392892644574855e-07\n",
      " loss = 5.72619570108654e-07\n",
      " loss = 5.66769796880363e-07\n",
      " loss = 6.998508380311437e-07\n",
      " loss = 6.982177545021556e-07\n",
      " loss = 8.339822963735522e-07\n",
      " loss = 8.259218903005919e-07\n",
      " loss = 4.406190502664822e-07\n",
      " loss = 6.91731409352073e-07\n",
      " loss = 9.603162823197612e-07\n",
      " loss = 6.874391315617074e-07\n",
      " loss = 8.096002356756342e-07\n",
      " loss = 8.020323563884174e-07\n",
      " loss = 7.946501549332554e-07\n",
      " loss = 5.730571309035698e-07\n",
      " loss = 6.788839250061116e-07\n",
      " loss = 9.013061224066808e-07\n",
      " loss = 6.754521259235609e-07\n",
      " loss = 6.738942522504447e-07\n",
      " loss = 6.723401685117221e-07\n",
      " loss = 7.72030231575035e-07\n",
      " loss = 6.692164665301467e-07\n",
      " loss = 6.676669036735574e-07\n",
      " loss = 6.661213138875148e-07\n",
      " loss = 5.685055483703513e-07\n",
      " loss = 7.642769727148356e-07\n",
      " loss = 5.654833186402763e-07\n",
      " loss = 5.589067208491142e-07\n",
      " loss = 6.586375788085946e-07\n",
      " loss = 7.630070495106538e-07\n",
      " loss = 6.554676838876986e-07\n",
      " loss = 7.545414329743258e-07\n",
      " loss = 8.433295126798161e-07\n",
      " loss = 5.656331873801559e-07\n",
      " loss = 7.399910574655783e-07\n",
      " loss = 7.336327039239717e-07\n",
      " loss = 5.658865732732642e-07\n",
      " loss = 6.449433656272779e-07\n",
      " loss = 5.572536025779701e-07\n",
      " loss = 5.505503513450274e-07\n",
      " loss = 6.40372927201385e-07\n",
      " loss = 6.388961011504287e-07\n",
      " loss = 5.412587457772569e-07\n",
      " loss = 6.360604570640063e-07\n",
      " loss = 7.354297458518699e-07\n",
      " loss = 4.41370599462699e-07\n",
      " loss = 8.427619182002317e-07\n",
      " loss = 6.300892508213219e-07\n",
      " loss = 7.241466354137976e-07\n",
      " loss = 7.177602571926197e-07\n",
      " loss = 7.973084892403278e-07\n",
      " loss = 7.007962155493513e-07\n",
      " loss = 6.234541398952158e-07\n",
      " loss = 6.219651728517175e-07\n",
      " loss = 5.482577947999982e-07\n",
      " loss = 5.413239048195257e-07\n",
      " loss = 5.346431381721732e-07\n",
      " loss = 7.02923656632263e-07\n",
      " loss = 6.968532414814073e-07\n",
      " loss = 7.689225984264959e-07\n",
      " loss = 5.434175290647257e-07\n",
      " loss = 5.364636929729174e-07\n",
      " loss = 6.874183725384655e-07\n",
      " loss = 5.331093507256441e-07\n",
      " loss = 7.642381217063279e-07\n",
      " loss = 6.047783396995336e-07\n",
      " loss = 7.439394109870535e-07\n",
      " loss = 6.638121567996164e-07\n",
      " loss = 6.585630745066369e-07\n",
      " loss = 6.534368448236472e-07\n",
      " loss = 6.484299956078773e-07\n",
      " loss = 5.991571154952135e-07\n",
      " loss = 5.976104498159137e-07\n",
      " loss = 5.50164340834089e-07\n",
      " loss = 6.452665942535491e-07\n",
      " loss = 5.930300873786656e-07\n",
      " loss = 5.915189337435912e-07\n",
      " loss = 5.413219856368245e-07\n",
      " loss = 5.879043331008578e-07\n",
      " loss = 5.864441116696859e-07\n",
      " loss = 5.298067900138676e-07\n",
      " loss = 5.227001229136922e-07\n",
      " loss = 5.812449366993133e-07\n",
      " loss = 6.455877294433642e-07\n",
      " loss = 6.403454912312215e-07\n",
      " loss = 5.778680399840011e-07\n",
      " loss = 4.607711506227677e-07\n",
      " loss = 6.41676041433717e-07\n",
      " loss = 5.732334438538428e-07\n",
      " loss = 5.718550446402548e-07\n",
      " loss = 6.343862392624574e-07\n",
      " loss = 5.694875234367281e-07\n",
      " loss = 5.68106316956414e-07\n",
      " loss = 5.667307392729224e-07\n",
      " loss = 5.653606948591312e-07\n",
      " loss = 5.026344107177423e-07\n",
      " loss = 6.28475835074505e-07\n",
      " loss = 6.233240722652933e-07\n",
      " loss = 5.603176071167137e-07\n",
      " loss = 5.589552315678785e-07\n",
      " loss = 5.575985166695763e-07\n",
      " loss = 6.746801968752217e-07\n",
      " loss = 5.558148415367867e-07\n",
      " loss = 5.030678690155639e-07\n",
      " loss = 4.400041046936611e-07\n",
      " loss = 5.505267190962615e-07\n",
      " loss = 4.835300511489313e-07\n",
      " loss = 5.477038048220932e-07\n",
      " loss = 4.7601383034166795e-07\n",
      " loss = 4.7020198601175107e-07\n",
      " loss = 4.6460135115373753e-07\n",
      " loss = 4.592035854846058e-07\n",
      " loss = 3.66645093695622e-07\n",
      " loss = 5.405659760051837e-07\n",
      " loss = 7.29572385819555e-07\n",
      " loss = 6.242842803144611e-07\n",
      " loss = 3.7143798255578356e-07\n",
      " loss = 5.353290475356591e-07\n",
      " loss = 4.4380341612440785e-07\n",
      " loss = 4.390240237107662e-07\n",
      " loss = 6.300668554048726e-07\n",
      " loss = 5.306788629200967e-07\n",
      " loss = 4.362948841126627e-07\n",
      " loss = 4.317058300846687e-07\n",
      " loss = 6.281981705634158e-07\n",
      " loss = 6.222085476374749e-07\n",
      " loss = 5.245906177823662e-07\n",
      " loss = 6.148794581647095e-07\n",
      " loss = 4.3467646309519105e-07\n",
      " loss = 5.209766454463625e-07\n",
      " loss = 5.197786639276769e-07\n",
      " loss = 5.18583475981912e-07\n",
      " loss = 5.173910737902283e-07\n",
      " loss = 4.262853383674556e-07\n",
      " loss = 3.282326665743085e-07\n",
      " loss = 5.149276896793725e-07\n",
      " loss = 4.132707964859454e-07\n",
      " loss = 5.13027311841943e-07\n",
      " loss = 4.0854725940309715e-07\n",
      " loss = 4.0463772992574705e-07\n",
      " loss = 6.20289155301057e-07\n",
      " loss = 5.087565597431795e-07\n",
      " loss = 5.075574508782618e-07\n",
      " loss = 2.9796230182918007e-07\n",
      " loss = 5.063919731156103e-07\n",
      " loss = 5.051765560055429e-07\n",
      " loss = 5.039656855999633e-07\n",
      " loss = 6.118494876541977e-07\n",
      " loss = 5.009437263474457e-07\n",
      " loss = 4.997597891231918e-07\n",
      " loss = 3.949674150074941e-07\n",
      " loss = 3.91276176192109e-07\n",
      " loss = 4.974512496915207e-07\n",
      " loss = 6.053152787195526e-07\n",
      " loss = 3.896621756753309e-07\n",
      " loss = 4.938790822787077e-07\n",
      " loss = 4.92695881308481e-07\n",
      " loss = 4.91517036252713e-07\n",
      " loss = 7.020843557708324e-07\n",
      " loss = 3.899985751174642e-07\n",
      " loss = 3.862539615462945e-07\n",
      " loss = 4.868519329186615e-07\n",
      " loss = 3.8208691106138106e-07\n",
      " loss = 4.851592605191128e-07\n",
      " loss = 3.780813162509578e-07\n",
      " loss = 5.922963217664467e-07\n",
      " loss = 5.862552243913758e-07\n",
      " loss = 3.7948888209727786e-07\n",
      " loss = 4.793715971486541e-07\n",
      " loss = 5.810263120873652e-07\n",
      " loss = 5.752135461026267e-07\n",
      " loss = 4.7490103913227294e-07\n",
      " loss = 5.679730416132293e-07\n",
      " loss = 4.7226136056261806e-07\n",
      " loss = 5.609819094819729e-07\n",
      " loss = 3.838118921492893e-07\n",
      " loss = 5.580959439196949e-07\n",
      " loss = 4.6755114288205627e-07\n",
      " loss = 5.513879017001278e-07\n",
      " loss = 4.651194718427925e-07\n",
      " loss = 4.640500221591464e-07\n",
      " loss = 3.017606878017328e-07\n",
      " loss = 5.498641282336211e-07\n",
      " loss = 5.446369940367064e-07\n",
      " loss = 4.597831293665742e-07\n",
      " loss = 3.7920439259520773e-07\n",
      " loss = 5.40684563037972e-07\n",
      " loss = 4.5661498920109844e-07\n",
      " loss = 4.555654018514931e-07\n",
      " loss = 4.5451824876171e-07\n",
      " loss = 3.751427725548411e-07\n",
      " loss = 4.5268379175328407e-07\n",
      " loss = 3.703945552112578e-07\n",
      " loss = 5.352673353149801e-07\n",
      " loss = 4.49557606100617e-07\n",
      " loss = 3.6815965753292127e-07\n",
      " loss = 4.477905207581594e-07\n",
      " loss = 4.467555615408506e-07\n",
      " loss = 4.457231927469149e-07\n",
      " loss = 3.622203827899868e-07\n",
      " loss = 3.585363005544005e-07\n",
      " loss = 4.4338699419400676e-07\n",
      " loss = 4.4235113844332824e-07\n",
      " loss = 5.288610990016989e-07\n",
      " loss = 3.560547597852869e-07\n",
      " loss = 6.127834014083833e-07\n",
      " loss = 3.57716344806171e-07\n",
      " loss = 3.5403809742031484e-07\n",
      " loss = 4.3619741056486253e-07\n",
      " loss = 5.204849793888573e-07\n",
      " loss = 4.337998793724923e-07\n",
      " loss = 4.32796031551578e-07\n",
      " loss = 4.3179473721578737e-07\n",
      " loss = 4.30795982174928e-07\n",
      " loss = 4.2979975255106947e-07\n",
      " loss = 3.4878863124091703e-07\n",
      " loss = 4.281593342309839e-07\n",
      " loss = 5.922238051928538e-07\n",
      " loss = 5.771090293857431e-07\n",
      " loss = 3.5507050847110845e-07\n",
      " loss = 4.955550372724833e-07\n",
      " loss = 4.22223390996495e-07\n",
      " loss = 3.525964992145113e-07\n",
      " loss = 4.2044707007578234e-07\n",
      " loss = 5.62547963383645e-07\n",
      " loss = 3.5326965852592235e-07\n",
      " loss = 3.4929018769611165e-07\n",
      " loss = 4.877199222413564e-07\n",
      " loss = 3.4768182261553206e-07\n",
      " loss = 4.854798852656726e-07\n",
      " loss = 3.460809392618708e-07\n",
      " loss = 4.127649797088302e-07\n",
      " loss = 3.415211458470782e-07\n",
      " loss = 2.646422819972297e-07\n",
      " loss = 5.690384561422058e-07\n",
      " loss = 3.3651030705522516e-07\n",
      " loss = 4.840095101101492e-07\n",
      " loss = 3.351410543254168e-07\n",
      " loss = 4.0661457774042897e-07\n",
      " loss = 4.056758782875604e-07\n",
      " loss = 4.047394918422812e-07\n",
      " loss = 3.2967492219406687e-07\n",
      " loss = 4.800535516211859e-07\n",
      " loss = 2.548706811889941e-07\n",
      " loss = 4.809368516624062e-07\n",
      " loss = 5.522040536054828e-07\n",
      " loss = 4.685092539153224e-07\n",
      " loss = 3.9780678237446126e-07\n",
      " loss = 3.9689297342635e-07\n",
      " loss = 3.9598126365846664e-07\n",
      " loss = 3.291593755818952e-07\n",
      " loss = 3.943427515945812e-07\n",
      " loss = 3.2488814183675513e-07\n",
      " loss = 3.2145040169543044e-07\n",
      " loss = 2.441341818459924e-07\n",
      " loss = 3.9193705599949735e-07\n",
      " loss = 4.70150479455167e-07\n",
      " loss = 2.3805781452224818e-07\n",
      " loss = 3.896054331547822e-07\n",
      " loss = 2.2703092389487345e-07\n",
      " loss = 5.609289232705566e-07\n",
      " loss = 3.069466049716276e-07\n",
      " loss = 3.863718582985594e-07\n",
      " loss = 2.2178237597435789e-07\n",
      " loss = 2.985468238623076e-07\n",
      " loss = 3.8519926407969274e-07\n",
      " loss = 5.615375728054912e-07\n",
      " loss = 3.822321666876161e-07\n",
      " loss = 3.81320027372533e-07\n",
      " loss = 3.804111304398293e-07\n",
      " loss = 3.795054298640467e-07\n",
      " loss = 4.591794141062092e-07\n",
      " loss = 4.546045131011935e-07\n",
      " loss = 3.018624674542129e-07\n",
      " loss = 4.5207609537855224e-07\n",
      " loss = 3.008447476122914e-07\n",
      " loss = 3.737394220627054e-07\n",
      " loss = 5.237574699659468e-07\n",
      " loss = 4.408552367339962e-07\n",
      " loss = 3.702057436105386e-07\n",
      " loss = 4.355959500351686e-07\n",
      " loss = 4.3153292584720566e-07\n",
      " loss = 2.46768188859156e-07\n",
      " loss = 4.3251900468603676e-07\n",
      " loss = 3.657574517048376e-07\n",
      " loss = 3.6491694186732255e-07\n",
      " loss = 3.640783736570182e-07\n",
      " loss = 3.010291986110357e-07\n",
      " loss = 4.2738829306688746e-07\n",
      " loss = 4.234071956380155e-07\n",
      " loss = 3.6059566372819955e-07\n",
      " loss = 3.5976721402158484e-07\n",
      " loss = 3.589406714145137e-07\n",
      " loss = 4.1669051819337617e-07\n",
      " loss = 3.0146992994996817e-07\n",
      " loss = 2.9808118912449156e-07\n",
      " loss = 3.5579199177663165e-07\n",
      " loss = 4.157846650878211e-07\n",
      " loss = 4.1196884804023015e-07\n",
      " loss = 2.979676677214532e-07\n",
      " loss = 2.946197941661264e-07\n",
      " loss = 3.5171869525111806e-07\n",
      " loss = 4.1107049066052595e-07\n",
      " loss = 2.9262589715015383e-07\n",
      " loss = 3.4929698673503657e-07\n",
      " loss = 2.8878114091552967e-07\n",
      " loss = 4.7224663665560666e-07\n",
      " loss = 2.9002561823501463e-07\n",
      " loss = 3.4608850695330094e-07\n",
      " loss = 3.452932346047097e-07\n",
      " loss = 4.6234239418645816e-07\n",
      " loss = 3.4347702977498837e-07\n",
      " loss = 3.4268666244819644e-07\n",
      " loss = 2.8849677613974855e-07\n",
      " loss = 3.412014079855776e-07\n",
      " loss = 2.2875581630324768e-07\n",
      " loss = 4.0083543251015257e-07\n",
      " loss = 2.8087190742858325e-07\n",
      " loss = 2.1735547233004937e-07\n",
      " loss = 3.381012781699526e-07\n",
      " loss = 4.024156863866596e-07\n",
      " loss = 3.3626539449671955e-07\n",
      " loss = 4.5959011816767563e-07\n",
      " loss = 2.775520242393344e-07\n",
      " loss = 2.154188301321457e-07\n",
      " loss = 2.6944418071479774e-07\n",
      " loss = 4.6530751288874594e-07\n",
      " loss = 3.925237574816156e-07\n",
      " loss = 2.72455513947968e-07\n",
      " loss = 2.090942411369546e-07\n",
      " loss = 3.9506872816463197e-07\n",
      " loss = 4.5369488784904754e-07\n",
      " loss = 2.1307234050266332e-07\n",
      " loss = 3.8929258029416226e-07\n",
      " loss = 3.855870546967349e-07\n",
      " loss = 4.386163919447257e-07\n",
      " loss = 3.2432716615629456e-07\n",
      " loss = 3.750492559154431e-07\n",
      " loss = 3.2277762393798003e-07\n",
      " loss = 3.709123567613041e-07\n",
      " loss = 2.749050995499241e-07\n",
      " loss = 3.205469180438818e-07\n",
      " loss = 2.2219562667812595e-07\n",
      " loss = 3.1924038830332644e-07\n",
      " loss = 2.649831048216124e-07\n",
      " loss = 3.179262160425909e-07\n",
      " loss = 3.171949836192995e-07\n",
      " loss = 3.1646546185630984e-07\n",
      " loss = 3.710272082753138e-07\n",
      " loss = 3.14862464523308e-07\n",
      " loss = 3.6674655833826243e-07\n",
      " loss = 2.632173472782305e-07\n",
      " loss = 4.174941792177772e-07\n",
      " loss = 3.1180558309019985e-07\n",
      " loss = 3.110871646261426e-07\n",
      " loss = 4.0524272203391125e-07\n",
      " loss = 3.0964957250637547e-07\n",
      " loss = 2.6626098634136e-07\n",
      " loss = 2.6309756198989147e-07\n",
      " loss = 3.549668822995543e-07\n",
      " loss = 3.518206902961009e-07\n",
      " loss = 3.060700096872617e-07\n",
      " loss = 3.4807251774738454e-07\n",
      " loss = 3.450795068414921e-07\n",
      " loss = 2.659901325318458e-07\n",
      " loss = 3.0327069467293916e-07\n",
      " loss = 3.0256284107068677e-07\n",
      " loss = 3.0185699036779723e-07\n",
      " loss = 2.604091404415099e-07\n",
      " loss = 3.0041855230863183e-07\n",
      " loss = 2.5658380796573183e-07\n",
      " loss = 2.5358848892587753e-07\n",
      " loss = 2.507013721712642e-07\n",
      " loss = 3.477257563340783e-07\n",
      " loss = 2.4951603393561246e-07\n",
      " loss = 2.4674698481341286e-07\n",
      " loss = 2.4407725167550955e-07\n",
      " loss = 2.9540724449731494e-07\n",
      " loss = 2.9472597189713345e-07\n",
      " loss = 2.940463546796942e-07\n",
      " loss = 2.400537003782087e-07\n",
      " loss = 2.9290236422050267e-07\n",
      " loss = 2.922242747466048e-07\n",
      " loss = 3.4641212218422666e-07\n",
      " loss = 2.906675511068271e-07\n",
      " loss = 3.422691307383205e-07\n",
      " loss = 3.889754923809738e-07\n",
      " loss = 2.429132596271365e-07\n",
      " loss = 3.3522604348585663e-07\n",
      " loss = 1.9651898520478063e-07\n",
      " loss = 1.8743984060469642e-07\n",
      " loss = 2.8620570932715194e-07\n",
      " loss = 2.8554366698086676e-07\n",
      " loss = 2.8488329996712157e-07\n",
      " loss = 3.9034901733580365e-07\n",
      " loss = 2.832173599044886e-07\n",
      " loss = 1.856656902150233e-07\n",
      " loss = 3.348388431711356e-07\n",
      " loss = 2.8141321058171277e-07\n",
      " loss = 2.8076530919341137e-07\n",
      " loss = 2.3019724124678083e-07\n",
      " loss = 2.2779492307464864e-07\n",
      " loss = 2.792303679622021e-07\n",
      " loss = 2.2506788681782566e-07\n",
      " loss = 2.7818665587023024e-07\n",
      " loss = 2.7753701772080885e-07\n",
      " loss = 2.220726899116889e-07\n",
      " loss = 3.3312701426291764e-07\n",
      " loss = 3.298599272275012e-07\n",
      " loss = 2.2275667276186226e-07\n",
      " loss = 2.205211144023148e-07\n",
      " loss = 3.850913856618918e-07\n",
      " loss = 3.2403215466273494e-07\n",
      " loss = 2.2300077819498157e-07\n",
      " loss = 2.715399829688165e-07\n",
      " loss = 2.7091203041913174e-07\n",
      " loss = 2.198441032423179e-07\n",
      " loss = 3.2213873953909976e-07\n",
      " loss = 3.1904723366770004e-07\n",
      " loss = 2.682337254917322e-07\n",
      " loss = 3.152552759977826e-07\n",
      " loss = 2.6686003788507523e-07\n",
      " loss = 2.6624688975991474e-07\n",
      " loss = 3.108569193274072e-07\n",
      " loss = 2.2183483973840542e-07\n",
      " loss = 3.0943348937201813e-07\n",
      " loss = 3.0659972722886774e-07\n",
      " loss = 2.630327036020667e-07\n",
      " loss = 2.6242729717797326e-07\n",
      " loss = 3.4324082627801975e-07\n",
      " loss = 2.2454615774420883e-07\n",
      " loss = 2.992635990783674e-07\n",
      " loss = 2.2331505750566475e-07\n",
      " loss = 2.5937449088947e-07\n",
      " loss = 2.2010433234827614e-07\n",
      " loss = 2.988535620105922e-07\n",
      " loss = 2.57581904633964e-07\n",
      " loss = 2.955727365642439e-07\n",
      " loss = 2.9297572357316175e-07\n",
      " loss = 1.8658243308374036e-07\n",
      " loss = 3.3244516724646635e-07\n",
      " loss = 2.1995631176219066e-07\n",
      " loss = 2.540076428317581e-07\n",
      " loss = 2.1673552494625673e-07\n",
      " loss = 2.9148560958075875e-07\n",
      " loss = 2.5224761486207967e-07\n",
      " loss = 2.1500154522958394e-07\n",
      " loss = 2.8969795882998224e-07\n",
      " loss = 2.505007587832043e-07\n",
      " loss = 2.132929048584013e-07\n",
      " loss = 2.4936714681231353e-07\n",
      " loss = 2.4879308125552623e-07\n",
      " loss = 2.8668067506544974e-07\n",
      " loss = 2.1110604954034953e-07\n",
      " loss = 2.4707604982994615e-07\n",
      " loss = 2.465074328006163e-07\n",
      " loss = 2.459401574412719e-07\n",
      " loss = 2.071037789298607e-07\n",
      " loss = 1.6467769963285077e-07\n",
      " loss = 2.445365514043359e-07\n",
      " loss = 2.8755885361485167e-07\n",
      " loss = 3.26479649866255e-07\n",
      " loss = 2.0476532707217673e-07\n",
      " loss = 2.420632870858611e-07\n",
      " loss = 2.0198587796365644e-07\n",
      " loss = 2.8232464246522825e-07\n",
      " loss = 2.4039679959811547e-07\n",
      " loss = 2.398445113588353e-07\n",
      " loss = 2.7847174175973984e-07\n",
      " loss = 2.7595530589795213e-07\n",
      " loss = 2.380983653690467e-07\n",
      " loss = 2.375487966063483e-07\n",
      " loss = 2.3700057870862395e-07\n",
      " loss = 2.3645370559837208e-07\n",
      " loss = 2.7124554180133295e-07\n",
      " loss = 2.3535931019374846e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss = 2.348139092778518e-07\n",
      " loss = 2.0074131878099376e-07\n",
      " loss = 2.6907692824586264e-07\n",
      " loss = 3.0022976502425657e-07\n",
      " loss = 1.728661417052475e-07\n",
      " loss = 2.657030076246732e-07\n",
      " loss = 2.315744252765101e-07\n",
      " loss = 2.3103570415772306e-07\n",
      " loss = 2.3049844816842145e-07\n",
      " loss = 2.618765223287846e-07\n",
      " loss = 1.6914709415221497e-07\n",
      " loss = 1.9510676399945834e-07\n",
      " loss = 2.639004831131096e-07\n",
      " loss = 2.2782391638395024e-07\n",
      " loss = 2.6101839715902996e-07\n",
      " loss = 2.2677450464579337e-07\n",
      " loss = 2.5822565684408e-07\n",
      " loss = 1.9550858449941828e-07\n",
      " loss = 2.251968705061229e-07\n",
      " loss = 2.2467498894654182e-07\n",
      " loss = 2.56217839235879e-07\n",
      " loss = 1.9331586721315518e-07\n",
      " loss = 2.2311397997665315e-07\n",
      " loss = 2.2259751794949825e-07\n",
      " loss = 2.2208237493120925e-07\n",
      " loss = 1.894438260156322e-07\n",
      " loss = 2.2107015702682839e-07\n",
      " loss = 1.867609040610191e-07\n",
      " loss = 1.846429828158146e-07\n",
      " loss = 2.196706088121039e-07\n",
      " loss = 1.8218955886794985e-07\n",
      " loss = 2.1876888338552383e-07\n",
      " loss = 1.7984395199670294e-07\n",
      " loss = 1.7795278327207989e-07\n",
      " loss = 1.7612889826414545e-07\n",
      " loss = 1.7436964235814085e-07\n",
      " loss = 1.7267246609891145e-07\n",
      " loss = 1.710349210244084e-07\n",
      " loss = 2.1643814589482315e-07\n",
      " loss = 1.2251524930726976e-07\n",
      " loss = 3.1515735175365635e-07\n",
      " loss = 2.148803263947014e-07\n",
      " loss = 1.6852092284440623e-07\n",
      " loss = 2.141345003270073e-07\n",
      " loss = 2.604805100234261e-07\n",
      " loss = 2.1283735439778602e-07\n",
      " loss = 2.1233268318950646e-07\n",
      " loss = 2.5633868013326815e-07\n",
      " loss = 2.537980863291146e-07\n",
      " loss = 2.513207223346174e-07\n",
      " loss = 2.0973749897768233e-07\n",
      " loss = 2.0925263156081195e-07\n",
      " loss = 2.4762380524983155e-07\n",
      " loss = 2.4528262974247387e-07\n",
      " loss = 1.366735130037886e-07\n",
      " loss = 2.4580545876072727e-07\n",
      " loss = 2.0670763879050685e-07\n",
      " loss = 2.428862737179413e-07\n",
      " loss = 2.0565016120147197e-07\n",
      " loss = 2.40063614888131e-07\n",
      " loss = 1.713898828741196e-07\n",
      " loss = 2.389657248040222e-07\n",
      " loss = 2.3677821292796145e-07\n",
      " loss = 2.3464408450445103e-07\n",
      " loss = 2.32561825356758e-07\n",
      " loss = 1.739002744690449e-07\n",
      " loss = 2.316355593176394e-07\n",
      " loss = 1.4461313336438818e-07\n",
      " loss = 2.322812329708105e-07\n",
      " loss = 1.4059774413231208e-07\n",
      " loss = 1.9995962048993015e-07\n",
      " loss = 2.3235912683065885e-07\n",
      " loss = 2.3025516978650487e-07\n",
      " loss = 1.687917807541845e-07\n",
      " loss = 1.9806828504177005e-07\n",
      " loss = 1.664441320665074e-07\n",
      " loss = 1.6458343337923515e-07\n",
      " loss = 1.627895420382475e-07\n",
      " loss = 1.6105982123548215e-07\n",
      " loss = 2.3298524938655587e-07\n",
      " loss = 1.9559845402148804e-07\n",
      " loss = 1.9514790224232528e-07\n",
      " loss = 1.9469842713268552e-07\n",
      " loss = 1.594353636602362e-07\n",
      " loss = 2.662450860949733e-07\n",
      " loss = 1.6014683927480166e-07\n",
      " loss = 1.584351413102796e-07\n",
      " loss = 1.567844940597317e-07\n",
      " loss = 2.2940267007989366e-07\n",
      " loss = 1.561936742348999e-07\n",
      " loss = 2.2820720905974408e-07\n",
      " loss = 2.6123405026164725e-07\n",
      " loss = 1.5794346227747273e-07\n",
      " loss = 1.8980896385324834e-07\n",
      " loss = 1.559157014308634e-07\n",
      " loss = 1.542797862505624e-07\n",
      " loss = 1.8876186337888523e-07\n",
      " loss = 1.52420325489386e-07\n",
      " loss = 1.88052467835172e-07\n",
      " loss = 1.8761393332682364e-07\n",
      " loss = 1.8717662668692376e-07\n",
      " loss = 1.8674053767922074e-07\n",
      " loss = 1.4985053563583356e-07\n",
      " loss = 1.860516767584956e-07\n",
      " loss = 1.1066206982791323e-07\n",
      " loss = 1.4557625333553876e-07\n",
      " loss = 2.2655198570537095e-07\n",
      " loss = 2.2425489980183484e-07\n",
      " loss = 2.599704480278983e-07\n",
      " loss = 1.8327117266897057e-07\n",
      " loss = 2.177265156106089e-07\n",
      " loss = 1.8228483035144883e-07\n",
      " loss = 2.1510417670317978e-07\n",
      " loss = 1.813340863460811e-07\n",
      " loss = 1.4926470267724216e-07\n",
      " loss = 1.4768923643242247e-07\n",
      " loss = 1.4616985411710682e-07\n",
      " loss = 1.447043429411888e-07\n",
      " loss = 1.798163146388904e-07\n",
      " loss = 1.793945002939472e-07\n",
      " loss = 2.5127834055599833e-07\n",
      " loss = 1.1160666894621832e-07\n",
      " loss = 1.781346430573371e-07\n",
      " loss = 1.4205555034012719e-07\n",
      " loss = 1.774891075445912e-07\n",
      " loss = 2.5027026678747276e-07\n",
      " loss = 1.7630828686402286e-07\n",
      " loss = 2.0953896745075612e-07\n",
      " loss = 2.3971756721275217e-07\n",
      " loss = 2.041781914105922e-07\n",
      " loss = 2.0231558250760883e-07\n",
      " loss = 1.472132840088693e-07\n",
      " loss = 1.734920151256787e-07\n",
      " loss = 2.0099210530595446e-07\n",
      " loss = 1.7265689353150432e-07\n",
      " loss = 1.9876179042162886e-07\n",
      " loss = 1.215364655254842e-07\n",
      " loss = 1.9929271643521218e-07\n",
      " loss = 1.4463663467047557e-07\n",
      " loss = 1.707133494725492e-07\n",
      " loss = 1.4266308476387647e-07\n",
      " loss = 1.1219117852566571e-07\n",
      " loss = 1.384026476720562e-07\n",
      " loss = 2.0208088281698211e-07\n",
      " loss = 2.0014799421424232e-07\n",
      " loss = 1.3876633455894326e-07\n",
      " loss = 1.6823209757237447e-07\n",
      " loss = 1.6784384989445693e-07\n",
      " loss = 1.3676703324719085e-07\n",
      " loss = 1.6719482034810994e-07\n",
      " loss = 1.668073332658148e-07\n",
      " loss = 1.6642085135689735e-07\n",
      " loss = 1.6603536844253877e-07\n"
     ]
    }
   ],
   "source": [
    "rg=reg_NN()\n",
    "rg.mini_batch_gredient_desent(regx_scaled,regy_scaled,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9ec7b804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rg.epoch_track,rg.cost_track)\n",
    "plt.title(\"Mini Batch Gredient Descent\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d61ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
